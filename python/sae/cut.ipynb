{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 10) (315, 10) (315, 10) (315,) (315,) (315,)\n",
      "(630, 10)\n",
      "(630,)\n",
      "(315, 10)\n",
      "(315,)\n",
      "(630, 10) (315, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "import struct\n",
    "np.random.seed(2018)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Input\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "import keras\n",
    "%matplotlib inline\n",
    "xfile1=\".\\\\data\\\\C1_feature_denoise.csv\"\n",
    "yfile1=\".\\\\data\\\\c1_wear_new.csv\"\n",
    "\n",
    "xfile2=\".\\\\data\\\\C4_feature_denoise.csv\"\n",
    "yfile2=\".\\\\data\\\\c4_wear_new.csv\"\n",
    "\n",
    "xfile3=\".\\\\data\\\\C6_feature_denoise.csv\"\n",
    "yfile3=\".\\\\data\\\\c6_wear_new.csv\"\n",
    "\n",
    "\n",
    "x1=pandas.read_csv(xfile1).values;\n",
    "x2=pandas.read_csv(xfile2).values;\n",
    "x3=pandas.read_csv(xfile3).values;\n",
    "y1=pandas.read_csv(yfile1).values[:,-1];\n",
    "y2=pandas.read_csv(yfile2).values[:,-1];\n",
    "y3=pandas.read_csv(yfile3).values[:,4];\n",
    "\n",
    "print(x1.shape,x2.shape,x3.shape,y1.shape,y2.shape,y3.shape);\n",
    "X_train=np.vstack((x1,x2))\n",
    "y_train=np.hstack((y1,y2))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test=x3;\n",
    "y_test=y3;\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "X_train=X_train.astype('float32')/255-0.5 # minmax_normalized(归一化在（-0.5,0.5）)之间\n",
    "X_test=X_test.astype('float32')/255-0.5 # minmax_normalized\n",
    "X_train_len=X_train.shape[0]\n",
    "X_test_len=X_test.shape[0]\n",
    "\n",
    "X_train=X_train.reshape((X_train_len,-1))\n",
    "X_test=X_test.reshape((X_test_len,-1))\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch': [], 'epoch': []}\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        #创建一个图\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')#plt.plot(x,y)，这个将数据画成曲线\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)#设置网格形式\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')#给x，y轴加注释\n",
    "        plt.legend(loc=\"upper right\")#设置图例显示位置\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 1840462548.8254\n",
      "Epoch 2/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 1624502670.9841\n",
      "Epoch 3/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 1454499120.7619\n",
      "Epoch 4/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 1292059533.2063\n",
      "Epoch 5/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 1129876419.0476\n",
      "Epoch 6/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 1003795710.4762\n",
      "Epoch 7/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 876318293.3333\n",
      "Epoch 8/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 771306502.6032\n",
      "Epoch 9/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 686530343.1111\n",
      "Epoch 10/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 579989943.6190\n",
      "Epoch 11/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 517631732.0635\n",
      "Epoch 12/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 442689214.9841\n",
      "Epoch 13/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 381690050.0317\n",
      "Epoch 14/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 338086470.8571\n",
      "Epoch 15/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 288007188.4127\n",
      "Epoch 16/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 249084224.0000\n",
      "Epoch 17/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 215073678.0317\n",
      "Epoch 18/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 184384560.3810\n",
      "Epoch 19/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 158134683.6825\n",
      "Epoch 20/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134243278.6667\n",
      "Epoch 21/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 111322528.5079\n",
      "Epoch 22/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 95492815.0476\n",
      "Epoch 23/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 76813319.8730\n",
      "Epoch 24/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 63403297.0714\n",
      "Epoch 25/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 52137059.0000\n",
      "Epoch 26/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 42113209.9683\n",
      "Epoch 27/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 34810503.2857\n",
      "Epoch 28/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 28568357.2222\n",
      "Epoch 29/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 22400539.1359\n",
      "Epoch 30/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 18539239.6230\n",
      "Epoch 31/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 14869523.2857\n",
      "Epoch 32/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 11997583.5556\n",
      "Epoch 33/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 9459055.5476\n",
      "Epoch 34/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 7608196.1736\n",
      "Epoch 35/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 5787564.2847\n",
      "Epoch 36/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 4427828.9206\n",
      "Epoch 37/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 3416778.2302\n",
      "Epoch 38/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 2732172.2261\n",
      "Epoch 39/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 1958650.1562\n",
      "Epoch 40/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 1420801.5134\n",
      "Epoch 41/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 1066218.3824\n",
      "Epoch 42/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 762298.0744\n",
      "Epoch 43/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 535049.8814\n",
      "Epoch 44/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 429220.3765\n",
      "Epoch 45/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 324197.1324\n",
      "Epoch 46/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 264168.1920\n",
      "Epoch 47/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 225547.9350\n",
      "Epoch 48/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 196851.4557\n",
      "Epoch 49/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 177378.9172\n",
      "Epoch 50/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 169481.2991\n",
      "Epoch 51/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 162107.4967\n",
      "Epoch 52/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 152598.5073\n",
      "Epoch 53/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 151709.1075\n",
      "Epoch 54/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 150903.6222\n",
      "Epoch 55/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 147730.3605\n",
      "Epoch 56/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 146366.4545\n",
      "Epoch 57/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 145150.7282\n",
      "Epoch 58/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140178.9649\n",
      "Epoch 59/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145210.3325\n",
      "Epoch 60/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143106.7176\n",
      "Epoch 61/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137953.3485\n",
      "Epoch 62/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145422.8773\n",
      "Epoch 63/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141889.3250\n",
      "Epoch 64/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138245.5176\n",
      "Epoch 65/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143391.4328\n",
      "Epoch 66/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144889.2019\n",
      "Epoch 67/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 145188.7158\n",
      "Epoch 68/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138779.4642\n",
      "Epoch 69/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145244.0492\n",
      "Epoch 70/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142186.8806\n",
      "Epoch 71/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138661.0546\n",
      "Epoch 72/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143354.5758\n",
      "Epoch 73/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141835.5156\n",
      "Epoch 74/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 144148.7839\n",
      "Epoch 75/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141192.0795\n",
      "Epoch 76/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144546.7007\n",
      "Epoch 77/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144265.5336\n",
      "Epoch 78/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141841.4276\n",
      "Epoch 79/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141640.2908\n",
      "Epoch 80/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141733.0911\n",
      "Epoch 81/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141022.7290\n",
      "Epoch 82/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141108.9050\n",
      "Epoch 83/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143817.8326\n",
      "Epoch 84/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145048.8167\n",
      "Epoch 85/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145577.3137\n",
      "Epoch 86/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143687.4254\n",
      "Epoch 87/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135593.8321\n",
      "Epoch 88/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140895.6673\n",
      "Epoch 89/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140459.7769\n",
      "Epoch 90/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144396.1279\n",
      "Epoch 91/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 33us/step - loss: 143490.7183\n",
      "Epoch 92/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139745.6587\n",
      "Epoch 93/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141405.3669\n",
      "Epoch 94/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142355.9049\n",
      "Epoch 95/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144134.5773\n",
      "Epoch 96/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 144298.8883\n",
      "Epoch 97/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140647.6820\n",
      "Epoch 98/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139102.7001\n",
      "Epoch 99/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 136552.3996\n",
      "Epoch 100/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144328.1775\n",
      "Epoch 101/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140828.6205\n",
      "Epoch 102/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142886.0595\n",
      "Epoch 103/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142442.3418\n",
      "Epoch 104/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 144206.4215\n",
      "Epoch 105/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143351.4025\n",
      "Epoch 106/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142845.6636\n",
      "Epoch 107/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139035.2481\n",
      "Epoch 108/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141894.8039\n",
      "Epoch 109/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141424.5908\n",
      "Epoch 110/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144185.4489\n",
      "Epoch 111/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141847.6941\n",
      "Epoch 112/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137932.0728\n",
      "Epoch 113/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142886.1594\n",
      "Epoch 114/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 145287.7774\n",
      "Epoch 115/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143160.9461\n",
      "Epoch 116/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139084.3997\n",
      "Epoch 117/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144161.6737\n",
      "Epoch 118/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142244.5978\n",
      "Epoch 119/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 140453.4831\n",
      "Epoch 120/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139068.8576\n",
      "Epoch 121/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143916.1975\n",
      "Epoch 122/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144417.0834\n",
      "Epoch 123/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143860.4911\n",
      "Epoch 124/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139721.1380\n",
      "Epoch 125/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137897.4645\n",
      "Epoch 126/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142135.9053\n",
      "Epoch 127/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144122.4276\n",
      "Epoch 128/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143878.6612\n",
      "Epoch 129/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143552.1031\n",
      "Epoch 130/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 141874.2146\n",
      "Epoch 131/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142253.5420\n",
      "Epoch 132/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144856.3447\n",
      "Epoch 133/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143720.0899\n",
      "Epoch 134/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141217.9079\n",
      "Epoch 135/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139620.0986\n",
      "Epoch 136/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140245.4365\n",
      "Epoch 137/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144521.2094\n",
      "Epoch 138/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 143742.0698\n",
      "Epoch 139/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140856.7594\n",
      "Epoch 140/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144084.9508\n",
      "Epoch 141/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143044.3158\n",
      "Epoch 142/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142319.0822\n",
      "Epoch 143/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139816.1648\n",
      "Epoch 144/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142632.3019\n",
      "Epoch 145/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136956.8560\n",
      "Epoch 146/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138976.7465\n",
      "Epoch 147/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142975.1920\n",
      "Epoch 148/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145448.3947\n",
      "Epoch 149/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140789.5888\n",
      "Epoch 150/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 144363.9482\n",
      "Epoch 151/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139215.0797\n",
      "Epoch 152/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142810.5763\n",
      "Epoch 153/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142827.5475\n",
      "Epoch 154/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143730.6753\n",
      "Epoch 155/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 139962.3513\n",
      "Epoch 156/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 140307.5082\n",
      "Epoch 157/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140557.7388\n",
      "Epoch 158/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139920.0051\n",
      "Epoch 159/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140618.2245\n",
      "Epoch 160/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141590.4531\n",
      "Epoch 161/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138233.8609\n",
      "Epoch 162/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 141969.6716\n",
      "Epoch 163/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 136631.2202\n",
      "Epoch 164/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143844.7542\n",
      "Epoch 165/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142392.2007\n",
      "Epoch 166/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 145529.2928\n",
      "Epoch 167/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145288.2625\n",
      "Epoch 168/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 144735.5227\n",
      "Epoch 169/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143778.7501\n",
      "Epoch 170/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141185.0180\n",
      "Epoch 171/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143393.4495\n",
      "Epoch 172/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138194.2881\n",
      "Epoch 173/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143635.2010\n",
      "Epoch 174/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139135.3487\n",
      "Epoch 175/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 150979.7636\n",
      "Epoch 176/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 156539.7922\n",
      "Epoch 177/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 159797.3947\n",
      "Epoch 178/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 150097.6302\n",
      "Epoch 179/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143964.8705\n",
      "Epoch 180/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 147792.5576\n",
      "Epoch 181/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 33us/step - loss: 141513.5311\n",
      "Epoch 182/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142796.5967\n",
      "Epoch 183/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143468.8244\n",
      "Epoch 184/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137288.7423\n",
      "Epoch 185/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136494.6104\n",
      "Epoch 186/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 148123.5474\n",
      "Epoch 187/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 140879.7362\n",
      "Epoch 188/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144397.4715\n",
      "Epoch 189/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 146747.2024\n",
      "Epoch 190/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144942.4405\n",
      "Epoch 191/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143829.0626\n",
      "Epoch 192/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142326.1332\n",
      "Epoch 193/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142526.4158\n",
      "Epoch 194/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139688.8316\n",
      "Epoch 195/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143747.0673\n",
      "Epoch 196/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142431.8848\n",
      "Epoch 197/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139435.0673\n",
      "Epoch 198/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142804.9361\n",
      "Epoch 199/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144185.4035\n",
      "Epoch 200/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 140787.0505\n",
      "Epoch 201/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143733.9598\n",
      "Epoch 202/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142495.6618\n",
      "Epoch 203/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 138737.2912\n",
      "Epoch 204/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144024.3818\n",
      "Epoch 205/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139713.2264\n",
      "Epoch 206/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139443.5965\n",
      "Epoch 207/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 143818.9564\n",
      "Epoch 208/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142841.3935\n",
      "Epoch 209/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143945.2624\n",
      "Epoch 210/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141882.6426\n",
      "Epoch 211/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141204.9651\n",
      "Epoch 212/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143948.6740\n",
      "Epoch 213/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142351.0495\n",
      "Epoch 214/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143845.1073\n",
      "Epoch 215/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140427.0372\n",
      "Epoch 216/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143163.7042\n",
      "Epoch 217/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144197.1445\n",
      "Epoch 218/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134620.5496\n",
      "Epoch 219/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141476.4333\n",
      "Epoch 220/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139770.6443\n",
      "Epoch 221/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142281.1912\n",
      "Epoch 222/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143686.0527\n",
      "Epoch 223/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143620.0680\n",
      "Epoch 224/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139900.0915\n",
      "Epoch 225/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141242.0770\n",
      "Epoch 226/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138384.1508\n",
      "Epoch 227/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 143130.3967\n",
      "Epoch 228/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139750.2148\n",
      "Epoch 229/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135258.9614\n",
      "Epoch 230/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142615.8707\n",
      "Epoch 231/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140558.6217\n",
      "Epoch 232/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138844.7964\n",
      "Epoch 233/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138048.6391\n",
      "Epoch 234/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141811.3472\n",
      "Epoch 235/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143337.8663\n",
      "Epoch 236/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 135251.5172\n",
      "Epoch 237/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141829.2483\n",
      "Epoch 238/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142189.8690\n",
      "Epoch 239/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139494.6766\n",
      "Epoch 240/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 144643.7348\n",
      "Epoch 241/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142665.3139\n",
      "Epoch 242/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143759.0677\n",
      "Epoch 243/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141310.8126\n",
      "Epoch 244/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141099.0881\n",
      "Epoch 245/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141544.7059\n",
      "Epoch 246/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142835.5442\n",
      "Epoch 247/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142779.2867\n",
      "Epoch 248/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143072.5690\n",
      "Epoch 249/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143512.8691\n",
      "Epoch 250/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141625.4464\n",
      "Epoch 251/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 141952.0833\n",
      "Epoch 252/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 143736.5066\n",
      "Epoch 253/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 137043.3247\n",
      "Epoch 254/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142803.0222\n",
      "Epoch 255/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141373.5399\n",
      "Epoch 256/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138283.0775\n",
      "Epoch 257/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140770.8165\n",
      "Epoch 258/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139516.4252\n",
      "Epoch 259/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 139605.5093\n",
      "Epoch 260/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140676.1864\n",
      "Epoch 261/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142472.4579\n",
      "Epoch 262/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142591.1900\n",
      "Epoch 263/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143852.6220\n",
      "Epoch 264/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140217.7447\n",
      "Epoch 265/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 144076.1000\n",
      "Epoch 266/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141110.2769\n",
      "Epoch 267/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142667.7581\n",
      "Epoch 268/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142473.1620\n",
      "Epoch 269/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140330.9168\n",
      "Epoch 270/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142088.1687\n",
      "Epoch 271/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 35us/step - loss: 138171.1193\n",
      "Epoch 272/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144566.2793\n",
      "Epoch 273/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139762.2361\n",
      "Epoch 274/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142283.7493\n",
      "Epoch 275/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143228.4669\n",
      "Epoch 276/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 138870.2319\n",
      "Epoch 277/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138955.1719\n",
      "Epoch 278/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133819.3645\n",
      "Epoch 279/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144766.0560\n",
      "Epoch 280/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142833.8650\n",
      "Epoch 281/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142635.5009\n",
      "Epoch 282/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 140537.7830\n",
      "Epoch 283/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 144876.2640\n",
      "Epoch 284/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143381.9933\n",
      "Epoch 285/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139978.5356\n",
      "Epoch 286/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142488.6993\n",
      "Epoch 287/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143398.0629\n",
      "Epoch 288/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143897.7232\n",
      "Epoch 289/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139267.5016\n",
      "Epoch 290/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138217.6372\n",
      "Epoch 291/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142121.4420\n",
      "Epoch 292/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142706.1293\n",
      "Epoch 293/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139075.2148\n",
      "Epoch 294/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136727.9836\n",
      "Epoch 295/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 138848.5378\n",
      "Epoch 296/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 143542.4204\n",
      "Epoch 297/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140311.9010\n",
      "Epoch 298/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139459.0807\n",
      "Epoch 299/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131716.9554\n",
      "Epoch 300/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145447.9260\n",
      "Epoch 301/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144998.7056\n",
      "Epoch 302/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141485.5661\n",
      "Epoch 303/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140089.8318\n",
      "Epoch 304/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138613.8212\n",
      "Epoch 305/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142353.5617\n",
      "Epoch 306/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142618.3514\n",
      "Epoch 307/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141331.1210\n",
      "Epoch 308/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142825.2581\n",
      "Epoch 309/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136695.9294\n",
      "Epoch 310/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138228.5107\n",
      "Epoch 311/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139964.9855\n",
      "Epoch 312/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139679.3336\n",
      "Epoch 313/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144130.6457\n",
      "Epoch 314/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143184.2600\n",
      "Epoch 315/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140813.3870\n",
      "Epoch 316/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139001.2806\n",
      "Epoch 317/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137999.3597\n",
      "Epoch 318/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137561.2576\n",
      "Epoch 319/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 140575.3318\n",
      "Epoch 320/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139407.0051\n",
      "Epoch 321/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140549.0397\n",
      "Epoch 322/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141809.3248\n",
      "Epoch 323/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 139152.8782\n",
      "Epoch 324/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143223.0880\n",
      "Epoch 325/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139894.0394\n",
      "Epoch 326/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142943.4637\n",
      "Epoch 327/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140911.4042\n",
      "Epoch 328/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134056.4405\n",
      "Epoch 329/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136239.6719\n",
      "Epoch 330/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142884.1549\n",
      "Epoch 331/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138292.6052\n",
      "Epoch 332/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 135905.6525\n",
      "Epoch 333/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 138595.1286\n",
      "Epoch 334/1000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 132390.0429\n",
      "Epoch 335/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 142416.7197\n",
      "Epoch 336/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142912.1029\n",
      "Epoch 337/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 143239.3045\n",
      "Epoch 338/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 143455.7192\n",
      "Epoch 339/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141672.6399\n",
      "Epoch 340/1000\n",
      "630/630 [==============================] - 0s 27us/step - loss: 139858.7513\n",
      "Epoch 341/1000\n",
      "630/630 [==============================] - 0s 29us/step - loss: 142897.9290\n",
      "Epoch 342/1000\n",
      "630/630 [==============================] - 0s 29us/step - loss: 137122.9258\n",
      "Epoch 343/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139587.8754\n",
      "Epoch 344/1000\n",
      "630/630 [==============================] - 0s 39us/step - loss: 140868.4426\n",
      "Epoch 345/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 139863.2235\n",
      "Epoch 346/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 143615.4518\n",
      "Epoch 347/1000\n",
      "630/630 [==============================] - 0s 31us/step - loss: 135485.6218\n",
      "Epoch 348/1000\n",
      "630/630 [==============================] - 0s 27us/step - loss: 143963.7409\n",
      "Epoch 349/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144335.6631\n",
      "Epoch 350/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137321.8622\n",
      "Epoch 351/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 140494.1340\n",
      "Epoch 352/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 142403.5643\n",
      "Epoch 353/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 140668.1423\n",
      "Epoch 354/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 143335.0918\n",
      "Epoch 355/1000\n",
      "630/630 [==============================] - 0s 27us/step - loss: 143151.2699\n",
      "Epoch 356/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 139023.3500\n",
      "Epoch 357/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142038.9031\n",
      "Epoch 358/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 140960.0208\n",
      "Epoch 359/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 140431.9828\n",
      "Epoch 360/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 139261.8426\n",
      "Epoch 361/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 28us/step - loss: 138984.1987\n",
      "Epoch 362/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 137589.6438\n",
      "Epoch 363/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 140476.8305\n",
      "Epoch 364/1000\n",
      "630/630 [==============================] - 0s 29us/step - loss: 141564.7785\n",
      "Epoch 365/1000\n",
      "630/630 [==============================] - 0s 27us/step - loss: 138068.7980\n",
      "Epoch 366/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 140589.2155\n",
      "Epoch 367/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 140670.0758\n",
      "Epoch 368/1000\n",
      "630/630 [==============================] - 0s 30us/step - loss: 140782.2603\n",
      "Epoch 369/1000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 141904.9082\n",
      "Epoch 370/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 142766.3148\n",
      "Epoch 371/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 144035.0788\n",
      "Epoch 372/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 141368.0828\n",
      "Epoch 373/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 138165.9680\n",
      "Epoch 374/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 141436.4857\n",
      "Epoch 375/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 141192.5674\n",
      "Epoch 376/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 141709.1062\n",
      "Epoch 377/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134693.4231\n",
      "Epoch 378/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140809.5351\n",
      "Epoch 379/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142211.8073\n",
      "Epoch 380/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142246.1042\n",
      "Epoch 381/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139117.5969\n",
      "Epoch 382/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138996.6023\n",
      "Epoch 383/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137862.5463\n",
      "Epoch 384/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138669.2292\n",
      "Epoch 385/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 139679.3122\n",
      "Epoch 386/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 142429.7487\n",
      "Epoch 387/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140256.1848\n",
      "Epoch 388/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142637.6601\n",
      "Epoch 389/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139441.0453\n",
      "Epoch 390/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140974.9158\n",
      "Epoch 391/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138073.7750\n",
      "Epoch 392/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141478.2904\n",
      "Epoch 393/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141723.5908\n",
      "Epoch 394/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138866.4272\n",
      "Epoch 395/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139613.1189\n",
      "Epoch 396/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 136665.2351\n",
      "Epoch 397/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139288.7184\n",
      "Epoch 398/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 137195.9793\n",
      "Epoch 399/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 126924.8787\n",
      "Epoch 400/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144921.0844\n",
      "Epoch 401/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140914.5053\n",
      "Epoch 402/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138656.0670\n",
      "Epoch 403/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144045.3676\n",
      "Epoch 404/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 163675.7873\n",
      "Epoch 405/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 157572.5815\n",
      "Epoch 406/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 146003.4675\n",
      "Epoch 407/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140776.0299\n",
      "Epoch 408/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 138385.2556\n",
      "Epoch 409/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141031.3682\n",
      "Epoch 410/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140202.3062\n",
      "Epoch 411/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 145689.2298\n",
      "Epoch 412/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138319.1510\n",
      "Epoch 413/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141023.8163\n",
      "Epoch 414/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 143275.0055\n",
      "Epoch 415/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139931.9573\n",
      "Epoch 416/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 137154.4407\n",
      "Epoch 417/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140191.6946\n",
      "Epoch 418/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 146010.5278\n",
      "Epoch 419/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141098.5285\n",
      "Epoch 420/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141947.1286\n",
      "Epoch 421/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142796.4111\n",
      "Epoch 422/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134491.5635\n",
      "Epoch 423/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137686.1130\n",
      "Epoch 424/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139812.9774\n",
      "Epoch 425/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139601.5471\n",
      "Epoch 426/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136453.1546\n",
      "Epoch 427/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138251.1290\n",
      "Epoch 428/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142685.4386\n",
      "Epoch 429/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140810.7342\n",
      "Epoch 430/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 141385.2529\n",
      "Epoch 431/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132912.4797\n",
      "Epoch 432/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 141001.8872\n",
      "Epoch 433/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141650.3282\n",
      "Epoch 434/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 140987.2182\n",
      "Epoch 435/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137967.0725\n",
      "Epoch 436/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136973.1173\n",
      "Epoch 437/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140720.1607\n",
      "Epoch 438/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140431.0704\n",
      "Epoch 439/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138355.4625\n",
      "Epoch 440/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140713.2220\n",
      "Epoch 441/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140474.8925\n",
      "Epoch 442/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139772.7504\n",
      "Epoch 443/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 137877.8147\n",
      "Epoch 444/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 139932.0799\n",
      "Epoch 445/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141087.6615\n",
      "Epoch 446/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139755.2793\n",
      "Epoch 447/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133154.6176\n",
      "Epoch 448/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142481.0350\n",
      "Epoch 449/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142179.2881\n",
      "Epoch 450/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 143969.4820\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 35us/step - loss: 147962.6176\n",
      "Epoch 452/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 150388.0474\n",
      "Epoch 453/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141251.4308\n",
      "Epoch 454/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138638.9380\n",
      "Epoch 455/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143371.4679\n",
      "Epoch 456/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139846.0205\n",
      "Epoch 457/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137169.8357\n",
      "Epoch 458/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135461.9878\n",
      "Epoch 459/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 140177.1708\n",
      "Epoch 460/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139538.1889\n",
      "Epoch 461/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141519.4318\n",
      "Epoch 462/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138099.2679\n",
      "Epoch 463/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141160.5335\n",
      "Epoch 464/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135124.6576\n",
      "Epoch 465/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138434.4101\n",
      "Epoch 466/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142036.0652\n",
      "Epoch 467/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142198.5491\n",
      "Epoch 468/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135151.5383\n",
      "Epoch 469/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141350.7861\n",
      "Epoch 470/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138000.2279\n",
      "Epoch 471/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142561.5791\n",
      "Epoch 472/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142182.4876\n",
      "Epoch 473/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 141182.6482\n",
      "Epoch 474/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 136482.5335\n",
      "Epoch 475/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 137667.5976\n",
      "Epoch 476/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140913.2575\n",
      "Epoch 477/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141397.6658\n",
      "Epoch 478/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136986.7189\n",
      "Epoch 479/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140434.3953\n",
      "Epoch 480/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137512.1912\n",
      "Epoch 481/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136158.6291\n",
      "Epoch 482/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131741.0652\n",
      "Epoch 483/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 150056.6447\n",
      "Epoch 484/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144917.3046\n",
      "Epoch 485/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144463.5417\n",
      "Epoch 486/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 146052.5768\n",
      "Epoch 487/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137363.9012\n",
      "Epoch 488/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 141736.3792\n",
      "Epoch 489/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134946.3953\n",
      "Epoch 490/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142922.9772\n",
      "Epoch 491/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139512.3371\n",
      "Epoch 492/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144735.4665\n",
      "Epoch 493/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 150214.6654\n",
      "Epoch 494/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139560.3667\n",
      "Epoch 495/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136702.2418\n",
      "Epoch 496/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144673.3597\n",
      "Epoch 497/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 151833.2502\n",
      "Epoch 498/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143147.0874\n",
      "Epoch 499/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 145135.2614\n",
      "Epoch 500/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142391.9402\n",
      "Epoch 501/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139629.1840\n",
      "Epoch 502/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 143411.2048\n",
      "Epoch 503/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140191.9726\n",
      "Epoch 504/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139510.5643\n",
      "Epoch 505/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140720.9904\n",
      "Epoch 506/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140515.1069\n",
      "Epoch 507/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 136929.3363\n",
      "Epoch 508/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132670.4275\n",
      "Epoch 509/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141430.1903\n",
      "Epoch 510/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140099.0726\n",
      "Epoch 511/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139890.4689\n",
      "Epoch 512/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138734.1925\n",
      "Epoch 513/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134965.3811\n",
      "Epoch 514/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138471.6364\n",
      "Epoch 515/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137300.2729\n",
      "Epoch 516/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134763.1058\n",
      "Epoch 517/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139980.5986\n",
      "Epoch 518/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 136608.7430\n",
      "Epoch 519/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 136342.0181\n",
      "Epoch 520/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133963.4183\n",
      "Epoch 521/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 137238.5572\n",
      "Epoch 522/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139638.3379\n",
      "Epoch 523/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 136901.2142\n",
      "Epoch 524/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139308.2297\n",
      "Epoch 525/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137140.7328\n",
      "Epoch 526/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137711.9718\n",
      "Epoch 527/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135124.3044\n",
      "Epoch 528/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134856.0694\n",
      "Epoch 529/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132438.1815\n",
      "Epoch 530/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136992.9090\n",
      "Epoch 531/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 136317.7917\n",
      "Epoch 532/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 138621.9659\n",
      "Epoch 533/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133660.7361\n",
      "Epoch 534/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134216.3785\n",
      "Epoch 535/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135582.1334\n",
      "Epoch 536/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140044.6410\n",
      "Epoch 537/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140601.3232\n",
      "Epoch 538/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 135460.4963\n",
      "Epoch 539/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139029.3559\n",
      "Epoch 540/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137922.2798\n",
      "Epoch 541/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 36us/step - loss: 139041.3832\n",
      "Epoch 542/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139660.3418\n",
      "Epoch 543/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134516.9375\n",
      "Epoch 544/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139803.1966\n",
      "Epoch 545/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141193.6516\n",
      "Epoch 546/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133426.3981\n",
      "Epoch 547/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137921.1905\n",
      "Epoch 548/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141636.4940\n",
      "Epoch 549/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141292.7778\n",
      "Epoch 550/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135461.1912\n",
      "Epoch 551/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139361.4380\n",
      "Epoch 552/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138928.2535\n",
      "Epoch 553/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138093.3890\n",
      "Epoch 554/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142489.8899\n",
      "Epoch 555/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144483.4722\n",
      "Epoch 556/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 144279.6264\n",
      "Epoch 557/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138641.2948\n",
      "Epoch 558/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 142302.6438\n",
      "Epoch 559/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142377.7300\n",
      "Epoch 560/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142470.1512\n",
      "Epoch 561/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135013.7102\n",
      "Epoch 562/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 138286.0224\n",
      "Epoch 563/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 136976.6770\n",
      "Epoch 564/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139081.7995\n",
      "Epoch 565/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140366.3867\n",
      "Epoch 566/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138465.9949\n",
      "Epoch 567/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137045.9375\n",
      "Epoch 568/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134928.7344\n",
      "Epoch 569/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136381.7765\n",
      "Epoch 570/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139624.8141\n",
      "Epoch 571/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136968.5838\n",
      "Epoch 572/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 136481.1165\n",
      "Epoch 573/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138634.5088\n",
      "Epoch 574/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138358.8844\n",
      "Epoch 575/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138238.4755\n",
      "Epoch 576/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136026.8033\n",
      "Epoch 577/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137270.4384\n",
      "Epoch 578/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136662.9302\n",
      "Epoch 579/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135263.3720\n",
      "Epoch 580/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137995.9578\n",
      "Epoch 581/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139690.7664\n",
      "Epoch 582/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133816.9624\n",
      "Epoch 583/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140365.1259\n",
      "Epoch 584/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139839.2576\n",
      "Epoch 585/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142255.2485\n",
      "Epoch 586/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141750.1403\n",
      "Epoch 587/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142188.7921\n",
      "Epoch 588/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138557.0841\n",
      "Epoch 589/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136806.9582\n",
      "Epoch 590/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137707.1106\n",
      "Epoch 591/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136569.0152\n",
      "Epoch 592/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135537.1358\n",
      "Epoch 593/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137527.8590\n",
      "Epoch 594/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133361.5247\n",
      "Epoch 595/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 139153.3321\n",
      "Epoch 596/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137401.0082\n",
      "Epoch 597/1000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 129384.8754\n",
      "Epoch 598/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139394.5746\n",
      "Epoch 599/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134331.5360\n",
      "Epoch 600/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134518.3573\n",
      "Epoch 601/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 134727.6075\n",
      "Epoch 602/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 137336.3858\n",
      "Epoch 603/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137690.9199\n",
      "Epoch 604/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138949.6848\n",
      "Epoch 605/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136969.0305\n",
      "Epoch 606/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 139206.0413\n",
      "Epoch 607/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 136147.0048\n",
      "Epoch 608/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 139238.4593\n",
      "Epoch 609/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 135196.8379\n",
      "Epoch 610/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137625.5412\n",
      "Epoch 611/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134641.6848\n",
      "Epoch 612/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137020.0564\n",
      "Epoch 613/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138478.4563\n",
      "Epoch 614/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134833.3125\n",
      "Epoch 615/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133163.1606\n",
      "Epoch 616/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136425.4209\n",
      "Epoch 617/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140596.6935\n",
      "Epoch 618/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137083.9815\n",
      "Epoch 619/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138170.6623\n",
      "Epoch 620/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138271.4456\n",
      "Epoch 621/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136474.2231\n",
      "Epoch 622/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138733.1340\n",
      "Epoch 623/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138531.6221\n",
      "Epoch 624/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135625.2832\n",
      "Epoch 625/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137326.0923\n",
      "Epoch 626/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137420.6577\n",
      "Epoch 627/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132869.4020\n",
      "Epoch 628/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 137380.6504\n",
      "Epoch 629/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134707.3079\n",
      "Epoch 630/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138060.5977\n",
      "Epoch 631/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 33us/step - loss: 133414.0443\n",
      "Epoch 632/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 141177.1338\n",
      "Epoch 633/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142386.7310\n",
      "Epoch 634/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 147779.0614\n",
      "Epoch 635/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137670.5390\n",
      "Epoch 636/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136991.4407\n",
      "Epoch 637/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 148654.9389\n",
      "Epoch 638/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 151236.8099\n",
      "Epoch 639/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 147751.0888\n",
      "Epoch 640/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 150978.9521\n",
      "Epoch 641/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 151435.0151\n",
      "Epoch 642/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 148924.3187\n",
      "Epoch 643/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 152475.3032\n",
      "Epoch 644/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140583.0248\n",
      "Epoch 645/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139370.4560\n",
      "Epoch 646/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136967.2447\n",
      "Epoch 647/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140434.3431\n",
      "Epoch 648/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137397.0517\n",
      "Epoch 649/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139697.8136\n",
      "Epoch 650/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135546.5753\n",
      "Epoch 651/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 133242.8006\n",
      "Epoch 652/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 138063.0470\n",
      "Epoch 653/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139433.8807\n",
      "Epoch 654/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132031.0494\n",
      "Epoch 655/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134087.2535\n",
      "Epoch 656/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137330.9047\n",
      "Epoch 657/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135432.7810\n",
      "Epoch 658/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134055.0467\n",
      "Epoch 659/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137520.9872\n",
      "Epoch 660/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133882.1598\n",
      "Epoch 661/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 131317.4782\n",
      "Epoch 662/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137462.0843\n",
      "Epoch 663/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 128750.3026\n",
      "Epoch 664/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132821.9436\n",
      "Epoch 665/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137054.5523\n",
      "Epoch 666/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131036.0668\n",
      "Epoch 667/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135423.9516\n",
      "Epoch 668/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137199.2369\n",
      "Epoch 669/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131576.6525\n",
      "Epoch 670/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141026.3751\n",
      "Epoch 671/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142429.8242\n",
      "Epoch 672/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 147517.0011\n",
      "Epoch 673/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141861.8632\n",
      "Epoch 674/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132294.9890\n",
      "Epoch 675/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138920.4758\n",
      "Epoch 676/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139094.5084\n",
      "Epoch 677/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140293.1740\n",
      "Epoch 678/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140541.0347\n",
      "Epoch 679/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135348.9597\n",
      "Epoch 680/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138445.8910\n",
      "Epoch 681/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133395.1767\n",
      "Epoch 682/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136395.2759\n",
      "Epoch 683/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138606.1791\n",
      "Epoch 684/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138316.9792\n",
      "Epoch 685/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 137299.7600\n",
      "Epoch 686/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131973.8880\n",
      "Epoch 687/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137053.5650\n",
      "Epoch 688/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137073.0495\n",
      "Epoch 689/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137583.2109\n",
      "Epoch 690/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133338.0875\n",
      "Epoch 691/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137205.8991\n",
      "Epoch 692/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132145.1095\n",
      "Epoch 693/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136443.4109\n",
      "Epoch 694/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136214.6927\n",
      "Epoch 695/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 133059.5719\n",
      "Epoch 696/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 131809.5980\n",
      "Epoch 697/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133601.9010\n",
      "Epoch 698/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136267.5479\n",
      "Epoch 699/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138430.7956\n",
      "Epoch 700/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132061.0130\n",
      "Epoch 701/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 128915.3371\n",
      "Epoch 702/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140240.5432\n",
      "Epoch 703/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138041.3403\n",
      "Epoch 704/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140568.4996\n",
      "Epoch 705/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139101.7264\n",
      "Epoch 706/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 134583.7920\n",
      "Epoch 707/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135722.2888\n",
      "Epoch 708/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133768.6312\n",
      "Epoch 709/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137247.6067\n",
      "Epoch 710/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137345.1155\n",
      "Epoch 711/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133790.7784\n",
      "Epoch 712/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136340.7386\n",
      "Epoch 713/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136644.0091\n",
      "Epoch 714/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137234.9371\n",
      "Epoch 715/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 136205.0148\n",
      "Epoch 716/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137372.9875\n",
      "Epoch 717/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135834.4927\n",
      "Epoch 718/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133975.5604\n",
      "Epoch 719/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135374.6790\n",
      "Epoch 720/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134907.8712\n",
      "Epoch 721/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 35us/step - loss: 136263.2628\n",
      "Epoch 722/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 133815.2698\n",
      "Epoch 723/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132065.4522\n",
      "Epoch 724/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 134969.3295\n",
      "Epoch 725/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130429.5253\n",
      "Epoch 726/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135925.2998\n",
      "Epoch 727/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 136122.1749\n",
      "Epoch 728/1000\n",
      "630/630 [==============================] - ETA: 0s - loss: 91511.929 - 0s 35us/step - loss: 135750.5680\n",
      "Epoch 729/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134413.8807\n",
      "Epoch 730/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136193.3358\n",
      "Epoch 731/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136138.9566\n",
      "Epoch 732/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 137039.9787\n",
      "Epoch 733/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136335.0148\n",
      "Epoch 734/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132259.3681\n",
      "Epoch 735/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136874.6734\n",
      "Epoch 736/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 134570.0638\n",
      "Epoch 737/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136499.2287\n",
      "Epoch 738/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133767.3070\n",
      "Epoch 739/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133610.1904\n",
      "Epoch 740/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 135713.1870\n",
      "Epoch 741/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 134186.5241\n",
      "Epoch 742/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138219.5397\n",
      "Epoch 743/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138038.6935\n",
      "Epoch 744/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130213.3371\n",
      "Epoch 745/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132221.6788\n",
      "Epoch 746/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137384.6885\n",
      "Epoch 747/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135987.3478\n",
      "Epoch 748/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138727.2252\n",
      "Epoch 749/1000\n",
      "630/630 [==============================] - 0s 43us/step - loss: 130032.0221\n",
      "Epoch 750/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 133094.5578\n",
      "Epoch 751/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 133779.5773\n",
      "Epoch 752/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 135705.2886\n",
      "Epoch 753/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 134081.4407\n",
      "Epoch 754/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135008.3593\n",
      "Epoch 755/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 129170.1260\n",
      "Epoch 756/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134779.1579\n",
      "Epoch 757/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 132764.5816\n",
      "Epoch 758/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134934.6335\n",
      "Epoch 759/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 135009.2313\n",
      "Epoch 760/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133920.3009\n",
      "Epoch 761/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136042.0711\n",
      "Epoch 762/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 129981.5365\n",
      "Epoch 763/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132510.9380\n",
      "Epoch 764/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140347.3797\n",
      "Epoch 765/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141602.5744\n",
      "Epoch 766/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 136120.9692\n",
      "Epoch 767/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 138815.8868\n",
      "Epoch 768/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 146411.5360\n",
      "Epoch 769/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140230.8688\n",
      "Epoch 770/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 141190.1350\n",
      "Epoch 771/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135959.6670\n",
      "Epoch 772/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139891.3136\n",
      "Epoch 773/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139993.7256\n",
      "Epoch 774/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138844.6029\n",
      "Epoch 775/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 138718.6321\n",
      "Epoch 776/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137331.6266\n",
      "Epoch 777/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135719.4338\n",
      "Epoch 778/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136943.9888\n",
      "Epoch 779/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 192705.9611\n",
      "Epoch 780/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 176714.7183\n",
      "Epoch 781/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 153574.4222\n",
      "Epoch 782/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 149367.9051\n",
      "Epoch 783/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 146119.8079\n",
      "Epoch 784/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 142916.3280\n",
      "Epoch 785/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 138107.3185\n",
      "Epoch 786/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 137856.9081\n",
      "Epoch 787/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142013.3678\n",
      "Epoch 788/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 152304.5490\n",
      "Epoch 789/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 144585.3440\n",
      "Epoch 790/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137300.5197\n",
      "Epoch 791/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140329.1306\n",
      "Epoch 792/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141955.6970\n",
      "Epoch 793/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139872.1218\n",
      "Epoch 794/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135068.7303\n",
      "Epoch 795/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136566.1024\n",
      "Epoch 796/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134707.0169\n",
      "Epoch 797/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134167.5157\n",
      "Epoch 798/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135538.6591\n",
      "Epoch 799/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133850.3275\n",
      "Epoch 800/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134589.0565\n",
      "Epoch 801/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135289.3567\n",
      "Epoch 802/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136168.0575\n",
      "Epoch 803/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133452.7809\n",
      "Epoch 804/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 130961.6828\n",
      "Epoch 805/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135789.3208\n",
      "Epoch 806/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133665.8436\n",
      "Epoch 807/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 133583.0720\n",
      "Epoch 808/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 132134.9182\n",
      "Epoch 809/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132950.5752\n",
      "Epoch 810/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 33us/step - loss: 131233.7006\n",
      "Epoch 811/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131001.9436\n",
      "Epoch 812/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130026.8216\n",
      "Epoch 813/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132377.6390\n",
      "Epoch 814/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 125909.2686\n",
      "Epoch 815/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 135877.9208\n",
      "Epoch 816/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137189.3163\n",
      "Epoch 817/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137457.7397\n",
      "Epoch 818/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 135463.4968\n",
      "Epoch 819/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 135290.5571\n",
      "Epoch 820/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133976.0071\n",
      "Epoch 821/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 131207.8005\n",
      "Epoch 822/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134869.1835\n",
      "Epoch 823/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 129962.7778\n",
      "Epoch 824/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136541.0068\n",
      "Epoch 825/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134815.0865\n",
      "Epoch 826/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130198.6473\n",
      "Epoch 827/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135078.3591\n",
      "Epoch 828/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134473.5398\n",
      "Epoch 829/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 134367.3596\n",
      "Epoch 830/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132049.7693\n",
      "Epoch 831/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 132347.4399\n",
      "Epoch 832/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134457.9207\n",
      "Epoch 833/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132633.2892\n",
      "Epoch 834/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 130845.8207\n",
      "Epoch 835/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131292.9173\n",
      "Epoch 836/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134312.4030\n",
      "Epoch 837/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132423.2459\n",
      "Epoch 838/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 129871.8278\n",
      "Epoch 839/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 124860.4422\n",
      "Epoch 840/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 127663.1995\n",
      "Epoch 841/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136689.2402\n",
      "Epoch 842/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137453.7980\n",
      "Epoch 843/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 139688.1837\n",
      "Epoch 844/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142001.1554\n",
      "Epoch 845/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139415.7034\n",
      "Epoch 846/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 156375.4151\n",
      "Epoch 847/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 180701.7060\n",
      "Epoch 848/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 149112.1507\n",
      "Epoch 849/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 180006.8966\n",
      "Epoch 850/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139559.4122\n",
      "Epoch 851/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 142599.3316\n",
      "Epoch 852/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 141601.4965\n",
      "Epoch 853/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137021.2445\n",
      "Epoch 854/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135284.5707\n",
      "Epoch 855/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 137226.2492\n",
      "Epoch 856/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 128812.5938\n",
      "Epoch 857/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 127830.3157\n",
      "Epoch 858/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134379.7163\n",
      "Epoch 859/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132443.0361\n",
      "Epoch 860/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132293.8123\n",
      "Epoch 861/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130841.7236\n",
      "Epoch 862/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131082.2331\n",
      "Epoch 863/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133102.3192\n",
      "Epoch 864/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131392.0028\n",
      "Epoch 865/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131922.1605\n",
      "Epoch 866/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 134963.4645\n",
      "Epoch 867/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 135143.5330\n",
      "Epoch 868/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 142391.1129\n",
      "Epoch 869/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 140724.3677\n",
      "Epoch 870/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 142019.6923\n",
      "Epoch 871/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 139834.2035\n",
      "Epoch 872/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 137270.5168\n",
      "Epoch 873/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 147291.1351\n",
      "Epoch 874/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 140245.0925\n",
      "Epoch 875/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 133821.7092\n",
      "Epoch 876/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 128778.4484\n",
      "Epoch 877/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 138263.1469\n",
      "Epoch 878/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 136902.1235\n",
      "Epoch 879/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138659.9259\n",
      "Epoch 880/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 136282.2705\n",
      "Epoch 881/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 134862.1464\n",
      "Epoch 882/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131880.8020\n",
      "Epoch 883/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134901.1024\n",
      "Epoch 884/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 133468.9822\n",
      "Epoch 885/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132784.3657\n",
      "Epoch 886/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133390.5346\n",
      "Epoch 887/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134128.6558\n",
      "Epoch 888/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133596.4074\n",
      "Epoch 889/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 130760.4583\n",
      "Epoch 890/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131632.5676\n",
      "Epoch 891/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131456.4782\n",
      "Epoch 892/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131980.9971\n",
      "Epoch 893/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133797.4792\n",
      "Epoch 894/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 128353.3678\n",
      "Epoch 895/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 130703.7571\n",
      "Epoch 896/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134090.8698\n",
      "Epoch 897/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132894.9839\n",
      "Epoch 898/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 128728.1367\n",
      "Epoch 899/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 129395.2690\n",
      "Epoch 900/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 33us/step - loss: 131352.1551\n",
      "Epoch 901/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 123176.8057\n",
      "Epoch 902/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133077.4494\n",
      "Epoch 903/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 127214.4325\n",
      "Epoch 904/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 131441.7186\n",
      "Epoch 905/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 134847.2292\n",
      "Epoch 906/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134551.1618\n",
      "Epoch 907/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 127860.3220\n",
      "Epoch 908/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 134574.7224\n",
      "Epoch 909/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132556.8483\n",
      "Epoch 910/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133721.9341\n",
      "Epoch 911/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 133341.7530\n",
      "Epoch 912/1000\n",
      "630/630 [==============================] - 0s 40us/step - loss: 131929.8809\n",
      "Epoch 913/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 126581.8557\n",
      "Epoch 914/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 130820.1722\n",
      "Epoch 915/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131099.2343\n",
      "Epoch 916/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131454.3581\n",
      "Epoch 917/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131896.6719\n",
      "Epoch 918/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 128012.9969\n",
      "Epoch 919/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 127508.7341\n",
      "Epoch 920/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131311.9730\n",
      "Epoch 921/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132005.4323\n",
      "Epoch 922/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132170.6740\n",
      "Epoch 923/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 124252.4439\n",
      "Epoch 924/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134191.6370\n",
      "Epoch 925/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 138774.3529\n",
      "Epoch 926/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 137810.5817\n",
      "Epoch 927/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 139149.0582\n",
      "Epoch 928/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 130001.8135\n",
      "Epoch 929/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 134025.6029\n",
      "Epoch 930/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 131835.9723\n",
      "Epoch 931/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 130988.4286\n",
      "Epoch 932/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 133434.7596\n",
      "Epoch 933/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 130729.7297\n",
      "Epoch 934/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 127298.4010\n",
      "Epoch 935/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 130507.7723\n",
      "Epoch 936/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 130255.0409\n",
      "Epoch 937/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 132393.2726\n",
      "Epoch 938/1000\n",
      "630/630 [==============================] - 0s 41us/step - loss: 133829.2511\n",
      "Epoch 939/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134418.3426\n",
      "Epoch 940/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 126843.5556\n",
      "Epoch 941/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 142263.6677\n",
      "Epoch 942/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 132703.5174\n",
      "Epoch 943/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134035.5233\n",
      "Epoch 944/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130252.4046\n",
      "Epoch 945/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 134467.9083\n",
      "Epoch 946/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 132015.1583\n",
      "Epoch 947/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131846.4853\n",
      "Epoch 948/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 129436.1910\n",
      "Epoch 949/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 126792.1815\n",
      "Epoch 950/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 128835.9846\n",
      "Epoch 951/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 129690.6197\n",
      "Epoch 952/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135843.8377\n",
      "Epoch 953/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 135867.4898\n",
      "Epoch 954/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132083.4273\n",
      "Epoch 955/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 124737.5439\n",
      "Epoch 956/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132079.7569\n",
      "Epoch 957/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131493.5328\n",
      "Epoch 958/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 130326.8863\n",
      "Epoch 959/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130136.3652\n",
      "Epoch 960/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 130745.8988\n",
      "Epoch 961/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 131094.4203\n",
      "Epoch 962/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 130212.4240\n",
      "Epoch 963/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 129795.0059\n",
      "Epoch 964/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 128749.6633\n",
      "Epoch 965/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 129192.0449\n",
      "Epoch 966/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 132099.8153\n",
      "Epoch 967/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 134877.8915\n",
      "Epoch 968/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 133070.5098\n",
      "Epoch 969/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 131955.4900\n",
      "Epoch 970/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130361.6422\n",
      "Epoch 971/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 126682.8857\n",
      "Epoch 972/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 127935.1930\n",
      "Epoch 973/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 130134.0011\n",
      "Epoch 974/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 129690.4330\n",
      "Epoch 975/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 125734.7882\n",
      "Epoch 976/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 129435.6133\n",
      "Epoch 977/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 133906.5949\n",
      "Epoch 978/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 132406.6927\n",
      "Epoch 979/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 140150.7463\n",
      "Epoch 980/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 161023.5882\n",
      "Epoch 981/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 146073.7154\n",
      "Epoch 982/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 149116.0174\n",
      "Epoch 983/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 159436.0449\n",
      "Epoch 984/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 160406.5320\n",
      "Epoch 985/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 140014.6625\n",
      "Epoch 986/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 169097.5377\n",
      "Epoch 987/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 159647.8118\n",
      "Epoch 988/1000\n",
      "630/630 [==============================] - 0s 38us/step - loss: 151531.2592\n",
      "Epoch 989/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 138049.2258\n",
      "Epoch 990/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 38us/step - loss: 134309.4760\n",
      "Epoch 991/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 132715.8960\n",
      "Epoch 992/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 128616.9164\n",
      "Epoch 993/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 131885.7882\n",
      "Epoch 994/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 125387.6868\n",
      "Epoch 995/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 130433.9091\n",
      "Epoch 996/1000\n",
      "630/630 [==============================] - 0s 36us/step - loss: 131118.7843\n",
      "Epoch 997/1000\n",
      "630/630 [==============================] - 0s 32us/step - loss: 125563.1535\n",
      "Epoch 998/1000\n",
      "630/630 [==============================] - 0s 33us/step - loss: 124543.5389\n",
      "Epoch 999/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 126468.9269\n",
      "Epoch 1000/1000\n",
      "630/630 [==============================] - 0s 35us/step - loss: 130501.0525\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2827b702710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1 = LossHistory()\n",
    "input_img=Input(shape=(10,))\n",
    "# 编码层\n",
    "#encoded=Dense(128,activation='relu',name='encoded_hidden1',activity_regularizer=regularizers.l1(0.01))(input_img)\n",
    "#encoded=Dense(64,activation='sigmoid',name='encoded_hidden2',activity_regularizer=regularizers.l1(0.01))(encoded)\n",
    "#encoded=Dense(32,activation='sigmoid',name='encoded_hidden3',activity_regularizer=regularizers.l1(0.01))(encoded)\n",
    "#encoder_output=Dense(16,activation='relu',name='encoded_hidden4',activity_regularizer=regularizers.l1(0.01))(encoded)\n",
    "LR=Dense(20,name='LR',activity_regularizer=regularizers.l1(0.01))(input_img)\n",
    "\n",
    "# 解码层\n",
    "decoded=Dense(10,name='decoded_hidden2')(LR)\n",
    "#decoded=Dense(32,activation='sigmoid',name='decoded_hidden3',activity_regularizer=regularizers.l1(0.01))(decoded)\n",
    "#decoded=Dense(64,activation='sigmoid',name='decoded_hidden4',activity_regularizer=regularizers.l1(0.01))(decoded)\n",
    "#decoded=Dense(128,activation='sigmoid',name='decoded_hidden5',activity_regularizer=regularizers.l1(0.01))(decoded)\n",
    "#decoded=Dense(10,activation='sigmoid',name='decoded_output')(decoded)\n",
    "\n",
    "# 构建自编码模型\n",
    "autoencoder=Model(inputs=input_img,outputs=decoded)\n",
    "\n",
    "# complile autoencoder 设置自编码的优化参数\n",
    "autoencoder.compile(optimizer='adam',loss='mse')\n",
    "# train\n",
    "hist=autoencoder.fit(X_train,X_train,epochs=1000,batch_size=100,shuffle=True,callbacks=[history1])\n",
    "history1.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 315 samples\n",
      "Epoch 1/10000\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 335657.7929 - val_loss: 161408.1616\n",
      "Epoch 2/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 268570.6192 - val_loss: 132996.7973\n",
      "Epoch 3/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 218816.6656 - val_loss: 111257.9630\n",
      "Epoch 4/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 181043.5163 - val_loss: 95847.5689\n",
      "Epoch 5/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 152624.7085 - val_loss: 85730.5957\n",
      "Epoch 6/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 136224.5668 - val_loss: 79555.5846\n",
      "Epoch 7/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 124604.4033 - val_loss: 75364.8170\n",
      "Epoch 8/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 118032.2580 - val_loss: 73312.8266\n",
      "Epoch 9/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 115719.4010 - val_loss: 71619.3035\n",
      "Epoch 10/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 109724.6741 - val_loss: 69942.2132\n",
      "Epoch 11/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 111152.8228 - val_loss: 68335.7468\n",
      "Epoch 12/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 106295.2738 - val_loss: 66943.0063\n",
      "Epoch 13/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 105001.7971 - val_loss: 65589.3340\n",
      "Epoch 14/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 100900.7334 - val_loss: 64343.0611\n",
      "Epoch 15/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 100155.8555 - val_loss: 63051.2591\n",
      "Epoch 16/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 95850.0515 - val_loss: 61758.9970\n",
      "Epoch 17/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 93841.9361 - val_loss: 60478.7814\n",
      "Epoch 18/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 92482.0548 - val_loss: 59187.6363\n",
      "Epoch 19/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 90302.9747 - val_loss: 57909.5440\n",
      "Epoch 20/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 88093.9044 - val_loss: 56678.8802\n",
      "Epoch 21/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 85335.8837 - val_loss: 55418.5317\n",
      "Epoch 22/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 80896.0479 - val_loss: 54211.9513\n",
      "Epoch 23/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 78529.7648 - val_loss: 53083.3266\n",
      "Epoch 24/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 76927.0723 - val_loss: 51888.8469\n",
      "Epoch 25/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 76162.0627 - val_loss: 50724.8441\n",
      "Epoch 26/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 73793.8238 - val_loss: 49751.6959\n",
      "Epoch 27/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 71883.3113 - val_loss: 48691.4410\n",
      "Epoch 28/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 69732.5050 - val_loss: 47754.7137\n",
      "Epoch 29/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 67956.2253 - val_loss: 46788.5831\n",
      "Epoch 30/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 66382.6328 - val_loss: 45857.5393\n",
      "Epoch 31/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 62491.4952 - val_loss: 44938.3826\n",
      "Epoch 32/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 63114.1978 - val_loss: 43993.4039\n",
      "Epoch 33/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 61330.1550 - val_loss: 43112.2186\n",
      "Epoch 34/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 59471.7936 - val_loss: 42270.5797\n",
      "Epoch 35/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 57690.4969 - val_loss: 41387.3361\n",
      "Epoch 36/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 55565.7692 - val_loss: 40521.5874\n",
      "Epoch 37/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 53445.9078 - val_loss: 39718.5881\n",
      "Epoch 38/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 52836.5193 - val_loss: 38922.5072\n",
      "Epoch 39/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 51518.3265 - val_loss: 38122.2793\n",
      "Epoch 40/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 48620.9696 - val_loss: 37333.2594\n",
      "Epoch 41/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 48866.8452 - val_loss: 36508.4746\n",
      "Epoch 42/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 45217.9013 - val_loss: 35632.4661\n",
      "Epoch 43/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 44338.4694 - val_loss: 34790.7304\n",
      "Epoch 44/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 43509.8232 - val_loss: 33945.6179\n",
      "Epoch 45/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 41454.8425 - val_loss: 33163.7179\n",
      "Epoch 46/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 41370.0741 - val_loss: 32395.7538\n",
      "Epoch 47/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 40114.6263 - val_loss: 31591.7923\n",
      "Epoch 48/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 38496.4762 - val_loss: 30862.2872\n",
      "Epoch 49/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 36899.7377 - val_loss: 30165.1571\n",
      "Epoch 50/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 35214.4616 - val_loss: 29515.8270\n",
      "Epoch 51/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 34519.4227 - val_loss: 28896.5015\n",
      "Epoch 52/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 33653.4764 - val_loss: 28292.3687\n",
      "Epoch 53/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 32602.0216 - val_loss: 27706.8714\n",
      "Epoch 54/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 31009.7516 - val_loss: 27119.2278\n",
      "Epoch 55/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 30093.6471 - val_loss: 26638.9616\n",
      "Epoch 56/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 29177.6992 - val_loss: 26139.3712\n",
      "Epoch 57/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 28353.0212 - val_loss: 25665.4445\n",
      "Epoch 58/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 27725.5872 - val_loss: 25187.1878\n",
      "Epoch 59/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 26865.0755 - val_loss: 24715.7431\n",
      "Epoch 60/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 25947.3462 - val_loss: 24269.7236\n",
      "Epoch 61/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 24414.4920 - val_loss: 23850.9572\n",
      "Epoch 62/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 24370.4980 - val_loss: 23441.8519\n",
      "Epoch 63/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 22954.1705 - val_loss: 23030.4943\n",
      "Epoch 64/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 22810.9593 - val_loss: 22664.4209\n",
      "Epoch 65/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 21923.5441 - val_loss: 22269.1999\n",
      "Epoch 66/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 21478.2351 - val_loss: 21912.9981\n",
      "Epoch 67/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 20756.1008 - val_loss: 21553.3483\n",
      "Epoch 68/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 20162.8373 - val_loss: 21213.5095\n",
      "Epoch 69/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 19480.6314 - val_loss: 20895.3761\n",
      "Epoch 70/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 18572.7535 - val_loss: 20578.7680\n",
      "Epoch 71/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 17962.9087 - val_loss: 20291.3567\n",
      "Epoch 72/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 17715.6678 - val_loss: 20019.7680\n",
      "Epoch 73/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 59us/step - loss: 17264.5923 - val_loss: 19767.0864\n",
      "Epoch 74/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 16604.7747 - val_loss: 19512.7879\n",
      "Epoch 75/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 16327.4568 - val_loss: 19288.0270\n",
      "Epoch 76/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 16014.3497 - val_loss: 19097.4819\n",
      "Epoch 77/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 15499.0872 - val_loss: 18831.4882\n",
      "Epoch 78/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 15285.5811 - val_loss: 18658.5847\n",
      "Epoch 79/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 14884.6278 - val_loss: 18446.0740\n",
      "Epoch 80/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 14422.1267 - val_loss: 18242.7097\n",
      "Epoch 81/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 14112.1964 - val_loss: 18082.3723\n",
      "Epoch 82/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 13846.0713 - val_loss: 17897.8013\n",
      "Epoch 83/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 13526.5444 - val_loss: 17724.5558\n",
      "Epoch 84/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 13184.2330 - val_loss: 17570.9133\n",
      "Epoch 85/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 12917.1063 - val_loss: 17407.8497\n",
      "Epoch 86/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 12672.4519 - val_loss: 17261.8575\n",
      "Epoch 87/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 12368.0374 - val_loss: 17120.2767\n",
      "Epoch 88/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 12167.7227 - val_loss: 16974.9089\n",
      "Epoch 89/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 11885.4902 - val_loss: 16868.1415\n",
      "Epoch 90/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 11719.8542 - val_loss: 16746.3992\n",
      "Epoch 91/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 11523.5547 - val_loss: 16685.0752\n",
      "Epoch 92/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 11334.4945 - val_loss: 16573.2128\n",
      "Epoch 93/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 11181.5511 - val_loss: 16567.7134\n",
      "Epoch 94/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 11177.7641 - val_loss: 16532.5528\n",
      "Epoch 95/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 11151.2405 - val_loss: 16533.4490\n",
      "Epoch 96/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 11165.5569 - val_loss: 16457.0436\n",
      "Epoch 97/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 11091.5621 - val_loss: 16413.9247\n",
      "Epoch 98/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10980.7667 - val_loss: 16368.3270\n",
      "Epoch 99/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10986.3262 - val_loss: 16345.0519\n",
      "Epoch 100/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 10971.7199 - val_loss: 16342.2561\n",
      "Epoch 101/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 10900.2256 - val_loss: 16261.9436\n",
      "Epoch 102/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10869.0317 - val_loss: 16241.8744\n",
      "Epoch 103/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10860.6296 - val_loss: 16233.7289\n",
      "Epoch 104/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10812.0671 - val_loss: 16168.0250\n",
      "Epoch 105/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10765.7746 - val_loss: 16141.8313\n",
      "Epoch 106/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10752.7784 - val_loss: 16134.8811\n",
      "Epoch 107/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10731.0090 - val_loss: 16062.5807\n",
      "Epoch 108/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10672.5745 - val_loss: 16048.6389\n",
      "Epoch 109/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10681.6958 - val_loss: 16011.0748\n",
      "Epoch 110/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10618.0316 - val_loss: 16008.2580\n",
      "Epoch 111/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 10614.4982 - val_loss: 15985.7791\n",
      "Epoch 112/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10559.3182 - val_loss: 15936.0920\n",
      "Epoch 113/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10531.3319 - val_loss: 15885.9408\n",
      "Epoch 114/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10527.6854 - val_loss: 15860.1787\n",
      "Epoch 115/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10505.2380 - val_loss: 15819.1762\n",
      "Epoch 116/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10430.5596 - val_loss: 15815.0992\n",
      "Epoch 117/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10425.2863 - val_loss: 15781.3361\n",
      "Epoch 118/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10385.8835 - val_loss: 15739.9108\n",
      "Epoch 119/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10366.1566 - val_loss: 15711.9986\n",
      "Epoch 120/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10334.8478 - val_loss: 15695.3828\n",
      "Epoch 121/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 10280.0556 - val_loss: 15662.9607\n",
      "Epoch 122/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10293.8097 - val_loss: 15635.8996\n",
      "Epoch 123/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 10250.0515 - val_loss: 15588.5574\n",
      "Epoch 124/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 10229.3928 - val_loss: 15557.5886\n",
      "Epoch 125/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10218.9571 - val_loss: 15550.4458\n",
      "Epoch 126/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10181.4727 - val_loss: 15513.5527\n",
      "Epoch 127/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10156.0993 - val_loss: 15522.3938\n",
      "Epoch 128/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10128.9134 - val_loss: 15461.2941\n",
      "Epoch 129/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10083.6865 - val_loss: 15458.8165\n",
      "Epoch 130/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10049.3917 - val_loss: 15398.9403\n",
      "Epoch 131/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10050.3532 - val_loss: 15385.6266\n",
      "Epoch 132/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10023.2753 - val_loss: 15342.8847\n",
      "Epoch 133/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 10007.0430 - val_loss: 15353.3904\n",
      "Epoch 134/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9965.1179 - val_loss: 15302.8271\n",
      "Epoch 135/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9932.3591 - val_loss: 15283.0268\n",
      "Epoch 136/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9917.3060 - val_loss: 15247.5262\n",
      "Epoch 137/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9874.1835 - val_loss: 15203.8499\n",
      "Epoch 138/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9874.1946 - val_loss: 15190.9273\n",
      "Epoch 139/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 9871.7118 - val_loss: 15167.9533\n",
      "Epoch 140/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 9821.8805 - val_loss: 15129.5865\n",
      "Epoch 141/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9793.2847 - val_loss: 15105.1878\n",
      "Epoch 142/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9751.8729 - val_loss: 15099.6525\n",
      "Epoch 143/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 9732.9242 - val_loss: 15065.2255\n",
      "Epoch 144/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9694.0133 - val_loss: 15036.7154\n",
      "Epoch 145/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 59us/step - loss: 9686.2888 - val_loss: 15018.9350\n",
      "Epoch 146/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9694.4027 - val_loss: 15019.3226\n",
      "Epoch 147/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9689.7180 - val_loss: 15013.2999\n",
      "Epoch 148/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9924.9047 - val_loss: 15195.4199\n",
      "Epoch 149/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9967.6708 - val_loss: 15056.3524\n",
      "Epoch 150/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9797.6447 - val_loss: 14973.3698\n",
      "Epoch 151/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9643.3107 - val_loss: 14947.2338\n",
      "Epoch 152/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9608.7488 - val_loss: 14859.6823\n",
      "Epoch 153/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9556.6054 - val_loss: 14860.1430\n",
      "Epoch 154/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9526.1880 - val_loss: 14821.3378\n",
      "Epoch 155/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9493.6104 - val_loss: 14779.1762\n",
      "Epoch 156/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9473.6132 - val_loss: 14759.7542\n",
      "Epoch 157/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9424.0974 - val_loss: 14732.3020\n",
      "Epoch 158/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9393.3800 - val_loss: 14709.1841\n",
      "Epoch 159/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9384.1655 - val_loss: 14683.3053\n",
      "Epoch 160/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 9363.3946 - val_loss: 14648.7564\n",
      "Epoch 161/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9337.1340 - val_loss: 14619.2818\n",
      "Epoch 162/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9306.7930 - val_loss: 14597.1538\n",
      "Epoch 163/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9301.8271 - val_loss: 14594.4543\n",
      "Epoch 164/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9282.0608 - val_loss: 14567.1033\n",
      "Epoch 165/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9247.2139 - val_loss: 14529.8883\n",
      "Epoch 166/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9249.0952 - val_loss: 14514.8142\n",
      "Epoch 167/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 9226.7398 - val_loss: 14507.6392\n",
      "Epoch 168/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9211.4888 - val_loss: 14468.1119\n",
      "Epoch 169/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9178.5205 - val_loss: 14443.0683\n",
      "Epoch 170/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9163.6543 - val_loss: 14430.7928\n",
      "Epoch 171/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9143.0722 - val_loss: 14398.7317\n",
      "Epoch 172/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9120.3663 - val_loss: 14413.1450\n",
      "Epoch 173/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9130.6514 - val_loss: 14366.8307\n",
      "Epoch 174/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9084.6100 - val_loss: 14326.5595\n",
      "Epoch 175/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9052.2628 - val_loss: 14298.6611\n",
      "Epoch 176/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9042.4071 - val_loss: 14299.4794\n",
      "Epoch 177/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9048.8449 - val_loss: 14282.7461\n",
      "Epoch 178/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9021.5109 - val_loss: 14250.2724\n",
      "Epoch 179/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 8998.0582 - val_loss: 14224.5340\n",
      "Epoch 180/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8972.7535 - val_loss: 14199.2786\n",
      "Epoch 181/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8936.3359 - val_loss: 14172.5425\n",
      "Epoch 182/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8938.3453 - val_loss: 14166.7604\n",
      "Epoch 183/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8911.2536 - val_loss: 14149.0292\n",
      "Epoch 184/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8896.7325 - val_loss: 14125.7369\n",
      "Epoch 185/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8881.7090 - val_loss: 14108.2374\n",
      "Epoch 186/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8861.0015 - val_loss: 14082.7006\n",
      "Epoch 187/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8837.2755 - val_loss: 14058.8990\n",
      "Epoch 188/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8809.1754 - val_loss: 14042.3052\n",
      "Epoch 189/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 8791.2359 - val_loss: 14017.3508\n",
      "Epoch 190/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8762.4337 - val_loss: 13997.5192\n",
      "Epoch 191/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8760.5973 - val_loss: 13982.2534\n",
      "Epoch 192/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8747.0769 - val_loss: 13952.4711\n",
      "Epoch 193/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8731.0934 - val_loss: 13963.0222\n",
      "Epoch 194/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8717.4690 - val_loss: 13924.8242\n",
      "Epoch 195/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8703.3979 - val_loss: 13949.8993\n",
      "Epoch 196/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 8751.6410 - val_loss: 13933.7610\n",
      "Epoch 197/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8745.5926 - val_loss: 13883.1909\n",
      "Epoch 198/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8681.1235 - val_loss: 13829.3613\n",
      "Epoch 199/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8630.9073 - val_loss: 13829.0716\n",
      "Epoch 200/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8623.7561 - val_loss: 13788.6904\n",
      "Epoch 201/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 8593.0003 - val_loss: 13776.1048\n",
      "Epoch 202/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8571.2196 - val_loss: 13755.6068\n",
      "Epoch 203/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 8561.4284 - val_loss: 13757.1386\n",
      "Epoch 204/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8538.0562 - val_loss: 13724.4317\n",
      "Epoch 205/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8521.9844 - val_loss: 13726.4898\n",
      "Epoch 206/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8516.0586 - val_loss: 13667.1433\n",
      "Epoch 207/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8496.2583 - val_loss: 13692.6789\n",
      "Epoch 208/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8478.6632 - val_loss: 13666.4353\n",
      "Epoch 209/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8525.9897 - val_loss: 13663.6360\n",
      "Epoch 210/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8786.8862 - val_loss: 13846.9845\n",
      "Epoch 211/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 9030.41 - 0s 52us/step - loss: 8798.9319 - val_loss: 13652.1427\n",
      "Epoch 212/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8486.4391 - val_loss: 13607.4281\n",
      "Epoch 213/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8462.5777 - val_loss: 13565.7022\n",
      "Epoch 214/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8434.8896 - val_loss: 13556.7693\n",
      "Epoch 215/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8503.6366 - val_loss: 13592.1073\n",
      "Epoch 216/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 8424.2892 - val_loss: 13508.5163\n",
      "Epoch 217/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 8375.7817 - val_loss: 13490.5147\n",
      "Epoch 218/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8338.9091 - val_loss: 13448.7583\n",
      "Epoch 219/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 8308.0555 - val_loss: 13424.8578\n",
      "Epoch 220/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8275.9182 - val_loss: 13417.2695\n",
      "Epoch 221/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8247.0282 - val_loss: 13389.1532\n",
      "Epoch 222/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8240.1863 - val_loss: 13368.5706\n",
      "Epoch 223/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8224.6119 - val_loss: 13349.0790\n",
      "Epoch 224/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 8212.0538 - val_loss: 13326.0473\n",
      "Epoch 225/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8190.0676 - val_loss: 13309.6235\n",
      "Epoch 226/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8172.2718 - val_loss: 13293.2906\n",
      "Epoch 227/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8164.5567 - val_loss: 13283.6061\n",
      "Epoch 228/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8151.3422 - val_loss: 13273.6463\n",
      "Epoch 229/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8138.9987 - val_loss: 13234.0409\n",
      "Epoch 230/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8122.3892 - val_loss: 13245.9263\n",
      "Epoch 231/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8129.1473 - val_loss: 13299.2718\n",
      "Epoch 232/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8330.2176 - val_loss: 13257.6554\n",
      "Epoch 233/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8141.2151 - val_loss: 13200.7462\n",
      "Epoch 234/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8096.4773 - val_loss: 13168.0492\n",
      "Epoch 235/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8064.8171 - val_loss: 13127.7602\n",
      "Epoch 236/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8018.1572 - val_loss: 13096.3756\n",
      "Epoch 237/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7983.6899 - val_loss: 13074.5640\n",
      "Epoch 238/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7972.9117 - val_loss: 13055.1900\n",
      "Epoch 239/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7959.8782 - val_loss: 13025.8078\n",
      "Epoch 240/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7957.4441 - val_loss: 13132.9718\n",
      "Epoch 241/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8355.7828 - val_loss: 13167.7950\n",
      "Epoch 242/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8103.4121 - val_loss: 12964.0761\n",
      "Epoch 243/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7956.6163 - val_loss: 12949.4803\n",
      "Epoch 244/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7885.4135 - val_loss: 12900.3322\n",
      "Epoch 245/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7850.9713 - val_loss: 12847.0860\n",
      "Epoch 246/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7810.7376 - val_loss: 12847.5379\n",
      "Epoch 247/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7824.1535 - val_loss: 12913.1286\n",
      "Epoch 248/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7944.8091 - val_loss: 12784.9161\n",
      "Epoch 249/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7787.3392 - val_loss: 12754.8692\n",
      "Epoch 250/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7755.5013 - val_loss: 12669.8184\n",
      "Epoch 251/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7660.8655 - val_loss: 12676.3109\n",
      "Epoch 252/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7750.5847 - val_loss: 12666.3896\n",
      "Epoch 253/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7648.5299 - val_loss: 12588.0829\n",
      "Epoch 254/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7619.7005 - val_loss: 12598.9531\n",
      "Epoch 255/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 7597.5496 - val_loss: 12544.4249\n",
      "Epoch 256/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7573.2835 - val_loss: 12484.4814\n",
      "Epoch 257/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7610.3386 - val_loss: 12499.8641\n",
      "Epoch 258/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7529.2583 - val_loss: 12442.8536\n",
      "Epoch 259/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7478.8609 - val_loss: 12429.7128\n",
      "Epoch 260/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7484.1213 - val_loss: 12422.9451\n",
      "Epoch 261/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7599.9260 - val_loss: 12480.2627\n",
      "Epoch 262/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7577.7681 - val_loss: 12402.5521\n",
      "Epoch 263/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7503.5899 - val_loss: 12383.9974\n",
      "Epoch 264/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7473.3172 - val_loss: 12294.6482\n",
      "Epoch 265/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7376.4639 - val_loss: 12266.6671\n",
      "Epoch 266/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7330.2294 - val_loss: 12243.9111\n",
      "Epoch 267/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7300.0103 - val_loss: 12223.0880\n",
      "Epoch 268/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7293.9206 - val_loss: 12184.9294\n",
      "Epoch 269/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7264.1191 - val_loss: 12217.1008\n",
      "Epoch 270/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7471.6320 - val_loss: 12312.6374\n",
      "Epoch 271/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7505.3259 - val_loss: 12180.5591\n",
      "Epoch 272/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7293.3969 - val_loss: 12144.6744\n",
      "Epoch 273/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7249.2956 - val_loss: 12090.6622\n",
      "Epoch 274/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7220.4144 - val_loss: 12051.9980\n",
      "Epoch 275/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7174.1711 - val_loss: 12038.6854\n",
      "Epoch 276/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7174.0016 - val_loss: 12025.4083\n",
      "Epoch 277/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7176.8777 - val_loss: 12052.8169\n",
      "Epoch 278/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7208.9227 - val_loss: 11957.7155\n",
      "Epoch 279/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7104.9051 - val_loss: 11947.8277\n",
      "Epoch 280/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7070.1334 - val_loss: 11950.6646\n",
      "Epoch 281/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 7184.7219 - val_loss: 11964.5515\n",
      "Epoch 282/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7112.0333 - val_loss: 11886.7937\n",
      "Epoch 283/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7052.1032 - val_loss: 11885.1864\n",
      "Epoch 284/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7052.0630 - val_loss: 11842.4753\n",
      "Epoch 285/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6998.4122 - val_loss: 11829.0108\n",
      "Epoch 286/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7010.1468 - val_loss: 11794.3458\n",
      "Epoch 287/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6993.7473 - val_loss: 11799.2265\n",
      "Epoch 288/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 7033.5465 - val_loss: 11820.3456\n",
      "Epoch 289/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 7133.6591 - val_loss: 11801.9583\n",
      "Epoch 290/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7007.9896 - val_loss: 11725.3276\n",
      "Epoch 291/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6944.8166 - val_loss: 11698.8873\n",
      "Epoch 292/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6918.2542 - val_loss: 11696.7540\n",
      "Epoch 293/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6903.1251 - val_loss: 11710.9668\n",
      "Epoch 294/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6918.1283 - val_loss: 11649.7016\n",
      "Epoch 295/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6875.0130 - val_loss: 11651.2348\n",
      "Epoch 296/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6881.8351 - val_loss: 11588.7706\n",
      "Epoch 297/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6820.9017 - val_loss: 11571.8229\n",
      "Epoch 298/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6789.3778 - val_loss: 11557.1913\n",
      "Epoch 299/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6774.4313 - val_loss: 11532.7356\n",
      "Epoch 300/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6760.6997 - val_loss: 11531.7327\n",
      "Epoch 301/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6879.3708 - val_loss: 11564.8830\n",
      "Epoch 302/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6800.5265 - val_loss: 11486.0728\n",
      "Epoch 303/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6754.6059 - val_loss: 11451.9084\n",
      "Epoch 304/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6714.3689 - val_loss: 11455.4821\n",
      "Epoch 305/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6761.7665 - val_loss: 11434.8840\n",
      "Epoch 306/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6723.6596 - val_loss: 11397.2175\n",
      "Epoch 307/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 6692.3630 - val_loss: 11392.8770\n",
      "Epoch 308/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6675.4700 - val_loss: 11357.0759\n",
      "Epoch 309/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6655.5003 - val_loss: 11339.5527\n",
      "Epoch 310/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 6639.2278 - val_loss: 11330.0454\n",
      "Epoch 311/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6657.3308 - val_loss: 11307.6536\n",
      "Epoch 312/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6592.1817 - val_loss: 11284.3247\n",
      "Epoch 313/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6596.1832 - val_loss: 11280.5008\n",
      "Epoch 314/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6625.5523 - val_loss: 11237.1927\n",
      "Epoch 315/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6582.3409 - val_loss: 11236.6353\n",
      "Epoch 316/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6550.7982 - val_loss: 11253.8758\n",
      "Epoch 317/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6589.5741 - val_loss: 11198.5333\n",
      "Epoch 318/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6546.3887 - val_loss: 11160.3063\n",
      "Epoch 319/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6490.9067 - val_loss: 11138.8919\n",
      "Epoch 320/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6464.2659 - val_loss: 11121.7099\n",
      "Epoch 321/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6455.2366 - val_loss: 11103.2995\n",
      "Epoch 322/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6431.2938 - val_loss: 11104.5344\n",
      "Epoch 323/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6441.1395 - val_loss: 11168.6016\n",
      "Epoch 324/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6731.1749 - val_loss: 11137.3221\n",
      "Epoch 325/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6552.2756 - val_loss: 11081.8090\n",
      "Epoch 326/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6500.4705 - val_loss: 11045.8326\n",
      "Epoch 327/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6446.6221 - val_loss: 11019.5076\n",
      "Epoch 328/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6395.0456 - val_loss: 10989.4104\n",
      "Epoch 329/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6367.2753 - val_loss: 10962.7318\n",
      "Epoch 330/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6342.1131 - val_loss: 10941.3273\n",
      "Epoch 331/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6313.9380 - val_loss: 10901.5201\n",
      "Epoch 332/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6295.8207 - val_loss: 10921.0206\n",
      "Epoch 333/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6292.3674 - val_loss: 10900.5117\n",
      "Epoch 334/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6280.4923 - val_loss: 10872.4918\n",
      "Epoch 335/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6259.1598 - val_loss: 10874.0442\n",
      "Epoch 336/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6274.5922 - val_loss: 10826.2025\n",
      "Epoch 337/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6242.3227 - val_loss: 10837.7223\n",
      "Epoch 338/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6279.8183 - val_loss: 10829.0196\n",
      "Epoch 339/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 6246.5808 - val_loss: 10774.9637\n",
      "Epoch 340/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6263.8365 - val_loss: 10798.5927\n",
      "Epoch 341/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6227.0705 - val_loss: 10779.3505\n",
      "Epoch 342/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6212.9434 - val_loss: 10747.5489\n",
      "Epoch 343/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6202.2000 - val_loss: 10729.7269\n",
      "Epoch 344/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6362.3972 - val_loss: 10828.9883\n",
      "Epoch 345/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6303.3277 - val_loss: 10679.2892\n",
      "Epoch 346/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6174.4443 - val_loss: 10687.3993\n",
      "Epoch 347/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6147.0517 - val_loss: 10653.5351\n",
      "Epoch 348/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6127.4261 - val_loss: 10645.5983\n",
      "Epoch 349/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6106.5022 - val_loss: 10608.6849\n",
      "Epoch 350/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6077.1216 - val_loss: 10598.2596\n",
      "Epoch 351/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 6065.0862 - val_loss: 10582.0347\n",
      "Epoch 352/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 6076.1477 - val_loss: 10550.0374\n",
      "Epoch 353/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6058.7876 - val_loss: 10779.4337\n",
      "Epoch 354/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6894.8537 - val_loss: 10986.0330\n",
      "Epoch 355/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 7321.78 - 0s 51us/step - loss: 6702.2260 - val_loss: 10716.7673\n",
      "Epoch 356/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6304.9161 - val_loss: 10589.4567\n",
      "Epoch 357/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6178.5952 - val_loss: 10548.3301\n",
      "Epoch 358/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6077.0978 - val_loss: 10487.0438\n",
      "Epoch 359/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 5996.3431 - val_loss: 10446.5486\n",
      "Epoch 360/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5970.7374 - val_loss: 10421.6797\n",
      "Epoch 361/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 5943.8478 - val_loss: 10402.4600\n",
      "Epoch 362/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5939.2890 - val_loss: 10443.5331\n",
      "Epoch 363/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 6078.8733 - val_loss: 10411.9597\n",
      "Epoch 364/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5958.7434 - val_loss: 10389.3304\n",
      "Epoch 365/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5932.6726 - val_loss: 10346.2790\n",
      "Epoch 366/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5898.5623 - val_loss: 10311.4771\n",
      "Epoch 367/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5864.1769 - val_loss: 10296.9633\n",
      "Epoch 368/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 5842.0914 - val_loss: 10302.6603\n",
      "Epoch 369/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5859.8496 - val_loss: 10281.2109\n",
      "Epoch 370/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5848.2323 - val_loss: 10256.2950\n",
      "Epoch 371/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5832.3370 - val_loss: 10249.6145\n",
      "Epoch 372/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5837.2238 - val_loss: 10316.2433\n",
      "Epoch 373/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 6099.7749 - val_loss: 10333.2012\n",
      "Epoch 374/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5940.7925 - val_loss: 10253.6166\n",
      "Epoch 375/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5943.3070 - val_loss: 10214.1519\n",
      "Epoch 376/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5810.2163 - val_loss: 10177.4635\n",
      "Epoch 377/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5794.6648 - val_loss: 10140.9044\n",
      "Epoch 378/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5736.5692 - val_loss: 10109.2903\n",
      "Epoch 379/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5698.4230 - val_loss: 10093.7281\n",
      "Epoch 380/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 5688.3827 - val_loss: 10079.9136\n",
      "Epoch 381/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5828.4655 - val_loss: 10147.8296\n",
      "Epoch 382/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5785.4671 - val_loss: 10067.0252\n",
      "Epoch 383/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5715.5804 - val_loss: 10032.0532\n",
      "Epoch 384/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5663.1461 - val_loss: 10006.1981\n",
      "Epoch 385/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 5624.8745 - val_loss: 9995.1925\n",
      "Epoch 386/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 5615.1527 - val_loss: 9976.9495\n",
      "Epoch 387/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5594.4774 - val_loss: 9952.7293\n",
      "Epoch 388/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5590.6424 - val_loss: 9983.7696\n",
      "Epoch 389/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5643.5227 - val_loss: 10027.6106\n",
      "Epoch 390/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5860.0128 - val_loss: 10016.2363\n",
      "Epoch 391/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5710.3349 - val_loss: 9950.9766\n",
      "Epoch 392/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5622.7179 - val_loss: 9938.8259\n",
      "Epoch 393/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5627.6466 - val_loss: 9893.6946\n",
      "Epoch 394/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5534.2669 - val_loss: 9849.3913\n",
      "Epoch 395/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5514.7939 - val_loss: 9896.8963\n",
      "Epoch 396/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5716.1046 - val_loss: 9905.6977\n",
      "Epoch 397/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 5613.8493 - val_loss: 9876.8770\n",
      "Epoch 398/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5596.7594 - val_loss: 9820.5323\n",
      "Epoch 399/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5547.3774 - val_loss: 9812.5104\n",
      "Epoch 400/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5514.0285 - val_loss: 9786.9794\n",
      "Epoch 401/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5503.8212 - val_loss: 9749.5078\n",
      "Epoch 402/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5456.1075 - val_loss: 9730.4783\n",
      "Epoch 403/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 5431.9580 - val_loss: 9706.1103\n",
      "Epoch 404/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5404.2963 - val_loss: 9798.7436\n",
      "Epoch 405/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5690.1877 - val_loss: 9842.5533\n",
      "Epoch 406/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5623.6825 - val_loss: 9730.9631\n",
      "Epoch 407/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5460.2008 - val_loss: 9688.4578\n",
      "Epoch 408/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5434.7512 - val_loss: 9636.3496\n",
      "Epoch 409/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5389.5594 - val_loss: 9631.6191\n",
      "Epoch 410/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 5364.6340 - val_loss: 9581.5400\n",
      "Epoch 411/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5334.5742 - val_loss: 9620.9909\n",
      "Epoch 412/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5419.0127 - val_loss: 9572.9125\n",
      "Epoch 413/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5317.3052 - val_loss: 9521.4666\n",
      "Epoch 414/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5283.3828 - val_loss: 9480.4883\n",
      "Epoch 415/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5260.9119 - val_loss: 9493.3651\n",
      "Epoch 416/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5323.1770 - val_loss: 9461.8418\n",
      "Epoch 417/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5264.4307 - val_loss: 9416.4604\n",
      "Epoch 418/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5205.4257 - val_loss: 9399.9271\n",
      "Epoch 419/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5193.7736 - val_loss: 9354.1046\n",
      "Epoch 420/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5152.5319 - val_loss: 9372.7904\n",
      "Epoch 421/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5217.4650 - val_loss: 9356.4471\n",
      "Epoch 422/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5185.2029 - val_loss: 9315.7370\n",
      "Epoch 423/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 5146.8134 - val_loss: 9281.0538\n",
      "Epoch 424/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5103.3937 - val_loss: 9269.7273\n",
      "Epoch 425/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5091.0088 - val_loss: 9270.7595\n",
      "Epoch 426/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5327.6007 - val_loss: 9408.5032\n",
      "Epoch 427/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5382.9540 - val_loss: 9299.6728\n",
      "Epoch 428/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 5189.1153 - val_loss: 9234.0366\n",
      "Epoch 429/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5110.1134 - val_loss: 9198.6754\n",
      "Epoch 430/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5053.3710 - val_loss: 9163.1162\n",
      "Epoch 431/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5033.2559 - val_loss: 9133.9535\n",
      "Epoch 432/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5020.6732 - val_loss: 9111.0304\n",
      "Epoch 433/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4988.6931 - val_loss: 9104.1713\n",
      "Epoch 434/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 4986.7744 - val_loss: 9065.5106\n",
      "Epoch 435/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4952.6775 - val_loss: 9047.3980\n",
      "Epoch 436/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4936.8171 - val_loss: 9039.2518\n",
      "Epoch 437/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4929.4716 - val_loss: 9026.6669\n",
      "Epoch 438/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4922.9063 - val_loss: 9026.6976\n",
      "Epoch 439/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4926.9951 - val_loss: 8995.8207\n",
      "Epoch 440/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4896.0291 - val_loss: 8972.6308\n",
      "Epoch 441/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4878.3532 - val_loss: 8948.4786\n",
      "Epoch 442/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4863.9938 - val_loss: 8933.2672\n",
      "Epoch 443/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4868.1066 - val_loss: 8926.4279\n",
      "Epoch 444/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4845.4905 - val_loss: 8901.9065\n",
      "Epoch 445/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4830.7202 - val_loss: 8893.2714\n",
      "Epoch 446/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4864.7720 - val_loss: 8891.3616\n",
      "Epoch 447/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4846.8450 - val_loss: 8882.9075\n",
      "Epoch 448/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4822.6019 - val_loss: 8838.3610\n",
      "Epoch 449/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4798.4824 - val_loss: 8820.0395\n",
      "Epoch 450/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4763.6854 - val_loss: 8791.2627\n",
      "Epoch 451/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4750.3319 - val_loss: 8792.1749\n",
      "Epoch 452/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4769.8825 - val_loss: 8928.2820\n",
      "Epoch 453/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5257.0342 - val_loss: 9049.9414\n",
      "Epoch 454/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5206.8984 - val_loss: 8901.7883\n",
      "Epoch 455/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4951.8852 - val_loss: 8790.3569\n",
      "Epoch 456/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4812.0576 - val_loss: 8771.6811\n",
      "Epoch 457/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4774.6208 - val_loss: 8722.5976\n",
      "Epoch 458/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4732.7817 - val_loss: 8685.0240\n",
      "Epoch 459/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4690.5271 - val_loss: 8670.5390\n",
      "Epoch 460/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4679.0630 - val_loss: 8640.3352\n",
      "Epoch 461/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4656.0151 - val_loss: 8637.3753\n",
      "Epoch 462/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4676.4306 - val_loss: 8622.3102\n",
      "Epoch 463/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4649.5403 - val_loss: 8631.1201\n",
      "Epoch 464/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4699.1536 - val_loss: 8625.4154\n",
      "Epoch 465/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4717.3833 - val_loss: 8603.7805\n",
      "Epoch 466/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4650.8945 - val_loss: 8581.1753\n",
      "Epoch 467/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4647.3072 - val_loss: 8554.3270\n",
      "Epoch 468/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4608.2006 - val_loss: 8559.1008\n",
      "Epoch 469/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4618.0298 - val_loss: 8523.6436\n",
      "Epoch 470/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4575.9326 - val_loss: 8517.9054\n",
      "Epoch 471/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4746.3951 - val_loss: 8630.2789\n",
      "Epoch 472/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4773.1820 - val_loss: 8513.7093\n",
      "Epoch 473/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4602.7515 - val_loss: 8477.9620\n",
      "Epoch 474/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4569.5548 - val_loss: 8470.3650\n",
      "Epoch 475/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4578.0098 - val_loss: 8449.9109\n",
      "Epoch 476/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4539.0493 - val_loss: 8394.9757\n",
      "Epoch 477/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4483.7099 - val_loss: 8390.2230\n",
      "Epoch 478/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4484.4572 - val_loss: 8405.7508\n",
      "Epoch 479/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4512.6837 - val_loss: 8359.3916\n",
      "Epoch 480/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4477.8829 - val_loss: 8347.1868\n",
      "Epoch 481/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4455.0407 - val_loss: 8333.2034\n",
      "Epoch 482/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4462.3042 - val_loss: 8328.0120\n",
      "Epoch 483/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4452.8379 - val_loss: 8314.8962\n",
      "Epoch 484/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4446.4399 - val_loss: 8300.0991\n",
      "Epoch 485/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4515.4588 - val_loss: 8345.9892\n",
      "Epoch 486/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4497.3658 - val_loss: 8269.2056\n",
      "Epoch 487/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4406.1032 - val_loss: 8227.7237\n",
      "Epoch 488/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4365.3873 - val_loss: 8211.7558\n",
      "Epoch 489/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4345.4680 - val_loss: 8195.0839\n",
      "Epoch 490/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4334.3870 - val_loss: 8184.8802\n",
      "Epoch 491/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4341.8722 - val_loss: 8203.1227\n",
      "Epoch 492/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4581.3376 - val_loss: 8352.9994\n",
      "Epoch 493/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4606.1908 - val_loss: 8249.4630\n",
      "Epoch 494/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4468.9866 - val_loss: 8203.1079\n",
      "Epoch 495/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4399.3345 - val_loss: 8159.4708\n",
      "Epoch 496/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 4382.0564 - val_loss: 8141.4576\n",
      "Epoch 497/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4346.8419 - val_loss: 8105.2776\n",
      "Epoch 498/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4284.8176 - val_loss: 8104.9467\n",
      "Epoch 499/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4308.6361 - val_loss: 8107.4542\n",
      "Epoch 500/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 4492.6131 - val_loss: 8206.8630\n",
      "Epoch 501/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4537.2401 - val_loss: 8142.5822\n",
      "Epoch 502/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4385.6493 - val_loss: 8074.9764\n",
      "Epoch 503/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4285.5400 - val_loss: 8039.2876\n",
      "Epoch 504/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4263.9396 - val_loss: 7986.3215\n",
      "Epoch 505/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4216.3441 - val_loss: 7984.7566\n",
      "Epoch 506/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4207.0027 - val_loss: 7984.5017\n",
      "Epoch 507/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 4258.8742 - val_loss: 7969.6150\n",
      "Epoch 508/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4198.1911 - val_loss: 7924.9260\n",
      "Epoch 509/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4159.1976 - val_loss: 7909.1873\n",
      "Epoch 510/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4137.6045 - val_loss: 7911.9450\n",
      "Epoch 511/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4150.2930 - val_loss: 7909.1810\n",
      "Epoch 512/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4209.5765 - val_loss: 7915.8514\n",
      "Epoch 513/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4174.0691 - val_loss: 7862.0403\n",
      "Epoch 514/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4113.9172 - val_loss: 7836.3736\n",
      "Epoch 515/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4094.1477 - val_loss: 7839.1925\n",
      "Epoch 516/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 4100.6079 - val_loss: 7824.6346\n",
      "Epoch 517/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4089.9914 - val_loss: 7799.3094\n",
      "Epoch 518/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4064.3082 - val_loss: 7776.6215\n",
      "Epoch 519/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4054.4679 - val_loss: 7780.1496\n",
      "Epoch 520/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4057.1577 - val_loss: 7772.3327\n",
      "Epoch 521/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4052.9693 - val_loss: 7754.6753\n",
      "Epoch 522/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 4027.4723 - val_loss: 7722.0324\n",
      "Epoch 523/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4005.3185 - val_loss: 7704.1067\n",
      "Epoch 524/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 3999.6816 - val_loss: 7705.9038\n",
      "Epoch 525/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 3999.3249 - val_loss: 7687.1149\n",
      "Epoch 526/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 3976.1725 - val_loss: 7682.3639\n",
      "Epoch 527/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4013.0307 - val_loss: 7760.6887\n",
      "Epoch 528/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4179.0666 - val_loss: 7752.3605\n",
      "Epoch 529/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4106.0681 - val_loss: 7672.2041\n",
      "Epoch 530/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4008.4918 - val_loss: 7661.9369\n",
      "Epoch 531/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3990.4066 - val_loss: 7683.6146\n",
      "Epoch 532/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4226.7748 - val_loss: 7813.8623\n",
      "Epoch 533/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 4329.4686 - val_loss: 7734.8238\n",
      "Epoch 534/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4180.9984 - val_loss: 7643.2404\n",
      "Epoch 535/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4064.4909 - val_loss: 7624.2939\n",
      "Epoch 536/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3967.1075 - val_loss: 7563.6028\n",
      "Epoch 537/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3929.3712 - val_loss: 7541.6799\n",
      "Epoch 538/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3891.9420 - val_loss: 7508.0147\n",
      "Epoch 539/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3883.5839 - val_loss: 7544.4693\n",
      "Epoch 540/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3911.9272 - val_loss: 7491.3540\n",
      "Epoch 541/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3879.6743 - val_loss: 7481.2199\n",
      "Epoch 542/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 3846.8284 - val_loss: 7462.1094\n",
      "Epoch 543/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3845.5989 - val_loss: 7450.2998\n",
      "Epoch 544/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3838.3114 - val_loss: 7467.9566\n",
      "Epoch 545/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3871.3991 - val_loss: 7408.8210\n",
      "Epoch 546/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3814.1977 - val_loss: 7413.6305\n",
      "Epoch 547/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3803.4175 - val_loss: 7438.2168\n",
      "Epoch 548/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3855.4403 - val_loss: 7412.0803\n",
      "Epoch 549/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3839.8336 - val_loss: 7390.6279\n",
      "Epoch 550/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3805.3897 - val_loss: 7374.2387\n",
      "Epoch 551/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3822.6771 - val_loss: 7363.6779\n",
      "Epoch 552/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 3778.1368 - val_loss: 7318.1226\n",
      "Epoch 553/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3851.7196 - val_loss: 7440.3744\n",
      "Epoch 554/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3961.3353 - val_loss: 7371.2193\n",
      "Epoch 555/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3825.0390 - val_loss: 7321.5508\n",
      "Epoch 556/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3771.3009 - val_loss: 7309.5327\n",
      "Epoch 557/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3759.1814 - val_loss: 7274.2380\n",
      "Epoch 558/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3725.8945 - val_loss: 7289.5805\n",
      "Epoch 559/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3768.8582 - val_loss: 7262.7910\n",
      "Epoch 560/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3725.5966 - val_loss: 7248.7351\n",
      "Epoch 561/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3723.1089 - val_loss: 7253.4906\n",
      "Epoch 562/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3791.6817 - val_loss: 7216.0545\n",
      "Epoch 563/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3700.0915 - val_loss: 7219.7944\n",
      "Epoch 564/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3697.3705 - val_loss: 7223.6871\n",
      "Epoch 565/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3795.6989 - val_loss: 7258.9354\n",
      "Epoch 566/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3802.7868 - val_loss: 7228.0863\n",
      "Epoch 567/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3740.6743 - val_loss: 7197.9196\n",
      "Epoch 568/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3735.2533 - val_loss: 7162.5829\n",
      "Epoch 569/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3661.6505 - val_loss: 7111.5943\n",
      "Epoch 570/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3626.3694 - val_loss: 7094.0709\n",
      "Epoch 571/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 3582.2368 - val_loss: 7091.5102\n",
      "Epoch 572/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3593.8438 - val_loss: 7098.2788\n",
      "Epoch 573/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3626.7292 - val_loss: 7063.8968\n",
      "Epoch 574/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3578.7472 - val_loss: 7040.5610\n",
      "Epoch 575/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3566.9415 - val_loss: 7027.8029\n",
      "Epoch 576/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3537.9146 - val_loss: 7034.6887\n",
      "Epoch 577/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3595.3608 - val_loss: 7025.7474\n",
      "Epoch 578/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3563.2086 - val_loss: 7007.1105\n",
      "Epoch 579/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3546.8589 - val_loss: 6992.2565\n",
      "Epoch 580/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 3526.7411 - val_loss: 6964.3414\n",
      "Epoch 581/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3499.3815 - val_loss: 6965.1181\n",
      "Epoch 582/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3526.4943 - val_loss: 6971.9969\n",
      "Epoch 583/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3519.1823 - val_loss: 6953.0071\n",
      "Epoch 584/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3601.6737 - val_loss: 6999.5763\n",
      "Epoch 585/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3577.1086 - val_loss: 6941.0399\n",
      "Epoch 586/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3511.2504 - val_loss: 6900.9592\n",
      "Epoch 587/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3470.4088 - val_loss: 6885.9366\n",
      "Epoch 588/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3460.9130 - val_loss: 6895.7694\n",
      "Epoch 589/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3486.5520 - val_loss: 6905.1249\n",
      "Epoch 590/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3522.1458 - val_loss: 6892.0242\n",
      "Epoch 591/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3483.7439 - val_loss: 6844.4077\n",
      "Epoch 592/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3445.4004 - val_loss: 6844.4006\n",
      "Epoch 593/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3438.2842 - val_loss: 6849.7340\n",
      "Epoch 594/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3484.4102 - val_loss: 6818.2439\n",
      "Epoch 595/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3436.5851 - val_loss: 6812.6150\n",
      "Epoch 596/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3430.3183 - val_loss: 6810.1020\n",
      "Epoch 597/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3436.6724 - val_loss: 6783.3672\n",
      "Epoch 598/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3409.2430 - val_loss: 6770.0428\n",
      "Epoch 599/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3413.3586 - val_loss: 6768.9324\n",
      "Epoch 600/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 3424.9049 - val_loss: 6760.9768\n",
      "Epoch 601/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3379.2111 - val_loss: 6726.6937\n",
      "Epoch 602/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3363.1754 - val_loss: 6731.6349\n",
      "Epoch 603/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3365.3091 - val_loss: 6701.9302\n",
      "Epoch 604/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3350.6065 - val_loss: 6738.8289\n",
      "Epoch 605/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3385.0496 - val_loss: 6688.7487\n",
      "Epoch 606/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3367.7976 - val_loss: 6677.2499\n",
      "Epoch 607/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3327.2270 - val_loss: 6667.6464\n",
      "Epoch 608/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3328.2973 - val_loss: 6643.1864\n",
      "Epoch 609/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3307.5315 - val_loss: 6649.0752\n",
      "Epoch 610/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3304.1689 - val_loss: 6623.5210\n",
      "Epoch 611/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 3290.5462 - val_loss: 6622.5258\n",
      "Epoch 612/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3293.5662 - val_loss: 6615.6013\n",
      "Epoch 613/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 3295.0037 - val_loss: 6590.9694\n",
      "Epoch 614/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3266.7242 - val_loss: 6580.7014\n",
      "Epoch 615/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3249.7001 - val_loss: 6576.0476\n",
      "Epoch 616/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3286.1975 - val_loss: 6561.1064\n",
      "Epoch 617/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3320.8254 - val_loss: 6570.9459\n",
      "Epoch 618/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3283.8799 - val_loss: 6547.1965\n",
      "Epoch 619/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3257.8467 - val_loss: 6506.0653\n",
      "Epoch 620/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3211.9935 - val_loss: 6490.1901\n",
      "Epoch 621/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3206.4107 - val_loss: 6597.2419\n",
      "Epoch 622/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3440.6422 - val_loss: 6557.9694\n",
      "Epoch 623/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3303.2146 - val_loss: 6501.7897\n",
      "Epoch 624/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3240.4466 - val_loss: 6475.9489\n",
      "Epoch 625/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3212.0815 - val_loss: 6477.2538\n",
      "Epoch 626/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3286.9622 - val_loss: 6523.7960\n",
      "Epoch 627/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3280.9445 - val_loss: 6453.5150\n",
      "Epoch 628/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3222.7442 - val_loss: 6438.8921\n",
      "Epoch 629/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 3202.3374 - val_loss: 6445.6263\n",
      "Epoch 630/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3281.1951 - val_loss: 6473.2700\n",
      "Epoch 631/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3256.0411 - val_loss: 6421.0739\n",
      "Epoch 632/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3191.6058 - val_loss: 6393.7761\n",
      "Epoch 633/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3155.5127 - val_loss: 6368.6985\n",
      "Epoch 634/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3148.7227 - val_loss: 6348.5868\n",
      "Epoch 635/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3120.3990 - val_loss: 6321.9985\n",
      "Epoch 636/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3095.8840 - val_loss: 6328.9426\n",
      "Epoch 637/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3093.8302 - val_loss: 6320.2417\n",
      "Epoch 638/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3121.0711 - val_loss: 6357.4382\n",
      "Epoch 639/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3184.2270 - val_loss: 6334.2634\n",
      "Epoch 640/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3130.2950 - val_loss: 6280.5442\n",
      "Epoch 641/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3082.9785 - val_loss: 6272.8061\n",
      "Epoch 642/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3086.0402 - val_loss: 6250.7696\n",
      "Epoch 643/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3054.8793 - val_loss: 6235.5505\n",
      "Epoch 644/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3055.3023 - val_loss: 6233.7824\n",
      "Epoch 645/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3031.8174 - val_loss: 6219.4316\n",
      "Epoch 646/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3068.0027 - val_loss: 6218.6168\n",
      "Epoch 647/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3051.2074 - val_loss: 6211.5910\n",
      "Epoch 648/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3047.6618 - val_loss: 6226.9268\n",
      "Epoch 649/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3071.0271 - val_loss: 6206.0666\n",
      "Epoch 650/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3035.4448 - val_loss: 6179.7664\n",
      "Epoch 651/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 3020.4193 - val_loss: 6184.5336\n",
      "Epoch 652/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3060.6818 - val_loss: 6171.0202\n",
      "Epoch 653/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 3031.7241 - val_loss: 6157.5793\n",
      "Epoch 654/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3019.7607 - val_loss: 6123.8846\n",
      "Epoch 655/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2984.7531 - val_loss: 6117.4570\n",
      "Epoch 656/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2989.2287 - val_loss: 6235.7332\n",
      "Epoch 657/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3306.6860 - val_loss: 6268.2763\n",
      "Epoch 658/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3242.6799 - val_loss: 6151.6576\n",
      "Epoch 659/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3073.5166 - val_loss: 6103.4197\n",
      "Epoch 660/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3020.1172 - val_loss: 6109.7945\n",
      "Epoch 661/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2996.2779 - val_loss: 6125.6589\n",
      "Epoch 662/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3119.0715 - val_loss: 6153.3761\n",
      "Epoch 663/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3138.1759 - val_loss: 6107.0554\n",
      "Epoch 664/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3071.0304 - val_loss: 6071.0336\n",
      "Epoch 665/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2977.4365 - val_loss: 6025.6348\n",
      "Epoch 666/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3014.0003 - val_loss: 6284.4521\n",
      "Epoch 667/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3491.8978 - val_loss: 6290.9129\n",
      "Epoch 668/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3359.2613 - val_loss: 6108.5639\n",
      "Epoch 669/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3147.8657 - val_loss: 6042.8784\n",
      "Epoch 670/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3009.5576 - val_loss: 5979.8069\n",
      "Epoch 671/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2894.2901 - val_loss: 6001.8395\n",
      "Epoch 672/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3036.9590 - val_loss: 5998.9309\n",
      "Epoch 673/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2930.8841 - val_loss: 5981.1175\n",
      "Epoch 674/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2954.3574 - val_loss: 5934.1177\n",
      "Epoch 675/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2879.7139 - val_loss: 5945.2097\n",
      "Epoch 676/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2878.5891 - val_loss: 5886.7635\n",
      "Epoch 677/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2827.4450 - val_loss: 5874.2669\n",
      "Epoch 678/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2824.6689 - val_loss: 5869.4218\n",
      "Epoch 679/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2808.3549 - val_loss: 5852.1031\n",
      "Epoch 680/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2790.1518 - val_loss: 5829.3413\n",
      "Epoch 681/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2806.4474 - val_loss: 5859.5386\n",
      "Epoch 682/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2831.0852 - val_loss: 5826.8171\n",
      "Epoch 683/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2784.5140 - val_loss: 5808.6737\n",
      "Epoch 684/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2785.5494 - val_loss: 5857.6494\n",
      "Epoch 685/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2862.0061 - val_loss: 5816.3393\n",
      "Epoch 686/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2820.1974 - val_loss: 5792.1925\n",
      "Epoch 687/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2756.7291 - val_loss: 5786.2193\n",
      "Epoch 688/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2783.8715 - val_loss: 5867.7916\n",
      "Epoch 689/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2947.4295 - val_loss: 5896.8873\n",
      "Epoch 690/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2989.7371 - val_loss: 5847.3452\n",
      "Epoch 691/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2895.7249 - val_loss: 5800.8990\n",
      "Epoch 692/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2853.9372 - val_loss: 5742.3562\n",
      "Epoch 693/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2753.2646 - val_loss: 5743.1824\n",
      "Epoch 694/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2769.0427 - val_loss: 5700.8871\n",
      "Epoch 695/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2718.6520 - val_loss: 5701.7058\n",
      "Epoch 696/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2726.0457 - val_loss: 5687.1607\n",
      "Epoch 697/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2716.7261 - val_loss: 5671.2740\n",
      "Epoch 698/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2693.3474 - val_loss: 5673.3948\n",
      "Epoch 699/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2695.0159 - val_loss: 5682.2668\n",
      "Epoch 700/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2714.8567 - val_loss: 5641.5529\n",
      "Epoch 701/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2681.0848 - val_loss: 5645.2650\n",
      "Epoch 702/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2677.4579 - val_loss: 5623.7641\n",
      "Epoch 703/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 2662.1192 - val_loss: 5622.5485\n",
      "Epoch 704/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2691.0778 - val_loss: 5594.3738\n",
      "Epoch 705/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2651.6052 - val_loss: 5596.9244\n",
      "Epoch 706/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2663.7821 - val_loss: 5598.5862\n",
      "Epoch 707/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2673.4262 - val_loss: 5569.2147\n",
      "Epoch 708/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2649.3972 - val_loss: 5588.5547\n",
      "Epoch 709/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2641.9446 - val_loss: 5574.1709\n",
      "Epoch 710/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2642.2737 - val_loss: 5553.6750\n",
      "Epoch 711/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2631.5533 - val_loss: 5556.6876\n",
      "Epoch 712/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2634.6812 - val_loss: 5548.8194\n",
      "Epoch 713/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2644.8893 - val_loss: 5523.5730\n",
      "Epoch 714/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2616.5951 - val_loss: 5504.2879\n",
      "Epoch 715/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2587.2208 - val_loss: 5503.6372\n",
      "Epoch 716/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 2586.8054 - val_loss: 5514.6033\n",
      "Epoch 717/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 2600.7378 - val_loss: 5474.3246\n",
      "Epoch 718/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2574.0380 - val_loss: 5490.4902\n",
      "Epoch 719/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2604.4168 - val_loss: 5494.1274\n",
      "Epoch 720/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2614.8774 - val_loss: 5465.1457\n",
      "Epoch 721/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2580.7244 - val_loss: 5455.4675\n",
      "Epoch 722/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2566.2850 - val_loss: 5429.4959\n",
      "Epoch 723/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2571.0336 - val_loss: 5431.2385\n",
      "Epoch 724/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2557.8646 - val_loss: 5403.6508\n",
      "Epoch 725/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2532.7395 - val_loss: 5398.5237\n",
      "Epoch 726/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 2525.4757 - val_loss: 5399.2345\n",
      "Epoch 727/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2522.8794 - val_loss: 5434.8125\n",
      "Epoch 728/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2602.8975 - val_loss: 5425.8122\n",
      "Epoch 729/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2567.7138 - val_loss: 5397.6355\n",
      "Epoch 730/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2537.1092 - val_loss: 5350.3569\n",
      "Epoch 731/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2509.8219 - val_loss: 5390.9758\n",
      "Epoch 732/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2614.9991 - val_loss: 5416.3850\n",
      "Epoch 733/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2594.8903 - val_loss: 5360.5697\n",
      "Epoch 734/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2521.9292 - val_loss: 5364.9324\n",
      "Epoch 735/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2529.9756 - val_loss: 5329.3879\n",
      "Epoch 736/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2504.6663 - val_loss: 5323.3641\n",
      "Epoch 737/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2483.7303 - val_loss: 5298.6210\n",
      "Epoch 738/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2503.0893 - val_loss: 5298.9186\n",
      "Epoch 739/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2489.7258 - val_loss: 5279.7752\n",
      "Epoch 740/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2479.4280 - val_loss: 5280.4606\n",
      "Epoch 741/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2474.7890 - val_loss: 5247.2892\n",
      "Epoch 742/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2443.4452 - val_loss: 5277.9166\n",
      "Epoch 743/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2489.8922 - val_loss: 5265.7951\n",
      "Epoch 744/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2489.1234 - val_loss: 5238.9530\n",
      "Epoch 745/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2444.1037 - val_loss: 5242.7259\n",
      "Epoch 746/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2456.9987 - val_loss: 5226.0773\n",
      "Epoch 747/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2451.4617 - val_loss: 5200.0000\n",
      "Epoch 748/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2408.5781 - val_loss: 5189.1417\n",
      "Epoch 749/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2408.1326 - val_loss: 5170.3100\n",
      "Epoch 750/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2406.2005 - val_loss: 5185.5623\n",
      "Epoch 751/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2412.4850 - val_loss: 5157.8777\n",
      "Epoch 752/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2404.8489 - val_loss: 5175.6753\n",
      "Epoch 753/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2445.8667 - val_loss: 5162.3612\n",
      "Epoch 754/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2414.1580 - val_loss: 5174.7753\n",
      "Epoch 755/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2465.7487 - val_loss: 5177.4082\n",
      "Epoch 756/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2447.2422 - val_loss: 5145.6024\n",
      "Epoch 757/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2410.7473 - val_loss: 5125.4417\n",
      "Epoch 758/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2374.4044 - val_loss: 5117.4718\n",
      "Epoch 759/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2385.7289 - val_loss: 5107.8657\n",
      "Epoch 760/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2381.8734 - val_loss: 5127.2549\n",
      "Epoch 761/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2414.0489 - val_loss: 5140.4917\n",
      "Epoch 762/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2443.4102 - val_loss: 5121.4505\n",
      "Epoch 763/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2405.1870 - val_loss: 5103.7760\n",
      "Epoch 764/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2398.9069 - val_loss: 5087.0225\n",
      "Epoch 765/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2364.0200 - val_loss: 5043.9277\n",
      "Epoch 766/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2325.2382 - val_loss: 5053.7006\n",
      "Epoch 767/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2339.1990 - val_loss: 5027.3580\n",
      "Epoch 768/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2313.5194 - val_loss: 5029.0708\n",
      "Epoch 769/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2324.9698 - val_loss: 5033.7293\n",
      "Epoch 770/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2359.0281 - val_loss: 5047.9765\n",
      "Epoch 771/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2366.1192 - val_loss: 5027.4736\n",
      "Epoch 772/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2339.1184 - val_loss: 5016.4031\n",
      "Epoch 773/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2325.9303 - val_loss: 5023.2151\n",
      "Epoch 774/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2418.0951 - val_loss: 5023.0958\n",
      "Epoch 775/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2367.2728 - val_loss: 5003.5913\n",
      "Epoch 776/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2398.9060 - val_loss: 5233.1950\n",
      "Epoch 777/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2998.5985 - val_loss: 5332.8451\n",
      "Epoch 778/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2940.6928 - val_loss: 5204.4200\n",
      "Epoch 779/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2690.3648 - val_loss: 5109.0854\n",
      "Epoch 780/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2583.6209 - val_loss: 5042.1642\n",
      "Epoch 781/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2471.1932 - val_loss: 4989.1209\n",
      "Epoch 782/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2359.5800 - val_loss: 4920.0715\n",
      "Epoch 783/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2279.0275 - val_loss: 4908.5189\n",
      "Epoch 784/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2270.0816 - val_loss: 4887.9239\n",
      "Epoch 785/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2268.6350 - val_loss: 4903.9052\n",
      "Epoch 786/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2266.7281 - val_loss: 4862.6763\n",
      "Epoch 787/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2225.9194 - val_loss: 4858.3472\n",
      "Epoch 788/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2216.8544 - val_loss: 4842.6417\n",
      "Epoch 789/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2216.5781 - val_loss: 4850.1807\n",
      "Epoch 790/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2252.5548 - val_loss: 4852.9652\n",
      "Epoch 791/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2262.8707 - val_loss: 4840.0620\n",
      "Epoch 792/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2235.2539 - val_loss: 4829.4412\n",
      "Epoch 793/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2242.0023 - val_loss: 4829.3808\n",
      "Epoch 794/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2213.7698 - val_loss: 4825.8022\n",
      "Epoch 795/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2346.6829 - val_loss: 4923.7274\n",
      "Epoch 796/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2412.5274 - val_loss: 4868.3850\n",
      "Epoch 797/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2303.4988 - val_loss: 4797.4379\n",
      "Epoch 798/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2229.1106 - val_loss: 4811.9235\n",
      "Epoch 799/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 2245.6118 - val_loss: 4787.0679\n",
      "Epoch 800/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2215.6440 - val_loss: 4786.3345\n",
      "Epoch 801/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2215.9422 - val_loss: 4806.8895\n",
      "Epoch 802/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2225.4869 - val_loss: 4764.4692\n",
      "Epoch 803/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2184.4679 - val_loss: 4775.8053\n",
      "Epoch 804/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2299.1833 - val_loss: 4828.8204\n",
      "Epoch 805/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2291.2299 - val_loss: 4767.4642\n",
      "Epoch 806/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2248.3504 - val_loss: 4734.8321\n",
      "Epoch 807/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2177.0457 - val_loss: 4704.4220\n",
      "Epoch 808/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2172.3376 - val_loss: 4725.2267\n",
      "Epoch 809/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2179.4323 - val_loss: 4702.9937\n",
      "Epoch 810/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2146.8215 - val_loss: 4675.8657\n",
      "Epoch 811/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2132.7846 - val_loss: 4679.1501\n",
      "Epoch 812/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2134.6745 - val_loss: 4648.6616\n",
      "Epoch 813/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2105.1676 - val_loss: 4673.4706\n",
      "Epoch 814/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2172.2429 - val_loss: 4657.2077\n",
      "Epoch 815/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2140.6789 - val_loss: 4655.3312\n",
      "Epoch 816/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2128.9177 - val_loss: 4687.5387\n",
      "Epoch 817/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2213.8274 - val_loss: 4635.4937\n",
      "Epoch 818/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2137.2482 - val_loss: 4643.5002\n",
      "Epoch 819/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2145.7133 - val_loss: 4635.0206\n",
      "Epoch 820/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2130.0730 - val_loss: 4619.7229\n",
      "Epoch 821/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2110.3711 - val_loss: 4593.6444\n",
      "Epoch 822/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2096.1134 - val_loss: 4602.1952\n",
      "Epoch 823/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2102.4658 - val_loss: 4573.3985\n",
      "Epoch 824/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2081.5064 - val_loss: 4565.8527\n",
      "Epoch 825/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2059.4473 - val_loss: 4548.4198\n",
      "Epoch 826/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2054.9700 - val_loss: 4563.8399\n",
      "Epoch 827/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2076.0404 - val_loss: 4558.5876\n",
      "Epoch 828/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2094.2986 - val_loss: 4557.3665\n",
      "Epoch 829/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2074.7397 - val_loss: 4576.7987\n",
      "Epoch 830/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2088.3713 - val_loss: 4540.9279\n",
      "Epoch 831/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2056.5770 - val_loss: 4506.1294\n",
      "Epoch 832/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 2029.6824 - val_loss: 4487.9043\n",
      "Epoch 833/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 2019.2357 - val_loss: 4499.5962\n",
      "Epoch 834/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2035.1457 - val_loss: 4513.0070\n",
      "Epoch 835/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2059.1848 - val_loss: 4486.3848\n",
      "Epoch 836/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2027.2598 - val_loss: 4475.0880\n",
      "Epoch 837/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2028.8867 - val_loss: 4481.1568\n",
      "Epoch 838/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2044.1101 - val_loss: 4467.2295\n",
      "Epoch 839/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2020.0315 - val_loss: 4454.3632\n",
      "Epoch 840/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2010.3535 - val_loss: 4473.6187\n",
      "Epoch 841/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2044.3366 - val_loss: 4459.6563\n",
      "Epoch 842/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2019.8174 - val_loss: 4433.5993\n",
      "Epoch 843/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2010.4504 - val_loss: 4431.3832\n",
      "Epoch 844/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1997.8014 - val_loss: 4412.4592\n",
      "Epoch 845/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1991.2482 - val_loss: 4404.5317\n",
      "Epoch 846/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1981.6896 - val_loss: 4389.6948\n",
      "Epoch 847/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 2054.63 - 0s 52us/step - loss: 1963.8253 - val_loss: 4376.8543\n",
      "Epoch 848/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1950.8895 - val_loss: 4389.0231\n",
      "Epoch 849/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1973.6639 - val_loss: 4385.1676\n",
      "Epoch 850/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1959.6326 - val_loss: 4370.4901\n",
      "Epoch 851/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1954.6562 - val_loss: 4391.8170\n",
      "Epoch 852/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1999.0604 - val_loss: 4421.4322\n",
      "Epoch 853/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2104.1076 - val_loss: 4437.5852\n",
      "Epoch 854/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2076.2303 - val_loss: 4399.9290\n",
      "Epoch 855/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2046.0941 - val_loss: 4373.3038\n",
      "Epoch 856/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2011.0232 - val_loss: 4347.4633\n",
      "Epoch 857/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1982.7154 - val_loss: 4331.2811\n",
      "Epoch 858/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1950.9886 - val_loss: 4320.3778\n",
      "Epoch 859/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1979.4567 - val_loss: 4562.5072\n",
      "Epoch 860/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 2705.9290 - val_loss: 4819.0545\n",
      "Epoch 861/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2878.3385 - val_loss: 4714.0581\n",
      "Epoch 862/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2650.7241 - val_loss: 4565.0961\n",
      "Epoch 863/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2397.3163 - val_loss: 4474.9169\n",
      "Epoch 864/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2242.8474 - val_loss: 4405.8335\n",
      "Epoch 865/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2135.6256 - val_loss: 4343.9270\n",
      "Epoch 866/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2052.0723 - val_loss: 4290.7259\n",
      "Epoch 867/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1972.9365 - val_loss: 4257.9971\n",
      "Epoch 868/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1987.7914 - val_loss: 4390.8763\n",
      "Epoch 869/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2149.6610 - val_loss: 4305.3955\n",
      "Epoch 870/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2024.9757 - val_loss: 4263.5861\n",
      "Epoch 871/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1960.3504 - val_loss: 4237.7174\n",
      "Epoch 872/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 1911.0632 - val_loss: 4213.0854\n",
      "Epoch 873/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1886.3250 - val_loss: 4199.3243\n",
      "Epoch 874/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1870.6652 - val_loss: 4223.5255\n",
      "Epoch 875/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1908.0066 - val_loss: 4203.4874\n",
      "Epoch 876/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1942.5000 - val_loss: 4202.7477\n",
      "Epoch 877/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1898.6894 - val_loss: 4214.3601\n",
      "Epoch 878/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1908.2974 - val_loss: 4187.1930\n",
      "Epoch 879/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1898.3148 - val_loss: 4167.2202\n",
      "Epoch 880/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1868.2523 - val_loss: 4173.1279\n",
      "Epoch 881/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1886.5809 - val_loss: 4166.9801\n",
      "Epoch 882/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1897.9257 - val_loss: 4157.8435\n",
      "Epoch 883/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1891.3911 - val_loss: 4190.2948\n",
      "Epoch 884/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1916.1960 - val_loss: 4169.9309\n",
      "Epoch 885/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1878.5218 - val_loss: 4139.5606\n",
      "Epoch 886/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1868.6158 - val_loss: 4132.4298\n",
      "Epoch 887/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1868.7802 - val_loss: 4105.5468\n",
      "Epoch 888/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1833.3472 - val_loss: 4126.5406\n",
      "Epoch 889/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1861.2068 - val_loss: 4114.2353\n",
      "Epoch 890/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1852.0990 - val_loss: 4115.9320\n",
      "Epoch 891/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1850.9101 - val_loss: 4120.3633\n",
      "Epoch 892/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1950.3104 - val_loss: 4180.4373\n",
      "Epoch 893/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1965.0855 - val_loss: 4099.8741\n",
      "Epoch 894/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1861.8406 - val_loss: 4080.1252\n",
      "Epoch 895/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1816.5937 - val_loss: 4075.0122\n",
      "Epoch 896/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1835.1901 - val_loss: 4078.0606\n",
      "Epoch 897/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1836.1443 - val_loss: 4060.0456\n",
      "Epoch 898/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1822.1794 - val_loss: 4061.0061\n",
      "Epoch 899/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1846.8307 - val_loss: 4046.3166\n",
      "Epoch 900/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1814.9237 - val_loss: 4033.0801\n",
      "Epoch 901/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1791.8741 - val_loss: 4016.7320\n",
      "Epoch 902/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1790.7476 - val_loss: 4021.3111\n",
      "Epoch 903/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1844.9033 - val_loss: 4048.2011\n",
      "Epoch 904/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1842.5436 - val_loss: 4028.7085\n",
      "Epoch 905/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1790.6898 - val_loss: 3991.5285\n",
      "Epoch 906/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1786.1641 - val_loss: 4006.9469\n",
      "Epoch 907/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1789.0400 - val_loss: 3983.6726\n",
      "Epoch 908/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1787.1627 - val_loss: 3984.8370\n",
      "Epoch 909/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1789.7522 - val_loss: 3990.9028\n",
      "Epoch 910/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1785.0725 - val_loss: 3981.1157\n",
      "Epoch 911/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1787.8824 - val_loss: 3961.5666\n",
      "Epoch 912/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1764.6187 - val_loss: 3941.1163\n",
      "Epoch 913/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1738.3721 - val_loss: 3959.6547\n",
      "Epoch 914/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1768.6948 - val_loss: 3984.2275\n",
      "Epoch 915/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1875.5556 - val_loss: 4002.4372\n",
      "Epoch 916/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1855.9036 - val_loss: 3961.3818\n",
      "Epoch 917/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1806.2379 - val_loss: 3929.3696\n",
      "Epoch 918/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1761.6649 - val_loss: 3913.0809\n",
      "Epoch 919/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1746.8511 - val_loss: 3909.6735\n",
      "Epoch 920/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1743.8406 - val_loss: 3913.0798\n",
      "Epoch 921/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1753.9632 - val_loss: 3906.0637\n",
      "Epoch 922/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1732.9415 - val_loss: 3889.3403\n",
      "Epoch 923/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1730.2964 - val_loss: 3882.1797\n",
      "Epoch 924/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1724.8706 - val_loss: 3899.1698\n",
      "Epoch 925/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1765.1007 - val_loss: 3890.8856\n",
      "Epoch 926/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1770.3506 - val_loss: 3870.1281\n",
      "Epoch 927/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1729.8884 - val_loss: 3870.5334\n",
      "Epoch 928/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1734.5872 - val_loss: 3878.7885\n",
      "Epoch 929/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1750.7458 - val_loss: 3866.7015\n",
      "Epoch 930/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1724.5594 - val_loss: 3849.8730\n",
      "Epoch 931/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1725.7998 - val_loss: 3844.3379\n",
      "Epoch 932/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1734.4634 - val_loss: 3848.2573\n",
      "Epoch 933/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1712.8376 - val_loss: 3825.4539\n",
      "Epoch 934/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1702.7121 - val_loss: 3809.9807\n",
      "Epoch 935/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1689.4884 - val_loss: 3814.9346\n",
      "Epoch 936/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1711.0421 - val_loss: 3835.1299\n",
      "Epoch 937/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1732.1774 - val_loss: 3828.2204\n",
      "Epoch 938/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1749.4792 - val_loss: 3855.1023\n",
      "Epoch 939/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1907.6858 - val_loss: 3949.8186\n",
      "Epoch 940/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1945.4904 - val_loss: 3885.3935\n",
      "Epoch 941/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1825.7772 - val_loss: 3841.3125\n",
      "Epoch 942/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1771.2682 - val_loss: 3781.4254\n",
      "Epoch 943/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1705.8648 - val_loss: 3789.6687\n",
      "Epoch 944/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1707.0055 - val_loss: 3778.0985\n",
      "Epoch 945/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 1694.1952 - val_loss: 3754.5307\n",
      "Epoch 946/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1678.0835 - val_loss: 3763.2060\n",
      "Epoch 947/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1676.5178 - val_loss: 3741.6764\n",
      "Epoch 948/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1664.6258 - val_loss: 3754.8121\n",
      "Epoch 949/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1689.4847 - val_loss: 3746.7873\n",
      "Epoch 950/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1676.5835 - val_loss: 3735.3299\n",
      "Epoch 951/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1666.1802 - val_loss: 3737.9067\n",
      "Epoch 952/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1691.3850 - val_loss: 3738.1181\n",
      "Epoch 953/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1687.9228 - val_loss: 3723.9699\n",
      "Epoch 954/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1662.1910 - val_loss: 3724.1002\n",
      "Epoch 955/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1678.6674 - val_loss: 3706.5971\n",
      "Epoch 956/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1655.7658 - val_loss: 3685.9183\n",
      "Epoch 957/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1629.4802 - val_loss: 3681.7457\n",
      "Epoch 958/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1629.0354 - val_loss: 3677.3303\n",
      "Epoch 959/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1631.6867 - val_loss: 3677.1845\n",
      "Epoch 960/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1634.7816 - val_loss: 3676.6024\n",
      "Epoch 961/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1637.0389 - val_loss: 3682.2486\n",
      "Epoch 962/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1640.6123 - val_loss: 3663.9391\n",
      "Epoch 963/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1620.6440 - val_loss: 3650.7781\n",
      "Epoch 964/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1620.0937 - val_loss: 3657.2592\n",
      "Epoch 965/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1649.5291 - val_loss: 3658.1901\n",
      "Epoch 966/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1631.9891 - val_loss: 3644.4964\n",
      "Epoch 967/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1645.2515 - val_loss: 3650.2260\n",
      "Epoch 968/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1658.2486 - val_loss: 3660.9567\n",
      "Epoch 969/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1667.4024 - val_loss: 3669.2769\n",
      "Epoch 970/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1684.6579 - val_loss: 3653.7381\n",
      "Epoch 971/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1653.2768 - val_loss: 3618.5955\n",
      "Epoch 972/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1615.5175 - val_loss: 3625.6717\n",
      "Epoch 973/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1624.3869 - val_loss: 3608.1214\n",
      "Epoch 974/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1613.9673 - val_loss: 3595.5251\n",
      "Epoch 975/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1603.0883 - val_loss: 3606.8112\n",
      "Epoch 976/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1615.7698 - val_loss: 3599.4753\n",
      "Epoch 977/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1623.3550 - val_loss: 3592.3646\n",
      "Epoch 978/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1614.2148 - val_loss: 3585.3654\n",
      "Epoch 979/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1615.1103 - val_loss: 3579.8634\n",
      "Epoch 980/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1618.7713 - val_loss: 3571.3072\n",
      "Epoch 981/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1618.9826 - val_loss: 3560.8842\n",
      "Epoch 982/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1581.0035 - val_loss: 3561.9687\n",
      "Epoch 983/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1597.8031 - val_loss: 3550.5241\n",
      "Epoch 984/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1603.3860 - val_loss: 3549.0357\n",
      "Epoch 985/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1586.4200 - val_loss: 3558.2090\n",
      "Epoch 986/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1620.3436 - val_loss: 3545.2911\n",
      "Epoch 987/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1592.0321 - val_loss: 3541.1270\n",
      "Epoch 988/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1594.1415 - val_loss: 3551.8982\n",
      "Epoch 989/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1650.3934 - val_loss: 3541.8648\n",
      "Epoch 990/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1613.0132 - val_loss: 3523.5606\n",
      "Epoch 991/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1582.8225 - val_loss: 3517.6839\n",
      "Epoch 992/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1587.2156 - val_loss: 3524.2198\n",
      "Epoch 993/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1591.1359 - val_loss: 3527.1339\n",
      "Epoch 994/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1581.3305 - val_loss: 3490.4953\n",
      "Epoch 995/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1568.8172 - val_loss: 3492.7183\n",
      "Epoch 996/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1592.7269 - val_loss: 3566.8416\n",
      "Epoch 997/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1692.7234 - val_loss: 3540.6433\n",
      "Epoch 998/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1667.1133 - val_loss: 3518.4381\n",
      "Epoch 999/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1623.8760 - val_loss: 3499.5415\n",
      "Epoch 1000/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1595.8476 - val_loss: 3493.3044\n",
      "Epoch 1001/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1592.4075 - val_loss: 3473.3833\n",
      "Epoch 1002/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1582.0198 - val_loss: 3462.3470\n",
      "Epoch 1003/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1546.9837 - val_loss: 3475.2637\n",
      "Epoch 1004/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1597.9930 - val_loss: 3479.9466\n",
      "Epoch 1005/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1582.3176 - val_loss: 3448.5902\n",
      "Epoch 1006/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1561.7474 - val_loss: 3443.1318\n",
      "Epoch 1007/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1559.3555 - val_loss: 3437.1198\n",
      "Epoch 1008/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1560.0105 - val_loss: 3458.6561\n",
      "Epoch 1009/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1602.0854 - val_loss: 3442.5626\n",
      "Epoch 1010/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1570.1614 - val_loss: 3426.4426\n",
      "Epoch 1011/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1551.9194 - val_loss: 3425.9003\n",
      "Epoch 1012/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1579.9584 - val_loss: 3434.6722\n",
      "Epoch 1013/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1589.5710 - val_loss: 3418.3614\n",
      "Epoch 1014/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1550.1265 - val_loss: 3400.7784\n",
      "Epoch 1015/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1540.6601 - val_loss: 3398.6415\n",
      "Epoch 1016/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1518.4047 - val_loss: 3384.7419\n",
      "Epoch 1017/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1515.7886 - val_loss: 3397.9431\n",
      "Epoch 1018/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 1548.5984 - val_loss: 3397.3972\n",
      "Epoch 1019/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1598.5529 - val_loss: 3412.6576\n",
      "Epoch 1020/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1576.5970 - val_loss: 3402.1842\n",
      "Epoch 1021/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1559.4460 - val_loss: 3382.2467\n",
      "Epoch 1022/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1532.9075 - val_loss: 3370.9610\n",
      "Epoch 1023/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1509.4204 - val_loss: 3365.8108\n",
      "Epoch 1024/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1520.9809 - val_loss: 3355.2818\n",
      "Epoch 1025/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1526.7473 - val_loss: 3362.7624\n",
      "Epoch 1026/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 1550.3457 - val_loss: 3551.8345\n",
      "Epoch 1027/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2029.5225 - val_loss: 3622.6505\n",
      "Epoch 1028/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1995.5943 - val_loss: 3538.8736\n",
      "Epoch 1029/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1822.8893 - val_loss: 3460.6176\n",
      "Epoch 1030/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1759.9999 - val_loss: 3426.1350\n",
      "Epoch 1031/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1637.8808 - val_loss: 3384.8996\n",
      "Epoch 1032/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1588.6973 - val_loss: 3360.9747\n",
      "Epoch 1033/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1549.6363 - val_loss: 3336.6268\n",
      "Epoch 1034/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1548.7250 - val_loss: 3315.4333\n",
      "Epoch 1035/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1526.9549 - val_loss: 3305.4376\n",
      "Epoch 1036/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1492.5654 - val_loss: 3324.8013\n",
      "Epoch 1037/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1530.1687 - val_loss: 3299.9381\n",
      "Epoch 1038/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1498.0430 - val_loss: 3294.5249\n",
      "Epoch 1039/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1491.8747 - val_loss: 3306.5622\n",
      "Epoch 1040/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1520.4217 - val_loss: 3295.7813\n",
      "Epoch 1041/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1514.2342 - val_loss: 3292.4270\n",
      "Epoch 1042/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1500.2380 - val_loss: 3290.1161\n",
      "Epoch 1043/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1485.9974 - val_loss: 3270.4448\n",
      "Epoch 1044/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1484.1911 - val_loss: 3272.0407\n",
      "Epoch 1045/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1480.5259 - val_loss: 3236.8426\n",
      "Epoch 1046/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1457.6606 - val_loss: 3311.3859\n",
      "Epoch 1047/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1640.0940 - val_loss: 3297.7144\n",
      "Epoch 1048/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1576.2634 - val_loss: 3313.5520\n",
      "Epoch 1049/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1565.1577 - val_loss: 3247.6148\n",
      "Epoch 1050/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1501.6895 - val_loss: 3257.5004\n",
      "Epoch 1051/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1512.5453 - val_loss: 3252.7715\n",
      "Epoch 1052/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1486.3237 - val_loss: 3231.5471\n",
      "Epoch 1053/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1470.2501 - val_loss: 3273.7120\n",
      "Epoch 1054/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1521.9781 - val_loss: 3245.4007\n",
      "Epoch 1055/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1490.4690 - val_loss: 3248.2968\n",
      "Epoch 1056/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1495.4268 - val_loss: 3254.5466\n",
      "Epoch 1057/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1525.3345 - val_loss: 3233.0164\n",
      "Epoch 1058/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1487.2162 - val_loss: 3207.7973\n",
      "Epoch 1059/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1450.8508 - val_loss: 3199.8420\n",
      "Epoch 1060/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1460.6851 - val_loss: 3184.1835\n",
      "Epoch 1061/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1441.3667 - val_loss: 3196.6599\n",
      "Epoch 1062/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1453.5402 - val_loss: 3206.3570\n",
      "Epoch 1063/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1473.2754 - val_loss: 3225.2231\n",
      "Epoch 1064/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1640.4113 - val_loss: 3332.4459\n",
      "Epoch 1065/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1714.5016 - val_loss: 3273.6806\n",
      "Epoch 1066/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1622.1710 - val_loss: 3254.0247\n",
      "Epoch 1067/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1556.0004 - val_loss: 3206.7763\n",
      "Epoch 1068/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1486.9206 - val_loss: 3185.6350\n",
      "Epoch 1069/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1557.7228 - val_loss: 3228.7182\n",
      "Epoch 1070/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1564.5711 - val_loss: 3220.0708\n",
      "Epoch 1071/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1521.9322 - val_loss: 3188.7143\n",
      "Epoch 1072/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1479.5938 - val_loss: 3174.8556\n",
      "Epoch 1073/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1458.6693 - val_loss: 3186.4812\n",
      "Epoch 1074/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1620.9595 - val_loss: 3275.3832\n",
      "Epoch 1075/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1681.2586 - val_loss: 3228.8568\n",
      "Epoch 1076/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1602.1764 - val_loss: 3205.7829\n",
      "Epoch 1077/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1549.1756 - val_loss: 3181.1851\n",
      "Epoch 1078/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1490.8545 - val_loss: 3146.4796\n",
      "Epoch 1079/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1520.7354 - val_loss: 3199.1685\n",
      "Epoch 1080/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1538.1925 - val_loss: 3163.3460\n",
      "Epoch 1081/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1498.4904 - val_loss: 3124.8524\n",
      "Epoch 1082/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1445.4406 - val_loss: 3140.7692\n",
      "Epoch 1083/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1452.0588 - val_loss: 3132.3158\n",
      "Epoch 1084/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1437.2514 - val_loss: 3109.3975\n",
      "Epoch 1085/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1446.3898 - val_loss: 3160.4551\n",
      "Epoch 1086/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1492.8434 - val_loss: 3129.2885\n",
      "Epoch 1087/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1456.7712 - val_loss: 3108.7576\n",
      "Epoch 1088/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1416.6915 - val_loss: 3185.6544\n",
      "Epoch 1089/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1556.5836 - val_loss: 3140.8251\n",
      "Epoch 1090/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 1471.2665 - val_loss: 3145.8078\n",
      "Epoch 1091/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 1517.26 - 0s 57us/step - loss: 1449.8281 - val_loss: 3131.3870\n",
      "Epoch 1092/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1429.8447 - val_loss: 3129.5097\n",
      "Epoch 1093/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1433.7615 - val_loss: 3159.1198\n",
      "Epoch 1094/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1504.1440 - val_loss: 3136.7535\n",
      "Epoch 1095/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1435.1367 - val_loss: 3124.9740\n",
      "Epoch 1096/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1422.5512 - val_loss: 3136.4211\n",
      "Epoch 1097/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1406.4036 - val_loss: 3118.9459\n",
      "Epoch 1098/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1370.3662 - val_loss: 3144.9638\n",
      "Epoch 1099/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1382.9893 - val_loss: 3136.7504\n",
      "Epoch 1100/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1409.8453 - val_loss: 3161.5733\n",
      "Epoch 1101/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1403.1093 - val_loss: 3144.2977\n",
      "Epoch 1102/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1393.7800 - val_loss: 3176.5981\n",
      "Epoch 1103/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1409.1931 - val_loss: 3146.1151\n",
      "Epoch 1104/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1372.0194 - val_loss: 3152.9988\n",
      "Epoch 1105/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1342.7613 - val_loss: 3112.7356\n",
      "Epoch 1106/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1411.5156 - val_loss: 3338.4569\n",
      "Epoch 1107/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1861.5700 - val_loss: 3286.1164\n",
      "Epoch 1108/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1579.3500 - val_loss: 3191.5459\n",
      "Epoch 1109/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1401.9775 - val_loss: 3162.0844\n",
      "Epoch 1110/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1353.5118 - val_loss: 3084.3236\n",
      "Epoch 1111/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1308.5698 - val_loss: 3070.5680\n",
      "Epoch 1112/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1315.6575 - val_loss: 3058.1142\n",
      "Epoch 1113/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1306.6045 - val_loss: 3055.0373\n",
      "Epoch 1114/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1272.4164 - val_loss: 3054.2852\n",
      "Epoch 1115/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2800.4800 - val_loss: 4505.2424\n",
      "Epoch 1116/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4926.2346 - val_loss: 5169.7585\n",
      "Epoch 1117/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5540.9507 - val_loss: 5003.7234\n",
      "Epoch 1118/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5115.7675 - val_loss: 4743.0802\n",
      "Epoch 1119/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4313.9090 - val_loss: 4375.7190\n",
      "Epoch 1120/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3651.9308 - val_loss: 3924.7658\n",
      "Epoch 1121/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2788.3502 - val_loss: 3599.6600\n",
      "Epoch 1122/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2297.2962 - val_loss: 3336.8205\n",
      "Epoch 1123/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1817.8895 - val_loss: 3195.6501\n",
      "Epoch 1124/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1579.3100 - val_loss: 3073.5088\n",
      "Epoch 1125/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1370.7067 - val_loss: 3019.6868\n",
      "Epoch 1126/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1288.5688 - val_loss: 3017.7447\n",
      "Epoch 1127/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1322.6252 - val_loss: 2959.9036\n",
      "Epoch 1128/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1260.3282 - val_loss: 3093.3622\n",
      "Epoch 1129/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2168.5699 - val_loss: 3586.2388\n",
      "Epoch 1130/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2538.5166 - val_loss: 3463.3704\n",
      "Epoch 1131/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2085.2796 - val_loss: 3257.5630\n",
      "Epoch 1132/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1773.2168 - val_loss: 3130.6252\n",
      "Epoch 1133/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1541.4573 - val_loss: 3035.1512\n",
      "Epoch 1134/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1362.7377 - val_loss: 2965.8855\n",
      "Epoch 1135/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1292.0780 - val_loss: 2938.6084\n",
      "Epoch 1136/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1277.1776 - val_loss: 2910.9272\n",
      "Epoch 1137/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1234.1256 - val_loss: 2879.8733\n",
      "Epoch 1138/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1296.8657 - val_loss: 3311.8514\n",
      "Epoch 1139/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2519.1945 - val_loss: 3647.9285\n",
      "Epoch 1140/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2756.7731 - val_loss: 3545.5471\n",
      "Epoch 1141/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2419.4456 - val_loss: 3317.0295\n",
      "Epoch 1142/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1952.1332 - val_loss: 3170.4195\n",
      "Epoch 1143/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1620.9144 - val_loss: 3047.0928\n",
      "Epoch 1144/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1468.5343 - val_loss: 2906.7714\n",
      "Epoch 1145/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1248.4959 - val_loss: 2871.3310\n",
      "Epoch 1146/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1408.0951 - val_loss: 2943.1985\n",
      "Epoch 1147/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1417.9626 - val_loss: 2904.3472\n",
      "Epoch 1148/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1293.7257 - val_loss: 2864.7042\n",
      "Epoch 1149/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1233.5429 - val_loss: 2842.1342\n",
      "Epoch 1150/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1172.7890 - val_loss: 2814.3977\n",
      "Epoch 1151/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1164.0107 - val_loss: 2782.3762\n",
      "Epoch 1152/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1194.7178 - val_loss: 2777.0224\n",
      "Epoch 1153/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1140.9339 - val_loss: 2781.0750\n",
      "Epoch 1154/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1146.2537 - val_loss: 2780.8381\n",
      "Epoch 1155/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3964.3772 - val_loss: 3632.9113\n",
      "Epoch 1156/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3390.4138 - val_loss: 4025.1669\n",
      "Epoch 1157/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3712.1046 - val_loss: 3914.0218\n",
      "Epoch 1158/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3213.4741 - val_loss: 3643.4784\n",
      "Epoch 1159/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2769.8215 - val_loss: 3468.0588\n",
      "Epoch 1160/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2396.0715 - val_loss: 3232.1814\n",
      "Epoch 1161/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1959.2512 - val_loss: 3069.0263\n",
      "Epoch 1162/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 1706.7048 - val_loss: 2955.6489\n",
      "Epoch 1163/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1478.1519 - val_loss: 2807.4860\n",
      "Epoch 1164/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1313.4974 - val_loss: 2810.7689\n",
      "Epoch 1165/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1281.8438 - val_loss: 2764.9663\n",
      "Epoch 1166/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1200.5513 - val_loss: 2746.7982\n",
      "Epoch 1167/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1162.5947 - val_loss: 2725.2324\n",
      "Epoch 1168/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1125.0007 - val_loss: 2696.6789\n",
      "Epoch 1169/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3562.7057 - val_loss: 4878.1669\n",
      "Epoch 1170/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5528.9442 - val_loss: 4922.1918\n",
      "Epoch 1171/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5658.2265 - val_loss: 4851.5727\n",
      "Epoch 1172/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5089.6007 - val_loss: 4511.9180\n",
      "Epoch 1173/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4345.3199 - val_loss: 4047.2805\n",
      "Epoch 1174/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3380.8164 - val_loss: 3673.6089\n",
      "Epoch 1175/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2850.2808 - val_loss: 3409.1755\n",
      "Epoch 1176/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2351.8261 - val_loss: 3133.6951\n",
      "Epoch 1177/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1920.6228 - val_loss: 2995.1967\n",
      "Epoch 1178/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1656.2588 - val_loss: 2858.6720\n",
      "Epoch 1179/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1437.2921 - val_loss: 2769.4166\n",
      "Epoch 1180/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1298.2273 - val_loss: 2720.8585\n",
      "Epoch 1181/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1181.9700 - val_loss: 2678.6694\n",
      "Epoch 1182/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1109.9710 - val_loss: 2652.9926\n",
      "Epoch 1183/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1106.5904 - val_loss: 2667.5621\n",
      "Epoch 1184/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1096.0326 - val_loss: 2639.9516\n",
      "Epoch 1185/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1106.1032 - val_loss: 2626.2577\n",
      "Epoch 1186/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1063.8816 - val_loss: 2632.2791\n",
      "Epoch 1187/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1071.4797 - val_loss: 2615.4495\n",
      "Epoch 1188/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1069.8167 - val_loss: 2609.0810\n",
      "Epoch 1189/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1063.4808 - val_loss: 2586.4805\n",
      "Epoch 1190/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1042.7870 - val_loss: 2587.1388\n",
      "Epoch 1191/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1031.8730 - val_loss: 2588.1680\n",
      "Epoch 1192/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1019.6531 - val_loss: 2575.7945\n",
      "Epoch 1193/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1102.2828 - val_loss: 2651.1705\n",
      "Epoch 1194/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1211.9500 - val_loss: 2635.6639\n",
      "Epoch 1195/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1135.0533 - val_loss: 2601.3796\n",
      "Epoch 1196/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1065.3439 - val_loss: 2589.6168\n",
      "Epoch 1197/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1044.9949 - val_loss: 2549.9777\n",
      "Epoch 1198/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1021.3455 - val_loss: 2565.5987\n",
      "Epoch 1199/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1091.5251 - val_loss: 2556.3330\n",
      "Epoch 1200/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1033.0586 - val_loss: 2543.6625\n",
      "Epoch 1201/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1011.5055 - val_loss: 2532.8920\n",
      "Epoch 1202/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1023.6603 - val_loss: 2621.0332\n",
      "Epoch 1203/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1418.2221 - val_loss: 2673.8916\n",
      "Epoch 1204/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1294.2570 - val_loss: 2644.4041\n",
      "Epoch 1205/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1210.7004 - val_loss: 2602.7533\n",
      "Epoch 1206/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1108.0167 - val_loss: 2554.2658\n",
      "Epoch 1207/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1072.8476 - val_loss: 2522.0996\n",
      "Epoch 1208/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1037.4965 - val_loss: 2510.0116\n",
      "Epoch 1209/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1014.2739 - val_loss: 2521.0991\n",
      "Epoch 1210/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1040.6697 - val_loss: 2510.9229\n",
      "Epoch 1211/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1016.0361 - val_loss: 2497.5420\n",
      "Epoch 1212/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1004.7047 - val_loss: 2499.2639\n",
      "Epoch 1213/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1011.6841 - val_loss: 2485.6829\n",
      "Epoch 1214/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1082.0861 - val_loss: 2512.8109\n",
      "Epoch 1215/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1062.9188 - val_loss: 2497.5260\n",
      "Epoch 1216/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1012.8399 - val_loss: 2470.1448\n",
      "Epoch 1217/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 985.6201 - val_loss: 2449.2958\n",
      "Epoch 1218/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1050.2103 - val_loss: 2587.7366\n",
      "Epoch 1219/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1321.1296 - val_loss: 2567.8857\n",
      "Epoch 1220/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1211.2443 - val_loss: 2544.7300\n",
      "Epoch 1221/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1118.8890 - val_loss: 2513.2250\n",
      "Epoch 1222/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1051.3090 - val_loss: 2457.6704\n",
      "Epoch 1223/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 986.3189 - val_loss: 2429.8685\n",
      "Epoch 1224/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 893.737 - 0s 54us/step - loss: 967.6896 - val_loss: 2439.8473\n",
      "Epoch 1225/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 994.0016 - val_loss: 2436.2257\n",
      "Epoch 1226/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 967.6271 - val_loss: 2430.8718\n",
      "Epoch 1227/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 949.5938 - val_loss: 2420.3362\n",
      "Epoch 1228/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 957.0621 - val_loss: 2405.1830\n",
      "Epoch 1229/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 968.1114 - val_loss: 2413.2653\n",
      "Epoch 1230/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 967.0305 - val_loss: 2406.4916\n",
      "Epoch 1231/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 953.1119 - val_loss: 2424.9073\n",
      "Epoch 1232/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1029.9154 - val_loss: 2425.0165\n",
      "Epoch 1233/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 993.7552 - val_loss: 2434.0352\n",
      "Epoch 1234/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 60us/step - loss: 1013.0547 - val_loss: 2408.6816\n",
      "Epoch 1235/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 998.0909 - val_loss: 2414.7712\n",
      "Epoch 1236/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1085.2422 - val_loss: 2433.2174\n",
      "Epoch 1237/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1141.3891 - val_loss: 2816.3984\n",
      "Epoch 1238/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2215.2677 - val_loss: 2964.2594\n",
      "Epoch 1239/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2131.9176 - val_loss: 2785.7209\n",
      "Epoch 1240/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1711.1932 - val_loss: 2649.9347\n",
      "Epoch 1241/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1354.9623 - val_loss: 2514.8776\n",
      "Epoch 1242/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1102.6092 - val_loss: 2416.8152\n",
      "Epoch 1243/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1026.2068 - val_loss: 2354.5648\n",
      "Epoch 1244/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 977.8090 - val_loss: 2391.5746\n",
      "Epoch 1245/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1118.6440 - val_loss: 2390.1345\n",
      "Epoch 1246/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 992.2864 - val_loss: 2410.9377\n",
      "Epoch 1247/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 970.5118 - val_loss: 2362.9240\n",
      "Epoch 1248/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 958.8326 - val_loss: 2375.0614\n",
      "Epoch 1249/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1118.6053 - val_loss: 2451.3427\n",
      "Epoch 1250/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1214.7673 - val_loss: 2412.6504\n",
      "Epoch 1251/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1086.4954 - val_loss: 2385.6965\n",
      "Epoch 1252/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1002.6519 - val_loss: 2362.2595\n",
      "Epoch 1253/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 960.5994 - val_loss: 2315.5548\n",
      "Epoch 1254/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 993.8133 - val_loss: 2527.0933\n",
      "Epoch 1255/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1561.2558 - val_loss: 2558.8129\n",
      "Epoch 1256/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1374.0182 - val_loss: 2464.6543\n",
      "Epoch 1257/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1164.5891 - val_loss: 2420.2966\n",
      "Epoch 1258/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1064.9011 - val_loss: 2342.2109\n",
      "Epoch 1259/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 950.5799 - val_loss: 2296.3294\n",
      "Epoch 1260/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 948.7670 - val_loss: 2291.8254\n",
      "Epoch 1261/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 956.1171 - val_loss: 2311.9614\n",
      "Epoch 1262/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 989.8140 - val_loss: 3115.3547\n",
      "Epoch 1263/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4065.2950 - val_loss: 4487.1026\n",
      "Epoch 1264/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 5573.3562 - val_loss: 4718.0461\n",
      "Epoch 1265/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 5834.3353 - val_loss: 4588.7380\n",
      "Epoch 1266/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5341.1476 - val_loss: 4300.5712\n",
      "Epoch 1267/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4715.2668 - val_loss: 3926.8005\n",
      "Epoch 1268/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3960.9480 - val_loss: 3677.7055\n",
      "Epoch 1269/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3571.0704 - val_loss: 3389.5271\n",
      "Epoch 1270/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3091.6925 - val_loss: 3145.8346\n",
      "Epoch 1271/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2531.1849 - val_loss: 2949.5485\n",
      "Epoch 1272/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2244.4477 - val_loss: 2759.3970\n",
      "Epoch 1273/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1853.7610 - val_loss: 2635.5002\n",
      "Epoch 1274/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1668.9507 - val_loss: 2550.0599\n",
      "Epoch 1275/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1471.0336 - val_loss: 2466.0770\n",
      "Epoch 1276/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1296.5933 - val_loss: 2378.1793\n",
      "Epoch 1277/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1132.2393 - val_loss: 2306.6472\n",
      "Epoch 1278/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 970.4628 - val_loss: 2263.3889\n",
      "Epoch 1279/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 907.7011 - val_loss: 2248.0614\n",
      "Epoch 1280/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 916.7360 - val_loss: 2246.6694\n",
      "Epoch 1281/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 886.8470 - val_loss: 2247.0790\n",
      "Epoch 1282/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 948.9423 - val_loss: 2245.2148\n",
      "Epoch 1283/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 929.8869 - val_loss: 2279.9127\n",
      "Epoch 1284/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 954.6141 - val_loss: 2255.8264\n",
      "Epoch 1285/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 951.5034 - val_loss: 2282.9275\n",
      "Epoch 1286/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 892.8891 - val_loss: 2218.3994\n",
      "Epoch 1287/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 897.4764 - val_loss: 2272.2173\n",
      "Epoch 1288/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1115.5253 - val_loss: 2259.3069\n",
      "Epoch 1289/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1012.6731 - val_loss: 2269.6564\n",
      "Epoch 1290/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 949.3160 - val_loss: 2253.2218\n",
      "Epoch 1291/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 914.9582 - val_loss: 2210.0362\n",
      "Epoch 1292/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 869.6833 - val_loss: 2185.8121\n",
      "Epoch 1293/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 851.4918 - val_loss: 2170.8341\n",
      "Epoch 1294/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 872.0271 - val_loss: 2223.1200\n",
      "Epoch 1295/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1095.8645 - val_loss: 2318.5990\n",
      "Epoch 1296/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1236.9619 - val_loss: 2282.1081\n",
      "Epoch 1297/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1105.8748 - val_loss: 2279.6027\n",
      "Epoch 1298/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 983.0852 - val_loss: 2236.5907\n",
      "Epoch 1299/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 941.2542 - val_loss: 2172.2234\n",
      "Epoch 1300/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 883.9432 - val_loss: 2178.2117\n",
      "Epoch 1301/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 921.9393 - val_loss: 2176.0570\n",
      "Epoch 1302/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 940.2020 - val_loss: 2181.1764\n",
      "Epoch 1303/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 900.9062 - val_loss: 2169.6519\n",
      "Epoch 1304/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 853.8224 - val_loss: 2157.0440\n",
      "Epoch 1305/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 839.7858 - val_loss: 2138.7605\n",
      "Epoch 1306/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 840.8626 - val_loss: 2138.0576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1307/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 875.4968 - val_loss: 2155.6635\n",
      "Epoch 1308/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 864.1360 - val_loss: 2149.1276\n",
      "Epoch 1309/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 846.3179 - val_loss: 2134.4746\n",
      "Epoch 1310/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 832.9491 - val_loss: 2134.2793\n",
      "Epoch 1311/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 834.7491 - val_loss: 2115.0053\n",
      "Epoch 1312/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 830.7790 - val_loss: 2124.0651\n",
      "Epoch 1313/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 878.8269 - val_loss: 2184.0912\n",
      "Epoch 1314/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1110.9351 - val_loss: 2191.7898\n",
      "Epoch 1315/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1014.7786 - val_loss: 2170.1635\n",
      "Epoch 1316/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 917.4248 - val_loss: 2129.0576\n",
      "Epoch 1317/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 865.3317 - val_loss: 2118.7451\n",
      "Epoch 1318/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 863.0671 - val_loss: 2118.8301\n",
      "Epoch 1319/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 860.3001 - val_loss: 2109.4998\n",
      "Epoch 1320/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 833.6112 - val_loss: 2115.3513\n",
      "Epoch 1321/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 918.1935 - val_loss: 2129.0948\n",
      "Epoch 1322/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 867.3331 - val_loss: 2126.6588\n",
      "Epoch 1323/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 832.0378 - val_loss: 2112.5789\n",
      "Epoch 1324/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 842.7996 - val_loss: 2203.3056\n",
      "Epoch 1325/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1276.6859 - val_loss: 2445.6334\n",
      "Epoch 1326/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1811.6130 - val_loss: 2455.6486\n",
      "Epoch 1327/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1688.7418 - val_loss: 2385.1349\n",
      "Epoch 1328/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1417.0243 - val_loss: 2286.1022\n",
      "Epoch 1329/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1185.1799 - val_loss: 2206.4527\n",
      "Epoch 1330/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1025.6490 - val_loss: 2135.0295\n",
      "Epoch 1331/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 962.2771 - val_loss: 2081.7895\n",
      "Epoch 1332/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 905.9494 - val_loss: 2068.7521\n",
      "Epoch 1333/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 841.5980 - val_loss: 2082.4325\n",
      "Epoch 1334/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 834.1951 - val_loss: 2097.8340\n",
      "Epoch 1335/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 821.6331 - val_loss: 2060.1553\n",
      "Epoch 1336/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 798.4445 - val_loss: 2048.1551\n",
      "Epoch 1337/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 798.7706 - val_loss: 2047.8130\n",
      "Epoch 1338/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 814.4892 - val_loss: 2052.7096\n",
      "Epoch 1339/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 839.1438 - val_loss: 2183.5475\n",
      "Epoch 1340/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1393.7198 - val_loss: 2255.2221\n",
      "Epoch 1341/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1347.3787 - val_loss: 2160.6728\n",
      "Epoch 1342/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1046.2127 - val_loss: 2183.1639\n",
      "Epoch 1343/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 909.2222 - val_loss: 2110.1625\n",
      "Epoch 1344/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 855.7515 - val_loss: 2016.0613\n",
      "Epoch 1345/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 817.0283 - val_loss: 2012.0256\n",
      "Epoch 1346/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 820.2177 - val_loss: 2022.8031\n",
      "Epoch 1347/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 820.0574 - val_loss: 2050.6836\n",
      "Epoch 1348/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 796.7804 - val_loss: 2100.4909\n",
      "Epoch 1349/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 854.6595 - val_loss: 2011.5323\n",
      "Epoch 1350/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 822.3052 - val_loss: 2052.3729\n",
      "Epoch 1351/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 797.4722 - val_loss: 2022.6523\n",
      "Epoch 1352/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 775.9135 - val_loss: 1998.6929\n",
      "Epoch 1353/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 774.4925 - val_loss: 1991.9524\n",
      "Epoch 1354/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 802.2350 - val_loss: 2000.3020\n",
      "Epoch 1355/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 784.3929 - val_loss: 2009.7615\n",
      "Epoch 1356/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 783.1140 - val_loss: 2003.3303\n",
      "Epoch 1357/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 831.1612 - val_loss: 2012.9309\n",
      "Epoch 1358/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 807.7464 - val_loss: 2033.3093\n",
      "Epoch 1359/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 824.2028 - val_loss: 2150.0085\n",
      "Epoch 1360/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1422.0179 - val_loss: 2202.6753\n",
      "Epoch 1361/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1286.6516 - val_loss: 2107.8787\n",
      "Epoch 1362/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1064.0337 - val_loss: 2089.4035\n",
      "Epoch 1363/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 948.2567 - val_loss: 2068.9235\n",
      "Epoch 1364/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 897.5731 - val_loss: 1988.7692\n",
      "Epoch 1365/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 821.6692 - val_loss: 2120.6712\n",
      "Epoch 1366/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1068.3594 - val_loss: 2055.8804\n",
      "Epoch 1367/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1128.0468 - val_loss: 2045.1291\n",
      "Epoch 1368/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 985.4609 - val_loss: 2125.9160\n",
      "Epoch 1369/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 878.6010 - val_loss: 2009.8843\n",
      "Epoch 1370/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 845.3880 - val_loss: 2037.7347\n",
      "Epoch 1371/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 933.6642 - val_loss: 1961.4228\n",
      "Epoch 1372/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 907.2015 - val_loss: 2001.7314\n",
      "Epoch 1373/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 842.2598 - val_loss: 2016.8788\n",
      "Epoch 1374/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 811.4942 - val_loss: 2030.4188\n",
      "Epoch 1375/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 909.1410 - val_loss: 1987.3183\n",
      "Epoch 1376/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 918.0153 - val_loss: 2005.9050\n",
      "Epoch 1377/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 846.5072 - val_loss: 1981.9542\n",
      "Epoch 1378/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 830.7358 - val_loss: 2015.0055\n",
      "Epoch 1379/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1019.1219 - val_loss: 1984.2715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1380/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 919.1882 - val_loss: 2002.4800\n",
      "Epoch 1381/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 833.3154 - val_loss: 1999.1781\n",
      "Epoch 1382/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 836.9373 - val_loss: 1939.5712\n",
      "Epoch 1383/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 802.8212 - val_loss: 2011.7353\n",
      "Epoch 1384/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 834.4451 - val_loss: 1926.3594\n",
      "Epoch 1385/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 810.0001 - val_loss: 1977.9680\n",
      "Epoch 1386/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 777.4543 - val_loss: 1954.1444\n",
      "Epoch 1387/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 768.1411 - val_loss: 1910.3837\n",
      "Epoch 1388/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 824.3591 - val_loss: 2034.1384\n",
      "Epoch 1389/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1374.1078 - val_loss: 2090.2153\n",
      "Epoch 1390/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 1244.6485 - val_loss: 2063.9041\n",
      "Epoch 1391/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1065.7964 - val_loss: 2086.1769\n",
      "Epoch 1392/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 913.8301 - val_loss: 1990.5893\n",
      "Epoch 1393/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 854.3187 - val_loss: 1953.0648\n",
      "Epoch 1394/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 784.6084 - val_loss: 1890.9382\n",
      "Epoch 1395/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 775.8385 - val_loss: 1884.9379\n",
      "Epoch 1396/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 747.1140 - val_loss: 1908.9616\n",
      "Epoch 1397/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 815.5602 - val_loss: 2096.3212\n",
      "Epoch 1398/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1273.5821 - val_loss: 2034.5997\n",
      "Epoch 1399/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1064.7710 - val_loss: 2026.6522\n",
      "Epoch 1400/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 894.9802 - val_loss: 1961.9047\n",
      "Epoch 1401/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 828.4739 - val_loss: 1916.6265\n",
      "Epoch 1402/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 770.2534 - val_loss: 1895.7132\n",
      "Epoch 1403/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 751.4853 - val_loss: 1893.8430\n",
      "Epoch 1404/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 745.1824 - val_loss: 1893.4585\n",
      "Epoch 1405/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 725.4163 - val_loss: 1872.1100\n",
      "Epoch 1406/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 760.3848 - val_loss: 1888.5647\n",
      "Epoch 1407/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1010.1344 - val_loss: 1902.5928\n",
      "Epoch 1408/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 930.3037 - val_loss: 1923.9703\n",
      "Epoch 1409/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 824.9060 - val_loss: 2017.5249\n",
      "Epoch 1410/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 780.5581 - val_loss: 1898.4498\n",
      "Epoch 1411/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 746.7349 - val_loss: 1837.3494\n",
      "Epoch 1412/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1225.5447 - val_loss: 2866.1862\n",
      "Epoch 1413/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3300.6591 - val_loss: 3281.5339\n",
      "Epoch 1414/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3689.3388 - val_loss: 3344.0437\n",
      "Epoch 1415/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3729.4096 - val_loss: 3097.1138\n",
      "Epoch 1416/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3163.4438 - val_loss: 2792.0997\n",
      "Epoch 1417/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2381.8601 - val_loss: 2418.6566\n",
      "Epoch 1418/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1792.0756 - val_loss: 2187.5322\n",
      "Epoch 1419/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1400.3919 - val_loss: 2032.4734\n",
      "Epoch 1420/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1148.1164 - val_loss: 1980.1314\n",
      "Epoch 1421/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 980.3180 - val_loss: 1898.6722\n",
      "Epoch 1422/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 819.4964 - val_loss: 1893.8614\n",
      "Epoch 1423/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 779.6663 - val_loss: 1884.3313\n",
      "Epoch 1424/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1817.6205 - val_loss: 4110.8080\n",
      "Epoch 1425/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7055.6531 - val_loss: 5696.1561\n",
      "Epoch 1426/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 8923.8396 - val_loss: 6182.3521\n",
      "Epoch 1427/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 9715.5850 - val_loss: 6181.0361\n",
      "Epoch 1428/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 9415.5494 - val_loss: 5972.2662\n",
      "Epoch 1429/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8940.4911 - val_loss: 5701.2466\n",
      "Epoch 1430/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8402.1068 - val_loss: 5428.5125\n",
      "Epoch 1431/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 7816.0010 - val_loss: 5189.3926\n",
      "Epoch 1432/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 7380.2405 - val_loss: 4923.7433\n",
      "Epoch 1433/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 6450.2534 - val_loss: 4652.8997\n",
      "Epoch 1434/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6379.6597 - val_loss: 4383.9844\n",
      "Epoch 1435/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5840.8095 - val_loss: 4124.9062\n",
      "Epoch 1436/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5338.7639 - val_loss: 3914.6124\n",
      "Epoch 1437/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4927.4089 - val_loss: 3692.5589\n",
      "Epoch 1438/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4408.1025 - val_loss: 3473.5599\n",
      "Epoch 1439/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4005.3670 - val_loss: 3288.3635\n",
      "Epoch 1440/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3704.4324 - val_loss: 3168.9714\n",
      "Epoch 1441/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3327.7680 - val_loss: 3030.5356\n",
      "Epoch 1442/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3165.7678 - val_loss: 2919.9051\n",
      "Epoch 1443/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2924.5271 - val_loss: 2823.0486\n",
      "Epoch 1444/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2704.8739 - val_loss: 2705.7801\n",
      "Epoch 1445/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2542.7693 - val_loss: 2604.9398\n",
      "Epoch 1446/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2278.1139 - val_loss: 2508.4929\n",
      "Epoch 1447/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2062.8955 - val_loss: 2422.9753\n",
      "Epoch 1448/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1946.8774 - val_loss: 2377.8995\n",
      "Epoch 1449/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1819.2422 - val_loss: 2300.3218\n",
      "Epoch 1450/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1691.1542 - val_loss: 2234.5068\n",
      "Epoch 1451/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1566.8223 - val_loss: 2184.1555\n",
      "Epoch 1452/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1411.0859 - val_loss: 2135.6476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1453/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1313.1670 - val_loss: 2118.4235\n",
      "Epoch 1454/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1204.2432 - val_loss: 2072.5814\n",
      "Epoch 1455/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1113.0620 - val_loss: 2042.6588\n",
      "Epoch 1456/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1122.8935 - val_loss: 2181.3559\n",
      "Epoch 1457/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2029.1910 - val_loss: 2431.5604\n",
      "Epoch 1458/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2266.4641 - val_loss: 2360.0925\n",
      "Epoch 1459/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1943.3668 - val_loss: 2218.0606\n",
      "Epoch 1460/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1587.7303 - val_loss: 2076.3892\n",
      "Epoch 1461/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1221.9565 - val_loss: 2055.6570\n",
      "Epoch 1462/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1052.2050 - val_loss: 1914.0260\n",
      "Epoch 1463/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 899.0437 - val_loss: 1858.4638\n",
      "Epoch 1464/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 781.5470 - val_loss: 1795.4610\n",
      "Epoch 1465/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 905.4603 - val_loss: 1791.8122\n",
      "Epoch 1466/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 879.9569 - val_loss: 1789.1303\n",
      "Epoch 1467/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 785.7998 - val_loss: 1845.5395\n",
      "Epoch 1468/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 758.6544 - val_loss: 1819.3066\n",
      "Epoch 1469/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 696.9330 - val_loss: 1818.0490\n",
      "Epoch 1470/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 690.2413 - val_loss: 1811.3585\n",
      "Epoch 1471/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 690.4754 - val_loss: 1762.4105\n",
      "Epoch 1472/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 734.8220 - val_loss: 1796.0163\n",
      "Epoch 1473/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1062.4155 - val_loss: 1832.0245\n",
      "Epoch 1474/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1016.1695 - val_loss: 1803.6679\n",
      "Epoch 1475/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 841.1328 - val_loss: 1882.9489\n",
      "Epoch 1476/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 810.5907 - val_loss: 1837.7899\n",
      "Epoch 1477/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 725.0218 - val_loss: 1785.6805\n",
      "Epoch 1478/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 734.1905 - val_loss: 1767.0569\n",
      "Epoch 1479/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 950.8785 - val_loss: 1764.8483\n",
      "Epoch 1480/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 897.2023 - val_loss: 1761.5306\n",
      "Epoch 1481/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 758.4505 - val_loss: 2138.4360\n",
      "Epoch 1482/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 922.8709 - val_loss: 1816.1571\n",
      "Epoch 1483/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1085.9480 - val_loss: 1793.8495\n",
      "Epoch 1484/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 957.3019 - val_loss: 1779.2323\n",
      "Epoch 1485/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 822.3526 - val_loss: 1826.4314\n",
      "Epoch 1486/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 786.5786 - val_loss: 1801.4996\n",
      "Epoch 1487/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 712.9471 - val_loss: 1805.4776\n",
      "Epoch 1488/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 799.1790 - val_loss: 1728.7043\n",
      "Epoch 1489/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 808.2923 - val_loss: 1745.3878\n",
      "Epoch 1490/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 725.3352 - val_loss: 1738.8230\n",
      "Epoch 1491/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 795.8524 - val_loss: 1745.3127\n",
      "Epoch 1492/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 719.3033 - val_loss: 1779.9744\n",
      "Epoch 1493/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 690.0948 - val_loss: 1783.8119\n",
      "Epoch 1494/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 815.4646 - val_loss: 1758.1874\n",
      "Epoch 1495/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 932.4859 - val_loss: 1725.3628\n",
      "Epoch 1496/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 816.0841 - val_loss: 1792.9736\n",
      "Epoch 1497/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 798.5857 - val_loss: 1739.6652\n",
      "Epoch 1498/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 691.3917 - val_loss: 1924.3343\n",
      "Epoch 1499/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 687.4888 - val_loss: 1788.2374\n",
      "Epoch 1500/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 733.9509 - val_loss: 1689.7300\n",
      "Epoch 1501/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 716.2955 - val_loss: 1924.0290\n",
      "Epoch 1502/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 747.3601 - val_loss: 1700.6160\n",
      "Epoch 1503/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 720.8780 - val_loss: 1715.7802\n",
      "Epoch 1504/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1060.6181 - val_loss: 1808.6478\n",
      "Epoch 1505/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1133.1053 - val_loss: 1756.5209\n",
      "Epoch 1506/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 936.4187 - val_loss: 1761.2311\n",
      "Epoch 1507/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 807.7750 - val_loss: 1780.2861\n",
      "Epoch 1508/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 761.5676 - val_loss: 1739.9351\n",
      "Epoch 1509/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 713.9504 - val_loss: 1722.0998\n",
      "Epoch 1510/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 805.5745 - val_loss: 1801.5203\n",
      "Epoch 1511/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1253.0510 - val_loss: 1816.7659\n",
      "Epoch 1512/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1160.3909 - val_loss: 1768.8774\n",
      "Epoch 1513/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 979.5908 - val_loss: 1756.6068\n",
      "Epoch 1514/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 841.8000 - val_loss: 1800.6376\n",
      "Epoch 1515/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 800.0820 - val_loss: 1741.7654\n",
      "Epoch 1516/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 737.7916 - val_loss: 1733.7139\n",
      "Epoch 1517/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 706.8138 - val_loss: 1681.2438\n",
      "Epoch 1518/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 810.8935 - val_loss: 1685.4062\n",
      "Epoch 1519/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 732.5381 - val_loss: 1684.1067\n",
      "Epoch 1520/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1078.7395 - val_loss: 1796.3053\n",
      "Epoch 1521/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1172.4729 - val_loss: 1739.1129\n",
      "Epoch 1522/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 971.8792 - val_loss: 1728.6862\n",
      "Epoch 1523/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 825.4812 - val_loss: 1803.7067\n",
      "Epoch 1524/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 761.3743 - val_loss: 1712.1606\n",
      "Epoch 1525/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 693.0265 - val_loss: 2030.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1526/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 747.1090 - val_loss: 1656.5400\n",
      "Epoch 1527/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 712.9502 - val_loss: 1706.7433\n",
      "Epoch 1528/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 687.4902 - val_loss: 1663.0646\n",
      "Epoch 1529/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 759.5310 - val_loss: 1664.7754\n",
      "Epoch 1530/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 706.4124 - val_loss: 1666.4743\n",
      "Epoch 1531/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 793.5418 - val_loss: 1686.4645\n",
      "Epoch 1532/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 746.5427 - val_loss: 1663.5090\n",
      "Epoch 1533/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 873.6619 - val_loss: 1658.3930\n",
      "Epoch 1534/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 828.0108 - val_loss: 1662.9720\n",
      "Epoch 1535/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 727.0848 - val_loss: 1897.0343\n",
      "Epoch 1536/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 668.0020 - val_loss: 1733.2348\n",
      "Epoch 1537/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 893.3405 - val_loss: 1778.5850\n",
      "Epoch 1538/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1341.1280 - val_loss: 1785.3700\n",
      "Epoch 1539/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1232.3363 - val_loss: 1734.6588\n",
      "Epoch 1540/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1023.5158 - val_loss: 1700.4695\n",
      "Epoch 1541/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 859.6797 - val_loss: 1777.6155\n",
      "Epoch 1542/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 842.7191 - val_loss: 1738.3108\n",
      "Epoch 1543/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 744.6852 - val_loss: 1645.6229\n",
      "Epoch 1544/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 673.9353 - val_loss: 1852.8305\n",
      "Epoch 1545/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 637.9664 - val_loss: 2047.4804\n",
      "Epoch 1546/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1037.7888 - val_loss: 1721.7209\n",
      "Epoch 1547/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1201.8117 - val_loss: 1701.2931\n",
      "Epoch 1548/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1058.1270 - val_loss: 1686.9267\n",
      "Epoch 1549/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 881.6685 - val_loss: 1688.4114\n",
      "Epoch 1550/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 793.4343 - val_loss: 1799.6815\n",
      "Epoch 1551/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 753.6121 - val_loss: 1662.3511\n",
      "Epoch 1552/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 675.4140 - val_loss: 1652.0093\n",
      "Epoch 1553/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 626.9952 - val_loss: 1852.4385\n",
      "Epoch 1554/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 839.3880 - val_loss: 1617.9800\n",
      "Epoch 1555/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 953.7047 - val_loss: 1606.8927\n",
      "Epoch 1556/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 818.7781 - val_loss: 1642.3005\n",
      "Epoch 1557/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 750.0275 - val_loss: 1707.9889\n",
      "Epoch 1558/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 693.7827 - val_loss: 1645.8422\n",
      "Epoch 1559/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 706.6728 - val_loss: 1649.6056\n",
      "Epoch 1560/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1146.8853 - val_loss: 1735.8213\n",
      "Epoch 1561/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1199.9839 - val_loss: 1676.3360\n",
      "Epoch 1562/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1003.5693 - val_loss: 1683.5836\n",
      "Epoch 1563/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 856.3697 - val_loss: 1697.2873\n",
      "Epoch 1564/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 759.7448 - val_loss: 1764.1082\n",
      "Epoch 1565/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 700.5097 - val_loss: 1683.4469\n",
      "Epoch 1566/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 644.3216 - val_loss: 1612.6495\n",
      "Epoch 1567/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 621.1967 - val_loss: 3283.3713\n",
      "Epoch 1568/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1954.8494 - val_loss: 2014.3062\n",
      "Epoch 1569/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2113.8781 - val_loss: 2126.9260\n",
      "Epoch 1570/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2097.2289 - val_loss: 2049.1773\n",
      "Epoch 1571/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1811.3488 - val_loss: 1940.5002\n",
      "Epoch 1572/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1492.1037 - val_loss: 1829.4178\n",
      "Epoch 1573/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1204.0609 - val_loss: 1816.7864\n",
      "Epoch 1574/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1098.1433 - val_loss: 1750.2864\n",
      "Epoch 1575/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 957.7809 - val_loss: 1681.5301\n",
      "Epoch 1576/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 856.1816 - val_loss: 1645.7625\n",
      "Epoch 1577/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 765.9422 - val_loss: 1669.4860\n",
      "Epoch 1578/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 704.9906 - val_loss: 1701.8432\n",
      "Epoch 1579/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 652.1592 - val_loss: 1615.1919\n",
      "Epoch 1580/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 650.0146 - val_loss: 1553.3235\n",
      "Epoch 1581/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 830.8931 - val_loss: 1543.1191\n",
      "Epoch 1582/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 724.5016 - val_loss: 1609.3456\n",
      "Epoch 1583/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 670.1240 - val_loss: 1580.2136\n",
      "Epoch 1584/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 716.1454 - val_loss: 1615.8604\n",
      "Epoch 1585/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 633.1002 - val_loss: 1615.1060\n",
      "Epoch 1586/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 668.4148 - val_loss: 2037.7130\n",
      "Epoch 1587/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1010.9107 - val_loss: 1717.3262\n",
      "Epoch 1588/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1286.1504 - val_loss: 1715.6775\n",
      "Epoch 1589/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1206.8117 - val_loss: 1678.4414\n",
      "Epoch 1590/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1046.0039 - val_loss: 1643.6462\n",
      "Epoch 1591/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 822.9927 - val_loss: 1669.5651\n",
      "Epoch 1592/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 782.7372 - val_loss: 1682.8136\n",
      "Epoch 1593/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 723.5982 - val_loss: 1607.4612\n",
      "Epoch 1594/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 658.8668 - val_loss: 1602.9196\n",
      "Epoch 1595/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 628.3056 - val_loss: 1537.5384\n",
      "Epoch 1596/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 650.1320 - val_loss: 1536.5987\n",
      "Epoch 1597/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 901.8554 - val_loss: 1549.2629\n",
      "Epoch 1598/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 838.2845 - val_loss: 1567.2245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1599/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 749.3267 - val_loss: 1657.0372\n",
      "Epoch 1600/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 702.6608 - val_loss: 1639.6045\n",
      "Epoch 1601/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 690.1206 - val_loss: 1549.0023\n",
      "Epoch 1602/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 681.2580 - val_loss: 2149.6354\n",
      "Epoch 1603/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 951.8955 - val_loss: 1631.4732\n",
      "Epoch 1604/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1166.8170 - val_loss: 1632.0066\n",
      "Epoch 1605/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1055.6829 - val_loss: 1590.7809\n",
      "Epoch 1606/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 896.6838 - val_loss: 1646.7031\n",
      "Epoch 1607/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 800.4044 - val_loss: 1650.2696\n",
      "Epoch 1608/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 731.9139 - val_loss: 1615.8762\n",
      "Epoch 1609/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 670.9456 - val_loss: 2162.6020\n",
      "Epoch 1610/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 757.4766 - val_loss: 1555.9809\n",
      "Epoch 1611/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 784.0788 - val_loss: 1600.4683\n",
      "Epoch 1612/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 635.8812 - val_loss: 1625.7392\n",
      "Epoch 1613/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 653.1102 - val_loss: 1500.3039\n",
      "Epoch 1614/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 677.7560 - val_loss: 1624.0588\n",
      "Epoch 1615/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 625.6942 - val_loss: 1614.6112\n",
      "Epoch 1616/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 627.8934 - val_loss: 1574.7611\n",
      "Epoch 1617/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1127.1798 - val_loss: 1711.4966\n",
      "Epoch 1618/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1413.4007 - val_loss: 1744.3698\n",
      "Epoch 1619/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1410.0605 - val_loss: 1666.1467\n",
      "Epoch 1620/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1160.2004 - val_loss: 1635.2874\n",
      "Epoch 1621/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 974.9269 - val_loss: 1613.2917\n",
      "Epoch 1622/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 779.1760 - val_loss: 1721.6438\n",
      "Epoch 1623/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 684.1255 - val_loss: 1582.0668\n",
      "Epoch 1624/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 628.8510 - val_loss: 1547.4075\n",
      "Epoch 1625/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 606.7441 - val_loss: 1472.1924\n",
      "Epoch 1626/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 619.7097 - val_loss: 2096.7705\n",
      "Epoch 1627/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 747.6762 - val_loss: 1477.9847\n",
      "Epoch 1628/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 733.1684 - val_loss: 1520.9581\n",
      "Epoch 1629/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 669.1125 - val_loss: 1584.2385\n",
      "Epoch 1630/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 616.0356 - val_loss: 1560.6552\n",
      "Epoch 1631/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 613.4879 - val_loss: 1530.5343\n",
      "Epoch 1632/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 606.8156 - val_loss: 1514.4675\n",
      "Epoch 1633/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 630.2932 - val_loss: 1485.5086\n",
      "Epoch 1634/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 627.0587 - val_loss: 1563.2035\n",
      "Epoch 1635/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 635.5870 - val_loss: 1473.7364\n",
      "Epoch 1636/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 819.2228 - val_loss: 1466.7604\n",
      "Epoch 1637/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 756.2016 - val_loss: 1501.4774\n",
      "Epoch 1638/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 690.5694 - val_loss: 2013.5004\n",
      "Epoch 1639/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1975.9981 - val_loss: 2129.8118\n",
      "Epoch 1640/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2068.4611 - val_loss: 1943.6614\n",
      "Epoch 1641/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1656.9077 - val_loss: 1730.7283\n",
      "Epoch 1642/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1093.6406 - val_loss: 1705.1522\n",
      "Epoch 1643/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 841.1882 - val_loss: 1656.5424\n",
      "Epoch 1644/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 705.8645 - val_loss: 1601.5017\n",
      "Epoch 1645/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 628.5309 - val_loss: 1485.0143\n",
      "Epoch 1646/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 756.7327 - val_loss: 1440.2758\n",
      "Epoch 1647/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 674.5867 - val_loss: 1487.5490\n",
      "Epoch 1648/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 619.4731 - val_loss: 1949.7060\n",
      "Epoch 1649/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 712.4910 - val_loss: 1445.0598\n",
      "Epoch 1650/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 685.0542 - val_loss: 1680.1469\n",
      "Epoch 1651/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 668.7414 - val_loss: 1436.3086\n",
      "Epoch 1652/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 682.4953 - val_loss: 1466.8315\n",
      "Epoch 1653/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 607.8780 - val_loss: 1718.4585\n",
      "Epoch 1654/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 594.7610 - val_loss: 1448.9763\n",
      "Epoch 1655/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 640.3120 - val_loss: 1599.6905\n",
      "Epoch 1656/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 605.4541 - val_loss: 1457.3548\n",
      "Epoch 1657/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 617.5103 - val_loss: 1435.5426\n",
      "Epoch 1658/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 633.8686 - val_loss: 1829.8740\n",
      "Epoch 1659/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 608.7623 - val_loss: 1773.3577\n",
      "Epoch 1660/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 682.7140 - val_loss: 1433.7149\n",
      "Epoch 1661/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 704.0293 - val_loss: 1538.2582\n",
      "Epoch 1662/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 638.7950 - val_loss: 1442.2253\n",
      "Epoch 1663/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 623.7138 - val_loss: 1481.0159\n",
      "Epoch 1664/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 791.1264 - val_loss: 1425.1658\n",
      "Epoch 1665/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 749.2720 - val_loss: 1433.0899\n",
      "Epoch 1666/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 643.7398 - val_loss: 1549.5130\n",
      "Epoch 1667/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1045.8468 - val_loss: 1605.6680\n",
      "Epoch 1668/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1370.1879 - val_loss: 1629.3579\n",
      "Epoch 1669/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1293.7208 - val_loss: 1539.1038\n",
      "Epoch 1670/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 978.9148 - val_loss: 1533.2829\n",
      "Epoch 1671/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 876.9253 - val_loss: 1586.3638\n",
      "Epoch 1672/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 756.5658 - val_loss: 1596.6453\n",
      "Epoch 1673/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 660.1036 - val_loss: 1609.0306\n",
      "Epoch 1674/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 569.9614 - val_loss: 1520.0181\n",
      "Epoch 1675/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 629.3815 - val_loss: 1534.9940\n",
      "Epoch 1676/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 671.7386 - val_loss: 1471.2583\n",
      "Epoch 1677/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 621.1662 - val_loss: 1725.4039\n",
      "Epoch 1678/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 819.4767 - val_loss: 1412.3866\n",
      "Epoch 1679/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 821.1811 - val_loss: 1448.4398\n",
      "Epoch 1680/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 686.8528 - val_loss: 1490.3942\n",
      "Epoch 1681/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 658.1539 - val_loss: 1422.0336\n",
      "Epoch 1682/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 683.3189 - val_loss: 1497.6019\n",
      "Epoch 1683/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 608.3678 - val_loss: 1564.3267\n",
      "Epoch 1684/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 631.9807 - val_loss: 1416.3857\n",
      "Epoch 1685/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 594.1332 - val_loss: 1419.6198\n",
      "Epoch 1686/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 633.9623 - val_loss: 1451.7880\n",
      "Epoch 1687/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 638.3878 - val_loss: 1378.0386\n",
      "Epoch 1688/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 601.3813 - val_loss: 1387.9917\n",
      "Epoch 1689/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 639.4391 - val_loss: 1444.1319\n",
      "Epoch 1690/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 596.9422 - val_loss: 1447.1800\n",
      "Epoch 1691/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 629.9669 - val_loss: 1944.9396\n",
      "Epoch 1692/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 680.5103 - val_loss: 1368.1226\n",
      "Epoch 1693/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 663.4941 - val_loss: 1511.9901\n",
      "Epoch 1694/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 631.9181 - val_loss: 1547.8483\n",
      "Epoch 1695/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 633.7641 - val_loss: 1388.8761\n",
      "Epoch 1696/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 659.3494 - val_loss: 1627.9469\n",
      "Epoch 1697/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 672.5280 - val_loss: 1367.7380\n",
      "Epoch 1698/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 706.6991 - val_loss: 1437.5575\n",
      "Epoch 1699/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 601.6046 - val_loss: 1403.2469\n",
      "Epoch 1700/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 610.8478 - val_loss: 1901.0310\n",
      "Epoch 1701/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 634.2560 - val_loss: 1386.5489\n",
      "Epoch 1702/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 653.2087 - val_loss: 1431.7845\n",
      "Epoch 1703/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 584.5855 - val_loss: 1412.0380\n",
      "Epoch 1704/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 591.4914 - val_loss: 2121.6720\n",
      "Epoch 1705/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1811.2029 - val_loss: 1884.0321\n",
      "Epoch 1706/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1839.2142 - val_loss: 1715.7838\n",
      "Epoch 1707/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1481.4563 - val_loss: 1579.4748\n",
      "Epoch 1708/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1227.9270 - val_loss: 1502.5688\n",
      "Epoch 1709/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 956.9989 - val_loss: 1516.1292\n",
      "Epoch 1710/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 825.6749 - val_loss: 1583.5674\n",
      "Epoch 1711/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 774.1707 - val_loss: 1552.8758\n",
      "Epoch 1712/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 675.5027 - val_loss: 1736.3281\n",
      "Epoch 1713/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 613.2040 - val_loss: 1363.9817\n",
      "Epoch 1714/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1120.4073 - val_loss: 1824.4428\n",
      "Epoch 1715/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2106.8975 - val_loss: 1938.2102\n",
      "Epoch 1716/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2020.6289 - val_loss: 1808.8345\n",
      "Epoch 1717/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1677.3731 - val_loss: 1675.5644\n",
      "Epoch 1718/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1255.1062 - val_loss: 1578.4219\n",
      "Epoch 1719/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 982.7476 - val_loss: 1603.2895\n",
      "Epoch 1720/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 793.5568 - val_loss: 1627.1772\n",
      "Epoch 1721/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 630.0229 - val_loss: 1444.6996\n",
      "Epoch 1722/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 673.9764 - val_loss: 1405.0856\n",
      "Epoch 1723/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 619.9461 - val_loss: 1339.3472\n",
      "Epoch 1724/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 632.4317 - val_loss: 2127.1171\n",
      "Epoch 1725/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1619.4547 - val_loss: 1777.7356\n",
      "Epoch 1726/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1530.8312 - val_loss: 1576.2480\n",
      "Epoch 1727/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1112.4945 - val_loss: 1459.1170\n",
      "Epoch 1728/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 899.0659 - val_loss: 1517.5350\n",
      "Epoch 1729/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 825.5289 - val_loss: 1667.1765\n",
      "Epoch 1730/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 710.2663 - val_loss: 1487.7476\n",
      "Epoch 1731/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 803.0658 - val_loss: 1445.1915\n",
      "Epoch 1732/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 858.3286 - val_loss: 1352.3177\n",
      "Epoch 1733/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 693.5075 - val_loss: 1432.1465\n",
      "Epoch 1734/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 638.2919 - val_loss: 1672.0441\n",
      "Epoch 1735/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 685.2634 - val_loss: 1332.1938\n",
      "Epoch 1736/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 685.8958 - val_loss: 1413.8050\n",
      "Epoch 1737/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 643.5418 - val_loss: 1392.5010\n",
      "Epoch 1738/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 792.7442 - val_loss: 1459.1547\n",
      "Epoch 1739/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1083.6486 - val_loss: 1423.7760\n",
      "Epoch 1740/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 895.2583 - val_loss: 1434.4992\n",
      "Epoch 1741/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 715.4939 - val_loss: 1583.7153\n",
      "Epoch 1742/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 638.5045 - val_loss: 1617.4838\n",
      "Epoch 1743/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 627.3437 - val_loss: 1330.5165\n",
      "Epoch 1744/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 640.3513 - val_loss: 1457.2289\n",
      "Epoch 1745/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 927.5404 - val_loss: 1486.6665\n",
      "Epoch 1746/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 794.4610 - val_loss: 1380.2504\n",
      "Epoch 1747/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 689.0024 - val_loss: 1412.1120\n",
      "Epoch 1748/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 634.7070 - val_loss: 1822.6190\n",
      "Epoch 1749/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 620.7092 - val_loss: 1473.7975\n",
      "Epoch 1750/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 691.8714 - val_loss: 1426.4539\n",
      "Epoch 1751/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 907.4941 - val_loss: 1361.4265\n",
      "Epoch 1752/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 740.4650 - val_loss: 1377.4327\n",
      "Epoch 1753/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 631.6100 - val_loss: 1415.1625\n",
      "Epoch 1754/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 576.6520 - val_loss: 1373.4130\n",
      "Epoch 1755/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 593.3887 - val_loss: 1530.9311\n",
      "Epoch 1756/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 564.1098 - val_loss: 1305.3152\n",
      "Epoch 1757/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 623.2046 - val_loss: 1604.1705\n",
      "Epoch 1758/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 562.0794 - val_loss: 1503.8516\n",
      "Epoch 1759/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 607.6487 - val_loss: 1588.6282\n",
      "Epoch 1760/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 548.6953 - val_loss: 1545.1405\n",
      "Epoch 1761/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 575.8587 - val_loss: 1746.6823\n",
      "Epoch 1762/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 601.4607 - val_loss: 1326.9975\n",
      "Epoch 1763/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 535.0899 - val_loss: 1526.6599\n",
      "Epoch 1764/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 543.7678 - val_loss: 1278.4387\n",
      "Epoch 1765/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 822.3129 - val_loss: 1320.3497\n",
      "Epoch 1766/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 784.3418 - val_loss: 1350.6632\n",
      "Epoch 1767/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 624.7774 - val_loss: 1300.7135\n",
      "Epoch 1768/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 636.0258 - val_loss: 1638.8492\n",
      "Epoch 1769/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 573.7660 - val_loss: 1561.3173\n",
      "Epoch 1770/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 584.8018 - val_loss: 1270.1402\n",
      "Epoch 1771/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 604.1107 - val_loss: 1322.4064\n",
      "Epoch 1772/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 636.1305 - val_loss: 1299.8712\n",
      "Epoch 1773/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 536.8283 - val_loss: 1289.2605\n",
      "Epoch 1774/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 519.7288 - val_loss: 1409.1537\n",
      "Epoch 1775/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 539.1400 - val_loss: 1354.4743\n",
      "Epoch 1776/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 575.9522 - val_loss: 1600.3140\n",
      "Epoch 1777/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 631.2941 - val_loss: 1239.9485\n",
      "Epoch 1778/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 576.0248 - val_loss: 1401.4446\n",
      "Epoch 1779/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 540.6326 - val_loss: 1328.6298\n",
      "Epoch 1780/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 578.2609 - val_loss: 1265.7689\n",
      "Epoch 1781/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 587.8446 - val_loss: 1446.4713\n",
      "Epoch 1782/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 554.0868 - val_loss: 1459.2837\n",
      "Epoch 1783/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 601.2139 - val_loss: 1688.5203\n",
      "Epoch 1784/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 589.9902 - val_loss: 1454.5012\n",
      "Epoch 1785/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 583.3715 - val_loss: 1244.3778\n",
      "Epoch 1786/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 624.6596 - val_loss: 1535.3323\n",
      "Epoch 1787/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 654.9915 - val_loss: 1243.6303\n",
      "Epoch 1788/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 615.1809 - val_loss: 1526.2893\n",
      "Epoch 1789/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 624.6588 - val_loss: 1268.6530\n",
      "Epoch 1790/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 678.5505 - val_loss: 1518.1942\n",
      "Epoch 1791/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 582.5218 - val_loss: 1449.3169\n",
      "Epoch 1792/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 553.0100 - val_loss: 1310.3711\n",
      "Epoch 1793/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 509.8639 - val_loss: 1227.6412\n",
      "Epoch 1794/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 591.3841 - val_loss: 1488.5924\n",
      "Epoch 1795/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 849.0664 - val_loss: 1312.9544\n",
      "Epoch 1796/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 676.9883 - val_loss: 1529.2626\n",
      "Epoch 1797/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 624.4647 - val_loss: 1232.9351\n",
      "Epoch 1798/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 629.9431 - val_loss: 1365.2291\n",
      "Epoch 1799/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 655.0664 - val_loss: 1259.6578\n",
      "Epoch 1800/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 547.9499 - val_loss: 1373.4662\n",
      "Epoch 1801/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 556.7819 - val_loss: 1572.7262\n",
      "Epoch 1802/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 625.5557 - val_loss: 1586.8986\n",
      "Epoch 1803/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 602.9856 - val_loss: 1433.7605\n",
      "Epoch 1804/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 572.6877 - val_loss: 1495.8687\n",
      "Epoch 1805/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 595.4966 - val_loss: 1229.3251\n",
      "Epoch 1806/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 548.1091 - val_loss: 1225.6488\n",
      "Epoch 1807/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 578.4610 - val_loss: 1304.0951\n",
      "Epoch 1808/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 602.3172 - val_loss: 1528.4150\n",
      "Epoch 1809/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 712.0239 - val_loss: 1263.3798\n",
      "Epoch 1810/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 657.1676 - val_loss: 1502.7737\n",
      "Epoch 1811/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 945.0882 - val_loss: 1426.1201\n",
      "Epoch 1812/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 804.1661 - val_loss: 1265.9488\n",
      "Epoch 1813/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 624.1770 - val_loss: 1269.8240\n",
      "Epoch 1814/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 565.4204 - val_loss: 1294.3579\n",
      "Epoch 1815/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 633.1899 - val_loss: 1228.0025\n",
      "Epoch 1816/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 626.2691 - val_loss: 1495.5717\n",
      "Epoch 1817/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 659.8900 - val_loss: 1232.3364\n",
      "Epoch 1818/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 647.0997 - val_loss: 1429.6490\n",
      "Epoch 1819/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 585.2284 - val_loss: 1678.5082\n",
      "Epoch 1820/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 675.8385 - val_loss: 1250.1701\n",
      "Epoch 1821/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 672.7041 - val_loss: 1511.1714\n",
      "Epoch 1822/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 597.2521 - val_loss: 1655.3341\n",
      "Epoch 1823/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1028.7641 - val_loss: 1345.4369\n",
      "Epoch 1824/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 912.0715 - val_loss: 1363.2223\n",
      "Epoch 1825/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 773.5208 - val_loss: 1290.1631\n",
      "Epoch 1826/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 725.5224 - val_loss: 1589.8648\n",
      "Epoch 1827/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 637.9402 - val_loss: 1267.5119\n",
      "Epoch 1828/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 669.5508 - val_loss: 1845.0491\n",
      "Epoch 1829/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2536.0434 - val_loss: 2555.0540\n",
      "Epoch 1830/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3413.0844 - val_loss: 2575.4679\n",
      "Epoch 1831/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3002.9310 - val_loss: 2294.0419\n",
      "Epoch 1832/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2016.0791 - val_loss: 1909.6413\n",
      "Epoch 1833/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1241.5566 - val_loss: 1442.5631\n",
      "Epoch 1834/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 896.2833 - val_loss: 1326.7529\n",
      "Epoch 1835/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 693.6891 - val_loss: 1474.9104\n",
      "Epoch 1836/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 621.8680 - val_loss: 1370.3461\n",
      "Epoch 1837/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 654.0471 - val_loss: 1266.2766\n",
      "Epoch 1838/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 645.9469 - val_loss: 1362.3917\n",
      "Epoch 1839/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 707.5171 - val_loss: 1362.2707\n",
      "Epoch 1840/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 586.9202 - val_loss: 1478.0671\n",
      "Epoch 1841/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 605.0552 - val_loss: 1505.9352\n",
      "Epoch 1842/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 540.7390 - val_loss: 1193.8211\n",
      "Epoch 1843/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 637.0903 - val_loss: 1293.2470\n",
      "Epoch 1844/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 863.4321 - val_loss: 1288.8562\n",
      "Epoch 1845/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 692.5547 - val_loss: 1625.7527\n",
      "Epoch 1846/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 658.7582 - val_loss: 1256.6436\n",
      "Epoch 1847/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 655.3121 - val_loss: 1412.7028\n",
      "Epoch 1848/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1254.9021 - val_loss: 1582.9644\n",
      "Epoch 1849/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1334.5420 - val_loss: 1405.1275\n",
      "Epoch 1850/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 832.0039 - val_loss: 1729.0916\n",
      "Epoch 1851/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 690.9392 - val_loss: 1268.9978\n",
      "Epoch 1852/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 664.8934 - val_loss: 1541.2160\n",
      "Epoch 1853/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 690.2879 - val_loss: 1234.2913\n",
      "Epoch 1854/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 690.9190 - val_loss: 1224.8399\n",
      "Epoch 1855/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 563.9154 - val_loss: 1291.9034\n",
      "Epoch 1856/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 553.2815 - val_loss: 1422.6408\n",
      "Epoch 1857/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 525.1783 - val_loss: 1460.2326\n",
      "Epoch 1858/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 793.9425 - val_loss: 1348.9422\n",
      "Epoch 1859/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 889.6566 - val_loss: 1291.2954\n",
      "Epoch 1860/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 777.4568 - val_loss: 1333.5246\n",
      "Epoch 1861/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 693.0967 - val_loss: 1371.0732\n",
      "Epoch 1862/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 621.6208 - val_loss: 1359.8142\n",
      "Epoch 1863/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 544.1678 - val_loss: 1346.7332\n",
      "Epoch 1864/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 542.2196 - val_loss: 1267.3230\n",
      "Epoch 1865/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 577.2730 - val_loss: 1254.3772\n",
      "Epoch 1866/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 525.8608 - val_loss: 1242.2252\n",
      "Epoch 1867/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 661.6202 - val_loss: 1330.4809\n",
      "Epoch 1868/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 756.3558 - val_loss: 1302.2084\n",
      "Epoch 1869/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 667.5481 - val_loss: 1636.7333\n",
      "Epoch 1870/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 719.3168 - val_loss: 1305.3799\n",
      "Epoch 1871/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 598.8520 - val_loss: 1375.2871\n",
      "Epoch 1872/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 621.0896 - val_loss: 1268.4586\n",
      "Epoch 1873/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 730.5417 - val_loss: 1292.9836\n",
      "Epoch 1874/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 620.3837 - val_loss: 1263.7412\n",
      "Epoch 1875/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 574.2844 - val_loss: 1288.1329\n",
      "Epoch 1876/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 491.8388 - val_loss: 1254.4892\n",
      "Epoch 1877/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 578.0328 - val_loss: 1393.8760\n",
      "Epoch 1878/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 555.9871 - val_loss: 1217.1439\n",
      "Epoch 1879/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 542.1364 - val_loss: 1255.9871\n",
      "Epoch 1880/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 572.6935 - val_loss: 1251.9239\n",
      "Epoch 1881/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 577.5575 - val_loss: 1314.2648\n",
      "Epoch 1882/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 663.3329 - val_loss: 1350.5750\n",
      "Epoch 1883/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 618.5108 - val_loss: 1323.0612\n",
      "Epoch 1884/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 563.6698 - val_loss: 1373.7937\n",
      "Epoch 1885/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 501.9302 - val_loss: 1255.2880\n",
      "Epoch 1886/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 592.3575 - val_loss: 1522.0401\n",
      "Epoch 1887/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 948.3162 - val_loss: 1472.9393\n",
      "Epoch 1888/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 723.3715 - val_loss: 1433.4723\n",
      "Epoch 1889/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 560.8434 - val_loss: 1477.5937\n",
      "Epoch 1890/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 737.4572 - val_loss: 1386.9788\n",
      "Epoch 1891/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 62us/step - loss: 838.9107 - val_loss: 1339.5938\n",
      "Epoch 1892/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 729.2524 - val_loss: 1368.2112\n",
      "Epoch 1893/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 828.8467 - val_loss: 1687.1873\n",
      "Epoch 1894/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 759.8410 - val_loss: 1286.9045\n",
      "Epoch 1895/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 678.8553 - val_loss: 1247.4745\n",
      "Epoch 1896/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 862.4874 - val_loss: 1312.0122\n",
      "Epoch 1897/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 866.8955 - val_loss: 1317.3505\n",
      "Epoch 1898/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2230.7640 - val_loss: 2477.1635\n",
      "Epoch 1899/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3607.6727 - val_loss: 2554.3618\n",
      "Epoch 1900/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3674.1013 - val_loss: 2582.1336\n",
      "Epoch 1901/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3075.4953 - val_loss: 2262.1856\n",
      "Epoch 1902/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2556.2345 - val_loss: 2080.8632\n",
      "Epoch 1903/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2081.3559 - val_loss: 1936.5687\n",
      "Epoch 1904/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1770.7307 - val_loss: 1750.9443\n",
      "Epoch 1905/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1421.5219 - val_loss: 1675.4420\n",
      "Epoch 1906/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1158.2654 - val_loss: 1606.2407\n",
      "Epoch 1907/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 952.3517 - val_loss: 1509.7593\n",
      "Epoch 1908/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 843.7569 - val_loss: 1414.7684\n",
      "Epoch 1909/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 744.4294 - val_loss: 1319.7996\n",
      "Epoch 1910/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 670.2723 - val_loss: 1365.5992\n",
      "Epoch 1911/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 611.6977 - val_loss: 1321.9770\n",
      "Epoch 1912/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 583.2668 - val_loss: 1300.0907\n",
      "Epoch 1913/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 629.6469 - val_loss: 1485.2940\n",
      "Epoch 1914/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1002.1083 - val_loss: 1432.7396\n",
      "Epoch 1915/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 794.7762 - val_loss: 1592.4088\n",
      "Epoch 1916/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 760.0620 - val_loss: 1490.7391\n",
      "Epoch 1917/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 847.5281 - val_loss: 1482.1694\n",
      "Epoch 1918/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 690.1855 - val_loss: 1540.1664\n",
      "Epoch 1919/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1495.3955 - val_loss: 1624.8336\n",
      "Epoch 1920/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1193.2147 - val_loss: 1294.6033\n",
      "Epoch 1921/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 1079.33 - 0s 54us/step - loss: 826.6247 - val_loss: 1498.2276\n",
      "Epoch 1922/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 756.6383 - val_loss: 1548.1970\n",
      "Epoch 1923/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 898.0634 - val_loss: 1485.8965\n",
      "Epoch 1924/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 681.8768 - val_loss: 1251.7301\n",
      "Epoch 1925/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 599.5004 - val_loss: 1331.8284\n",
      "Epoch 1926/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 541.5392 - val_loss: 1413.4211\n",
      "Epoch 1927/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 623.5669 - val_loss: 1181.3686\n",
      "Epoch 1928/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 620.6185 - val_loss: 1210.2704\n",
      "Epoch 1929/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 832.5251 - val_loss: 1391.5176\n",
      "Epoch 1930/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1023.2703 - val_loss: 1412.4278\n",
      "Epoch 1931/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 820.9213 - val_loss: 1297.5756\n",
      "Epoch 1932/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 605.2351 - val_loss: 1281.0445\n",
      "Epoch 1933/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 550.5021 - val_loss: 1306.1828\n",
      "Epoch 1934/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 516.7282 - val_loss: 1360.9617\n",
      "Epoch 1935/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 557.3375 - val_loss: 1925.2390\n",
      "Epoch 1936/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1092.3704 - val_loss: 1433.2379\n",
      "Epoch 1937/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 865.3152 - val_loss: 1354.3001\n",
      "Epoch 1938/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 726.9431 - val_loss: 1263.3671\n",
      "Epoch 1939/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 645.2605 - val_loss: 1134.8903\n",
      "Epoch 1940/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 632.9963 - val_loss: 1349.8400\n",
      "Epoch 1941/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 662.3380 - val_loss: 1215.1117\n",
      "Epoch 1942/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 631.3263 - val_loss: 1277.6656\n",
      "Epoch 1943/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 958.9104 - val_loss: 1589.8531\n",
      "Epoch 1944/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1560.0854 - val_loss: 1443.7866\n",
      "Epoch 1945/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1195.0939 - val_loss: 1290.6706\n",
      "Epoch 1946/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 836.9024 - val_loss: 1208.1804\n",
      "Epoch 1947/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 767.1628 - val_loss: 1213.0461\n",
      "Epoch 1948/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 641.1412 - val_loss: 1473.0090\n",
      "Epoch 1949/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 660.4334 - val_loss: 1381.5291\n",
      "Epoch 1950/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 579.8653 - val_loss: 1283.8383\n",
      "Epoch 1951/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 562.1711 - val_loss: 1161.7992\n",
      "Epoch 1952/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 527.3924 - val_loss: 1462.4457\n",
      "Epoch 1953/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 553.6882 - val_loss: 1199.6518\n",
      "Epoch 1954/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 618.8365 - val_loss: 1423.1670\n",
      "Epoch 1955/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 621.4183 - val_loss: 1269.4003\n",
      "Epoch 1956/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 566.2898 - val_loss: 1319.8931\n",
      "Epoch 1957/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 533.8085 - val_loss: 1331.1279\n",
      "Epoch 1958/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 587.7913 - val_loss: 1125.1780\n",
      "Epoch 1959/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 676.8983 - val_loss: 1558.0684\n",
      "Epoch 1960/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 863.4033 - val_loss: 1395.0116\n",
      "Epoch 1961/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 822.9159 - val_loss: 1177.9670\n",
      "Epoch 1962/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 605.1939 - val_loss: 1517.0401\n",
      "Epoch 1963/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 916.0048 - val_loss: 1371.8022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1964/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1038.2440 - val_loss: 1277.8416\n",
      "Epoch 1965/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 877.2394 - val_loss: 1212.1109\n",
      "Epoch 1966/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 697.1524 - val_loss: 1225.6334\n",
      "Epoch 1967/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 609.1292 - val_loss: 1190.0676\n",
      "Epoch 1968/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 536.7992 - val_loss: 1221.3201\n",
      "Epoch 1969/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 499.4360 - val_loss: 1242.9254\n",
      "Epoch 1970/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 494.6035 - val_loss: 1388.8516\n",
      "Epoch 1971/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 484.8286 - val_loss: 1222.3486\n",
      "Epoch 1972/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 517.8550 - val_loss: 1341.6668\n",
      "Epoch 1973/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 469.0535 - val_loss: 1298.7772\n",
      "Epoch 1974/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 467.8249 - val_loss: 1137.4973\n",
      "Epoch 1975/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 733.8793 - val_loss: 1465.2069\n",
      "Epoch 1976/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 917.3317 - val_loss: 1198.9590\n",
      "Epoch 1977/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 881.4775 - val_loss: 1176.2823\n",
      "Epoch 1978/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 634.3519 - val_loss: 1413.6170\n",
      "Epoch 1979/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 569.3394 - val_loss: 1197.6645\n",
      "Epoch 1980/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 599.2327 - val_loss: 1154.9122\n",
      "Epoch 1981/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 547.3998 - val_loss: 1206.1301\n",
      "Epoch 1982/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 485.6970 - val_loss: 1275.7140\n",
      "Epoch 1983/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 522.5770 - val_loss: 1134.3210\n",
      "Epoch 1984/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 635.9798 - val_loss: 1168.6041\n",
      "Epoch 1985/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 550.3686 - val_loss: 1188.0252\n",
      "Epoch 1986/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 529.4545 - val_loss: 1182.7297\n",
      "Epoch 1987/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 521.3713 - val_loss: 1137.4597\n",
      "Epoch 1988/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 505.9855 - val_loss: 1319.0054\n",
      "Epoch 1989/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 490.2337 - val_loss: 1159.6684\n",
      "Epoch 1990/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 467.7770 - val_loss: 1181.6683\n",
      "Epoch 1991/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 456.4893 - val_loss: 1188.7135\n",
      "Epoch 1992/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 447.4574 - val_loss: 1379.6370\n",
      "Epoch 1993/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 515.0429 - val_loss: 1167.5593\n",
      "Epoch 1994/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 475.5358 - val_loss: 1210.6582\n",
      "Epoch 1995/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 455.0512 - val_loss: 1169.2287\n",
      "Epoch 1996/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 483.8646 - val_loss: 1097.7730\n",
      "Epoch 1997/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 517.2817 - val_loss: 1230.3293\n",
      "Epoch 1998/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 471.7657 - val_loss: 1158.5747\n",
      "Epoch 1999/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 443.2449 - val_loss: 1224.3943\n",
      "Epoch 2000/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 937.4704 - val_loss: 1412.6054\n",
      "Epoch 2001/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1351.9338 - val_loss: 1401.2839\n",
      "Epoch 2002/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1273.1981 - val_loss: 1334.7866\n",
      "Epoch 2003/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1041.4112 - val_loss: 1314.8251\n",
      "Epoch 2004/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 812.6262 - val_loss: 1257.2596\n",
      "Epoch 2005/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 699.9427 - val_loss: 1155.5573\n",
      "Epoch 2006/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 635.3542 - val_loss: 1138.3683\n",
      "Epoch 2007/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 581.0901 - val_loss: 1107.3957\n",
      "Epoch 2008/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 521.6471 - val_loss: 1156.9855\n",
      "Epoch 2009/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 476.1602 - val_loss: 1225.0164\n",
      "Epoch 2010/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 471.5200 - val_loss: 1209.5936\n",
      "Epoch 2011/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 484.4645 - val_loss: 1188.4742\n",
      "Epoch 2012/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 484.7659 - val_loss: 1251.8642\n",
      "Epoch 2013/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.2853 - val_loss: 1189.1622\n",
      "Epoch 2014/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 431.8661 - val_loss: 1236.8126\n",
      "Epoch 2015/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 452.0447 - val_loss: 1134.2993\n",
      "Epoch 2016/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 575.6302 - val_loss: 1107.6889\n",
      "Epoch 2017/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 528.5625 - val_loss: 1182.0516\n",
      "Epoch 2018/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 492.8582 - val_loss: 1240.3693\n",
      "Epoch 2019/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 485.7643 - val_loss: 1175.3733\n",
      "Epoch 2020/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 526.7059 - val_loss: 1101.0505\n",
      "Epoch 2021/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 495.8802 - val_loss: 1347.9592\n",
      "Epoch 2022/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 525.7827 - val_loss: 1087.9514\n",
      "Epoch 2023/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.7534 - val_loss: 1176.9252\n",
      "Epoch 2024/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 516.5187 - val_loss: 1140.5519\n",
      "Epoch 2025/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 464.2476 - val_loss: 1133.8008\n",
      "Epoch 2026/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 458.3830 - val_loss: 1231.2455\n",
      "Epoch 2027/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 445.7222 - val_loss: 1145.8617\n",
      "Epoch 2028/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.0355 - val_loss: 1243.1436\n",
      "Epoch 2029/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 559.8651 - val_loss: 1280.7715\n",
      "Epoch 2030/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1130.2917 - val_loss: 1351.2182\n",
      "Epoch 2031/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 937.8436 - val_loss: 1071.5696\n",
      "Epoch 2032/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 643.0575 - val_loss: 1055.5001\n",
      "Epoch 2033/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 581.8267 - val_loss: 1074.1531\n",
      "Epoch 2034/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 704.9164 - val_loss: 1176.5717\n",
      "Epoch 2035/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1116.8812 - val_loss: 1253.4445\n",
      "Epoch 2036/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 774.6076 - val_loss: 1283.7449\n",
      "Epoch 2037/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 1120.8007 - val_loss: 1575.5956\n",
      "Epoch 2038/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1160.5735 - val_loss: 1397.5205\n",
      "Epoch 2039/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 766.4489 - val_loss: 1343.9675\n",
      "Epoch 2040/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 792.7764 - val_loss: 1113.6497\n",
      "Epoch 2041/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 851.9190 - val_loss: 1318.1279\n",
      "Epoch 2042/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 686.6954 - val_loss: 1066.3869\n",
      "Epoch 2043/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 554.0741 - val_loss: 1106.6496\n",
      "Epoch 2044/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 505.7374 - val_loss: 1120.2900\n",
      "Epoch 2045/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 558.1543 - val_loss: 1100.8956\n",
      "Epoch 2046/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 679.4016 - val_loss: 1057.8671\n",
      "Epoch 2047/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 601.1977 - val_loss: 1158.7600\n",
      "Epoch 2048/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 602.8699 - val_loss: 1138.0527\n",
      "Epoch 2049/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 493.6366 - val_loss: 1087.1525\n",
      "Epoch 2050/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 473.9643 - val_loss: 1110.6692\n",
      "Epoch 2051/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 450.6034 - val_loss: 1149.5847\n",
      "Epoch 2052/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 485.1525 - val_loss: 1061.9094\n",
      "Epoch 2053/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 474.3890 - val_loss: 1181.8084\n",
      "Epoch 2054/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 459.1086 - val_loss: 1117.4489\n",
      "Epoch 2055/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 481.0889 - val_loss: 1109.8736\n",
      "Epoch 2056/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 497.8021 - val_loss: 1231.8950\n",
      "Epoch 2057/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 490.2749 - val_loss: 1136.7308\n",
      "Epoch 2058/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 501.9645 - val_loss: 1202.6331\n",
      "Epoch 2059/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 463.9179 - val_loss: 1186.7475\n",
      "Epoch 2060/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 488.1924 - val_loss: 1113.4042\n",
      "Epoch 2061/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 505.2158 - val_loss: 1056.5012\n",
      "Epoch 2062/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 698.6615 - val_loss: 1227.2699\n",
      "Epoch 2063/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1041.4150 - val_loss: 1156.1916\n",
      "Epoch 2064/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 744.8747 - val_loss: 1052.3657\n",
      "Epoch 2065/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 694.0006 - val_loss: 1062.0391\n",
      "Epoch 2066/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 561.2956 - val_loss: 1108.3273\n",
      "Epoch 2067/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 532.9138 - val_loss: 1268.5779\n",
      "Epoch 2068/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 467.1444 - val_loss: 1081.7418\n",
      "Epoch 2069/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 465.9130 - val_loss: 1126.1427\n",
      "Epoch 2070/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 461.0681 - val_loss: 1353.6742\n",
      "Epoch 2071/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 728.1234 - val_loss: 1138.9200\n",
      "Epoch 2072/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 615.7044 - val_loss: 1124.5216\n",
      "Epoch 2073/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 492.1856 - val_loss: 1129.7723\n",
      "Epoch 2074/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 461.0172 - val_loss: 1099.2893\n",
      "Epoch 2075/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 445.2478 - val_loss: 1114.5653\n",
      "Epoch 2076/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 423.1957 - val_loss: 1107.7377\n",
      "Epoch 2077/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 479.3135 - val_loss: 1141.1332\n",
      "Epoch 2078/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 436.8873 - val_loss: 1433.4577\n",
      "Epoch 2079/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 776.6998 - val_loss: 1143.5325\n",
      "Epoch 2080/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 766.7928 - val_loss: 1066.1555\n",
      "Epoch 2081/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 598.7587 - val_loss: 1016.7519\n",
      "Epoch 2082/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 682.8569 - val_loss: 1067.3807\n",
      "Epoch 2083/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 576.4722 - val_loss: 1097.1093\n",
      "Epoch 2084/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 476.0154 - val_loss: 1248.4436\n",
      "Epoch 2085/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 459.4369 - val_loss: 1175.2350\n",
      "Epoch 2086/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 553.3600 - val_loss: 1168.5638\n",
      "Epoch 2087/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 595.9084 - val_loss: 1116.4774\n",
      "Epoch 2088/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 517.2021 - val_loss: 1094.7709\n",
      "Epoch 2089/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 488.5104 - val_loss: 1148.1138\n",
      "Epoch 2090/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 443.4956 - val_loss: 1156.5238\n",
      "Epoch 2091/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 426.7311 - val_loss: 1103.9737\n",
      "Epoch 2092/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 436.4175 - val_loss: 1171.0901\n",
      "Epoch 2093/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 444.8276 - val_loss: 1126.9163\n",
      "Epoch 2094/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 412.2349 - val_loss: 1128.4418\n",
      "Epoch 2095/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 408.7444 - val_loss: 1254.6079\n",
      "Epoch 2096/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 419.5832 - val_loss: 1497.3663\n",
      "Epoch 2097/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 444.7373 - val_loss: 1107.8162\n",
      "Epoch 2098/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 458.3830 - val_loss: 1045.4160\n",
      "Epoch 2099/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 439.7054 - val_loss: 1014.8064\n",
      "Epoch 2100/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 463.8887 - val_loss: 1047.4618\n",
      "Epoch 2101/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 518.8798 - val_loss: 1203.6024\n",
      "Epoch 2102/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 505.8319 - val_loss: 1064.0617\n",
      "Epoch 2103/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 461.3077 - val_loss: 1017.4745\n",
      "Epoch 2104/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 675.1468 - val_loss: 1274.2816\n",
      "Epoch 2105/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 798.5664 - val_loss: 1016.9892\n",
      "Epoch 2106/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 619.6942 - val_loss: 1108.4258\n",
      "Epoch 2107/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 572.6405 - val_loss: 1008.8462\n",
      "Epoch 2108/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 493.1927 - val_loss: 949.1114\n",
      "Epoch 2109/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 578.7892 - val_loss: 1313.2452\n",
      "Epoch 2110/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 635.4496 - val_loss: 1268.2485\n",
      "Epoch 2111/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 721.2738 - val_loss: 1397.3567\n",
      "Epoch 2112/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 736.8673 - val_loss: 1192.6289\n",
      "Epoch 2113/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 560.5716 - val_loss: 1110.4612\n",
      "Epoch 2114/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 677.9137 - val_loss: 998.3267\n",
      "Epoch 2115/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 877.1542 - val_loss: 1105.1344\n",
      "Epoch 2116/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 792.4776 - val_loss: 1111.0741\n",
      "Epoch 2117/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 554.1697 - val_loss: 1040.2278\n",
      "Epoch 2118/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 518.7429 - val_loss: 1944.0577\n",
      "Epoch 2119/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2219.3017 - val_loss: 1638.0296\n",
      "Epoch 2120/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2235.9113 - val_loss: 1625.6559\n",
      "Epoch 2121/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2049.8950 - val_loss: 1516.4887\n",
      "Epoch 2122/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1703.5349 - val_loss: 1357.9289\n",
      "Epoch 2123/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1182.8998 - val_loss: 1412.6514\n",
      "Epoch 2124/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 794.1868 - val_loss: 1161.9389\n",
      "Epoch 2125/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 650.8606 - val_loss: 1167.2734\n",
      "Epoch 2126/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 573.2428 - val_loss: 1427.6519\n",
      "Epoch 2127/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 820.7075 - val_loss: 1384.4485\n",
      "Epoch 2128/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 806.8943 - val_loss: 1020.0551\n",
      "Epoch 2129/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 575.6334 - val_loss: 1035.7543\n",
      "Epoch 2130/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 499.0417 - val_loss: 1067.2747\n",
      "Epoch 2131/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 521.5164 - val_loss: 1071.2497\n",
      "Epoch 2132/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 463.2672 - val_loss: 1015.0075\n",
      "Epoch 2133/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 564.7697 - val_loss: 1136.2844\n",
      "Epoch 2134/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 511.9221 - val_loss: 1030.6700\n",
      "Epoch 2135/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 457.1745 - val_loss: 1085.5893\n",
      "Epoch 2136/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 433.5589 - val_loss: 1103.6189\n",
      "Epoch 2137/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 443.6524 - val_loss: 1165.0434\n",
      "Epoch 2138/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 544.0737 - val_loss: 1040.2327\n",
      "Epoch 2139/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 502.8454 - val_loss: 1129.6323\n",
      "Epoch 2140/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 449.0150 - val_loss: 1137.6338\n",
      "Epoch 2141/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 445.0266 - val_loss: 1300.5122\n",
      "Epoch 2142/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 659.1894 - val_loss: 1190.7245\n",
      "Epoch 2143/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 785.0932 - val_loss: 1088.5666\n",
      "Epoch 2144/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 598.9308 - val_loss: 1084.6680\n",
      "Epoch 2145/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 567.2428 - val_loss: 1051.4545\n",
      "Epoch 2146/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 489.4477 - val_loss: 1030.1442\n",
      "Epoch 2147/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 462.1486 - val_loss: 1170.3462\n",
      "Epoch 2148/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 473.3157 - val_loss: 1023.9761\n",
      "Epoch 2149/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 520.6932 - val_loss: 1109.8133\n",
      "Epoch 2150/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 568.5591 - val_loss: 1075.6335\n",
      "Epoch 2151/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 631.8215 - val_loss: 1239.3776\n",
      "Epoch 2152/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 502.3252 - val_loss: 1300.8107\n",
      "Epoch 2153/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 497.4019 - val_loss: 1381.6966\n",
      "Epoch 2154/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 513.1354 - val_loss: 1173.0915\n",
      "Epoch 2155/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 463.6790 - val_loss: 1110.8481\n",
      "Epoch 2156/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 435.6347 - val_loss: 1108.6077\n",
      "Epoch 2157/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 434.9973 - val_loss: 1049.0032\n",
      "Epoch 2158/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 493.9524 - val_loss: 1346.8119\n",
      "Epoch 2159/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 726.5678 - val_loss: 1061.3024\n",
      "Epoch 2160/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 559.2894 - val_loss: 969.2777\n",
      "Epoch 2161/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 489.4594 - val_loss: 1029.5284\n",
      "Epoch 2162/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 435.5213 - val_loss: 1130.3097\n",
      "Epoch 2163/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 444.2982 - val_loss: 1068.9606\n",
      "Epoch 2164/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 443.1718 - val_loss: 1089.1823\n",
      "Epoch 2165/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 432.1432 - val_loss: 1069.7798\n",
      "Epoch 2166/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 396.6904 - val_loss: 1107.1009\n",
      "Epoch 2167/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 415.2352 - val_loss: 1155.7738\n",
      "Epoch 2168/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 511.6171 - val_loss: 1096.1611\n",
      "Epoch 2169/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 476.6127 - val_loss: 1045.4369\n",
      "Epoch 2170/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 444.2106 - val_loss: 1135.0467\n",
      "Epoch 2171/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 409.0711 - val_loss: 1081.1652\n",
      "Epoch 2172/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 488.5158 - val_loss: 1281.0022\n",
      "Epoch 2173/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 497.5012 - val_loss: 1161.1029\n",
      "Epoch 2174/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 540.2318 - val_loss: 1075.9294\n",
      "Epoch 2175/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 521.9246 - val_loss: 1252.0877\n",
      "Epoch 2176/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 502.7661 - val_loss: 1054.5439\n",
      "Epoch 2177/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 513.5986 - val_loss: 1139.1584\n",
      "Epoch 2178/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.8173 - val_loss: 1249.5716\n",
      "Epoch 2179/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1789.0742 - val_loss: 1905.2670\n",
      "Epoch 2180/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2250.3561 - val_loss: 1697.6428\n",
      "Epoch 2181/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1845.9555 - val_loss: 1420.3657\n",
      "Epoch 2182/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1538.4706 - val_loss: 1221.4886\n",
      "Epoch 2183/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 1312.9874 - val_loss: 1110.3651\n",
      "Epoch 2184/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 979.0255 - val_loss: 969.8876\n",
      "Epoch 2185/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 702.3956 - val_loss: 1166.2086\n",
      "Epoch 2186/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 572.1025 - val_loss: 1147.1708\n",
      "Epoch 2187/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 501.3414 - val_loss: 1131.8602\n",
      "Epoch 2188/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 439.1999 - val_loss: 1234.5894\n",
      "Epoch 2189/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 459.1912 - val_loss: 1064.4105\n",
      "Epoch 2190/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.2038 - val_loss: 1138.6052\n",
      "Epoch 2191/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 411.0654 - val_loss: 1151.6441\n",
      "Epoch 2192/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 414.1392 - val_loss: 1105.1797\n",
      "Epoch 2193/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 466.6436 - val_loss: 1011.1922\n",
      "Epoch 2194/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 472.9636 - val_loss: 1198.9888\n",
      "Epoch 2195/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 448.9250 - val_loss: 1065.6570\n",
      "Epoch 2196/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 415.2092 - val_loss: 1215.0582\n",
      "Epoch 2197/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 544.1052 - val_loss: 1063.8821\n",
      "Epoch 2198/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 505.8579 - val_loss: 1107.9926\n",
      "Epoch 2199/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 481.9600 - val_loss: 1249.9628\n",
      "Epoch 2200/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 443.0112 - val_loss: 1391.6477\n",
      "Epoch 2201/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 613.3041 - val_loss: 1120.7540\n",
      "Epoch 2202/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 544.0410 - val_loss: 1048.2281\n",
      "Epoch 2203/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 488.6601 - val_loss: 1051.5660\n",
      "Epoch 2204/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 437.5038 - val_loss: 1110.8033\n",
      "Epoch 2205/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 452.2802 - val_loss: 1016.6827\n",
      "Epoch 2206/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 477.3217 - val_loss: 1041.6540\n",
      "Epoch 2207/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 452.4687 - val_loss: 1028.8129\n",
      "Epoch 2208/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 433.6026 - val_loss: 1086.1790\n",
      "Epoch 2209/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.7057 - val_loss: 1045.5557\n",
      "Epoch 2210/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 428.1336 - val_loss: 1105.8941\n",
      "Epoch 2211/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.2572 - val_loss: 1152.7584\n",
      "Epoch 2212/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 509.5490 - val_loss: 1064.5611\n",
      "Epoch 2213/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 466.2666 - val_loss: 1095.7021\n",
      "Epoch 2214/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 438.6399 - val_loss: 1056.1336\n",
      "Epoch 2215/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 437.3202 - val_loss: 1060.6473\n",
      "Epoch 2216/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 428.0725 - val_loss: 1128.7898\n",
      "Epoch 2217/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 412.9258 - val_loss: 1080.5563\n",
      "Epoch 2218/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 399.8262 - val_loss: 1016.8664\n",
      "Epoch 2219/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 408.0431 - val_loss: 1130.3772\n",
      "Epoch 2220/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 405.2611 - val_loss: 1091.1759\n",
      "Epoch 2221/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.9985 - val_loss: 1049.2165\n",
      "Epoch 2222/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 391.3845 - val_loss: 1056.0757\n",
      "Epoch 2223/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 387.5381 - val_loss: 1076.5700\n",
      "Epoch 2224/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 388.5505 - val_loss: 1114.1909\n",
      "Epoch 2225/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 381.6351 - val_loss: 1005.4364\n",
      "Epoch 2226/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.7390 - val_loss: 1053.5875\n",
      "Epoch 2227/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 393.0008 - val_loss: 1010.7767\n",
      "Epoch 2228/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 420.3130 - val_loss: 1006.0497\n",
      "Epoch 2229/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 411.1228 - val_loss: 974.3095\n",
      "Epoch 2230/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 416.9418 - val_loss: 942.4750\n",
      "Epoch 2231/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 424.2563 - val_loss: 972.4097\n",
      "Epoch 2232/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 428.5406 - val_loss: 1089.7382\n",
      "Epoch 2233/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 405.6973 - val_loss: 957.4825\n",
      "Epoch 2234/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 404.2387 - val_loss: 985.1740\n",
      "Epoch 2235/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 412.7783 - val_loss: 924.0269\n",
      "Epoch 2236/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 444.1498 - val_loss: 932.8711\n",
      "Epoch 2237/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 603.9958 - val_loss: 1051.9628\n",
      "Epoch 2238/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 544.1233 - val_loss: 909.7832\n",
      "Epoch 2239/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 591.2047 - val_loss: 1167.5191\n",
      "Epoch 2240/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 567.6673 - val_loss: 919.5578\n",
      "Epoch 2241/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 554.2517 - val_loss: 1456.1688\n",
      "Epoch 2242/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 532.2151 - val_loss: 1029.0772\n",
      "Epoch 2243/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 480.3277 - val_loss: 943.9882\n",
      "Epoch 2244/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 467.3555 - val_loss: 1102.4754\n",
      "Epoch 2245/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 535.7810 - val_loss: 1079.6617\n",
      "Epoch 2246/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 511.9252 - val_loss: 1024.2380\n",
      "Epoch 2247/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 449.6500 - val_loss: 1210.2754\n",
      "Epoch 2248/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 546.0987 - val_loss: 1088.9141\n",
      "Epoch 2249/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 737.1068 - val_loss: 1124.6678\n",
      "Epoch 2250/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 592.0010 - val_loss: 1120.7015\n",
      "Epoch 2251/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 468.2729 - val_loss: 1168.6017\n",
      "Epoch 2252/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 475.3082 - val_loss: 1199.4428\n",
      "Epoch 2253/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 498.5945 - val_loss: 1188.7187\n",
      "Epoch 2254/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 442.5616 - val_loss: 1021.4840\n",
      "Epoch 2255/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 470.9958 - val_loss: 1050.2639\n",
      "Epoch 2256/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 427.1826 - val_loss: 1076.4041\n",
      "Epoch 2257/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 410.0549 - val_loss: 1240.1687\n",
      "Epoch 2258/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 647.0250 - val_loss: 1076.1319\n",
      "Epoch 2259/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 626.3545 - val_loss: 1007.4841\n",
      "Epoch 2260/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 516.6436 - val_loss: 1069.9300\n",
      "Epoch 2261/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.9476 - val_loss: 1058.8025\n",
      "Epoch 2262/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 500.7605 - val_loss: 1045.4219\n",
      "Epoch 2263/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 468.6398 - val_loss: 1309.8391\n",
      "Epoch 2264/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 488.7060 - val_loss: 1027.2603\n",
      "Epoch 2265/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 423.6421 - val_loss: 1208.7242\n",
      "Epoch 2266/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 543.1530 - val_loss: 1036.8562\n",
      "Epoch 2267/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 614.1391 - val_loss: 1037.7871\n",
      "Epoch 2268/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 522.5296 - val_loss: 1090.8912\n",
      "Epoch 2269/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 440.8364 - val_loss: 1065.3659\n",
      "Epoch 2270/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 429.8354 - val_loss: 1014.2157\n",
      "Epoch 2271/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 426.9424 - val_loss: 1078.3341\n",
      "Epoch 2272/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 391.6818 - val_loss: 1153.2689\n",
      "Epoch 2273/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 397.2075 - val_loss: 1011.4613\n",
      "Epoch 2274/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 394.8919 - val_loss: 1063.0359\n",
      "Epoch 2275/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 388.1500 - val_loss: 1190.0724\n",
      "Epoch 2276/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.8193 - val_loss: 1083.2368\n",
      "Epoch 2277/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 387.4142 - val_loss: 1115.6828\n",
      "Epoch 2278/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 383.6708 - val_loss: 1115.7853\n",
      "Epoch 2279/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 381.9762 - val_loss: 1090.2080\n",
      "Epoch 2280/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 368.9961 - val_loss: 1054.6292\n",
      "Epoch 2281/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 460.7619 - val_loss: 1037.0473\n",
      "Epoch 2282/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 498.9052 - val_loss: 970.2004\n",
      "Epoch 2283/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 463.2914 - val_loss: 1037.9604\n",
      "Epoch 2284/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 388.9575 - val_loss: 1005.0386\n",
      "Epoch 2285/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 588.9710 - val_loss: 978.9942\n",
      "Epoch 2286/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 551.3210 - val_loss: 910.0763\n",
      "Epoch 2287/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 490.1804 - val_loss: 1240.6929\n",
      "Epoch 2288/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 444.3056 - val_loss: 1174.3188\n",
      "Epoch 2289/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 475.1868 - val_loss: 1310.3675\n",
      "Epoch 2290/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1521.3704 - val_loss: 1212.3488\n",
      "Epoch 2291/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1292.1025 - val_loss: 1319.0639\n",
      "Epoch 2292/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 843.4323 - val_loss: 1196.8370\n",
      "Epoch 2293/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 615.2941 - val_loss: 1063.3941\n",
      "Epoch 2294/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 564.1871 - val_loss: 1010.3975\n",
      "Epoch 2295/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 471.3051 - val_loss: 1070.2338\n",
      "Epoch 2296/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 483.6568 - val_loss: 996.9487\n",
      "Epoch 2297/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 991.4696 - val_loss: 1033.9999\n",
      "Epoch 2298/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 817.0577 - val_loss: 1069.2938\n",
      "Epoch 2299/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 556.9327 - val_loss: 993.1641\n",
      "Epoch 2300/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1087.7180 - val_loss: 1088.5466\n",
      "Epoch 2301/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 958.7109 - val_loss: 942.0592\n",
      "Epoch 2302/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 664.3917 - val_loss: 967.7105\n",
      "Epoch 2303/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 553.0287 - val_loss: 1228.5360\n",
      "Epoch 2304/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 492.2914 - val_loss: 1158.0019\n",
      "Epoch 2305/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 448.8656 - val_loss: 1034.5709\n",
      "Epoch 2306/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 535.8911 - val_loss: 1132.3176\n",
      "Epoch 2307/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 471.0460 - val_loss: 1084.2115\n",
      "Epoch 2308/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1016.3925 - val_loss: 1322.0203\n",
      "Epoch 2309/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1008.8382 - val_loss: 1080.2726\n",
      "Epoch 2310/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 675.4927 - val_loss: 1114.5865\n",
      "Epoch 2311/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 657.4922 - val_loss: 1199.8652\n",
      "Epoch 2312/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 538.3425 - val_loss: 1060.6748\n",
      "Epoch 2313/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 470.8070 - val_loss: 1073.2328\n",
      "Epoch 2314/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 452.8156 - val_loss: 1019.6556\n",
      "Epoch 2315/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 439.2486 - val_loss: 1115.2493\n",
      "Epoch 2316/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 408.0296 - val_loss: 1136.9440\n",
      "Epoch 2317/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 410.2389 - val_loss: 1110.1939\n",
      "Epoch 2318/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 394.8092 - val_loss: 1098.3426\n",
      "Epoch 2319/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 397.8093 - val_loss: 1098.2353\n",
      "Epoch 2320/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 406.6399 - val_loss: 1038.5043\n",
      "Epoch 2321/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 415.2645 - val_loss: 1074.0986\n",
      "Epoch 2322/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 389.3204 - val_loss: 984.8288\n",
      "Epoch 2323/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 387.8886 - val_loss: 965.6534\n",
      "Epoch 2324/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 428.6371 - val_loss: 1295.7334\n",
      "Epoch 2325/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 431.0780 - val_loss: 1115.0656\n",
      "Epoch 2326/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 388.3357 - val_loss: 1018.6854\n",
      "Epoch 2327/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 385.3448 - val_loss: 952.2996\n",
      "Epoch 2328/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 475.8606 - val_loss: 931.2614\n",
      "Epoch 2329/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 425.1375 - val_loss: 888.4053\n",
      "Epoch 2330/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 736.9733 - val_loss: 1092.1051\n",
      "Epoch 2331/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 708.4453 - val_loss: 1095.4605\n",
      "Epoch 2332/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 531.6366 - val_loss: 1062.3198\n",
      "Epoch 2333/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 823.0240 - val_loss: 2278.0763\n",
      "Epoch 2334/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1426.7868 - val_loss: 1281.9195\n",
      "Epoch 2335/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1578.1464 - val_loss: 1127.9102\n",
      "Epoch 2336/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1244.6249 - val_loss: 1095.1880\n",
      "Epoch 2337/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 824.8868 - val_loss: 1133.7280\n",
      "Epoch 2338/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 664.2056 - val_loss: 1172.1071\n",
      "Epoch 2339/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 555.8933 - val_loss: 1144.6786\n",
      "Epoch 2340/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 463.8600 - val_loss: 1088.3868\n",
      "Epoch 2341/10000\n",
      "630/630 [==============================] - 0s 79us/step - loss: 434.6529 - val_loss: 1033.2712\n",
      "Epoch 2342/10000\n",
      "630/630 [==============================] - 0s 101us/step - loss: 423.5924 - val_loss: 977.7149\n",
      "Epoch 2343/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 439.6818 - val_loss: 911.0055\n",
      "Epoch 2344/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 463.6351 - val_loss: 919.2689\n",
      "Epoch 2345/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 443.0478 - val_loss: 940.3894\n",
      "Epoch 2346/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 603.7264 - val_loss: 970.2583\n",
      "Epoch 2347/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 793.3071 - val_loss: 1160.1213\n",
      "Epoch 2348/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 621.5330 - val_loss: 957.9838\n",
      "Epoch 2349/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 499.3318 - val_loss: 1123.1753\n",
      "Epoch 2350/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 478.5033 - val_loss: 1322.8291\n",
      "Epoch 2351/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 465.5587 - val_loss: 1062.9387\n",
      "Epoch 2352/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 425.2785 - val_loss: 1037.3363\n",
      "Epoch 2353/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 917.5491 - val_loss: 979.2447\n",
      "Epoch 2354/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 736.3835 - val_loss: 1204.1896\n",
      "Epoch 2355/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 633.9255 - val_loss: 1079.5296\n",
      "Epoch 2356/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 520.4916 - val_loss: 1068.7771\n",
      "Epoch 2357/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 480.6030 - val_loss: 983.8451\n",
      "Epoch 2358/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 445.0777 - val_loss: 1079.7077\n",
      "Epoch 2359/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 413.3372 - val_loss: 1129.7313\n",
      "Epoch 2360/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 411.9068 - val_loss: 996.2608\n",
      "Epoch 2361/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 391.8120 - val_loss: 1023.0333\n",
      "Epoch 2362/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 393.3818 - val_loss: 1034.8415\n",
      "Epoch 2363/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 400.3431 - val_loss: 986.0262\n",
      "Epoch 2364/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 471.4126 - val_loss: 962.1129\n",
      "Epoch 2365/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 584.6899 - val_loss: 1033.8800\n",
      "Epoch 2366/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 575.2176 - val_loss: 1093.4872\n",
      "Epoch 2367/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 473.3451 - val_loss: 1099.5859\n",
      "Epoch 2368/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 452.5458 - val_loss: 1021.1634\n",
      "Epoch 2369/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 544.670 - 0s 55us/step - loss: 427.8533 - val_loss: 999.0349\n",
      "Epoch 2370/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 411.8159 - val_loss: 1040.8050\n",
      "Epoch 2371/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 398.9497 - val_loss: 978.1719\n",
      "Epoch 2372/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 414.9830 - val_loss: 1006.8295\n",
      "Epoch 2373/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.7721 - val_loss: 1039.1686\n",
      "Epoch 2374/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 398.2025 - val_loss: 964.5195\n",
      "Epoch 2375/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 392.6577 - val_loss: 976.2698\n",
      "Epoch 2376/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.8988 - val_loss: 987.7023\n",
      "Epoch 2377/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 394.6964 - val_loss: 989.8508\n",
      "Epoch 2378/10000\n",
      "630/630 [==============================] - 0s 78us/step - loss: 434.9739 - val_loss: 1051.9194\n",
      "Epoch 2379/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 441.7457 - val_loss: 1124.6446\n",
      "Epoch 2380/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 424.3296 - val_loss: 1116.2957\n",
      "Epoch 2381/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 386.7791 - val_loss: 1178.7314\n",
      "Epoch 2382/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 389.9389 - val_loss: 968.5479\n",
      "Epoch 2383/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 384.6580 - val_loss: 1105.9224\n",
      "Epoch 2384/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 421.6334 - val_loss: 962.1604\n",
      "Epoch 2385/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 508.3261 - val_loss: 942.1369\n",
      "Epoch 2386/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 549.1395 - val_loss: 1004.3929\n",
      "Epoch 2387/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 504.7851 - val_loss: 1118.0221\n",
      "Epoch 2388/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.9208 - val_loss: 1042.1187\n",
      "Epoch 2389/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 393.8280 - val_loss: 997.9244\n",
      "Epoch 2390/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 449.4575 - val_loss: 1005.5068\n",
      "Epoch 2391/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 518.8639 - val_loss: 941.3789\n",
      "Epoch 2392/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 469.5278 - val_loss: 1364.4396\n",
      "Epoch 2393/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 553.7257 - val_loss: 976.8059\n",
      "Epoch 2394/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 545.8616 - val_loss: 950.8688\n",
      "Epoch 2395/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 601.0497 - val_loss: 945.5340\n",
      "Epoch 2396/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 956.2136 - val_loss: 1140.7424\n",
      "Epoch 2397/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 629.0595 - val_loss: 1171.3658\n",
      "Epoch 2398/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 519.4025 - val_loss: 1114.2716\n",
      "Epoch 2399/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 469.7290 - val_loss: 992.0808\n",
      "Epoch 2400/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 458.3331 - val_loss: 1001.5242\n",
      "Epoch 2401/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 496.0763 - val_loss: 1084.2030\n",
      "Epoch 2402/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 442.4957 - val_loss: 999.0942\n",
      "Epoch 2403/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 412.2553 - val_loss: 1034.9152\n",
      "Epoch 2404/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 391.2610 - val_loss: 993.0086\n",
      "Epoch 2405/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 394.7513 - val_loss: 958.9181\n",
      "Epoch 2406/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 373.3287 - val_loss: 1105.0565\n",
      "Epoch 2407/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.6948 - val_loss: 1178.7486\n",
      "Epoch 2408/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 498.6881 - val_loss: 1086.1929\n",
      "Epoch 2409/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 530.7584 - val_loss: 896.8670\n",
      "Epoch 2410/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 467.6870 - val_loss: 1131.8206\n",
      "Epoch 2411/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 385.6329 - val_loss: 997.1241\n",
      "Epoch 2412/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 388.9654 - val_loss: 987.7405\n",
      "Epoch 2413/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 424.1772 - val_loss: 953.4797\n",
      "Epoch 2414/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 432.2232 - val_loss: 950.2104\n",
      "Epoch 2415/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 405.3461 - val_loss: 1133.5544\n",
      "Epoch 2416/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 454.491 - 0s 62us/step - loss: 445.8257 - val_loss: 944.8450\n",
      "Epoch 2417/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 450.4703 - val_loss: 861.9037\n",
      "Epoch 2418/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 838.9316 - val_loss: 848.0776\n",
      "Epoch 2419/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 619.7127 - val_loss: 931.7953\n",
      "Epoch 2420/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 571.8253 - val_loss: 1347.0962\n",
      "Epoch 2421/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 520.2092 - val_loss: 952.5137\n",
      "Epoch 2422/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 450.3050 - val_loss: 998.4217\n",
      "Epoch 2423/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.4108 - val_loss: 957.0237\n",
      "Epoch 2424/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 417.4121 - val_loss: 1059.7767\n",
      "Epoch 2425/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 408.7297 - val_loss: 1163.1504\n",
      "Epoch 2426/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 408.0273 - val_loss: 1054.8456\n",
      "Epoch 2427/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.7022 - val_loss: 1127.3202\n",
      "Epoch 2428/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 463.7651 - val_loss: 965.2496\n",
      "Epoch 2429/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 439.5042 - val_loss: 1004.4394\n",
      "Epoch 2430/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.0012 - val_loss: 1160.7889\n",
      "Epoch 2431/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 410.4281 - val_loss: 1070.3771\n",
      "Epoch 2432/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 376.6457 - val_loss: 1038.5129\n",
      "Epoch 2433/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 367.3178 - val_loss: 969.0847\n",
      "Epoch 2434/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 386.2222 - val_loss: 932.2197\n",
      "Epoch 2435/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.8289 - val_loss: 934.2058\n",
      "Epoch 2436/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 392.5734 - val_loss: 877.6327\n",
      "Epoch 2437/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 471.6635 - val_loss: 1060.8907\n",
      "Epoch 2438/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 448.9353 - val_loss: 927.8464\n",
      "Epoch 2439/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.7581 - val_loss: 946.6468\n",
      "Epoch 2440/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.4834 - val_loss: 974.6905\n",
      "Epoch 2441/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 358.5444 - val_loss: 937.0163\n",
      "Epoch 2442/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 350.1705 - val_loss: 947.5500\n",
      "Epoch 2443/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 343.4808 - val_loss: 983.1395\n",
      "Epoch 2444/10000\n",
      "630/630 [==============================] - 0s 74us/step - loss: 345.3017 - val_loss: 991.8089\n",
      "Epoch 2445/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 374.6886 - val_loss: 1010.6872\n",
      "Epoch 2446/10000\n",
      "630/630 [==============================] - 0s 97us/step - loss: 380.6854 - val_loss: 867.5826\n",
      "Epoch 2447/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 384.8202 - val_loss: 1024.4030\n",
      "Epoch 2448/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 376.7338 - val_loss: 1124.4010\n",
      "Epoch 2449/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 415.1969 - val_loss: 1014.4006\n",
      "Epoch 2450/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 426.7337 - val_loss: 980.6110\n",
      "Epoch 2451/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 377.0985 - val_loss: 983.8783\n",
      "Epoch 2452/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.4413 - val_loss: 1058.3981\n",
      "Epoch 2453/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 374.2303 - val_loss: 856.2710\n",
      "Epoch 2454/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 546.9764 - val_loss: 1209.8338\n",
      "Epoch 2455/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 597.7088 - val_loss: 996.5773\n",
      "Epoch 2456/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 810.4810 - val_loss: 1393.6837\n",
      "Epoch 2457/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 913.5501 - val_loss: 934.1745\n",
      "Epoch 2458/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1084.5875 - val_loss: 982.9424\n",
      "Epoch 2459/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 886.2100 - val_loss: 962.3343\n",
      "Epoch 2460/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 637.0570 - val_loss: 898.4007\n",
      "Epoch 2461/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 507.0834 - val_loss: 1032.2379\n",
      "Epoch 2462/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 421.0576 - val_loss: 1084.6583\n",
      "Epoch 2463/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 536.8544 - val_loss: 1041.1436\n",
      "Epoch 2464/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 559.6703 - val_loss: 1020.3728\n",
      "Epoch 2465/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 474.4889 - val_loss: 1171.6206\n",
      "Epoch 2466/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 423.8751 - val_loss: 1118.0816\n",
      "Epoch 2467/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 403.0266 - val_loss: 1152.8434\n",
      "Epoch 2468/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 393.1433 - val_loss: 1055.7731\n",
      "Epoch 2469/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 376.9724 - val_loss: 1096.2795\n",
      "Epoch 2470/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 382.3855 - val_loss: 1061.4627\n",
      "Epoch 2471/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 366.9237 - val_loss: 1031.8671\n",
      "Epoch 2472/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 375.0560 - val_loss: 937.5894\n",
      "Epoch 2473/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 415.2979 - val_loss: 921.5716\n",
      "Epoch 2474/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 464.0304 - val_loss: 1242.7682\n",
      "Epoch 2475/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 648.9916 - val_loss: 873.4205\n",
      "Epoch 2476/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 770.0969 - val_loss: 1054.6263\n",
      "Epoch 2477/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 592.6109 - val_loss: 968.0544\n",
      "Epoch 2478/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 481.5173 - val_loss: 1047.0338\n",
      "Epoch 2479/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 403.1269 - val_loss: 911.0894\n",
      "Epoch 2480/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 462.9634 - val_loss: 976.3690\n",
      "Epoch 2481/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 461.2552 - val_loss: 1010.4000\n",
      "Epoch 2482/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 451.9909 - val_loss: 932.9851\n",
      "Epoch 2483/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 464.6427 - val_loss: 988.0226\n",
      "Epoch 2484/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 435.1923 - val_loss: 1062.5357\n",
      "Epoch 2485/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 476.2071 - val_loss: 990.1697\n",
      "Epoch 2486/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 449.9998 - val_loss: 963.5703\n",
      "Epoch 2487/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 459.5687 - val_loss: 1071.5677\n",
      "Epoch 2488/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 407.7327 - val_loss: 1030.8842\n",
      "Epoch 2489/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 393.8100 - val_loss: 1057.5574\n",
      "Epoch 2490/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 382.4652 - val_loss: 1044.4598\n",
      "Epoch 2491/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 372.9471 - val_loss: 931.1519\n",
      "Epoch 2492/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 347.1360 - val_loss: 989.5380\n",
      "Epoch 2493/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 329.0928 - val_loss: 1039.7002\n",
      "Epoch 2494/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.5995 - val_loss: 936.4833\n",
      "Epoch 2495/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 349.6574 - val_loss: 939.2499\n",
      "Epoch 2496/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 423.2919 - val_loss: 785.4668\n",
      "Epoch 2497/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 461.5420 - val_loss: 955.5850\n",
      "Epoch 2498/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 387.1827 - val_loss: 848.1163\n",
      "Epoch 2499/10000\n",
      "630/630 [==============================] - 0s 92us/step - loss: 508.6727 - val_loss: 1102.3942\n",
      "Epoch 2500/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 488.1524 - val_loss: 1045.8268\n",
      "Epoch 2501/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 452.1519 - val_loss: 956.7637\n",
      "Epoch 2502/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 406.8563 - val_loss: 954.7535\n",
      "Epoch 2503/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 395.5342 - val_loss: 894.1585\n",
      "Epoch 2504/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 410.5190 - val_loss: 966.8173\n",
      "Epoch 2505/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 401.2285 - val_loss: 970.3166\n",
      "Epoch 2506/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 371.0497 - val_loss: 956.6297\n",
      "Epoch 2507/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 387.9670 - val_loss: 937.6160\n",
      "Epoch 2508/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 369.3952 - val_loss: 1449.9011\n",
      "Epoch 2509/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 761.2392 - val_loss: 943.8635\n",
      "Epoch 2510/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 733.4814 - val_loss: 920.1017\n",
      "Epoch 2511/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 988.0836 - val_loss: 1103.5357\n",
      "Epoch 2512/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 802.8986 - val_loss: 1035.7245\n",
      "Epoch 2513/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 673.3015 - val_loss: 928.0696\n",
      "Epoch 2514/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 527.7278 - val_loss: 953.7922\n",
      "Epoch 2515/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 471.4468 - val_loss: 1036.2611\n",
      "Epoch 2516/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 810.7236 - val_loss: 1337.2391\n",
      "Epoch 2517/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 834.9633 - val_loss: 957.2628\n",
      "Epoch 2518/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 645.4188 - val_loss: 885.3173\n",
      "Epoch 2519/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 566.4001 - val_loss: 838.6134\n",
      "Epoch 2520/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 519.1513 - val_loss: 1022.2413\n",
      "Epoch 2521/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 512.1453 - val_loss: 1032.2728\n",
      "Epoch 2522/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 855.5881 - val_loss: 1216.6025\n",
      "Epoch 2523/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1159.1121 - val_loss: 1206.5597\n",
      "Epoch 2524/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1053.9989 - val_loss: 1031.2301\n",
      "Epoch 2525/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 784.9762 - val_loss: 1013.4969\n",
      "Epoch 2526/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 660.7654 - val_loss: 1085.3773\n",
      "Epoch 2527/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 586.7545 - val_loss: 906.3762\n",
      "Epoch 2528/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 803.2217 - val_loss: 863.7378\n",
      "Epoch 2529/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 647.0751 - val_loss: 1350.9092\n",
      "Epoch 2530/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 555.1065 - val_loss: 1105.9535\n",
      "Epoch 2531/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 466.8756 - val_loss: 1087.2934\n",
      "Epoch 2532/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 627.0467 - val_loss: 1186.5963\n",
      "Epoch 2533/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 668.3395 - val_loss: 1096.7105\n",
      "Epoch 2534/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 503.4386 - val_loss: 1113.6744\n",
      "Epoch 2535/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 441.5493 - val_loss: 1276.7427\n",
      "Epoch 2536/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 426.2006 - val_loss: 1212.0099\n",
      "Epoch 2537/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 393.3874 - val_loss: 1028.6073\n",
      "Epoch 2538/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.2199 - val_loss: 1059.2861\n",
      "Epoch 2539/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 389.6993 - val_loss: 971.1825\n",
      "Epoch 2540/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 380.8869 - val_loss: 1095.0059\n",
      "Epoch 2541/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 409.5140 - val_loss: 931.9756\n",
      "Epoch 2542/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 412.9503 - val_loss: 862.1077\n",
      "Epoch 2543/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 520.2725 - val_loss: 826.3138\n",
      "Epoch 2544/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 578.4257 - val_loss: 1182.3981\n",
      "Epoch 2545/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.9367 - val_loss: 1123.1390\n",
      "Epoch 2546/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 393.7263 - val_loss: 945.6328\n",
      "Epoch 2547/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 400.4173 - val_loss: 970.5774\n",
      "Epoch 2548/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 384.0735 - val_loss: 1141.0837\n",
      "Epoch 2549/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 368.1639 - val_loss: 946.4839\n",
      "Epoch 2550/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 372.1913 - val_loss: 957.8808\n",
      "Epoch 2551/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.6196 - val_loss: 983.7858\n",
      "Epoch 2552/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 372.1896 - val_loss: 1054.3172\n",
      "Epoch 2553/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 529.7832 - val_loss: 859.8909\n",
      "Epoch 2554/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 563.9393 - val_loss: 857.5153\n",
      "Epoch 2555/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 559.3935 - val_loss: 1060.4916\n",
      "Epoch 2556/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 503.1735 - val_loss: 866.3482\n",
      "Epoch 2557/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 426.5430 - val_loss: 887.7901\n",
      "Epoch 2558/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 551.7272 - val_loss: 1183.0320\n",
      "Epoch 2559/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 559.3379 - val_loss: 901.4742\n",
      "Epoch 2560/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 503.0905 - val_loss: 954.9231\n",
      "Epoch 2561/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 484.4410 - val_loss: 985.1280\n",
      "Epoch 2562/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 412.2003 - val_loss: 994.8006\n",
      "Epoch 2563/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 390.5951 - val_loss: 988.3151\n",
      "Epoch 2564/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 377.5071 - val_loss: 1112.5003\n",
      "Epoch 2565/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 388.9771 - val_loss: 816.8307\n",
      "Epoch 2566/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 490.8320 - val_loss: 1021.2342\n",
      "Epoch 2567/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 427.9677 - val_loss: 1240.2188\n",
      "Epoch 2568/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 504.4423 - val_loss: 946.2554\n",
      "Epoch 2569/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 449.0919 - val_loss: 934.6015\n",
      "Epoch 2570/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 466.8569 - val_loss: 1108.8588\n",
      "Epoch 2571/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 395.7417 - val_loss: 1057.9961\n",
      "Epoch 2572/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 391.4234 - val_loss: 1203.8402\n",
      "Epoch 2573/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 403.6287 - val_loss: 1113.4978\n",
      "Epoch 2574/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 534.6082 - val_loss: 1014.5137\n",
      "Epoch 2575/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 449.9656 - val_loss: 964.3624\n",
      "Epoch 2576/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 414.0613 - val_loss: 953.0943\n",
      "Epoch 2577/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 406.2470 - val_loss: 947.2285\n",
      "Epoch 2578/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 496.2585 - val_loss: 1002.0282\n",
      "Epoch 2579/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 461.7433 - val_loss: 892.3003\n",
      "Epoch 2580/10000\n",
      "630/630 [==============================] - 0s 87us/step - loss: 425.7896 - val_loss: 1014.6979\n",
      "Epoch 2581/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 392.9974 - val_loss: 1254.0075\n",
      "Epoch 2582/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 487.7716 - val_loss: 899.5349\n",
      "Epoch 2583/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 489.5351 - val_loss: 893.1224\n",
      "Epoch 2584/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 456.0773 - val_loss: 941.9236\n",
      "Epoch 2585/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 417.2567 - val_loss: 1014.5135\n",
      "Epoch 2586/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 378.7973 - val_loss: 1059.9979\n",
      "Epoch 2587/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 606.9416 - val_loss: 1085.9424\n",
      "Epoch 2588/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1358.9624 - val_loss: 1257.8202\n",
      "Epoch 2589/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 965.9030 - val_loss: 1077.7182\n",
      "Epoch 2590/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 711.7676 - val_loss: 1084.7942\n",
      "Epoch 2591/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 663.2112 - val_loss: 1048.3013\n",
      "Epoch 2592/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 573.0182 - val_loss: 1140.1817\n",
      "Epoch 2593/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 501.7870 - val_loss: 942.2804\n",
      "Epoch 2594/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 439.1083 - val_loss: 1517.8876\n",
      "Epoch 2595/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 639.1188 - val_loss: 888.2974\n",
      "Epoch 2596/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 483.2378 - val_loss: 886.3684\n",
      "Epoch 2597/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 472.6392 - val_loss: 876.2046\n",
      "Epoch 2598/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 514.1358 - val_loss: 925.3223\n",
      "Epoch 2599/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 415.9442 - val_loss: 877.7812\n",
      "Epoch 2600/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 440.8805 - val_loss: 838.4050\n",
      "Epoch 2601/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 536.6875 - val_loss: 1059.5460\n",
      "Epoch 2602/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 412.8189 - val_loss: 1206.3041\n",
      "Epoch 2603/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 455.5656 - val_loss: 1010.4826\n",
      "Epoch 2604/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 410.6620 - val_loss: 915.3842\n",
      "Epoch 2605/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 374.7615 - val_loss: 1037.5936\n",
      "Epoch 2606/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 437.5260 - val_loss: 1062.8188\n",
      "Epoch 2607/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 383.2782 - val_loss: 879.3449\n",
      "Epoch 2608/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 441.3754 - val_loss: 1123.1171\n",
      "Epoch 2609/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.2002 - val_loss: 998.3854\n",
      "Epoch 2610/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 427.3722 - val_loss: 1048.0545\n",
      "Epoch 2611/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 577.9409 - val_loss: 850.8760\n",
      "Epoch 2612/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 452.3210 - val_loss: 1146.0629\n",
      "Epoch 2613/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 416.9679 - val_loss: 966.6225\n",
      "Epoch 2614/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 382.0459 - val_loss: 1206.9150\n",
      "Epoch 2615/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 445.8617 - val_loss: 977.9486\n",
      "Epoch 2616/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 518.8251 - val_loss: 1168.4221\n",
      "Epoch 2617/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 516.2050 - val_loss: 977.4067\n",
      "Epoch 2618/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 489.1605 - val_loss: 967.4952\n",
      "Epoch 2619/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 426.1305 - val_loss: 966.4547\n",
      "Epoch 2620/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.2817 - val_loss: 1027.6316\n",
      "Epoch 2621/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 407.1842 - val_loss: 985.4150\n",
      "Epoch 2622/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 576.3973 - val_loss: 961.5847\n",
      "Epoch 2623/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 713.0879 - val_loss: 1106.1961\n",
      "Epoch 2624/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 665.9058 - val_loss: 1077.9783\n",
      "Epoch 2625/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 592.2433 - val_loss: 1121.7759\n",
      "Epoch 2626/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 553.7859 - val_loss: 951.7176\n",
      "Epoch 2627/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 462.2746 - val_loss: 977.2483\n",
      "Epoch 2628/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 469.8857 - val_loss: 843.0727\n",
      "Epoch 2629/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 517.1399 - val_loss: 1210.7598\n",
      "Epoch 2630/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 451.3015 - val_loss: 1091.2337\n",
      "Epoch 2631/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.4700 - val_loss: 952.1196\n",
      "Epoch 2632/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.7623 - val_loss: 977.5414\n",
      "Epoch 2633/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 363.6216 - val_loss: 1035.6976\n",
      "Epoch 2634/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 381.1502 - val_loss: 1018.5024\n",
      "Epoch 2635/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.6058 - val_loss: 1059.9961\n",
      "Epoch 2636/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 379.3336 - val_loss: 1048.7053\n",
      "Epoch 2637/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 372.2304 - val_loss: 1091.0853\n",
      "Epoch 2638/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 414.5395 - val_loss: 902.4992\n",
      "Epoch 2639/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 407.3798 - val_loss: 934.2807\n",
      "Epoch 2640/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 391.3722 - val_loss: 1021.7145\n",
      "Epoch 2641/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 397.9821 - val_loss: 885.3720\n",
      "Epoch 2642/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.2822 - val_loss: 973.9890\n",
      "Epoch 2643/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 440.4504 - val_loss: 880.2904\n",
      "Epoch 2644/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 405.1086 - val_loss: 954.6029\n",
      "Epoch 2645/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 371.9308 - val_loss: 974.5356\n",
      "Epoch 2646/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 340.8584 - val_loss: 1100.1973\n",
      "Epoch 2647/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 375.5224 - val_loss: 853.4363\n",
      "Epoch 2648/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 397.5539 - val_loss: 867.8452\n",
      "Epoch 2649/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1117.6122 - val_loss: 2912.5136\n",
      "Epoch 2650/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5739.1216 - val_loss: 4611.2338\n",
      "Epoch 2651/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7802.3114 - val_loss: 5260.9395\n",
      "Epoch 2652/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 8281.0184 - val_loss: 5114.8209\n",
      "Epoch 2653/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 8006.5416 - val_loss: 4868.5319\n",
      "Epoch 2654/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7136.8896 - val_loss: 4590.4924\n",
      "Epoch 2655/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 6459.6695 - val_loss: 4179.5048\n",
      "Epoch 2656/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5920.2572 - val_loss: 3971.5583\n",
      "Epoch 2657/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5014.9932 - val_loss: 3505.1020\n",
      "Epoch 2658/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4586.4237 - val_loss: 3228.6780\n",
      "Epoch 2659/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3979.4575 - val_loss: 2905.9049\n",
      "Epoch 2660/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3434.4975 - val_loss: 2653.2237\n",
      "Epoch 2661/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2933.2727 - val_loss: 2398.2082\n",
      "Epoch 2662/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2428.4689 - val_loss: 2174.8535\n",
      "Epoch 2663/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2126.8232 - val_loss: 2047.2785\n",
      "Epoch 2664/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1794.9297 - val_loss: 1907.3304\n",
      "Epoch 2665/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1578.7762 - val_loss: 1810.8423\n",
      "Epoch 2666/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1474.1323 - val_loss: 1165.4781\n",
      "Epoch 2667/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1364.7696 - val_loss: 1347.1589\n",
      "Epoch 2668/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1182.9469 - val_loss: 1557.0696\n",
      "Epoch 2669/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1048.0930 - val_loss: 1350.8634\n",
      "Epoch 2670/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 958.7095 - val_loss: 1239.9657\n",
      "Epoch 2671/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 883.4260 - val_loss: 1134.5740\n",
      "Epoch 2672/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 812.6237 - val_loss: 1183.5603\n",
      "Epoch 2673/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 777.6157 - val_loss: 1063.5435\n",
      "Epoch 2674/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 716.7095 - val_loss: 1003.7663\n",
      "Epoch 2675/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 657.5761 - val_loss: 1128.3867\n",
      "Epoch 2676/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 620.2135 - val_loss: 880.5272\n",
      "Epoch 2677/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 852.2634 - val_loss: 872.8851\n",
      "Epoch 2678/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 729.1553 - val_loss: 992.5204\n",
      "Epoch 2679/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 691.6620 - val_loss: 1071.2984\n",
      "Epoch 2680/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 608.5813 - val_loss: 934.6641\n",
      "Epoch 2681/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 566.7107 - val_loss: 1053.1865\n",
      "Epoch 2682/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 522.9481 - val_loss: 871.9382\n",
      "Epoch 2683/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 572.3784 - val_loss: 1292.2628\n",
      "Epoch 2684/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 516.7600 - val_loss: 1004.3684\n",
      "Epoch 2685/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 465.2184 - val_loss: 1238.0402\n",
      "Epoch 2686/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 480.1900 - val_loss: 964.3119\n",
      "Epoch 2687/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 426.2176 - val_loss: 1001.7445\n",
      "Epoch 2688/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 459.1295 - val_loss: 1006.5323\n",
      "Epoch 2689/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 440.9067 - val_loss: 898.7408\n",
      "Epoch 2690/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 480.3223 - val_loss: 1219.6412\n",
      "Epoch 2691/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 443.4222 - val_loss: 1220.5642\n",
      "Epoch 2692/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 406.8207 - val_loss: 1143.5687\n",
      "Epoch 2693/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 404.7839 - val_loss: 1088.8661\n",
      "Epoch 2694/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 389.7982 - val_loss: 929.3598\n",
      "Epoch 2695/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.0842 - val_loss: 975.2636\n",
      "Epoch 2696/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 418.0618 - val_loss: 1140.6884\n",
      "Epoch 2697/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 422.5611 - val_loss: 926.7742\n",
      "Epoch 2698/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.6725 - val_loss: 981.6636\n",
      "Epoch 2699/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 398.8243 - val_loss: 854.1805\n",
      "Epoch 2700/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 917.0956 - val_loss: 1105.6711\n",
      "Epoch 2701/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 889.8398 - val_loss: 922.6020\n",
      "Epoch 2702/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 626.8689 - val_loss: 1034.2370\n",
      "Epoch 2703/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 472.3605 - val_loss: 1115.0188\n",
      "Epoch 2704/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 410.4161 - val_loss: 900.3733\n",
      "Epoch 2705/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.8781 - val_loss: 974.8673\n",
      "Epoch 2706/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 393.2464 - val_loss: 898.4636\n",
      "Epoch 2707/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.2716 - val_loss: 823.9878\n",
      "Epoch 2708/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 373.4814 - val_loss: 934.3427\n",
      "Epoch 2709/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 355.1303 - val_loss: 796.3209\n",
      "Epoch 2710/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 455.7860 - val_loss: 1235.4094\n",
      "Epoch 2711/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 547.8164 - val_loss: 875.8219\n",
      "Epoch 2712/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 471.9766 - val_loss: 823.5083\n",
      "Epoch 2713/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 487.2320 - val_loss: 868.0407\n",
      "Epoch 2714/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 588.7804 - val_loss: 865.0031\n",
      "Epoch 2715/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 451.4000 - val_loss: 860.6317\n",
      "Epoch 2716/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 480.2209 - val_loss: 941.5311\n",
      "Epoch 2717/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 440.2058 - val_loss: 971.7031\n",
      "Epoch 2718/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 541.4876 - val_loss: 1280.1885\n",
      "Epoch 2719/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 603.7573 - val_loss: 1128.9695\n",
      "Epoch 2720/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 539.5662 - val_loss: 1007.1752\n",
      "Epoch 2721/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 479.8947 - val_loss: 1071.2978\n",
      "Epoch 2722/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 422.4015 - val_loss: 893.8537\n",
      "Epoch 2723/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 394.1069 - val_loss: 929.8313\n",
      "Epoch 2724/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 392.1433 - val_loss: 911.5958\n",
      "Epoch 2725/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 369.1151 - val_loss: 1008.1909\n",
      "Epoch 2726/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 402.6438 - val_loss: 881.8635\n",
      "Epoch 2727/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 370.2819 - val_loss: 939.7028\n",
      "Epoch 2728/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 350.9598 - val_loss: 895.6731\n",
      "Epoch 2729/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 333.3332 - val_loss: 948.7953\n",
      "Epoch 2730/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.2444 - val_loss: 1021.1496\n",
      "Epoch 2731/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 352.6651 - val_loss: 771.4320\n",
      "Epoch 2732/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 777.7290 - val_loss: 1019.9344\n",
      "Epoch 2733/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 539.6447 - val_loss: 793.6329\n",
      "Epoch 2734/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1107.4941 - val_loss: 996.2301\n",
      "Epoch 2735/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1185.6396 - val_loss: 1143.6960\n",
      "Epoch 2736/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 856.3641 - val_loss: 1080.3601\n",
      "Epoch 2737/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 650.8706 - val_loss: 1071.2458\n",
      "Epoch 2738/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 531.1047 - val_loss: 943.0943\n",
      "Epoch 2739/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 510.4333 - val_loss: 848.1415\n",
      "Epoch 2740/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 561.9740 - val_loss: 957.5979\n",
      "Epoch 2741/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 740.0545 - val_loss: 1212.5433\n",
      "Epoch 2742/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 665.6622 - val_loss: 963.7118\n",
      "Epoch 2743/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 597.2966 - val_loss: 805.8043\n",
      "Epoch 2744/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 475.4295 - val_loss: 1024.1611\n",
      "Epoch 2745/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 433.9443 - val_loss: 1040.2042\n",
      "Epoch 2746/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 437.4768 - val_loss: 1097.4596\n",
      "Epoch 2747/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 396.9050 - val_loss: 880.0330\n",
      "Epoch 2748/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 365.4822 - val_loss: 941.0138\n",
      "Epoch 2749/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 374.6074 - val_loss: 948.7762\n",
      "Epoch 2750/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 341.3977 - val_loss: 1105.0193\n",
      "Epoch 2751/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 358.2872 - val_loss: 1070.1812\n",
      "Epoch 2752/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.3567 - val_loss: 943.9242\n",
      "Epoch 2753/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 344.8734 - val_loss: 1109.8247\n",
      "Epoch 2754/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.7889 - val_loss: 986.9373\n",
      "Epoch 2755/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 598.5476 - val_loss: 1021.2896\n",
      "Epoch 2756/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1424.5337 - val_loss: 1116.0393\n",
      "Epoch 2757/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1201.9604 - val_loss: 931.0611\n",
      "Epoch 2758/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1001.9110 - val_loss: 1094.5032\n",
      "Epoch 2759/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 899.9045 - val_loss: 964.2631\n",
      "Epoch 2760/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 606.3318 - val_loss: 932.9188\n",
      "Epoch 2761/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 438.8051 - val_loss: 970.3143\n",
      "Epoch 2762/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 445.0459 - val_loss: 898.9168\n",
      "Epoch 2763/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 473.7706 - val_loss: 894.0280\n",
      "Epoch 2764/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 473.0143 - val_loss: 1561.2182\n",
      "Epoch 2765/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 575.4050 - val_loss: 959.7289\n",
      "Epoch 2766/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 432.5274 - val_loss: 885.9066\n",
      "Epoch 2767/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 400.3457 - val_loss: 970.3056\n",
      "Epoch 2768/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 398.1530 - val_loss: 928.8117\n",
      "Epoch 2769/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 357.1283 - val_loss: 934.5279\n",
      "Epoch 2770/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 428.444 - 0s 54us/step - loss: 349.1271 - val_loss: 937.5287\n",
      "Epoch 2771/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 367.9894 - val_loss: 831.9662\n",
      "Epoch 2772/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 382.4216 - val_loss: 845.0201\n",
      "Epoch 2773/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 365.6170 - val_loss: 1007.1675\n",
      "Epoch 2774/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 341.1219 - val_loss: 986.7092\n",
      "Epoch 2775/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 323.6949 - val_loss: 1036.2948\n",
      "Epoch 2776/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.0338 - val_loss: 960.4231\n",
      "Epoch 2777/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 315.4103 - val_loss: 941.0979\n",
      "Epoch 2778/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.8192 - val_loss: 968.0568\n",
      "Epoch 2779/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 333.8313 - val_loss: 1011.6145\n",
      "Epoch 2780/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 321.7405 - val_loss: 985.0319\n",
      "Epoch 2781/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 333.5905 - val_loss: 881.2758\n",
      "Epoch 2782/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 340.8386 - val_loss: 857.8195\n",
      "Epoch 2783/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 338.5984 - val_loss: 852.1779\n",
      "Epoch 2784/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 356.0986 - val_loss: 803.9077\n",
      "Epoch 2785/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 348.3684 - val_loss: 791.4216\n",
      "Epoch 2786/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 384.5945 - val_loss: 866.1835\n",
      "Epoch 2787/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 483.5605 - val_loss: 1470.6549\n",
      "Epoch 2788/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 655.4197 - val_loss: 1427.7253\n",
      "Epoch 2789/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 474.4938 - val_loss: 957.3847\n",
      "Epoch 2790/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 608.0047 - val_loss: 915.1662\n",
      "Epoch 2791/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 669.0114 - val_loss: 1050.9692\n",
      "Epoch 2792/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 586.4624 - val_loss: 935.3606\n",
      "Epoch 2793/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 459.4775 - val_loss: 896.3943\n",
      "Epoch 2794/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 411.1303 - val_loss: 957.9040\n",
      "Epoch 2795/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 370.8705 - val_loss: 929.4632\n",
      "Epoch 2796/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.4880 - val_loss: 989.0610\n",
      "Epoch 2797/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 404.8341 - val_loss: 839.7970\n",
      "Epoch 2798/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 399.4304 - val_loss: 949.0093\n",
      "Epoch 2799/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 389.0445 - val_loss: 832.9486\n",
      "Epoch 2800/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 406.6735 - val_loss: 845.9577\n",
      "Epoch 2801/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 348.0774 - val_loss: 904.2544\n",
      "Epoch 2802/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 340.8523 - val_loss: 840.5031\n",
      "Epoch 2803/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.3077 - val_loss: 855.2114\n",
      "Epoch 2804/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 356.9048 - val_loss: 1001.4163\n",
      "Epoch 2805/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 358.8526 - val_loss: 1131.0614\n",
      "Epoch 2806/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 399.3217 - val_loss: 790.2459\n",
      "Epoch 2807/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 523.1382 - val_loss: 907.9079\n",
      "Epoch 2808/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 516.9999 - val_loss: 770.0267\n",
      "Epoch 2809/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 455.7134 - val_loss: 801.8890\n",
      "Epoch 2810/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 388.9611 - val_loss: 903.8344\n",
      "Epoch 2811/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 328.4685 - val_loss: 1248.4916\n",
      "Epoch 2812/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 478.8699 - val_loss: 884.6191\n",
      "Epoch 2813/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 418.0767 - val_loss: 944.6511\n",
      "Epoch 2814/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 380.4032 - val_loss: 869.4737\n",
      "Epoch 2815/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 361.5577 - val_loss: 891.0797\n",
      "Epoch 2816/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 387.0094 - val_loss: 853.2747\n",
      "Epoch 2817/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 347.8850 - val_loss: 836.2156\n",
      "Epoch 2818/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 351.7700 - val_loss: 876.0232\n",
      "Epoch 2819/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 327.4767 - val_loss: 830.0217\n",
      "Epoch 2820/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 323.3599 - val_loss: 840.3018\n",
      "Epoch 2821/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 329.1250 - val_loss: 816.9132\n",
      "Epoch 2822/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.0968 - val_loss: 828.1124\n",
      "Epoch 2823/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 390.6451 - val_loss: 761.9397\n",
      "Epoch 2824/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 370.8858 - val_loss: 855.7734\n",
      "Epoch 2825/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.4807 - val_loss: 849.8973\n",
      "Epoch 2826/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 331.4828 - val_loss: 861.3639\n",
      "Epoch 2827/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 325.3362 - val_loss: 867.0213\n",
      "Epoch 2828/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 332.4831 - val_loss: 779.7766\n",
      "Epoch 2829/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 334.2136 - val_loss: 853.3237\n",
      "Epoch 2830/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 323.4890 - val_loss: 877.8018\n",
      "Epoch 2831/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 310.9744 - val_loss: 892.9825\n",
      "Epoch 2832/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 358.0143 - val_loss: 793.3124\n",
      "Epoch 2833/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 474.3654 - val_loss: 853.6044\n",
      "Epoch 2834/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 635.3644 - val_loss: 910.0509\n",
      "Epoch 2835/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 544.6805 - val_loss: 1018.9827\n",
      "Epoch 2836/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 450.5087 - val_loss: 992.0738\n",
      "Epoch 2837/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 485.8820 - val_loss: 899.9400\n",
      "Epoch 2838/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 775.6628 - val_loss: 1281.7271\n",
      "Epoch 2839/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 628.4647 - val_loss: 1529.2649\n",
      "Epoch 2840/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 62us/step - loss: 627.5345 - val_loss: 710.3624\n",
      "Epoch 2841/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 549.7550 - val_loss: 1001.7369\n",
      "Epoch 2842/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 431.4992 - val_loss: 1033.7128\n",
      "Epoch 2843/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 392.6956 - val_loss: 858.8461\n",
      "Epoch 2844/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 359.0325 - val_loss: 937.9440\n",
      "Epoch 2845/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.9214 - val_loss: 895.5758\n",
      "Epoch 2846/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 410.8848 - val_loss: 794.7161\n",
      "Epoch 2847/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 740.7461 - val_loss: 929.1844\n",
      "Epoch 2848/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 708.5281 - val_loss: 998.6110\n",
      "Epoch 2849/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 517.0515 - val_loss: 901.6251\n",
      "Epoch 2850/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 415.3018 - val_loss: 1047.1320\n",
      "Epoch 2851/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 391.2113 - val_loss: 892.2506\n",
      "Epoch 2852/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 395.0183 - val_loss: 839.6938\n",
      "Epoch 2853/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 363.9100 - val_loss: 978.1296\n",
      "Epoch 2854/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.1607 - val_loss: 864.8148\n",
      "Epoch 2855/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.0613 - val_loss: 870.2559\n",
      "Epoch 2856/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 322.9618 - val_loss: 939.8016\n",
      "Epoch 2857/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 318.4264 - val_loss: 981.8419\n",
      "Epoch 2858/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.2284 - val_loss: 840.3454\n",
      "Epoch 2859/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.3281 - val_loss: 1024.2002\n",
      "Epoch 2860/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 379.1115 - val_loss: 913.7121\n",
      "Epoch 2861/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 390.7314 - val_loss: 927.9350\n",
      "Epoch 2862/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 339.3431 - val_loss: 872.1488\n",
      "Epoch 2863/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.3847 - val_loss: 984.0980\n",
      "Epoch 2864/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 369.8359 - val_loss: 912.7540\n",
      "Epoch 2865/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 411.5880 - val_loss: 881.5057\n",
      "Epoch 2866/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.2026 - val_loss: 987.2542\n",
      "Epoch 2867/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 432.6761 - val_loss: 775.4425\n",
      "Epoch 2868/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 659.8215 - val_loss: 1576.0923\n",
      "Epoch 2869/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 3221.9697 - val_loss: 3019.9325\n",
      "Epoch 2870/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4524.2261 - val_loss: 2811.2912\n",
      "Epoch 2871/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4256.7666 - val_loss: 2846.7764\n",
      "Epoch 2872/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3666.6076 - val_loss: 2668.3195\n",
      "Epoch 2873/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3329.0761 - val_loss: 2235.0351\n",
      "Epoch 2874/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 3034.0864 - val_loss: 2060.3127\n",
      "Epoch 2875/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2538.8977 - val_loss: 1802.2525\n",
      "Epoch 2876/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2179.1613 - val_loss: 1816.0699\n",
      "Epoch 2877/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1874.7430 - val_loss: 1689.8745\n",
      "Epoch 2878/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1659.5037 - val_loss: 1709.9154\n",
      "Epoch 2879/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1480.8632 - val_loss: 1618.3424\n",
      "Epoch 2880/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1393.8954 - val_loss: 1434.1997\n",
      "Epoch 2881/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1248.4371 - val_loss: 1273.8777\n",
      "Epoch 2882/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1069.6118 - val_loss: 1354.8619\n",
      "Epoch 2883/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1091.6367 - val_loss: 1042.7861\n",
      "Epoch 2884/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 990.2278 - val_loss: 1316.6966\n",
      "Epoch 2885/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 895.1674 - val_loss: 1271.1085\n",
      "Epoch 2886/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 831.8654 - val_loss: 1062.7347\n",
      "Epoch 2887/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 747.4990 - val_loss: 1047.0643\n",
      "Epoch 2888/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 688.2408 - val_loss: 1055.3004\n",
      "Epoch 2889/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 665.9838 - val_loss: 1077.2582\n",
      "Epoch 2890/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 616.6099 - val_loss: 1065.4171\n",
      "Epoch 2891/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 597.7072 - val_loss: 1044.6004\n",
      "Epoch 2892/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 585.8350 - val_loss: 990.8458\n",
      "Epoch 2893/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 563.5883 - val_loss: 1094.7609\n",
      "Epoch 2894/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 557.5260 - val_loss: 1147.2166\n",
      "Epoch 2895/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 546.7695 - val_loss: 1063.2590\n",
      "Epoch 2896/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 530.9315 - val_loss: 1059.1009\n",
      "Epoch 2897/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 511.8004 - val_loss: 997.5839\n",
      "Epoch 2898/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 488.8034 - val_loss: 1012.9042\n",
      "Epoch 2899/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 497.5572 - val_loss: 936.4904\n",
      "Epoch 2900/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 443.5209 - val_loss: 941.0338\n",
      "Epoch 2901/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 421.4092 - val_loss: 938.3535\n",
      "Epoch 2902/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 430.7221 - val_loss: 807.9270\n",
      "Epoch 2903/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 552.2620 - val_loss: 1571.0547\n",
      "Epoch 2904/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 723.5043 - val_loss: 1118.9885\n",
      "Epoch 2905/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 637.4462 - val_loss: 808.3372\n",
      "Epoch 2906/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 529.6684 - val_loss: 755.4926\n",
      "Epoch 2907/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 514.9626 - val_loss: 758.6924\n",
      "Epoch 2908/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 479.9197 - val_loss: 730.5236\n",
      "Epoch 2909/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 566.1389 - val_loss: 821.9123\n",
      "Epoch 2910/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 525.2621 - val_loss: 750.4995\n",
      "Epoch 2911/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 481.5739 - val_loss: 826.6026\n",
      "Epoch 2912/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.0015 - val_loss: 940.2280\n",
      "Epoch 2913/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 410.9516 - val_loss: 866.7441\n",
      "Epoch 2914/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 414.7367 - val_loss: 808.9671\n",
      "Epoch 2915/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 489.4490 - val_loss: 1394.8152\n",
      "Epoch 2916/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2260.1113 - val_loss: 2256.3445\n",
      "Epoch 2917/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3221.5705 - val_loss: 2283.5140\n",
      "Epoch 2918/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3135.4072 - val_loss: 2165.8610\n",
      "Epoch 2919/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2651.6741 - val_loss: 1992.0454\n",
      "Epoch 2920/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 2173.7677 - val_loss: 1641.5638\n",
      "Epoch 2921/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1601.6013 - val_loss: 1463.3528\n",
      "Epoch 2922/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1221.3122 - val_loss: 1175.7902\n",
      "Epoch 2923/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 844.9590 - val_loss: 1156.8740\n",
      "Epoch 2924/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 708.3619 - val_loss: 920.9120\n",
      "Epoch 2925/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 607.7232 - val_loss: 995.3802\n",
      "Epoch 2926/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 619.8084 - val_loss: 962.1255\n",
      "Epoch 2927/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 522.3981 - val_loss: 993.4941\n",
      "Epoch 2928/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 515.5853 - val_loss: 902.2281\n",
      "Epoch 2929/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 453.1546 - val_loss: 914.6049\n",
      "Epoch 2930/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 419.2446 - val_loss: 901.5215\n",
      "Epoch 2931/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 410.1760 - val_loss: 879.1628\n",
      "Epoch 2932/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 397.5280 - val_loss: 920.2441\n",
      "Epoch 2933/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 395.7343 - val_loss: 926.6022\n",
      "Epoch 2934/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 407.2656 - val_loss: 1001.9637\n",
      "Epoch 2935/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 388.3691 - val_loss: 825.4256\n",
      "Epoch 2936/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 404.9282 - val_loss: 821.2331\n",
      "Epoch 2937/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 381.9494 - val_loss: 909.9398\n",
      "Epoch 2938/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 440.7802 - val_loss: 868.3582\n",
      "Epoch 2939/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 487.6580 - val_loss: 971.0233\n",
      "Epoch 2940/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 434.2362 - val_loss: 986.4112\n",
      "Epoch 2941/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 424.6603 - val_loss: 868.6033\n",
      "Epoch 2942/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 407.5437 - val_loss: 894.9707\n",
      "Epoch 2943/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 411.5616 - val_loss: 819.1948\n",
      "Epoch 2944/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 391.8026 - val_loss: 929.7425\n",
      "Epoch 2945/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 640.7521 - val_loss: 914.4986\n",
      "Epoch 2946/10000\n",
      "630/630 [==============================] - 0s 117us/step - loss: 801.0684 - val_loss: 1194.3966\n",
      "Epoch 2947/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 793.5174 - val_loss: 895.5104\n",
      "Epoch 2948/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 644.6466 - val_loss: 980.9242\n",
      "Epoch 2949/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 579.0554 - val_loss: 989.4347\n",
      "Epoch 2950/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 547.4526 - val_loss: 869.0052\n",
      "Epoch 2951/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 430.1168 - val_loss: 872.8332\n",
      "Epoch 2952/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 464.1589 - val_loss: 889.6574\n",
      "Epoch 2953/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 410.7257 - val_loss: 836.9346\n",
      "Epoch 2954/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 470.5126 - val_loss: 957.1680\n",
      "Epoch 2955/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 426.8756 - val_loss: 902.3708\n",
      "Epoch 2956/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 521.7027 - val_loss: 1121.5123\n",
      "Epoch 2957/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1197.1321 - val_loss: 1290.0822\n",
      "Epoch 2958/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1247.4476 - val_loss: 1157.1842\n",
      "Epoch 2959/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 999.3768 - val_loss: 1093.0886\n",
      "Epoch 2960/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 740.8761 - val_loss: 1132.6960\n",
      "Epoch 2961/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 574.9515 - val_loss: 963.9506\n",
      "Epoch 2962/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 500.1584 - val_loss: 909.9535\n",
      "Epoch 2963/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 447.4909 - val_loss: 1131.2268\n",
      "Epoch 2964/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 460.2110 - val_loss: 877.9497\n",
      "Epoch 2965/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 468.6673 - val_loss: 937.1134\n",
      "Epoch 2966/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 453.8170 - val_loss: 1079.4416\n",
      "Epoch 2967/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 437.3637 - val_loss: 907.7573\n",
      "Epoch 2968/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 437.8435 - val_loss: 907.3072\n",
      "Epoch 2969/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.2387 - val_loss: 933.1013\n",
      "Epoch 2970/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 540.7380 - val_loss: 1112.4614\n",
      "Epoch 2971/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1308.1453 - val_loss: 1287.6256\n",
      "Epoch 2972/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1152.9761 - val_loss: 1036.8051\n",
      "Epoch 2973/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 702.9252 - val_loss: 955.9606\n",
      "Epoch 2974/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 616.8038 - val_loss: 1088.0761\n",
      "Epoch 2975/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 590.0357 - val_loss: 1038.6117\n",
      "Epoch 2976/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 520.5276 - val_loss: 866.5721\n",
      "Epoch 2977/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 495.0431 - val_loss: 871.3865\n",
      "Epoch 2978/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 448.3172 - val_loss: 936.7233\n",
      "Epoch 2979/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 410.5017 - val_loss: 978.0089\n",
      "Epoch 2980/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 385.7734 - val_loss: 1210.6694\n",
      "Epoch 2981/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 449.8722 - val_loss: 863.9459\n",
      "Epoch 2982/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 409.1918 - val_loss: 924.4586\n",
      "Epoch 2983/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 509.1822 - val_loss: 954.5285\n",
      "Epoch 2984/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 582.8657 - val_loss: 815.1287\n",
      "Epoch 2985/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 558.9346 - val_loss: 786.8685\n",
      "Epoch 2986/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 551.4174 - val_loss: 1173.1610\n",
      "Epoch 2987/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 449.2356 - val_loss: 974.2877\n",
      "Epoch 2988/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 408.7641 - val_loss: 1024.8155\n",
      "Epoch 2989/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 381.0800 - val_loss: 1192.9708\n",
      "Epoch 2990/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 545.3614 - val_loss: 779.6622\n",
      "Epoch 2991/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 454.0435 - val_loss: 921.4408\n",
      "Epoch 2992/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 399.2993 - val_loss: 922.8482\n",
      "Epoch 2993/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 383.6528 - val_loss: 971.3410\n",
      "Epoch 2994/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 338.1824 - val_loss: 1021.0107\n",
      "Epoch 2995/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 367.7062 - val_loss: 871.8537\n",
      "Epoch 2996/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 384.5928 - val_loss: 788.9064\n",
      "Epoch 2997/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 433.4903 - val_loss: 836.2311\n",
      "Epoch 2998/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 504.6057 - val_loss: 889.7996\n",
      "Epoch 2999/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 461.4827 - val_loss: 863.1533\n",
      "Epoch 3000/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 489.1925 - val_loss: 993.4831\n",
      "Epoch 3001/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 453.1038 - val_loss: 779.2348\n",
      "Epoch 3002/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 419.9807 - val_loss: 762.2100\n",
      "Epoch 3003/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 550.6227 - val_loss: 1108.0236\n",
      "Epoch 3004/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 443.4334 - val_loss: 1053.0531\n",
      "Epoch 3005/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 405.9602 - val_loss: 922.2893\n",
      "Epoch 3006/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.7871 - val_loss: 910.8001\n",
      "Epoch 3007/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 385.5820 - val_loss: 947.7851\n",
      "Epoch 3008/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 400.6399 - val_loss: 804.3441\n",
      "Epoch 3009/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 391.2927 - val_loss: 725.1872\n",
      "Epoch 3010/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 704.1360 - val_loss: 822.4340\n",
      "Epoch 3011/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 503.1225 - val_loss: 881.0900\n",
      "Epoch 3012/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 418.1631 - val_loss: 931.9537\n",
      "Epoch 3013/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.9793 - val_loss: 981.7716\n",
      "Epoch 3014/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 353.8719 - val_loss: 923.2525\n",
      "Epoch 3015/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 400.9846 - val_loss: 1058.2440\n",
      "Epoch 3016/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 641.9953 - val_loss: 1135.3733\n",
      "Epoch 3017/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 712.0119 - val_loss: 999.3104\n",
      "Epoch 3018/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 507.3557 - val_loss: 805.3791\n",
      "Epoch 3019/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 487.1748 - val_loss: 1085.4840\n",
      "Epoch 3020/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 398.7566 - val_loss: 1149.2497\n",
      "Epoch 3021/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.8920 - val_loss: 1430.5695\n",
      "Epoch 3022/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 482.7782 - val_loss: 835.8426\n",
      "Epoch 3023/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 391.3834 - val_loss: 806.0353\n",
      "Epoch 3024/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 379.3134 - val_loss: 1029.8884\n",
      "Epoch 3025/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.4304 - val_loss: 898.8466\n",
      "Epoch 3026/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 406.8694 - val_loss: 852.8445\n",
      "Epoch 3027/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 444.8922 - val_loss: 1277.3634\n",
      "Epoch 3028/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 580.4464 - val_loss: 1091.6426\n",
      "Epoch 3029/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 537.4275 - val_loss: 1034.6485\n",
      "Epoch 3030/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 483.6281 - val_loss: 952.6512\n",
      "Epoch 3031/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 456.7478 - val_loss: 744.2415\n",
      "Epoch 3032/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 607.4230 - val_loss: 1218.4751\n",
      "Epoch 3033/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 459.2697 - val_loss: 875.0709\n",
      "Epoch 3034/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 376.8064 - val_loss: 858.2234\n",
      "Epoch 3035/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 343.8670 - val_loss: 922.2103\n",
      "Epoch 3036/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.6466 - val_loss: 1001.0189\n",
      "Epoch 3037/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 434.2697 - val_loss: 945.9275\n",
      "Epoch 3038/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 377.4658 - val_loss: 931.5831\n",
      "Epoch 3039/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 431.7013 - val_loss: 1058.0279\n",
      "Epoch 3040/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.2950 - val_loss: 910.2334\n",
      "Epoch 3041/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.3133 - val_loss: 887.5900\n",
      "Epoch 3042/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 336.3894 - val_loss: 915.5476\n",
      "Epoch 3043/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.1631 - val_loss: 778.0840\n",
      "Epoch 3044/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 359.9866 - val_loss: 777.3099\n",
      "Epoch 3045/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.1028 - val_loss: 891.7326\n",
      "Epoch 3046/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 317.7462 - val_loss: 1013.5598\n",
      "Epoch 3047/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 855.2047 - val_loss: 1078.4520\n",
      "Epoch 3048/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1283.6547 - val_loss: 1202.2263\n",
      "Epoch 3049/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1136.4854 - val_loss: 1101.9734\n",
      "Epoch 3050/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 875.9139 - val_loss: 1100.3149\n",
      "Epoch 3051/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 682.2489 - val_loss: 1013.2561\n",
      "Epoch 3052/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 543.5891 - val_loss: 1024.1883\n",
      "Epoch 3053/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 476.2123 - val_loss: 939.0105\n",
      "Epoch 3054/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 410.0970 - val_loss: 944.1537\n",
      "Epoch 3055/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 382.0994 - val_loss: 1032.4136\n",
      "Epoch 3056/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.5444 - val_loss: 962.3093\n",
      "Epoch 3057/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 395.3633 - val_loss: 994.0488\n",
      "Epoch 3058/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.1950 - val_loss: 1001.2418\n",
      "Epoch 3059/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 377.3963 - val_loss: 889.6500\n",
      "Epoch 3060/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 351.4799 - val_loss: 959.6938\n",
      "Epoch 3061/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.0548 - val_loss: 943.2651\n",
      "Epoch 3062/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.7764 - val_loss: 1045.6512\n",
      "Epoch 3063/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1054.0670 - val_loss: 999.5126\n",
      "Epoch 3064/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 987.4982 - val_loss: 1074.9138\n",
      "Epoch 3065/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 797.4796 - val_loss: 1227.2003\n",
      "Epoch 3066/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 635.1840 - val_loss: 1016.7515\n",
      "Epoch 3067/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 509.0638 - val_loss: 982.1593\n",
      "Epoch 3068/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 510.6899 - val_loss: 761.4632\n",
      "Epoch 3069/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 430.9468 - val_loss: 937.9053\n",
      "Epoch 3070/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 372.1825 - val_loss: 879.2308\n",
      "Epoch 3071/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 351.2167 - val_loss: 876.6831\n",
      "Epoch 3072/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 360.4704 - val_loss: 795.3937\n",
      "Epoch 3073/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.4619 - val_loss: 824.6250\n",
      "Epoch 3074/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 356.8810 - val_loss: 818.0164\n",
      "Epoch 3075/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 588.5169 - val_loss: 975.3262\n",
      "Epoch 3076/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1376.6781 - val_loss: 1274.0149\n",
      "Epoch 3077/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1236.2158 - val_loss: 1221.1235\n",
      "Epoch 3078/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 990.6781 - val_loss: 842.6012\n",
      "Epoch 3079/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 870.8940 - val_loss: 989.6361\n",
      "Epoch 3080/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 535.8848 - val_loss: 900.4418\n",
      "Epoch 3081/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 598.5159 - val_loss: 1490.8293\n",
      "Epoch 3082/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 622.3107 - val_loss: 806.1468\n",
      "Epoch 3083/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 828.2057 - val_loss: 1267.9164\n",
      "Epoch 3084/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 653.7370 - val_loss: 984.3508\n",
      "Epoch 3085/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 492.2813 - val_loss: 964.8644\n",
      "Epoch 3086/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 433.5349 - val_loss: 821.7436\n",
      "Epoch 3087/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 425.1285 - val_loss: 1062.2665\n",
      "Epoch 3088/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 540.7995 - val_loss: 934.1633\n",
      "Epoch 3089/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 519.9317 - val_loss: 920.0341\n",
      "Epoch 3090/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 535.6412 - val_loss: 853.7702\n",
      "Epoch 3091/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 443.3399 - val_loss: 883.2579\n",
      "Epoch 3092/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 432.8748 - val_loss: 939.1028\n",
      "Epoch 3093/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.9293 - val_loss: 1037.2336\n",
      "Epoch 3094/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 449.0593 - val_loss: 936.5166\n",
      "Epoch 3095/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 449.7558 - val_loss: 850.3973\n",
      "Epoch 3096/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 434.7093 - val_loss: 911.3586\n",
      "Epoch 3097/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 382.6595 - val_loss: 1026.6122\n",
      "Epoch 3098/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 369.2883 - val_loss: 918.1454\n",
      "Epoch 3099/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 749.7438 - val_loss: 1260.2059\n",
      "Epoch 3100/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1966.1095 - val_loss: 1190.5974\n",
      "Epoch 3101/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1571.9729 - val_loss: 930.1882\n",
      "Epoch 3102/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 936.3415 - val_loss: 1076.7718\n",
      "Epoch 3103/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 602.3160 - val_loss: 982.9640\n",
      "Epoch 3104/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 586.5639 - val_loss: 1130.0713\n",
      "Epoch 3105/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 851.1432 - val_loss: 1100.8376\n",
      "Epoch 3106/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 701.6168 - val_loss: 1031.4413\n",
      "Epoch 3107/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 554.6472 - val_loss: 862.8918\n",
      "Epoch 3108/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 488.4145 - val_loss: 907.8456\n",
      "Epoch 3109/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 437.2734 - val_loss: 947.0690\n",
      "Epoch 3110/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 463.9217 - val_loss: 765.8821\n",
      "Epoch 3111/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 519.8321 - val_loss: 826.9987\n",
      "Epoch 3112/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 483.5138 - val_loss: 875.7025\n",
      "Epoch 3113/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 422.7670 - val_loss: 837.9433\n",
      "Epoch 3114/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 496.4660 - val_loss: 855.4447\n",
      "Epoch 3115/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 495.1631 - val_loss: 1225.5778\n",
      "Epoch 3116/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 530.8642 - val_loss: 1008.8944\n",
      "Epoch 3117/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 540.0956 - val_loss: 1419.5853\n",
      "Epoch 3118/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1961.5042 - val_loss: 1854.3751\n",
      "Epoch 3119/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2290.5615 - val_loss: 1838.7271\n",
      "Epoch 3120/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2063.8763 - val_loss: 1659.8902\n",
      "Epoch 3121/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1771.2220 - val_loss: 1465.1095\n",
      "Epoch 3122/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1425.7366 - val_loss: 1268.2617\n",
      "Epoch 3123/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1064.5365 - val_loss: 1083.5682\n",
      "Epoch 3124/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 808.3486 - val_loss: 1127.5881\n",
      "Epoch 3125/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 655.5327 - val_loss: 1054.0664\n",
      "Epoch 3126/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 545.3676 - val_loss: 968.6756\n",
      "Epoch 3127/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 500.1297 - val_loss: 1029.7966\n",
      "Epoch 3128/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 473.3231 - val_loss: 966.4363\n",
      "Epoch 3129/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 435.0609 - val_loss: 1021.8402\n",
      "Epoch 3130/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 402.4300 - val_loss: 937.4935\n",
      "Epoch 3131/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 387.3404 - val_loss: 928.5486\n",
      "Epoch 3132/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 387.0978 - val_loss: 890.6080\n",
      "Epoch 3133/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 434.9119 - val_loss: 784.7333\n",
      "Epoch 3134/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 479.1091 - val_loss: 879.3690\n",
      "Epoch 3135/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 435.0423 - val_loss: 898.2148\n",
      "Epoch 3136/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 407.1774 - val_loss: 938.2214\n",
      "Epoch 3137/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 436.6346 - val_loss: 836.0299\n",
      "Epoch 3138/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 415.9706 - val_loss: 863.9512\n",
      "Epoch 3139/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.4355 - val_loss: 926.7894\n",
      "Epoch 3140/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 370.5320 - val_loss: 1021.8115\n",
      "Epoch 3141/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1195.5805 - val_loss: 1784.5383\n",
      "Epoch 3142/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2226.5116 - val_loss: 1808.4891\n",
      "Epoch 3143/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1966.8469 - val_loss: 1825.1985\n",
      "Epoch 3144/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1549.3216 - val_loss: 1243.0682\n",
      "Epoch 3145/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1140.0652 - val_loss: 1128.8807\n",
      "Epoch 3146/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 876.1270 - val_loss: 1063.4688\n",
      "Epoch 3147/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 650.1509 - val_loss: 946.7587\n",
      "Epoch 3148/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 547.2828 - val_loss: 961.1001\n",
      "Epoch 3149/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 492.9380 - val_loss: 1066.8544\n",
      "Epoch 3150/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 424.1742 - val_loss: 950.4314\n",
      "Epoch 3151/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 405.6190 - val_loss: 925.1778\n",
      "Epoch 3152/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 404.9654 - val_loss: 987.7502\n",
      "Epoch 3153/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 374.2310 - val_loss: 1118.1135\n",
      "Epoch 3154/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 451.3731 - val_loss: 870.2259\n",
      "Epoch 3155/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 578.4399 - val_loss: 931.3559\n",
      "Epoch 3156/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 636.9178 - val_loss: 928.2980\n",
      "Epoch 3157/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 543.1485 - val_loss: 1057.1363\n",
      "Epoch 3158/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 461.7783 - val_loss: 1011.5183\n",
      "Epoch 3159/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 451.8067 - val_loss: 898.8143\n",
      "Epoch 3160/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 469.1277 - val_loss: 822.8998\n",
      "Epoch 3161/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 556.0963 - val_loss: 835.1290\n",
      "Epoch 3162/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 479.5853 - val_loss: 844.3983\n",
      "Epoch 3163/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 447.3967 - val_loss: 996.0118\n",
      "Epoch 3164/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 443.7469 - val_loss: 820.2883\n",
      "Epoch 3165/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 586.8492 - val_loss: 856.3665\n",
      "Epoch 3166/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 836.6065 - val_loss: 1143.1821\n",
      "Epoch 3167/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1449.6605 - val_loss: 1542.2782\n",
      "Epoch 3168/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1065.0532 - val_loss: 1343.6588\n",
      "Epoch 3169/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 752.3674 - val_loss: 1050.4620\n",
      "Epoch 3170/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 520.3906 - val_loss: 1201.8516\n",
      "Epoch 3171/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 713.1076 - val_loss: 995.4857\n",
      "Epoch 3172/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 647.5103 - val_loss: 836.6491\n",
      "Epoch 3173/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 699.7796 - val_loss: 1173.3351\n",
      "Epoch 3174/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 559.5419 - val_loss: 923.2227\n",
      "Epoch 3175/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 482.9784 - val_loss: 1535.4369\n",
      "Epoch 3176/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 528.1620 - val_loss: 834.3051\n",
      "Epoch 3177/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 447.1515 - val_loss: 999.8328\n",
      "Epoch 3178/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 408.1342 - val_loss: 1338.0630\n",
      "Epoch 3179/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 459.6212 - val_loss: 970.4718\n",
      "Epoch 3180/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 569.0270 - val_loss: 810.6456\n",
      "Epoch 3181/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 480.9252 - val_loss: 1330.9701\n",
      "Epoch 3182/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 484.9401 - val_loss: 941.2527\n",
      "Epoch 3183/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 441.3771 - val_loss: 810.5425\n",
      "Epoch 3184/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 444.4922 - val_loss: 1502.0818\n",
      "Epoch 3185/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 524.9957 - val_loss: 927.9105\n",
      "Epoch 3186/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 442.5907 - val_loss: 1017.6209\n",
      "Epoch 3187/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 400.9894 - val_loss: 1182.3047\n",
      "Epoch 3188/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 387.8749 - val_loss: 1061.1264\n",
      "Epoch 3189/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 366.6314 - val_loss: 839.6668\n",
      "Epoch 3190/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 441.0348 - val_loss: 851.0122\n",
      "Epoch 3191/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 450.0735 - val_loss: 876.3860\n",
      "Epoch 3192/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 446.8020 - val_loss: 1004.5915\n",
      "Epoch 3193/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 432.7364 - val_loss: 899.4353\n",
      "Epoch 3194/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 369.3468 - val_loss: 938.5087\n",
      "Epoch 3195/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 443.7100 - val_loss: 908.0001\n",
      "Epoch 3196/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 496.5487 - val_loss: 823.8678\n",
      "Epoch 3197/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 430.3180 - val_loss: 923.0535\n",
      "Epoch 3198/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 395.9312 - val_loss: 1023.0709\n",
      "Epoch 3199/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2041.5364 - val_loss: 2550.1051\n",
      "Epoch 3200/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 3043.6546 - val_loss: 1772.3811\n",
      "Epoch 3201/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2829.4775 - val_loss: 1355.3340\n",
      "Epoch 3202/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1883.4100 - val_loss: 1123.6087\n",
      "Epoch 3203/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1233.4883 - val_loss: 1242.9800\n",
      "Epoch 3204/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 877.9286 - val_loss: 1188.0592\n",
      "Epoch 3205/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 692.6399 - val_loss: 1078.3409\n",
      "Epoch 3206/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 604.7893 - val_loss: 1037.3095\n",
      "Epoch 3207/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 499.6990 - val_loss: 993.1300\n",
      "Epoch 3208/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 466.0771 - val_loss: 1042.9870\n",
      "Epoch 3209/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 437.3382 - val_loss: 1008.7504\n",
      "Epoch 3210/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 407.7591 - val_loss: 1070.0280\n",
      "Epoch 3211/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 373.0513 - val_loss: 1014.7992\n",
      "Epoch 3212/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.8263 - val_loss: 1140.8472\n",
      "Epoch 3213/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 356.8517 - val_loss: 1087.3882\n",
      "Epoch 3214/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 369.9346 - val_loss: 1111.4289\n",
      "Epoch 3215/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.4494 - val_loss: 1165.0466\n",
      "Epoch 3216/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.4069 - val_loss: 930.5043\n",
      "Epoch 3217/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.1916 - val_loss: 880.8679\n",
      "Epoch 3218/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 363.7273 - val_loss: 1022.8816\n",
      "Epoch 3219/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 348.9308 - val_loss: 892.6529\n",
      "Epoch 3220/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.4015 - val_loss: 939.1519\n",
      "Epoch 3221/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 345.6235 - val_loss: 982.4856\n",
      "Epoch 3222/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 386.4594 - val_loss: 1027.1193\n",
      "Epoch 3223/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 592.4680 - val_loss: 937.9083\n",
      "Epoch 3224/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 500.0897 - val_loss: 1008.7723\n",
      "Epoch 3225/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.6292 - val_loss: 883.2827\n",
      "Epoch 3226/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 383.8355 - val_loss: 871.4291\n",
      "Epoch 3227/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.9866 - val_loss: 960.2408\n",
      "Epoch 3228/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 343.0559 - val_loss: 960.2697\n",
      "Epoch 3229/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.9102 - val_loss: 945.4636\n",
      "Epoch 3230/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 454.3649 - val_loss: 867.4280\n",
      "Epoch 3231/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 449.1151 - val_loss: 908.9809\n",
      "Epoch 3232/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 415.5077 - val_loss: 955.1857\n",
      "Epoch 3233/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 382.5162 - val_loss: 871.7716\n",
      "Epoch 3234/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 355.5127 - val_loss: 1039.4224\n",
      "Epoch 3235/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 371.8610 - val_loss: 1000.2926\n",
      "Epoch 3236/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 409.8826 - val_loss: 911.8693\n",
      "Epoch 3237/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 398.7831 - val_loss: 907.0530\n",
      "Epoch 3238/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.3627 - val_loss: 970.3972\n",
      "Epoch 3239/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 320.5353 - val_loss: 909.1850\n",
      "Epoch 3240/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.7578 - val_loss: 1471.6986\n",
      "Epoch 3241/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5514.5981 - val_loss: 5466.4947\n",
      "Epoch 3242/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 10934.7775 - val_loss: 6643.3389\n",
      "Epoch 3243/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 12133.0957 - val_loss: 6573.6124\n",
      "Epoch 3244/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 11994.1353 - val_loss: 6508.9704\n",
      "Epoch 3245/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 11002.4677 - val_loss: 6255.6514\n",
      "Epoch 3246/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 10830.9918 - val_loss: 5684.9819\n",
      "Epoch 3247/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 10271.7649 - val_loss: 5406.9870\n",
      "Epoch 3248/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 9636.4769 - val_loss: 5105.8390\n",
      "Epoch 3249/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 9253.5326 - val_loss: 4818.7404\n",
      "Epoch 3250/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 8517.3056 - val_loss: 4759.9657\n",
      "Epoch 3251/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 7711.6149 - val_loss: 4753.3928\n",
      "Epoch 3252/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 7371.4053 - val_loss: 4184.4393\n",
      "Epoch 3253/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 7312.7205 - val_loss: 4117.0067\n",
      "Epoch 3254/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 6976.9997 - val_loss: 3946.0036\n",
      "Epoch 3255/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 6764.4708 - val_loss: 4045.1030\n",
      "Epoch 3256/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6164.8127 - val_loss: 3826.1767\n",
      "Epoch 3257/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 6260.9695 - val_loss: 3741.1219\n",
      "Epoch 3258/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 6013.0964 - val_loss: 3629.3280\n",
      "Epoch 3259/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5765.6495 - val_loss: 3523.2593\n",
      "Epoch 3260/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 5561.4032 - val_loss: 3421.8104\n",
      "Epoch 3261/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 5324.9635 - val_loss: 3327.0746\n",
      "Epoch 3262/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 5115.8307 - val_loss: 3236.4988\n",
      "Epoch 3263/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4859.7143 - val_loss: 3136.7376\n",
      "Epoch 3264/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 4612.4723 - val_loss: 3058.1298\n",
      "Epoch 3265/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4439.2838 - val_loss: 2951.3239\n",
      "Epoch 3266/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 4150.5940 - val_loss: 2862.7381\n",
      "Epoch 3267/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 4006.3737 - val_loss: 2783.9779\n",
      "Epoch 3268/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3882.8012 - val_loss: 2720.2676\n",
      "Epoch 3269/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3753.8777 - val_loss: 2629.2765\n",
      "Epoch 3270/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 3641.0683 - val_loss: 2545.8815\n",
      "Epoch 3271/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 3429.2924 - val_loss: 2465.4215\n",
      "Epoch 3272/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3276.6203 - val_loss: 2408.1213\n",
      "Epoch 3273/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 3120.2288 - val_loss: 2340.0372\n",
      "Epoch 3274/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3054.1692 - val_loss: 2295.2560\n",
      "Epoch 3275/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2832.8515 - val_loss: 2238.1030\n",
      "Epoch 3276/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 2732.1163 - val_loss: 2176.3679\n",
      "Epoch 3277/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2641.1850 - val_loss: 2130.2137\n",
      "Epoch 3278/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 2475.6917 - val_loss: 2088.0336\n",
      "Epoch 3279/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2438.2017 - val_loss: 2041.0149\n",
      "Epoch 3280/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2412.8592 - val_loss: 1999.3151\n",
      "Epoch 3281/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2312.5306 - val_loss: 1964.0846\n",
      "Epoch 3282/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2244.7784 - val_loss: 1911.2486\n",
      "Epoch 3283/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2114.8034 - val_loss: 1866.2015\n",
      "Epoch 3284/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2105.9358 - val_loss: 1835.8188\n",
      "Epoch 3285/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2023.7869 - val_loss: 1791.9312\n",
      "Epoch 3286/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1933.1302 - val_loss: 1758.9984\n",
      "Epoch 3287/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1899.2496 - val_loss: 1709.5649\n",
      "Epoch 3288/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1815.5309 - val_loss: 1666.5654\n",
      "Epoch 3289/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1773.6203 - val_loss: 1622.1026\n",
      "Epoch 3290/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1668.7861 - val_loss: 1598.3383\n",
      "Epoch 3291/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1633.8846 - val_loss: 1594.6884\n",
      "Epoch 3292/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1568.1639 - val_loss: 1571.7198\n",
      "Epoch 3293/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1589.4201 - val_loss: 1558.8563\n",
      "Epoch 3294/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1524.5281 - val_loss: 1558.7448\n",
      "Epoch 3295/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1517.3160 - val_loss: 1544.2254\n",
      "Epoch 3296/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1439.1909 - val_loss: 1518.0814\n",
      "Epoch 3297/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1418.5314 - val_loss: 1506.7514\n",
      "Epoch 3298/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1417.2706 - val_loss: 1483.0562\n",
      "Epoch 3299/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1388.9300 - val_loss: 1464.0395\n",
      "Epoch 3300/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1342.8986 - val_loss: 1460.2674\n",
      "Epoch 3301/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1313.9710 - val_loss: 1447.8992\n",
      "Epoch 3302/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1282.8207 - val_loss: 1441.0766\n",
      "Epoch 3303/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1259.1816 - val_loss: 1428.5627\n",
      "Epoch 3304/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1253.4486 - val_loss: 1431.0608\n",
      "Epoch 3305/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1222.7654 - val_loss: 1421.9113\n",
      "Epoch 3306/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1201.7469 - val_loss: 1412.2016\n",
      "Epoch 3307/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1194.1764 - val_loss: 1390.4545\n",
      "Epoch 3308/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1143.5256 - val_loss: 1382.7918\n",
      "Epoch 3309/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1186.7500 - val_loss: 1377.1294\n",
      "Epoch 3310/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1145.6019 - val_loss: 1368.0333\n",
      "Epoch 3311/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1130.0824 - val_loss: 1370.8555\n",
      "Epoch 3312/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1076.0657 - val_loss: 1349.9616\n",
      "Epoch 3313/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1085.2529 - val_loss: 1361.1504\n",
      "Epoch 3314/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1088.3709 - val_loss: 1337.4344\n",
      "Epoch 3315/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1037.5283 - val_loss: 1330.0948\n",
      "Epoch 3316/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1032.6768 - val_loss: 1318.5489\n",
      "Epoch 3317/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1012.7519 - val_loss: 1319.1657\n",
      "Epoch 3318/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 998.0356 - val_loss: 1312.5066\n",
      "Epoch 3319/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 998.9942 - val_loss: 1312.0134\n",
      "Epoch 3320/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 961.5408 - val_loss: 1290.9535\n",
      "Epoch 3321/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 923.8411 - val_loss: 1282.2603\n",
      "Epoch 3322/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 953.3000 - val_loss: 1281.3961\n",
      "Epoch 3323/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 900.6572 - val_loss: 1264.1231\n",
      "Epoch 3324/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 915.9828 - val_loss: 1269.2501\n",
      "Epoch 3325/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 905.0432 - val_loss: 1261.9698\n",
      "Epoch 3326/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 880.0550 - val_loss: 1252.1238\n",
      "Epoch 3327/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 871.5216 - val_loss: 1240.0656\n",
      "Epoch 3328/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 834.0101 - val_loss: 1235.0220\n",
      "Epoch 3329/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 827.5853 - val_loss: 1233.1675\n",
      "Epoch 3330/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 814.7843 - val_loss: 1212.3370\n",
      "Epoch 3331/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 807.7174 - val_loss: 1244.4473\n",
      "Epoch 3332/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 780.6960 - val_loss: 1206.6022\n",
      "Epoch 3333/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 768.2460 - val_loss: 1194.1867\n",
      "Epoch 3334/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 762.2038 - val_loss: 1199.0651\n",
      "Epoch 3335/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 727.0011 - val_loss: 1153.9092\n",
      "Epoch 3336/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 699.9897 - val_loss: 1138.5834\n",
      "Epoch 3337/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 703.1218 - val_loss: 1126.2697\n",
      "Epoch 3338/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 676.4651 - val_loss: 1107.7183\n",
      "Epoch 3339/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 641.3913 - val_loss: 1097.8183\n",
      "Epoch 3340/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 649.5076 - val_loss: 1079.1525\n",
      "Epoch 3341/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 631.5160 - val_loss: 1082.1621\n",
      "Epoch 3342/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 642.7611 - val_loss: 1078.0615\n",
      "Epoch 3343/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 624.1703 - val_loss: 1084.1591\n",
      "Epoch 3344/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 608.0112 - val_loss: 1085.5509\n",
      "Epoch 3345/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 595.1576 - val_loss: 1041.2854\n",
      "Epoch 3346/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 590.4286 - val_loss: 1071.8758\n",
      "Epoch 3347/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 583.3036 - val_loss: 1087.3909\n",
      "Epoch 3348/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 563.0791 - val_loss: 1036.2260\n",
      "Epoch 3349/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 562.5641 - val_loss: 1078.3973\n",
      "Epoch 3350/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 554.7485 - val_loss: 1045.3601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3351/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 545.5817 - val_loss: 1041.7306\n",
      "Epoch 3352/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 532.8369 - val_loss: 1029.3463\n",
      "Epoch 3353/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 528.2917 - val_loss: 1038.9077\n",
      "Epoch 3354/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 528.9411 - val_loss: 1055.7025\n",
      "Epoch 3355/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 517.6988 - val_loss: 1025.3447\n",
      "Epoch 3356/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 501.0791 - val_loss: 1064.9172\n",
      "Epoch 3357/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 504.7839 - val_loss: 1031.4401\n",
      "Epoch 3358/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 496.3062 - val_loss: 1016.7485\n",
      "Epoch 3359/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 488.4710 - val_loss: 1017.4205\n",
      "Epoch 3360/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 487.1726 - val_loss: 1046.6434\n",
      "Epoch 3361/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 478.5749 - val_loss: 1014.4467\n",
      "Epoch 3362/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 473.9871 - val_loss: 998.6023\n",
      "Epoch 3363/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 459.4076 - val_loss: 1008.6324\n",
      "Epoch 3364/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 438.3944 - val_loss: 1013.0961\n",
      "Epoch 3365/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 437.4477 - val_loss: 989.3811\n",
      "Epoch 3366/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 430.2872 - val_loss: 1009.4527\n",
      "Epoch 3367/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 421.2066 - val_loss: 979.0076\n",
      "Epoch 3368/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 424.2217 - val_loss: 939.3137\n",
      "Epoch 3369/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 422.4545 - val_loss: 989.4505\n",
      "Epoch 3370/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 410.4487 - val_loss: 999.9605\n",
      "Epoch 3371/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 397.3009 - val_loss: 995.7265\n",
      "Epoch 3372/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 406.3393 - val_loss: 960.4105\n",
      "Epoch 3373/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 395.8886 - val_loss: 1000.8574\n",
      "Epoch 3374/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 402.5489 - val_loss: 988.7504\n",
      "Epoch 3375/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 384.6377 - val_loss: 996.3956\n",
      "Epoch 3376/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 376.7696 - val_loss: 960.0562\n",
      "Epoch 3377/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 377.0962 - val_loss: 932.3815\n",
      "Epoch 3378/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.4448 - val_loss: 1015.4109\n",
      "Epoch 3379/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 355.2007 - val_loss: 950.9745\n",
      "Epoch 3380/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 361.4164 - val_loss: 896.7938\n",
      "Epoch 3381/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.9050 - val_loss: 904.2157\n",
      "Epoch 3382/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 362.2159 - val_loss: 984.8389\n",
      "Epoch 3383/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 354.3186 - val_loss: 965.1342\n",
      "Epoch 3384/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 354.2892 - val_loss: 886.8405\n",
      "Epoch 3385/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 363.1496 - val_loss: 981.3529\n",
      "Epoch 3386/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.2264 - val_loss: 928.4392\n",
      "Epoch 3387/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.3679 - val_loss: 883.7292\n",
      "Epoch 3388/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 335.3590 - val_loss: 869.3772\n",
      "Epoch 3389/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.9798 - val_loss: 902.5569\n",
      "Epoch 3390/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 321.2229 - val_loss: 954.8709\n",
      "Epoch 3391/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 322.4656 - val_loss: 916.1422\n",
      "Epoch 3392/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 336.8610 - val_loss: 928.7562\n",
      "Epoch 3393/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.9622 - val_loss: 900.1498\n",
      "Epoch 3394/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.1869 - val_loss: 855.2409\n",
      "Epoch 3395/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 365.9637 - val_loss: 996.4469\n",
      "Epoch 3396/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 353.0643 - val_loss: 1164.1508\n",
      "Epoch 3397/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.7062 - val_loss: 1514.4998\n",
      "Epoch 3398/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 435.0142 - val_loss: 851.2176\n",
      "Epoch 3399/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 363.8358 - val_loss: 859.9745\n",
      "Epoch 3400/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 336.9379 - val_loss: 817.2999\n",
      "Epoch 3401/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 364.0029 - val_loss: 781.9305\n",
      "Epoch 3402/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 490.5019 - val_loss: 1174.5916\n",
      "Epoch 3403/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 571.2575 - val_loss: 797.0156\n",
      "Epoch 3404/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 592.1014 - val_loss: 828.1891\n",
      "Epoch 3405/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 413.4225 - val_loss: 856.0651\n",
      "Epoch 3406/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 404.0557 - val_loss: 890.5931\n",
      "Epoch 3407/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 359.5760 - val_loss: 941.2736\n",
      "Epoch 3408/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.2381 - val_loss: 870.5271\n",
      "Epoch 3409/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 328.3514 - val_loss: 1127.3918\n",
      "Epoch 3410/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 391.1654 - val_loss: 1210.9125\n",
      "Epoch 3411/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 359.0045 - val_loss: 934.5028\n",
      "Epoch 3412/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 352.0589 - val_loss: 796.0862\n",
      "Epoch 3413/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 349.7086 - val_loss: 858.6179\n",
      "Epoch 3414/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 342.2748 - val_loss: 846.6994\n",
      "Epoch 3415/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.4200 - val_loss: 859.5332\n",
      "Epoch 3416/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 337.5739 - val_loss: 892.7530\n",
      "Epoch 3417/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 328.8126 - val_loss: 1014.1037\n",
      "Epoch 3418/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.9462 - val_loss: 916.9609\n",
      "Epoch 3419/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 306.0808 - val_loss: 947.3074\n",
      "Epoch 3420/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 319.9413 - val_loss: 905.1372\n",
      "Epoch 3421/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 313.4580 - val_loss: 920.2739\n",
      "Epoch 3422/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.7930 - val_loss: 896.9860\n",
      "Epoch 3423/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.8639 - val_loss: 769.8991\n",
      "Epoch 3424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 355.4284 - val_loss: 854.0632\n",
      "Epoch 3425/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.0028 - val_loss: 811.1253\n",
      "Epoch 3426/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.4745 - val_loss: 771.5897\n",
      "Epoch 3427/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.2122 - val_loss: 808.7444\n",
      "Epoch 3428/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 387.2353 - val_loss: 1272.9438\n",
      "Epoch 3429/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 385.8298 - val_loss: 939.8256\n",
      "Epoch 3430/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.9491 - val_loss: 959.4867\n",
      "Epoch 3431/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 326.1698 - val_loss: 847.3294\n",
      "Epoch 3432/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.7054 - val_loss: 873.1112\n",
      "Epoch 3433/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 303.2049 - val_loss: 882.7517\n",
      "Epoch 3434/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 299.9238 - val_loss: 836.8792\n",
      "Epoch 3435/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 300.3093 - val_loss: 853.0689\n",
      "Epoch 3436/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 303.6931 - val_loss: 881.3928\n",
      "Epoch 3437/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 322.0101 - val_loss: 1175.9019\n",
      "Epoch 3438/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 391.1724 - val_loss: 819.6234\n",
      "Epoch 3439/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 382.6572 - val_loss: 843.3586\n",
      "Epoch 3440/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 550.8354 - val_loss: 839.3292\n",
      "Epoch 3441/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 568.2658 - val_loss: 940.6726\n",
      "Epoch 3442/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 445.1854 - val_loss: 1855.7510\n",
      "Epoch 3443/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1016.8963 - val_loss: 1391.2596\n",
      "Epoch 3444/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1364.7304 - val_loss: 1393.8955\n",
      "Epoch 3445/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1140.9793 - val_loss: 1319.6732\n",
      "Epoch 3446/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 922.0149 - val_loss: 1246.5066\n",
      "Epoch 3447/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 749.9758 - val_loss: 1292.3368\n",
      "Epoch 3448/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 708.9055 - val_loss: 1281.8209\n",
      "Epoch 3449/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 630.0765 - val_loss: 1212.3783\n",
      "Epoch 3450/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 573.1671 - val_loss: 1254.1361\n",
      "Epoch 3451/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 532.0212 - val_loss: 1225.3171\n",
      "Epoch 3452/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 500.2364 - val_loss: 1155.3042\n",
      "Epoch 3453/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 503.1869 - val_loss: 1207.4913\n",
      "Epoch 3454/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 472.0938 - val_loss: 1158.6884\n",
      "Epoch 3455/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 460.8954 - val_loss: 1061.2268\n",
      "Epoch 3456/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 454.4792 - val_loss: 1136.6245\n",
      "Epoch 3457/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 431.1760 - val_loss: 849.5626\n",
      "Epoch 3458/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 409.3411 - val_loss: 826.6418\n",
      "Epoch 3459/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 383.1925 - val_loss: 729.6151\n",
      "Epoch 3460/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 461.6124 - val_loss: 1362.3472\n",
      "Epoch 3461/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 401.8608 - val_loss: 905.1173\n",
      "Epoch 3462/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 352.2553 - val_loss: 858.9521\n",
      "Epoch 3463/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.2986 - val_loss: 828.1693\n",
      "Epoch 3464/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 343.7680 - val_loss: 818.4705\n",
      "Epoch 3465/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 351.0765 - val_loss: 881.3975\n",
      "Epoch 3466/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.3598 - val_loss: 761.3642\n",
      "Epoch 3467/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.3384 - val_loss: 837.8800\n",
      "Epoch 3468/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 391.6492 - val_loss: 795.9815\n",
      "Epoch 3469/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 410.5378 - val_loss: 1020.4895\n",
      "Epoch 3470/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 395.5425 - val_loss: 876.3257\n",
      "Epoch 3471/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 346.1309 - val_loss: 826.6854\n",
      "Epoch 3472/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 327.9768 - val_loss: 862.6868\n",
      "Epoch 3473/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 327.1548 - val_loss: 824.2881\n",
      "Epoch 3474/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 398.7381 - val_loss: 1239.8732\n",
      "Epoch 3475/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 404.8461 - val_loss: 920.6624\n",
      "Epoch 3476/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.7538 - val_loss: 902.4398\n",
      "Epoch 3477/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 328.4171 - val_loss: 820.0279\n",
      "Epoch 3478/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 308.3052 - val_loss: 816.3937\n",
      "Epoch 3479/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 303.6769 - val_loss: 845.9393\n",
      "Epoch 3480/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 317.6324 - val_loss: 848.8706\n",
      "Epoch 3481/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 303.8028 - val_loss: 888.9983\n",
      "Epoch 3482/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.5330 - val_loss: 862.2169\n",
      "Epoch 3483/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 333.8547 - val_loss: 925.6588\n",
      "Epoch 3484/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 329.7799 - val_loss: 866.9640\n",
      "Epoch 3485/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 375.3890 - val_loss: 845.3209\n",
      "Epoch 3486/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.9239 - val_loss: 857.8517\n",
      "Epoch 3487/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.6972 - val_loss: 907.8547\n",
      "Epoch 3488/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.9638 - val_loss: 791.6769\n",
      "Epoch 3489/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 430.1312 - val_loss: 851.6670\n",
      "Epoch 3490/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 383.0807 - val_loss: 790.1307\n",
      "Epoch 3491/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 340.9353 - val_loss: 804.7018\n",
      "Epoch 3492/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 355.2268 - val_loss: 1238.3538\n",
      "Epoch 3493/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 447.9744 - val_loss: 1022.2332\n",
      "Epoch 3494/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 405.4148 - val_loss: 963.8597\n",
      "Epoch 3495/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.5952 - val_loss: 900.9211\n",
      "Epoch 3496/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 341.3413 - val_loss: 863.6446\n",
      "Epoch 3497/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 329.1344 - val_loss: 850.3165\n",
      "Epoch 3498/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.4577 - val_loss: 879.9775\n",
      "Epoch 3499/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 354.2246 - val_loss: 937.7372\n",
      "Epoch 3500/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 584.3502 - val_loss: 947.3317\n",
      "Epoch 3501/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 483.6669 - val_loss: 858.4851\n",
      "Epoch 3502/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 389.4213 - val_loss: 837.5133\n",
      "Epoch 3503/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.0378 - val_loss: 949.4007\n",
      "Epoch 3504/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.4566 - val_loss: 885.7685\n",
      "Epoch 3505/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.8961 - val_loss: 1038.2908\n",
      "Epoch 3506/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 343.8127 - val_loss: 945.5209\n",
      "Epoch 3507/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 314.1182 - val_loss: 871.0995\n",
      "Epoch 3508/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.2710 - val_loss: 788.5474\n",
      "Epoch 3509/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 315.4878 - val_loss: 839.2613\n",
      "Epoch 3510/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 320.2858 - val_loss: 870.9621\n",
      "Epoch 3511/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 366.2194 - val_loss: 893.6753\n",
      "Epoch 3512/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 391.1191 - val_loss: 929.2616\n",
      "Epoch 3513/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 454.3143 - val_loss: 1020.3636\n",
      "Epoch 3514/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 362.8481 - val_loss: 963.3291\n",
      "Epoch 3515/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 366.6025 - val_loss: 925.5721\n",
      "Epoch 3516/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 335.9078 - val_loss: 851.6834\n",
      "Epoch 3517/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.3842 - val_loss: 920.4669\n",
      "Epoch 3518/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 347.0514 - val_loss: 838.1382\n",
      "Epoch 3519/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 353.9589 - val_loss: 854.7458\n",
      "Epoch 3520/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 359.7778 - val_loss: 887.8676\n",
      "Epoch 3521/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.7661 - val_loss: 872.4087\n",
      "Epoch 3522/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 316.8547 - val_loss: 895.0821\n",
      "Epoch 3523/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.0075 - val_loss: 740.1346\n",
      "Epoch 3524/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 618.6207 - val_loss: 1148.7134\n",
      "Epoch 3525/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 464.3454 - val_loss: 854.9196\n",
      "Epoch 3526/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 392.9191 - val_loss: 861.0047\n",
      "Epoch 3527/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 353.7661 - val_loss: 904.1003\n",
      "Epoch 3528/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 378.9923 - val_loss: 842.5935\n",
      "Epoch 3529/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 365.8312 - val_loss: 819.6779\n",
      "Epoch 3530/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.6444 - val_loss: 1313.2215\n",
      "Epoch 3531/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 871.8769 - val_loss: 1391.4449\n",
      "Epoch 3532/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1078.3748 - val_loss: 1302.5306\n",
      "Epoch 3533/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 855.6014 - val_loss: 1194.2569\n",
      "Epoch 3534/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 674.3877 - val_loss: 1119.3215\n",
      "Epoch 3535/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 518.8826 - val_loss: 954.7583\n",
      "Epoch 3536/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 448.3119 - val_loss: 911.4215\n",
      "Epoch 3537/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 372.9038 - val_loss: 957.3215\n",
      "Epoch 3538/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.8553 - val_loss: 822.0418\n",
      "Epoch 3539/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 348.2250 - val_loss: 880.4577\n",
      "Epoch 3540/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.5429 - val_loss: 996.1645\n",
      "Epoch 3541/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 369.4108 - val_loss: 753.7394\n",
      "Epoch 3542/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 549.0735 - val_loss: 902.2166\n",
      "Epoch 3543/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 475.8799 - val_loss: 1071.2706\n",
      "Epoch 3544/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 425.1972 - val_loss: 866.0420\n",
      "Epoch 3545/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 407.1990 - val_loss: 743.2501\n",
      "Epoch 3546/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.1048 - val_loss: 952.8091\n",
      "Epoch 3547/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 402.5453 - val_loss: 831.8611\n",
      "Epoch 3548/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 418.0834 - val_loss: 819.4104\n",
      "Epoch 3549/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 351.9290 - val_loss: 823.1703\n",
      "Epoch 3550/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.7465 - val_loss: 868.1186\n",
      "Epoch 3551/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 357.3150 - val_loss: 795.3142\n",
      "Epoch 3552/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.1348 - val_loss: 794.6746\n",
      "Epoch 3553/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 357.1622 - val_loss: 778.4313\n",
      "Epoch 3554/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.9408 - val_loss: 782.7032\n",
      "Epoch 3555/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 368.7269 - val_loss: 773.7463\n",
      "Epoch 3556/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 421.9293 - val_loss: 802.0059\n",
      "Epoch 3557/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 402.5117 - val_loss: 958.9434\n",
      "Epoch 3558/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 402.6594 - val_loss: 829.9690\n",
      "Epoch 3559/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 361.8380 - val_loss: 792.4999\n",
      "Epoch 3560/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 335.2513 - val_loss: 750.6070\n",
      "Epoch 3561/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.6230 - val_loss: 835.8842\n",
      "Epoch 3562/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.0445 - val_loss: 821.8179\n",
      "Epoch 3563/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 413.5872 - val_loss: 862.2844\n",
      "Epoch 3564/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 348.0712 - val_loss: 911.6338\n",
      "Epoch 3565/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 364.2541 - val_loss: 948.9949\n",
      "Epoch 3566/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 468.7922 - val_loss: 841.1075\n",
      "Epoch 3567/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 418.6130 - val_loss: 801.0883\n",
      "Epoch 3568/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 372.3183 - val_loss: 817.2801\n",
      "Epoch 3569/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 342.9931 - val_loss: 801.5354\n",
      "Epoch 3570/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 320.8445 - val_loss: 788.1554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3571/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 350.9917 - val_loss: 803.4091\n",
      "Epoch 3572/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 382.1076 - val_loss: 788.1891\n",
      "Epoch 3573/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 403.4377 - val_loss: 697.9344\n",
      "Epoch 3574/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 558.4711 - val_loss: 1291.1884\n",
      "Epoch 3575/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 421.5243 - val_loss: 888.6100\n",
      "Epoch 3576/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 371.5701 - val_loss: 797.0529\n",
      "Epoch 3577/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.4914 - val_loss: 838.6654\n",
      "Epoch 3578/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 331.3970 - val_loss: 1007.6998\n",
      "Epoch 3579/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 387.2739 - val_loss: 1010.0719\n",
      "Epoch 3580/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 375.3876 - val_loss: 1002.6565\n",
      "Epoch 3581/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 451.4717 - val_loss: 807.8351\n",
      "Epoch 3582/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 406.4256 - val_loss: 803.2011\n",
      "Epoch 3583/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 451.3993 - val_loss: 828.8624\n",
      "Epoch 3584/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 374.7729 - val_loss: 1139.8549\n",
      "Epoch 3585/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.6370 - val_loss: 869.4630\n",
      "Epoch 3586/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 350.2421 - val_loss: 903.5058\n",
      "Epoch 3587/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.7354 - val_loss: 943.0216\n",
      "Epoch 3588/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 364.9279 - val_loss: 961.4354\n",
      "Epoch 3589/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 378.8924 - val_loss: 945.5161\n",
      "Epoch 3590/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 404.7793 - val_loss: 881.2287\n",
      "Epoch 3591/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 383.2146 - val_loss: 1003.3222\n",
      "Epoch 3592/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 402.6114 - val_loss: 861.5851\n",
      "Epoch 3593/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.4642 - val_loss: 808.8569\n",
      "Epoch 3594/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 412.0869 - val_loss: 883.0508\n",
      "Epoch 3595/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 455.4500 - val_loss: 776.4901\n",
      "Epoch 3596/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 532.2162 - val_loss: 1001.3158\n",
      "Epoch 3597/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 511.4931 - val_loss: 862.5471\n",
      "Epoch 3598/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 408.7948 - val_loss: 800.0691\n",
      "Epoch 3599/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 396.2733 - val_loss: 1554.3090\n",
      "Epoch 3600/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 522.8437 - val_loss: 856.5296\n",
      "Epoch 3601/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 523.7889 - val_loss: 817.6033\n",
      "Epoch 3602/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 404.9671 - val_loss: 833.9491\n",
      "Epoch 3603/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.7383 - val_loss: 846.6469\n",
      "Epoch 3604/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 360.9981 - val_loss: 756.9406\n",
      "Epoch 3605/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 347.3949 - val_loss: 913.1450\n",
      "Epoch 3606/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 337.5583 - val_loss: 855.7950\n",
      "Epoch 3607/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 346.0157 - val_loss: 889.0955\n",
      "Epoch 3608/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.3462 - val_loss: 882.5673\n",
      "Epoch 3609/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 305.0176 - val_loss: 936.7891\n",
      "Epoch 3610/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 319.0680 - val_loss: 939.0487\n",
      "Epoch 3611/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 416.1310 - val_loss: 805.7154\n",
      "Epoch 3612/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 448.5560 - val_loss: 808.6401\n",
      "Epoch 3613/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 372.1065 - val_loss: 887.6641\n",
      "Epoch 3614/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 340.3343 - val_loss: 912.6250\n",
      "Epoch 3615/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 362.6897 - val_loss: 967.9841\n",
      "Epoch 3616/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.3351 - val_loss: 862.9144\n",
      "Epoch 3617/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 322.6341 - val_loss: 1033.7054\n",
      "Epoch 3618/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 374.3130 - val_loss: 1025.9428\n",
      "Epoch 3619/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 408.4609 - val_loss: 850.2162\n",
      "Epoch 3620/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 347.4760 - val_loss: 816.4192\n",
      "Epoch 3621/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 336.8901 - val_loss: 746.2995\n",
      "Epoch 3622/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.8875 - val_loss: 865.2729\n",
      "Epoch 3623/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 314.2129 - val_loss: 881.1345\n",
      "Epoch 3624/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.5141 - val_loss: 876.2081\n",
      "Epoch 3625/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 313.2347 - val_loss: 915.5293\n",
      "Epoch 3626/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.8261 - val_loss: 811.1633\n",
      "Epoch 3627/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.1163 - val_loss: 886.9130\n",
      "Epoch 3628/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 392.4172 - val_loss: 837.8280\n",
      "Epoch 3629/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.2880 - val_loss: 805.4858\n",
      "Epoch 3630/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 357.5422 - val_loss: 792.6048\n",
      "Epoch 3631/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 336.1016 - val_loss: 763.0658\n",
      "Epoch 3632/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 405.7485 - val_loss: 854.9366\n",
      "Epoch 3633/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 379.5540 - val_loss: 1007.9411\n",
      "Epoch 3634/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.2692 - val_loss: 1021.9465\n",
      "Epoch 3635/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.9242 - val_loss: 850.9337\n",
      "Epoch 3636/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.1032 - val_loss: 817.5722\n",
      "Epoch 3637/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.3437 - val_loss: 890.0931\n",
      "Epoch 3638/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.9070 - val_loss: 857.8630\n",
      "Epoch 3639/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 314.6129 - val_loss: 813.3501\n",
      "Epoch 3640/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 340.0919 - val_loss: 799.4433\n",
      "Epoch 3641/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 382.3967 - val_loss: 818.5793\n",
      "Epoch 3642/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 354.8428 - val_loss: 856.4444\n",
      "Epoch 3643/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.3362 - val_loss: 811.7354\n",
      "Epoch 3644/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 299.5565 - val_loss: 818.8117\n",
      "Epoch 3645/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 367.5891 - val_loss: 873.0155\n",
      "Epoch 3646/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 364.4626 - val_loss: 769.5382\n",
      "Epoch 3647/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 342.2612 - val_loss: 829.0335\n",
      "Epoch 3648/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 309.1062 - val_loss: 892.2872\n",
      "Epoch 3649/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 294.5231 - val_loss: 1026.1525\n",
      "Epoch 3650/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 409.9087 - val_loss: 878.8349\n",
      "Epoch 3651/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.9557 - val_loss: 835.6337\n",
      "Epoch 3652/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 342.0004 - val_loss: 829.1344\n",
      "Epoch 3653/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 308.8452 - val_loss: 895.4411\n",
      "Epoch 3654/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 501.3184 - val_loss: 761.5414\n",
      "Epoch 3655/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 570.5619 - val_loss: 831.9595\n",
      "Epoch 3656/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 424.2438 - val_loss: 862.6574\n",
      "Epoch 3657/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 368.5194 - val_loss: 951.8058\n",
      "Epoch 3658/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 358.2536 - val_loss: 1076.9255\n",
      "Epoch 3659/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 439.3274 - val_loss: 1004.4223\n",
      "Epoch 3660/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 405.9063 - val_loss: 1030.5404\n",
      "Epoch 3661/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 407.7673 - val_loss: 810.0253\n",
      "Epoch 3662/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.4785 - val_loss: 775.4881\n",
      "Epoch 3663/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 332.2177 - val_loss: 783.9005\n",
      "Epoch 3664/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.6428 - val_loss: 994.2558\n",
      "Epoch 3665/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 393.4509 - val_loss: 899.3030\n",
      "Epoch 3666/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 381.7220 - val_loss: 876.7172\n",
      "Epoch 3667/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 352.1616 - val_loss: 863.2416\n",
      "Epoch 3668/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.3752 - val_loss: 939.2913\n",
      "Epoch 3669/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.5394 - val_loss: 864.4601\n",
      "Epoch 3670/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 338.3706 - val_loss: 855.8647\n",
      "Epoch 3671/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 316.2245 - val_loss: 881.0022\n",
      "Epoch 3672/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 347.3240 - val_loss: 781.9007\n",
      "Epoch 3673/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.7018 - val_loss: 843.5722\n",
      "Epoch 3674/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.0315 - val_loss: 922.8849\n",
      "Epoch 3675/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 382.0343 - val_loss: 849.1543\n",
      "Epoch 3676/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.4295 - val_loss: 987.1658\n",
      "Epoch 3677/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 439.1629 - val_loss: 852.6549\n",
      "Epoch 3678/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 385.0382 - val_loss: 809.0562\n",
      "Epoch 3679/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 360.6233 - val_loss: 867.2604\n",
      "Epoch 3680/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 346.8740 - val_loss: 847.2573\n",
      "Epoch 3681/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 324.2056 - val_loss: 852.2534\n",
      "Epoch 3682/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.1873 - val_loss: 957.8528\n",
      "Epoch 3683/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 832.4063 - val_loss: 1466.3462\n",
      "Epoch 3684/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1183.9262 - val_loss: 1426.4772\n",
      "Epoch 3685/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1022.5507 - val_loss: 910.7989\n",
      "Epoch 3686/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 850.4684 - val_loss: 771.0613\n",
      "Epoch 3687/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 626.7671 - val_loss: 827.2724\n",
      "Epoch 3688/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 546.7280 - val_loss: 1009.9659\n",
      "Epoch 3689/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 496.1819 - val_loss: 822.7862\n",
      "Epoch 3690/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 440.4084 - val_loss: 1015.3986\n",
      "Epoch 3691/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 408.3375 - val_loss: 1021.0107\n",
      "Epoch 3692/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 392.6203 - val_loss: 1084.6201\n",
      "Epoch 3693/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 426.1231 - val_loss: 968.5714\n",
      "Epoch 3694/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 375.2539 - val_loss: 927.0334\n",
      "Epoch 3695/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.2514 - val_loss: 978.4511\n",
      "Epoch 3696/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.1973 - val_loss: 865.9091\n",
      "Epoch 3697/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 339.8882 - val_loss: 827.8443\n",
      "Epoch 3698/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.9126 - val_loss: 860.9566\n",
      "Epoch 3699/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 327.0540 - val_loss: 809.3250\n",
      "Epoch 3700/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.5634 - val_loss: 848.5806\n",
      "Epoch 3701/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 340.3173 - val_loss: 1128.2842\n",
      "Epoch 3702/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 648.8159 - val_loss: 1005.8952\n",
      "Epoch 3703/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 682.3498 - val_loss: 1148.2945\n",
      "Epoch 3704/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 549.8279 - val_loss: 991.6113\n",
      "Epoch 3705/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 407.3288 - val_loss: 953.2567\n",
      "Epoch 3706/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 361.3369 - val_loss: 793.3177\n",
      "Epoch 3707/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.0261 - val_loss: 838.8131\n",
      "Epoch 3708/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.9710 - val_loss: 834.6830\n",
      "Epoch 3709/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 362.6111 - val_loss: 772.8229\n",
      "Epoch 3710/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 427.9102 - val_loss: 777.9089\n",
      "Epoch 3711/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.8918 - val_loss: 826.7621\n",
      "Epoch 3712/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.6204 - val_loss: 818.2450\n",
      "Epoch 3713/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 319.7962 - val_loss: 822.1756\n",
      "Epoch 3714/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 337.5371 - val_loss: 721.7639\n",
      "Epoch 3715/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 380.1283 - val_loss: 751.1373\n",
      "Epoch 3716/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 372.3203 - val_loss: 885.8360\n",
      "Epoch 3717/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 440.0254 - val_loss: 998.6535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3718/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 392.3000 - val_loss: 995.1462\n",
      "Epoch 3719/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 432.0031 - val_loss: 860.9489\n",
      "Epoch 3720/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 499.2538 - val_loss: 918.5452\n",
      "Epoch 3721/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 480.1052 - val_loss: 841.6721\n",
      "Epoch 3722/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 391.8209 - val_loss: 846.5398\n",
      "Epoch 3723/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 364.8739 - val_loss: 828.0225\n",
      "Epoch 3724/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 343.2909 - val_loss: 822.8017\n",
      "Epoch 3725/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 365.7607 - val_loss: 853.3101\n",
      "Epoch 3726/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 335.2188 - val_loss: 722.4147\n",
      "Epoch 3727/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1014.8483 - val_loss: 742.5602\n",
      "Epoch 3728/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 878.5811 - val_loss: 687.0954\n",
      "Epoch 3729/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 552.1219 - val_loss: 849.0260\n",
      "Epoch 3730/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 572.7038 - val_loss: 977.6921\n",
      "Epoch 3731/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 458.6861 - val_loss: 1079.8030\n",
      "Epoch 3732/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 424.8582 - val_loss: 823.9590\n",
      "Epoch 3733/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 425.2672 - val_loss: 866.6316\n",
      "Epoch 3734/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.5911 - val_loss: 1060.2326\n",
      "Epoch 3735/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 386.8251 - val_loss: 997.4279\n",
      "Epoch 3736/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 356.2037 - val_loss: 893.1422\n",
      "Epoch 3737/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 337.4168 - val_loss: 919.3078\n",
      "Epoch 3738/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.9165 - val_loss: 908.9460\n",
      "Epoch 3739/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.1932 - val_loss: 864.6603\n",
      "Epoch 3740/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 314.5616 - val_loss: 1003.6187\n",
      "Epoch 3741/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 330.3607 - val_loss: 870.1197\n",
      "Epoch 3742/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.8902 - val_loss: 921.9883\n",
      "Epoch 3743/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 450.6989 - val_loss: 938.2948\n",
      "Epoch 3744/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 435.5966 - val_loss: 821.8998\n",
      "Epoch 3745/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 432.5215 - val_loss: 715.5062\n",
      "Epoch 3746/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 392.9405 - val_loss: 939.6511\n",
      "Epoch 3747/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 355.1862 - val_loss: 942.7759\n",
      "Epoch 3748/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.6145 - val_loss: 944.5923\n",
      "Epoch 3749/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 367.7000 - val_loss: 926.0826\n",
      "Epoch 3750/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 456.1851 - val_loss: 927.9087\n",
      "Epoch 3751/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 414.8412 - val_loss: 750.8191\n",
      "Epoch 3752/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 419.6807 - val_loss: 829.1305\n",
      "Epoch 3753/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.5529 - val_loss: 969.9249\n",
      "Epoch 3754/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 376.0660 - val_loss: 919.9996\n",
      "Epoch 3755/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.6285 - val_loss: 983.8500\n",
      "Epoch 3756/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 423.6075 - val_loss: 969.2111\n",
      "Epoch 3757/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 415.2797 - val_loss: 803.1983\n",
      "Epoch 3758/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 362.7584 - val_loss: 877.6741\n",
      "Epoch 3759/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 396.4734 - val_loss: 830.6601\n",
      "Epoch 3760/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 337.4499 - val_loss: 803.5782\n",
      "Epoch 3761/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 317.8138 - val_loss: 838.0034\n",
      "Epoch 3762/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.4916 - val_loss: 858.4589\n",
      "Epoch 3763/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.0572 - val_loss: 958.4213\n",
      "Epoch 3764/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.8088 - val_loss: 910.8075\n",
      "Epoch 3765/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 333.3065 - val_loss: 827.8373\n",
      "Epoch 3766/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 320.9663 - val_loss: 988.4534\n",
      "Epoch 3767/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.9037 - val_loss: 821.8839\n",
      "Epoch 3768/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 339.6210 - val_loss: 763.6782\n",
      "Epoch 3769/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.1447 - val_loss: 892.1673\n",
      "Epoch 3770/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.6054 - val_loss: 811.2834\n",
      "Epoch 3771/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.2621 - val_loss: 892.7246\n",
      "Epoch 3772/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.9586 - val_loss: 980.8560\n",
      "Epoch 3773/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.5133 - val_loss: 847.2109\n",
      "Epoch 3774/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 398.6853 - val_loss: 880.2334\n",
      "Epoch 3775/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 391.9949 - val_loss: 901.0381\n",
      "Epoch 3776/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 378.3706 - val_loss: 1018.3707\n",
      "Epoch 3777/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 337.2444 - val_loss: 845.2723\n",
      "Epoch 3778/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 410.2973 - val_loss: 853.6997\n",
      "Epoch 3779/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.4545 - val_loss: 857.3898\n",
      "Epoch 3780/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 325.1072 - val_loss: 1056.3973\n",
      "Epoch 3781/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 534.1113 - val_loss: 892.2716\n",
      "Epoch 3782/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 479.6642 - val_loss: 873.1913\n",
      "Epoch 3783/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 423.0761 - val_loss: 862.2859\n",
      "Epoch 3784/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 392.8140 - val_loss: 850.4080\n",
      "Epoch 3785/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.4696 - val_loss: 837.0711\n",
      "Epoch 3786/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 365.1696 - val_loss: 839.3352\n",
      "Epoch 3787/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 345.9528 - val_loss: 780.9807\n",
      "Epoch 3788/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.5341 - val_loss: 849.0723\n",
      "Epoch 3789/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 306.6518 - val_loss: 834.9964\n",
      "Epoch 3790/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 327.3585 - val_loss: 928.1101\n",
      "Epoch 3791/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 329.9864 - val_loss: 971.8554\n",
      "Epoch 3792/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 375.2436 - val_loss: 1011.3400\n",
      "Epoch 3793/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 326.9663 - val_loss: 1142.0647\n",
      "Epoch 3794/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 338.7208 - val_loss: 936.8088\n",
      "Epoch 3795/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 347.9029 - val_loss: 995.7440\n",
      "Epoch 3796/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 349.3544 - val_loss: 849.7263\n",
      "Epoch 3797/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 328.0985 - val_loss: 894.4825\n",
      "Epoch 3798/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.3308 - val_loss: 921.3923\n",
      "Epoch 3799/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 353.2661 - val_loss: 945.7136\n",
      "Epoch 3800/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 367.0011 - val_loss: 752.4561\n",
      "Epoch 3801/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 524.0859 - val_loss: 901.5447\n",
      "Epoch 3802/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 477.8336 - val_loss: 848.2138\n",
      "Epoch 3803/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 427.1333 - val_loss: 772.6131\n",
      "Epoch 3804/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 357.3814 - val_loss: 770.5349\n",
      "Epoch 3805/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 553.2843 - val_loss: 762.3009\n",
      "Epoch 3806/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 434.8223 - val_loss: 977.4446\n",
      "Epoch 3807/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 506.7474 - val_loss: 825.9245\n",
      "Epoch 3808/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 463.5567 - val_loss: 723.9511\n",
      "Epoch 3809/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 421.3957 - val_loss: 860.5258\n",
      "Epoch 3810/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 351.1001 - val_loss: 784.8124\n",
      "Epoch 3811/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 401.8209 - val_loss: 2889.1138\n",
      "Epoch 3812/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1641.0624 - val_loss: 1166.5170\n",
      "Epoch 3813/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1633.5727 - val_loss: 1673.9396\n",
      "Epoch 3814/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1276.3157 - val_loss: 1275.5458\n",
      "Epoch 3815/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1007.6666 - val_loss: 1184.1044\n",
      "Epoch 3816/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 743.8331 - val_loss: 1259.2496\n",
      "Epoch 3817/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 651.2593 - val_loss: 1184.0330\n",
      "Epoch 3818/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 568.5510 - val_loss: 1252.6829\n",
      "Epoch 3819/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 471.5106 - val_loss: 808.1117\n",
      "Epoch 3820/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 390.9352 - val_loss: 1036.6538\n",
      "Epoch 3821/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 439.1597 - val_loss: 747.3910\n",
      "Epoch 3822/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 466.4779 - val_loss: 809.4825\n",
      "Epoch 3823/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 455.5623 - val_loss: 1261.6607\n",
      "Epoch 3824/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 508.1974 - val_loss: 788.3073\n",
      "Epoch 3825/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 469.8954 - val_loss: 789.4922\n",
      "Epoch 3826/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 418.4216 - val_loss: 826.6687\n",
      "Epoch 3827/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.1886 - val_loss: 1038.1660\n",
      "Epoch 3828/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 597.1167 - val_loss: 824.7705\n",
      "Epoch 3829/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 672.3460 - val_loss: 1002.4193\n",
      "Epoch 3830/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 546.8654 - val_loss: 760.5051\n",
      "Epoch 3831/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 456.8687 - val_loss: 778.2487\n",
      "Epoch 3832/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.9045 - val_loss: 832.0219\n",
      "Epoch 3833/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 349.5468 - val_loss: 961.2643\n",
      "Epoch 3834/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 320.5547 - val_loss: 867.7046\n",
      "Epoch 3835/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 388.9630 - val_loss: 795.3825\n",
      "Epoch 3836/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 437.5777 - val_loss: 956.8735\n",
      "Epoch 3837/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 381.4421 - val_loss: 1032.3626\n",
      "Epoch 3838/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 325.0976 - val_loss: 891.3643\n",
      "Epoch 3839/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 324.4241 - val_loss: 1040.8905\n",
      "Epoch 3840/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.0122 - val_loss: 1081.5539\n",
      "Epoch 3841/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 577.3289 - val_loss: 854.2320\n",
      "Epoch 3842/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 735.2539 - val_loss: 1022.5563\n",
      "Epoch 3843/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 562.6814 - val_loss: 880.0121\n",
      "Epoch 3844/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 477.1232 - val_loss: 860.7508\n",
      "Epoch 3845/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 445.7236 - val_loss: 838.7221\n",
      "Epoch 3846/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 391.8158 - val_loss: 946.1468\n",
      "Epoch 3847/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 364.8952 - val_loss: 1025.3171\n",
      "Epoch 3848/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 394.9373 - val_loss: 912.2158\n",
      "Epoch 3849/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 372.7162 - val_loss: 927.1923\n",
      "Epoch 3850/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 348.4949 - val_loss: 850.1815\n",
      "Epoch 3851/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 329.9699 - val_loss: 839.2135\n",
      "Epoch 3852/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 406.9925 - val_loss: 788.5402\n",
      "Epoch 3853/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 465.3454 - val_loss: 838.6941\n",
      "Epoch 3854/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.9645 - val_loss: 908.3733\n",
      "Epoch 3855/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 355.1642 - val_loss: 1090.0061\n",
      "Epoch 3856/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 397.2786 - val_loss: 1078.7627\n",
      "Epoch 3857/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 385.3446 - val_loss: 791.3005\n",
      "Epoch 3858/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 482.8693 - val_loss: 899.8031\n",
      "Epoch 3859/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 413.3995 - val_loss: 957.0576\n",
      "Epoch 3860/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 406.4498 - val_loss: 773.4196\n",
      "Epoch 3861/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 369.3673 - val_loss: 948.0012\n",
      "Epoch 3862/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 337.5958 - val_loss: 790.9139\n",
      "Epoch 3863/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 389.4972 - val_loss: 880.8573\n",
      "Epoch 3864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 53us/step - loss: 391.1569 - val_loss: 885.2277\n",
      "Epoch 3865/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 353.1457 - val_loss: 823.1069\n",
      "Epoch 3866/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 363.9854 - val_loss: 967.1619\n",
      "Epoch 3867/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 394.4793 - val_loss: 797.3574\n",
      "Epoch 3868/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 395.4022 - val_loss: 818.7965\n",
      "Epoch 3869/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 337.7265 - val_loss: 875.7619\n",
      "Epoch 3870/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 349.8089 - val_loss: 873.7974\n",
      "Epoch 3871/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.7722 - val_loss: 838.0876\n",
      "Epoch 3872/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 357.3732 - val_loss: 1016.3375\n",
      "Epoch 3873/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.3500 - val_loss: 791.3917\n",
      "Epoch 3874/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 381.0758 - val_loss: 990.7090\n",
      "Epoch 3875/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 365.0110 - val_loss: 858.9652\n",
      "Epoch 3876/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 345.3415 - val_loss: 867.5649\n",
      "Epoch 3877/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 418.9976 - val_loss: 916.1381\n",
      "Epoch 3878/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 364.8021 - val_loss: 929.3572\n",
      "Epoch 3879/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 382.6917 - val_loss: 794.4866\n",
      "Epoch 3880/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 356.7917 - val_loss: 875.4705\n",
      "Epoch 3881/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.3206 - val_loss: 872.2619\n",
      "Epoch 3882/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 324.7738 - val_loss: 1179.1464\n",
      "Epoch 3883/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 597.6883 - val_loss: 1207.1407\n",
      "Epoch 3884/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 659.3875 - val_loss: 881.9195\n",
      "Epoch 3885/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 835.6352 - val_loss: 768.2341\n",
      "Epoch 3886/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 827.7083 - val_loss: 691.1204\n",
      "Epoch 3887/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 659.9875 - val_loss: 931.2372\n",
      "Epoch 3888/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 513.8974 - val_loss: 933.1857\n",
      "Epoch 3889/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 386.2719 - val_loss: 956.2495\n",
      "Epoch 3890/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 454.0230 - val_loss: 956.9112\n",
      "Epoch 3891/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 379.4723 - val_loss: 984.7841\n",
      "Epoch 3892/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 375.0947 - val_loss: 886.0569\n",
      "Epoch 3893/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 366.8593 - val_loss: 893.0534\n",
      "Epoch 3894/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.2506 - val_loss: 929.4793\n",
      "Epoch 3895/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 348.0856 - val_loss: 935.1705\n",
      "Epoch 3896/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 373.2512 - val_loss: 1071.0803\n",
      "Epoch 3897/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 436.2674 - val_loss: 809.7666\n",
      "Epoch 3898/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 547.9861 - val_loss: 943.8021\n",
      "Epoch 3899/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 452.6881 - val_loss: 832.0907\n",
      "Epoch 3900/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 366.0231 - val_loss: 877.3347\n",
      "Epoch 3901/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 320.6997 - val_loss: 956.2549\n",
      "Epoch 3902/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.7838 - val_loss: 785.5669\n",
      "Epoch 3903/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.0426 - val_loss: 817.9104\n",
      "Epoch 3904/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 345.5391 - val_loss: 765.2753\n",
      "Epoch 3905/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 351.5758 - val_loss: 883.1596\n",
      "Epoch 3906/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 483.1055 - val_loss: 878.8208\n",
      "Epoch 3907/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 527.6470 - val_loss: 854.8348\n",
      "Epoch 3908/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 480.2006 - val_loss: 854.7179\n",
      "Epoch 3909/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 416.7218 - val_loss: 848.4691\n",
      "Epoch 3910/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 368.8368 - val_loss: 993.9671\n",
      "Epoch 3911/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 323.9799 - val_loss: 945.9717\n",
      "Epoch 3912/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 346.3468 - val_loss: 842.3829\n",
      "Epoch 3913/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 395.8765 - val_loss: 1101.1508\n",
      "Epoch 3914/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.1799 - val_loss: 967.9871\n",
      "Epoch 3915/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 385.6354 - val_loss: 975.8230\n",
      "Epoch 3916/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.2348 - val_loss: 902.8435\n",
      "Epoch 3917/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 330.8843 - val_loss: 924.7418\n",
      "Epoch 3918/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.0974 - val_loss: 889.8950\n",
      "Epoch 3919/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 406.5974 - val_loss: 837.7633\n",
      "Epoch 3920/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 361.3167 - val_loss: 811.7778\n",
      "Epoch 3921/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 347.5981 - val_loss: 850.8340\n",
      "Epoch 3922/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 380.3422 - val_loss: 738.6338\n",
      "Epoch 3923/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.5555 - val_loss: 781.4333\n",
      "Epoch 3924/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 341.0688 - val_loss: 824.2243\n",
      "Epoch 3925/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.2693 - val_loss: 838.0233\n",
      "Epoch 3926/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.6320 - val_loss: 894.4403\n",
      "Epoch 3927/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 311.8334 - val_loss: 886.5210\n",
      "Epoch 3928/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.8906 - val_loss: 841.1398\n",
      "Epoch 3929/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 403.6199 - val_loss: 1271.0171\n",
      "Epoch 3930/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 748.7936 - val_loss: 779.8884\n",
      "Epoch 3931/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 635.5785 - val_loss: 738.5979\n",
      "Epoch 3932/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 512.2876 - val_loss: 839.0537\n",
      "Epoch 3933/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 460.4470 - val_loss: 988.4683\n",
      "Epoch 3934/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 392.9812 - val_loss: 989.6715\n",
      "Epoch 3935/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 354.4784 - val_loss: 966.6579\n",
      "Epoch 3936/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 335.0926 - val_loss: 1093.3762\n",
      "Epoch 3937/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 359.7615 - val_loss: 866.3429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3938/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.8441 - val_loss: 854.2425\n",
      "Epoch 3939/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.9406 - val_loss: 906.5056\n",
      "Epoch 3940/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.4482 - val_loss: 846.3017\n",
      "Epoch 3941/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 332.9278 - val_loss: 812.9788\n",
      "Epoch 3942/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 323.9573 - val_loss: 904.2776\n",
      "Epoch 3943/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 300.2754 - val_loss: 841.3469\n",
      "Epoch 3944/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 301.0063 - val_loss: 829.6875\n",
      "Epoch 3945/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 352.1364 - val_loss: 863.4617\n",
      "Epoch 3946/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 394.6219 - val_loss: 821.6729\n",
      "Epoch 3947/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.6322 - val_loss: 872.6978\n",
      "Epoch 3948/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 337.2505 - val_loss: 873.4884\n",
      "Epoch 3949/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 357.9284 - val_loss: 859.1275\n",
      "Epoch 3950/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 346.7123 - val_loss: 894.5699\n",
      "Epoch 3951/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 389.6326 - val_loss: 853.2218\n",
      "Epoch 3952/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 365.6441 - val_loss: 867.9700\n",
      "Epoch 3953/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.4375 - val_loss: 1210.6510\n",
      "Epoch 3954/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 658.4497 - val_loss: 715.3729\n",
      "Epoch 3955/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 526.5709 - val_loss: 848.1758\n",
      "Epoch 3956/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 486.9367 - val_loss: 792.6864\n",
      "Epoch 3957/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 451.8336 - val_loss: 829.5138\n",
      "Epoch 3958/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.8124 - val_loss: 857.4238\n",
      "Epoch 3959/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 363.3689 - val_loss: 869.6899\n",
      "Epoch 3960/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 486.7492 - val_loss: 1046.0998\n",
      "Epoch 3961/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 495.1875 - val_loss: 822.4877\n",
      "Epoch 3962/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.8282 - val_loss: 835.5978\n",
      "Epoch 3963/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 367.7416 - val_loss: 792.3701\n",
      "Epoch 3964/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.6494 - val_loss: 888.6702\n",
      "Epoch 3965/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 338.9764 - val_loss: 922.8113\n",
      "Epoch 3966/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.5706 - val_loss: 819.7271\n",
      "Epoch 3967/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 356.7185 - val_loss: 924.4692\n",
      "Epoch 3968/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 351.1596 - val_loss: 942.5210\n",
      "Epoch 3969/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 327.4802 - val_loss: 935.2600\n",
      "Epoch 3970/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 337.5612 - val_loss: 1022.3226\n",
      "Epoch 3971/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 333.4081 - val_loss: 985.2204\n",
      "Epoch 3972/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 321.0863 - val_loss: 873.7012\n",
      "Epoch 3973/10000\n",
      "630/630 [==============================] - 0s 77us/step - loss: 314.1661 - val_loss: 783.8751\n",
      "Epoch 3974/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 325.7494 - val_loss: 832.2500\n",
      "Epoch 3975/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.1949 - val_loss: 851.7439\n",
      "Epoch 3976/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.6566 - val_loss: 825.5183\n",
      "Epoch 3977/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 377.2900 - val_loss: 835.7774\n",
      "Epoch 3978/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.1399 - val_loss: 809.4911\n",
      "Epoch 3979/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 319.2482 - val_loss: 861.3391\n",
      "Epoch 3980/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.3346 - val_loss: 817.9670\n",
      "Epoch 3981/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 326.4805 - val_loss: 899.0234\n",
      "Epoch 3982/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.1853 - val_loss: 846.9160\n",
      "Epoch 3983/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.6739 - val_loss: 790.9245\n",
      "Epoch 3984/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.1386 - val_loss: 849.4620\n",
      "Epoch 3985/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 323.3114 - val_loss: 794.5662\n",
      "Epoch 3986/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 313.1637 - val_loss: 761.9378\n",
      "Epoch 3987/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 379.2223 - val_loss: 829.9796\n",
      "Epoch 3988/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 364.6029 - val_loss: 1009.5010\n",
      "Epoch 3989/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 617.8896 - val_loss: 842.3826\n",
      "Epoch 3990/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 453.3718 - val_loss: 864.8343\n",
      "Epoch 3991/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 426.3071 - val_loss: 783.0239\n",
      "Epoch 3992/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 426.1232 - val_loss: 1170.2835\n",
      "Epoch 3993/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 402.2068 - val_loss: 1163.8222\n",
      "Epoch 3994/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 380.1456 - val_loss: 1145.5808\n",
      "Epoch 3995/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 415.5668 - val_loss: 962.5327\n",
      "Epoch 3996/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 400.0964 - val_loss: 905.6667\n",
      "Epoch 3997/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 417.2538 - val_loss: 740.6687\n",
      "Epoch 3998/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 437.8155 - val_loss: 736.9865\n",
      "Epoch 3999/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 432.0593 - val_loss: 801.7393\n",
      "Epoch 4000/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 404.1167 - val_loss: 1131.1143\n",
      "Epoch 4001/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 439.9197 - val_loss: 827.3710\n",
      "Epoch 4002/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 422.8470 - val_loss: 818.8382\n",
      "Epoch 4003/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 416.3227 - val_loss: 902.9680\n",
      "Epoch 4004/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.2528 - val_loss: 1018.6630\n",
      "Epoch 4005/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 349.0561 - val_loss: 837.0865\n",
      "Epoch 4006/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 464.1077 - val_loss: 858.3909\n",
      "Epoch 4007/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.4329 - val_loss: 891.2547\n",
      "Epoch 4008/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.5154 - val_loss: 931.5288\n",
      "Epoch 4009/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 319.1150 - val_loss: 847.0782\n",
      "Epoch 4010/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.6733 - val_loss: 849.4705\n",
      "Epoch 4011/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 300.1916 - val_loss: 743.5655\n",
      "Epoch 4012/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 304.4421 - val_loss: 785.7378\n",
      "Epoch 4013/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 364.9481 - val_loss: 683.7969\n",
      "Epoch 4014/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 392.2333 - val_loss: 734.7558\n",
      "Epoch 4015/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 396.0681 - val_loss: 728.0682\n",
      "Epoch 4016/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 364.4600 - val_loss: 872.4196\n",
      "Epoch 4017/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 382.2564 - val_loss: 881.5153\n",
      "Epoch 4018/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 430.8306 - val_loss: 834.6117\n",
      "Epoch 4019/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 396.8141 - val_loss: 836.4699\n",
      "Epoch 4020/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 342.4242 - val_loss: 824.6876\n",
      "Epoch 4021/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 686.9678 - val_loss: 1106.6128\n",
      "Epoch 4022/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2337.3494 - val_loss: 2020.2474\n",
      "Epoch 4023/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2622.0442 - val_loss: 1925.0333\n",
      "Epoch 4024/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2130.7453 - val_loss: 1597.9231\n",
      "Epoch 4025/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 1560.4823 - val_loss: 1262.7435\n",
      "Epoch 4026/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 1315.7685 - val_loss: 1184.6502\n",
      "Epoch 4027/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1084.2988 - val_loss: 1208.4150\n",
      "Epoch 4028/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 963.5270 - val_loss: 1052.9391\n",
      "Epoch 4029/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 861.1434 - val_loss: 1286.3866\n",
      "Epoch 4030/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 843.5069 - val_loss: 1023.2011\n",
      "Epoch 4031/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 765.5778 - val_loss: 1043.1901\n",
      "Epoch 4032/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 734.3931 - val_loss: 1008.4671\n",
      "Epoch 4033/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 687.6011 - val_loss: 950.3120\n",
      "Epoch 4034/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 671.4908 - val_loss: 1123.7200\n",
      "Epoch 4035/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 647.5333 - val_loss: 968.2247\n",
      "Epoch 4036/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 605.4628 - val_loss: 1102.5366\n",
      "Epoch 4037/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 560.0203 - val_loss: 925.7264\n",
      "Epoch 4038/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 534.2739 - val_loss: 887.4612\n",
      "Epoch 4039/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 516.8037 - val_loss: 873.3237\n",
      "Epoch 4040/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 482.0680 - val_loss: 949.2030\n",
      "Epoch 4041/10000\n",
      "630/630 [==============================] - 0s 72us/step - loss: 468.6907 - val_loss: 909.5242\n",
      "Epoch 4042/10000\n",
      "630/630 [==============================] - 0s 93us/step - loss: 431.0631 - val_loss: 888.8037\n",
      "Epoch 4043/10000\n",
      "630/630 [==============================] - 0s 157us/step - loss: 388.2072 - val_loss: 880.3640\n",
      "Epoch 4044/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 368.0716 - val_loss: 826.0869\n",
      "Epoch 4045/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 409.864 - 0s 67us/step - loss: 359.7545 - val_loss: 764.8810\n",
      "Epoch 4046/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 358.5545 - val_loss: 901.1391\n",
      "Epoch 4047/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 338.1191 - val_loss: 896.8388\n",
      "Epoch 4048/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 341.4193 - val_loss: 995.7691\n",
      "Epoch 4049/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 374.2499 - val_loss: 867.1755\n",
      "Epoch 4050/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 355.8809 - val_loss: 775.4078\n",
      "Epoch 4051/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.3113 - val_loss: 795.3269\n",
      "Epoch 4052/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 323.4868 - val_loss: 785.7196\n",
      "Epoch 4053/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 310.6828 - val_loss: 878.0272\n",
      "Epoch 4054/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 311.8331 - val_loss: 971.8408\n",
      "Epoch 4055/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 321.5124 - val_loss: 830.2336\n",
      "Epoch 4056/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 329.8065 - val_loss: 1007.4171\n",
      "Epoch 4057/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.1704 - val_loss: 1055.1490\n",
      "Epoch 4058/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 641.0833 - val_loss: 689.0743\n",
      "Epoch 4059/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 435.3951 - val_loss: 1031.0609\n",
      "Epoch 4060/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 597.5409 - val_loss: 852.0479\n",
      "Epoch 4061/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 687.5157 - val_loss: 986.4231\n",
      "Epoch 4062/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 560.0083 - val_loss: 910.0412\n",
      "Epoch 4063/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 440.6923 - val_loss: 934.7829\n",
      "Epoch 4064/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 415.6069 - val_loss: 857.4041\n",
      "Epoch 4065/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.2296 - val_loss: 837.1180\n",
      "Epoch 4066/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 334.3402 - val_loss: 818.9640\n",
      "Epoch 4067/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 306.9601 - val_loss: 945.0619\n",
      "Epoch 4068/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 326.9792 - val_loss: 879.1197\n",
      "Epoch 4069/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.6956 - val_loss: 935.7472\n",
      "Epoch 4070/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 337.1384 - val_loss: 906.0371\n",
      "Epoch 4071/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 383.7439 - val_loss: 865.5445\n",
      "Epoch 4072/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.4145 - val_loss: 933.6294\n",
      "Epoch 4073/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 455.7244 - val_loss: 903.0491\n",
      "Epoch 4074/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.6369 - val_loss: 983.7027\n",
      "Epoch 4075/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.7539 - val_loss: 951.7485\n",
      "Epoch 4076/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 332.1682 - val_loss: 861.5700\n",
      "Epoch 4077/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.9681 - val_loss: 876.5300\n",
      "Epoch 4078/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 331.7119 - val_loss: 872.3517\n",
      "Epoch 4079/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 639.6683 - val_loss: 969.0564\n",
      "Epoch 4080/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 624.7803 - val_loss: 1177.4910\n",
      "Epoch 4081/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 547.8385 - val_loss: 966.9577\n",
      "Epoch 4082/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 477.3815 - val_loss: 978.8329\n",
      "Epoch 4083/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 446.6103 - val_loss: 835.9653\n",
      "Epoch 4084/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 380.6977 - val_loss: 822.4726\n",
      "Epoch 4085/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 356.9048 - val_loss: 765.0802\n",
      "Epoch 4086/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 371.1881 - val_loss: 773.8684\n",
      "Epoch 4087/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 341.1526 - val_loss: 785.3911\n",
      "Epoch 4088/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 326.2305 - val_loss: 805.8379\n",
      "Epoch 4089/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 323.2943 - val_loss: 747.4361\n",
      "Epoch 4090/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.7882 - val_loss: 745.5012\n",
      "Epoch 4091/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 314.7626 - val_loss: 798.7479\n",
      "Epoch 4092/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.0229 - val_loss: 940.8181\n",
      "Epoch 4093/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 328.6204 - val_loss: 815.7006\n",
      "Epoch 4094/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.8367 - val_loss: 918.3170\n",
      "Epoch 4095/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 316.9803 - val_loss: 1100.0952\n",
      "Epoch 4096/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 349.9315 - val_loss: 909.2767\n",
      "Epoch 4097/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 365.9326 - val_loss: 924.0399\n",
      "Epoch 4098/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.2227 - val_loss: 910.9052\n",
      "Epoch 4099/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 329.9209 - val_loss: 921.8321\n",
      "Epoch 4100/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.5137 - val_loss: 848.2682\n",
      "Epoch 4101/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 357.5086 - val_loss: 841.4559\n",
      "Epoch 4102/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 317.8751 - val_loss: 807.6977\n",
      "Epoch 4103/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 304.2428 - val_loss: 798.4152\n",
      "Epoch 4104/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 334.9348 - val_loss: 736.9761\n",
      "Epoch 4105/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.8616 - val_loss: 946.3591\n",
      "Epoch 4106/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 417.7331 - val_loss: 778.1582\n",
      "Epoch 4107/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 363.2596 - val_loss: 798.4737\n",
      "Epoch 4108/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.8533 - val_loss: 837.0838\n",
      "Epoch 4109/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.6521 - val_loss: 781.5974\n",
      "Epoch 4110/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 310.7728 - val_loss: 774.5215\n",
      "Epoch 4111/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 340.9311 - val_loss: 987.0567\n",
      "Epoch 4112/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 340.2651 - val_loss: 869.1879\n",
      "Epoch 4113/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 339.7973 - val_loss: 855.8309\n",
      "Epoch 4114/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 327.0223 - val_loss: 887.3079\n",
      "Epoch 4115/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 326.6985 - val_loss: 775.3815\n",
      "Epoch 4116/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 309.4020 - val_loss: 788.5080\n",
      "Epoch 4117/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 301.2813 - val_loss: 810.5423\n",
      "Epoch 4118/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 310.2304 - val_loss: 781.9855\n",
      "Epoch 4119/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 338.4361 - val_loss: 832.8188\n",
      "Epoch 4120/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 311.9332 - val_loss: 873.2585\n",
      "Epoch 4121/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 301.4451 - val_loss: 872.6564\n",
      "Epoch 4122/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 403.1041 - val_loss: 861.1401\n",
      "Epoch 4123/10000\n",
      "630/630 [==============================] - 0s 123us/step - loss: 377.4678 - val_loss: 783.8105\n",
      "Epoch 4124/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 384.0734 - val_loss: 834.8449\n",
      "Epoch 4125/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 354.0165 - val_loss: 870.4179\n",
      "Epoch 4126/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 324.4337 - val_loss: 824.9419\n",
      "Epoch 4127/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 280.555 - 0s 66us/step - loss: 305.4433 - val_loss: 833.9962\n",
      "Epoch 4128/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 378.9308 - val_loss: 826.4829\n",
      "Epoch 4129/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 371.5686 - val_loss: 743.0942\n",
      "Epoch 4130/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 346.2907 - val_loss: 801.7449\n",
      "Epoch 4131/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 313.9223 - val_loss: 770.4483\n",
      "Epoch 4132/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 368.2788 - val_loss: 763.4381\n",
      "Epoch 4133/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.9428 - val_loss: 779.0390\n",
      "Epoch 4134/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 325.1694 - val_loss: 775.9802\n",
      "Epoch 4135/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 310.4359 - val_loss: 742.1336\n",
      "Epoch 4136/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 371.4049 - val_loss: 746.5950\n",
      "Epoch 4137/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 451.1373 - val_loss: 775.7370\n",
      "Epoch 4138/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.9228 - val_loss: 839.9749\n",
      "Epoch 4139/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 350.9534 - val_loss: 764.1039\n",
      "Epoch 4140/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 372.9526 - val_loss: 905.1169\n",
      "Epoch 4141/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 374.7175 - val_loss: 742.7504\n",
      "Epoch 4142/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 500.9377 - val_loss: 1053.2844\n",
      "Epoch 4143/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 659.0477 - val_loss: 1046.3398\n",
      "Epoch 4144/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 502.1464 - val_loss: 783.2183\n",
      "Epoch 4145/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 441.6769 - val_loss: 754.5700\n",
      "Epoch 4146/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 376.9438 - val_loss: 942.6290\n",
      "Epoch 4147/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.5478 - val_loss: 928.4346\n",
      "Epoch 4148/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.4351 - val_loss: 903.2164\n",
      "Epoch 4149/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 449.0647 - val_loss: 1012.6831\n",
      "Epoch 4150/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 691.5432 - val_loss: 901.0213\n",
      "Epoch 4151/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 657.9791 - val_loss: 878.5880\n",
      "Epoch 4152/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 631.4320 - val_loss: 971.3391\n",
      "Epoch 4153/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 613.3971 - val_loss: 879.7115\n",
      "Epoch 4154/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 598.7166 - val_loss: 873.3155\n",
      "Epoch 4155/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 549.6684 - val_loss: 886.0926\n",
      "Epoch 4156/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 511.3354 - val_loss: 966.2709\n",
      "Epoch 4157/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 475.4895 - val_loss: 871.9213\n",
      "Epoch 4158/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 439.7168 - val_loss: 930.8613\n",
      "Epoch 4159/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 419.9108 - val_loss: 837.5979\n",
      "Epoch 4160/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 398.0644 - val_loss: 897.0337\n",
      "Epoch 4161/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 362.6692 - val_loss: 860.3361\n",
      "Epoch 4162/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 364.5899 - val_loss: 799.6937\n",
      "Epoch 4163/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 372.9855 - val_loss: 828.7682\n",
      "Epoch 4164/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 338.3723 - val_loss: 979.8133\n",
      "Epoch 4165/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 366.6989 - val_loss: 1143.5770\n",
      "Epoch 4166/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 381.3138 - val_loss: 806.8790\n",
      "Epoch 4167/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 580.6072 - val_loss: 1288.6476\n",
      "Epoch 4168/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 683.2736 - val_loss: 1216.0695\n",
      "Epoch 4169/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 557.2112 - val_loss: 1044.1786\n",
      "Epoch 4170/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 456.5259 - val_loss: 678.8623\n",
      "Epoch 4171/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 479.2940 - val_loss: 698.5463\n",
      "Epoch 4172/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 445.2771 - val_loss: 938.8769\n",
      "Epoch 4173/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 647.8999 - val_loss: 719.6170\n",
      "Epoch 4174/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 632.9191 - val_loss: 1009.0650\n",
      "Epoch 4175/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 566.1361 - val_loss: 991.7116\n",
      "Epoch 4176/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 524.1721 - val_loss: 909.0177\n",
      "Epoch 4177/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 475.9859 - val_loss: 858.7510\n",
      "Epoch 4178/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 451.2478 - val_loss: 1291.1673\n",
      "Epoch 4179/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 528.9711 - val_loss: 702.5536\n",
      "Epoch 4180/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 503.4402 - val_loss: 901.7228\n",
      "Epoch 4181/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 476.0728 - val_loss: 804.2929\n",
      "Epoch 4182/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 517.5221 - val_loss: 840.0076\n",
      "Epoch 4183/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 438.0121 - val_loss: 802.0333\n",
      "Epoch 4184/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 410.7121 - val_loss: 747.9519\n",
      "Epoch 4185/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 419.4301 - val_loss: 895.5654\n",
      "Epoch 4186/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 417.4544 - val_loss: 782.8683\n",
      "Epoch 4187/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 545.5696 - val_loss: 1031.8863\n",
      "Epoch 4188/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 394.6989 - val_loss: 857.5501\n",
      "Epoch 4189/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.9856 - val_loss: 856.0638\n",
      "Epoch 4190/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 395.2512 - val_loss: 815.0548\n",
      "Epoch 4191/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 363.5748 - val_loss: 1003.2751\n",
      "Epoch 4192/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 351.7747 - val_loss: 951.5880\n",
      "Epoch 4193/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.9413 - val_loss: 946.3506\n",
      "Epoch 4194/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.4361 - val_loss: 823.4871\n",
      "Epoch 4195/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.2387 - val_loss: 825.2121\n",
      "Epoch 4196/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 342.8330 - val_loss: 767.6000\n",
      "Epoch 4197/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 322.2472 - val_loss: 756.3881\n",
      "Epoch 4198/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 355.4681 - val_loss: 808.0339\n",
      "Epoch 4199/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 393.9404 - val_loss: 1079.1208\n",
      "Epoch 4200/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 385.6682 - val_loss: 795.1746\n",
      "Epoch 4201/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.0104 - val_loss: 790.9276\n",
      "Epoch 4202/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 375.9940 - val_loss: 905.8923\n",
      "Epoch 4203/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 345.6802 - val_loss: 1021.4453\n",
      "Epoch 4204/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 395.3614 - val_loss: 800.4763\n",
      "Epoch 4205/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.5692 - val_loss: 789.1339\n",
      "Epoch 4206/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 352.9000 - val_loss: 788.1377\n",
      "Epoch 4207/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 317.9638 - val_loss: 884.9674\n",
      "Epoch 4208/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 320.7885 - val_loss: 1072.8774\n",
      "Epoch 4209/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 360.9379 - val_loss: 1057.3552\n",
      "Epoch 4210/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 389.3318 - val_loss: 961.3774\n",
      "Epoch 4211/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 354.5817 - val_loss: 941.5776\n",
      "Epoch 4212/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 339.0490 - val_loss: 992.8385\n",
      "Epoch 4213/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 553.5031 - val_loss: 822.0413\n",
      "Epoch 4214/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 623.0094 - val_loss: 824.1241\n",
      "Epoch 4215/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 576.2349 - val_loss: 1112.7567\n",
      "Epoch 4216/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 482.3626 - val_loss: 920.9876\n",
      "Epoch 4217/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 446.0037 - val_loss: 929.2257\n",
      "Epoch 4218/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 390.2690 - val_loss: 907.6288\n",
      "Epoch 4219/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.8734 - val_loss: 1103.8545\n",
      "Epoch 4220/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.7662 - val_loss: 911.2159\n",
      "Epoch 4221/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 617.1128 - val_loss: 777.8964\n",
      "Epoch 4222/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 768.5895 - val_loss: 888.3219\n",
      "Epoch 4223/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 499.3755 - val_loss: 1035.4824\n",
      "Epoch 4224/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 483.6536 - val_loss: 977.8391\n",
      "Epoch 4225/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 429.6601 - val_loss: 944.0706\n",
      "Epoch 4226/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 373.5373 - val_loss: 893.0737\n",
      "Epoch 4227/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 348.8178 - val_loss: 892.9997\n",
      "Epoch 4228/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 349.4555 - val_loss: 814.7805\n",
      "Epoch 4229/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 386.2615 - val_loss: 718.6916\n",
      "Epoch 4230/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 731.3103 - val_loss: 782.2656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4231/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 553.6434 - val_loss: 756.6071\n",
      "Epoch 4232/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 589.2400 - val_loss: 986.8887\n",
      "Epoch 4233/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 495.3818 - val_loss: 721.2329\n",
      "Epoch 4234/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 413.4284 - val_loss: 973.8524\n",
      "Epoch 4235/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 416.0026 - val_loss: 1057.2227\n",
      "Epoch 4236/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 513.9557 - val_loss: 911.1601\n",
      "Epoch 4237/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 502.1036 - val_loss: 885.3629\n",
      "Epoch 4238/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 464.5722 - val_loss: 888.5155\n",
      "Epoch 4239/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.1349 - val_loss: 854.8381\n",
      "Epoch 4240/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.4851 - val_loss: 903.5350\n",
      "Epoch 4241/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.4881 - val_loss: 884.7127\n",
      "Epoch 4242/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 363.0861 - val_loss: 878.3766\n",
      "Epoch 4243/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 380.6771 - val_loss: 905.7098\n",
      "Epoch 4244/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.0276 - val_loss: 871.4248\n",
      "Epoch 4245/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 321.9700 - val_loss: 1051.5582\n",
      "Epoch 4246/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 445.0390 - val_loss: 801.8523\n",
      "Epoch 4247/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 397.5248 - val_loss: 789.4121\n",
      "Epoch 4248/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 344.1763 - val_loss: 786.3949\n",
      "Epoch 4249/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 315.1654 - val_loss: 820.4127\n",
      "Epoch 4250/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 504.0311 - val_loss: 785.5989\n",
      "Epoch 4251/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 425.8401 - val_loss: 816.1368\n",
      "Epoch 4252/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 403.9228 - val_loss: 802.5109\n",
      "Epoch 4253/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 400.9984 - val_loss: 837.6815\n",
      "Epoch 4254/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 396.0619 - val_loss: 786.4274\n",
      "Epoch 4255/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 484.5030 - val_loss: 1005.1817\n",
      "Epoch 4256/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 479.3002 - val_loss: 852.5595\n",
      "Epoch 4257/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 419.2293 - val_loss: 771.5169\n",
      "Epoch 4258/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.3793 - val_loss: 750.9516\n",
      "Epoch 4259/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 347.8501 - val_loss: 802.4278\n",
      "Epoch 4260/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.4495 - val_loss: 1116.7584\n",
      "Epoch 4261/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 523.4671 - val_loss: 1149.2880\n",
      "Epoch 4262/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 468.4924 - val_loss: 1011.7924\n",
      "Epoch 4263/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 392.0046 - val_loss: 1032.0522\n",
      "Epoch 4264/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 394.2934 - val_loss: 836.8020\n",
      "Epoch 4265/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 371.8018 - val_loss: 862.7848\n",
      "Epoch 4266/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 339.2749 - val_loss: 807.9898\n",
      "Epoch 4267/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 333.3962 - val_loss: 796.2050\n",
      "Epoch 4268/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 342.7115 - val_loss: 821.6084\n",
      "Epoch 4269/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.9109 - val_loss: 881.6787\n",
      "Epoch 4270/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 320.7764 - val_loss: 834.8997\n",
      "Epoch 4271/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 407.6548 - val_loss: 771.4311\n",
      "Epoch 4272/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 340.7934 - val_loss: 812.6721\n",
      "Epoch 4273/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.9052 - val_loss: 838.8056\n",
      "Epoch 4274/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.1922 - val_loss: 815.3089\n",
      "Epoch 4275/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.8320 - val_loss: 832.7878\n",
      "Epoch 4276/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.7226 - val_loss: 824.5752\n",
      "Epoch 4277/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 349.6862 - val_loss: 880.9445\n",
      "Epoch 4278/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 374.3361 - val_loss: 808.0395\n",
      "Epoch 4279/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 338.4748 - val_loss: 874.8759\n",
      "Epoch 4280/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 322.5745 - val_loss: 861.5063\n",
      "Epoch 4281/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 330.6703 - val_loss: 801.9403\n",
      "Epoch 4282/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 350.0781 - val_loss: 753.4171\n",
      "Epoch 4283/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 356.8267 - val_loss: 692.5910\n",
      "Epoch 4284/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 368.6679 - val_loss: 693.3062\n",
      "Epoch 4285/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 428.3998 - val_loss: 776.5960\n",
      "Epoch 4286/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.5885 - val_loss: 822.1297\n",
      "Epoch 4287/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 742.2526 - val_loss: 1139.8006\n",
      "Epoch 4288/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 665.7967 - val_loss: 817.9713\n",
      "Epoch 4289/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 555.8317 - val_loss: 817.7373\n",
      "Epoch 4290/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 492.9266 - val_loss: 843.3579\n",
      "Epoch 4291/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 429.6377 - val_loss: 905.3117\n",
      "Epoch 4292/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 377.3400 - val_loss: 933.0970\n",
      "Epoch 4293/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 330.2538 - val_loss: 960.0176\n",
      "Epoch 4294/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 960.1632 - val_loss: 824.2493\n",
      "Epoch 4295/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 975.7426 - val_loss: 1403.6828\n",
      "Epoch 4296/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 953.5111 - val_loss: 1390.8009\n",
      "Epoch 4297/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 861.4673 - val_loss: 1421.7089\n",
      "Epoch 4298/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 742.1146 - val_loss: 1194.8273\n",
      "Epoch 4299/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 611.7631 - val_loss: 716.2935\n",
      "Epoch 4300/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 535.7061 - val_loss: 952.2154\n",
      "Epoch 4301/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 482.3635 - val_loss: 873.9714\n",
      "Epoch 4302/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 429.6604 - val_loss: 841.8027\n",
      "Epoch 4303/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 388.2908 - val_loss: 870.6440\n",
      "Epoch 4304/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 352.2969 - val_loss: 961.2180\n",
      "Epoch 4305/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.8393 - val_loss: 880.9214\n",
      "Epoch 4306/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 456.3547 - val_loss: 894.9307\n",
      "Epoch 4307/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 452.2735 - val_loss: 856.8542\n",
      "Epoch 4308/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.9488 - val_loss: 905.5838\n",
      "Epoch 4309/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 417.2481 - val_loss: 872.6062\n",
      "Epoch 4310/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 387.8479 - val_loss: 801.7567\n",
      "Epoch 4311/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 363.7153 - val_loss: 855.8374\n",
      "Epoch 4312/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 343.9630 - val_loss: 799.0276\n",
      "Epoch 4313/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 576.5376 - val_loss: 930.0150\n",
      "Epoch 4314/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 498.7216 - val_loss: 880.1340\n",
      "Epoch 4315/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 450.0765 - val_loss: 955.4408\n",
      "Epoch 4316/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 409.0942 - val_loss: 877.9602\n",
      "Epoch 4317/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 383.1709 - val_loss: 887.8575\n",
      "Epoch 4318/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 369.5141 - val_loss: 804.4200\n",
      "Epoch 4319/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.9092 - val_loss: 2712.2112\n",
      "Epoch 4320/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 836.8565 - val_loss: 1314.3755\n",
      "Epoch 4321/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 799.7609 - val_loss: 1217.1886\n",
      "Epoch 4322/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 629.2622 - val_loss: 703.6351\n",
      "Epoch 4323/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 532.1405 - val_loss: 853.6833\n",
      "Epoch 4324/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 510.2275 - val_loss: 861.6160\n",
      "Epoch 4325/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.3833 - val_loss: 872.8858\n",
      "Epoch 4326/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 409.4445 - val_loss: 949.9623\n",
      "Epoch 4327/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 396.8873 - val_loss: 909.5272\n",
      "Epoch 4328/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.1347 - val_loss: 907.8348\n",
      "Epoch 4329/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 333.6048 - val_loss: 881.9065\n",
      "Epoch 4330/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 337.9565 - val_loss: 781.2024\n",
      "Epoch 4331/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.3929 - val_loss: 793.7095\n",
      "Epoch 4332/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.9345 - val_loss: 902.6958\n",
      "Epoch 4333/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.6029 - val_loss: 794.1924\n",
      "Epoch 4334/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 341.4232 - val_loss: 772.8294\n",
      "Epoch 4335/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 348.8494 - val_loss: 732.5620\n",
      "Epoch 4336/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 344.4960 - val_loss: 821.0838\n",
      "Epoch 4337/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 327.8275 - val_loss: 857.9922\n",
      "Epoch 4338/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 369.6903 - val_loss: 769.5047\n",
      "Epoch 4339/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.4112 - val_loss: 823.1737\n",
      "Epoch 4340/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 454.2409 - val_loss: 805.9123\n",
      "Epoch 4341/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 366.0926 - val_loss: 781.5463\n",
      "Epoch 4342/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 325.5787 - val_loss: 917.5974\n",
      "Epoch 4343/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 306.3995 - val_loss: 843.2164\n",
      "Epoch 4344/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.3500 - val_loss: 817.5123\n",
      "Epoch 4345/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.9203 - val_loss: 880.5838\n",
      "Epoch 4346/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 372.1426 - val_loss: 887.0397\n",
      "Epoch 4347/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 413.0292 - val_loss: 1007.0167\n",
      "Epoch 4348/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 363.6140 - val_loss: 990.0751\n",
      "Epoch 4349/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 324.6336 - val_loss: 893.8234\n",
      "Epoch 4350/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 390.6736 - val_loss: 828.3820\n",
      "Epoch 4351/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 493.9097 - val_loss: 856.7303\n",
      "Epoch 4352/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 461.8865 - val_loss: 821.3131\n",
      "Epoch 4353/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 420.3570 - val_loss: 847.8040\n",
      "Epoch 4354/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.6694 - val_loss: 913.0417\n",
      "Epoch 4355/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 355.8592 - val_loss: 840.1858\n",
      "Epoch 4356/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.7173 - val_loss: 907.8354\n",
      "Epoch 4357/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 341.5879 - val_loss: 812.5956\n",
      "Epoch 4358/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 456.0294 - val_loss: 751.4167\n",
      "Epoch 4359/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 611.6219 - val_loss: 741.1518\n",
      "Epoch 4360/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 483.5786 - val_loss: 735.6446\n",
      "Epoch 4361/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 417.5867 - val_loss: 771.7251\n",
      "Epoch 4362/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 396.2752 - val_loss: 777.4996\n",
      "Epoch 4363/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 338.8685 - val_loss: 753.8251\n",
      "Epoch 4364/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 375.1978 - val_loss: 853.6704\n",
      "Epoch 4365/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 472.6834 - val_loss: 924.0037\n",
      "Epoch 4366/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 404.1319 - val_loss: 996.0776\n",
      "Epoch 4367/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 393.2793 - val_loss: 910.8025\n",
      "Epoch 4368/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 337.9998 - val_loss: 946.2118\n",
      "Epoch 4369/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.5132 - val_loss: 897.6843\n",
      "Epoch 4370/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 321.9981 - val_loss: 926.3176\n",
      "Epoch 4371/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 327.4879 - val_loss: 794.4757\n",
      "Epoch 4372/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 307.4889 - val_loss: 872.9259\n",
      "Epoch 4373/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.4033 - val_loss: 1137.7384\n",
      "Epoch 4374/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 716.0422 - val_loss: 787.3005\n",
      "Epoch 4375/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 593.1832 - val_loss: 739.8960\n",
      "Epoch 4376/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 596.5884 - val_loss: 1141.8543\n",
      "Epoch 4377/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 548.7572 - val_loss: 999.3619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4378/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 530.2363 - val_loss: 814.3530\n",
      "Epoch 4379/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 421.2603 - val_loss: 834.1405\n",
      "Epoch 4380/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 401.4312 - val_loss: 934.4876\n",
      "Epoch 4381/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 359.1141 - val_loss: 914.1464\n",
      "Epoch 4382/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.0097 - val_loss: 871.6524\n",
      "Epoch 4383/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 330.4031 - val_loss: 881.4467\n",
      "Epoch 4384/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 327.9178 - val_loss: 797.3684\n",
      "Epoch 4385/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 328.6749 - val_loss: 841.4641\n",
      "Epoch 4386/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 344.6315 - val_loss: 870.8502\n",
      "Epoch 4387/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 393.8064 - val_loss: 735.9044\n",
      "Epoch 4388/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.6753 - val_loss: 731.4188\n",
      "Epoch 4389/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 334.8093 - val_loss: 928.5578\n",
      "Epoch 4390/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 340.2204 - val_loss: 917.3192\n",
      "Epoch 4391/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 384.1142 - val_loss: 789.2084\n",
      "Epoch 4392/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 412.8826 - val_loss: 892.9814\n",
      "Epoch 4393/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.9903 - val_loss: 856.1530\n",
      "Epoch 4394/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.5974 - val_loss: 833.0823\n",
      "Epoch 4395/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 296.3764 - val_loss: 871.8441\n",
      "Epoch 4396/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 329.4305 - val_loss: 998.3298\n",
      "Epoch 4397/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.8299 - val_loss: 783.0371\n",
      "Epoch 4398/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 338.4777 - val_loss: 834.3766\n",
      "Epoch 4399/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.5976 - val_loss: 886.9064\n",
      "Epoch 4400/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 347.5481 - val_loss: 804.0316\n",
      "Epoch 4401/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 400.3361 - val_loss: 901.9595\n",
      "Epoch 4402/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 400.1081 - val_loss: 890.6532\n",
      "Epoch 4403/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 391.5649 - val_loss: 782.5575\n",
      "Epoch 4404/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 351.7496 - val_loss: 806.8234\n",
      "Epoch 4405/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.7342 - val_loss: 974.9839\n",
      "Epoch 4406/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 377.7835 - val_loss: 852.2852\n",
      "Epoch 4407/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.5031 - val_loss: 915.3205\n",
      "Epoch 4408/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.1705 - val_loss: 879.4273\n",
      "Epoch 4409/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.7866 - val_loss: 840.2791\n",
      "Epoch 4410/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 344.8582 - val_loss: 812.0251\n",
      "Epoch 4411/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.8660 - val_loss: 877.4070\n",
      "Epoch 4412/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 304.5898 - val_loss: 837.1559\n",
      "Epoch 4413/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.7230 - val_loss: 781.2368\n",
      "Epoch 4414/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.0342 - val_loss: 839.3653\n",
      "Epoch 4415/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.1275 - val_loss: 747.5244\n",
      "Epoch 4416/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 367.7502 - val_loss: 903.5868\n",
      "Epoch 4417/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.0732 - val_loss: 908.4444\n",
      "Epoch 4418/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 309.4035 - val_loss: 778.9534\n",
      "Epoch 4419/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 299.4572 - val_loss: 784.8629\n",
      "Epoch 4420/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 305.2422 - val_loss: 744.0111\n",
      "Epoch 4421/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 335.0695 - val_loss: 794.6346\n",
      "Epoch 4422/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 398.9902 - val_loss: 779.4270\n",
      "Epoch 4423/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 389.3839 - val_loss: 1101.6811\n",
      "Epoch 4424/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 407.1801 - val_loss: 830.1993\n",
      "Epoch 4425/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 336.5369 - val_loss: 848.5457\n",
      "Epoch 4426/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.0372 - val_loss: 798.1713\n",
      "Epoch 4427/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.2817 - val_loss: 874.1812\n",
      "Epoch 4428/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.3633 - val_loss: 769.3526\n",
      "Epoch 4429/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 312.1504 - val_loss: 834.8773\n",
      "Epoch 4430/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 318.8735 - val_loss: 801.2438\n",
      "Epoch 4431/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 313.1396 - val_loss: 951.9915\n",
      "Epoch 4432/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 306.9846 - val_loss: 1016.7125\n",
      "Epoch 4433/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 353.9124 - val_loss: 919.7720\n",
      "Epoch 4434/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.5619 - val_loss: 1014.7507\n",
      "Epoch 4435/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.5674 - val_loss: 909.7174\n",
      "Epoch 4436/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.8137 - val_loss: 1003.6199\n",
      "Epoch 4437/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 426.0250 - val_loss: 879.2778\n",
      "Epoch 4438/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 371.8082 - val_loss: 808.7321\n",
      "Epoch 4439/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 362.7593 - val_loss: 789.0447\n",
      "Epoch 4440/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 373.4986 - val_loss: 922.5583\n",
      "Epoch 4441/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.5100 - val_loss: 892.3419\n",
      "Epoch 4442/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 363.4949 - val_loss: 901.3815\n",
      "Epoch 4443/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 318.5010 - val_loss: 820.3326\n",
      "Epoch 4444/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 370.7100 - val_loss: 825.5810\n",
      "Epoch 4445/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 358.6045 - val_loss: 744.2866\n",
      "Epoch 4446/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.1866 - val_loss: 792.3004\n",
      "Epoch 4447/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 357.2862 - val_loss: 791.2783\n",
      "Epoch 4448/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 451.1055 - val_loss: 793.6160\n",
      "Epoch 4449/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 397.0659 - val_loss: 901.3431\n",
      "Epoch 4450/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 384.3324 - val_loss: 867.7893\n",
      "Epoch 4451/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.9957 - val_loss: 891.9105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4452/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 311.9821 - val_loss: 839.2195\n",
      "Epoch 4453/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.8579 - val_loss: 871.1665\n",
      "Epoch 4454/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 317.4521 - val_loss: 796.8317\n",
      "Epoch 4455/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 359.2965 - val_loss: 850.8841\n",
      "Epoch 4456/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 486.9421 - val_loss: 775.7310\n",
      "Epoch 4457/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 442.4954 - val_loss: 802.5320\n",
      "Epoch 4458/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 421.0448 - val_loss: 869.8147\n",
      "Epoch 4459/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 365.3768 - val_loss: 859.8015\n",
      "Epoch 4460/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 355.1738 - val_loss: 779.7044\n",
      "Epoch 4461/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 456.8214 - val_loss: 842.6074\n",
      "Epoch 4462/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 432.5476 - val_loss: 787.0019\n",
      "Epoch 4463/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 432.3787 - val_loss: 890.1327\n",
      "Epoch 4464/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 414.6576 - val_loss: 886.3298\n",
      "Epoch 4465/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 347.3247 - val_loss: 866.8088\n",
      "Epoch 4466/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 317.4002 - val_loss: 1448.1829\n",
      "Epoch 4467/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 730.2697 - val_loss: 1048.5578\n",
      "Epoch 4468/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 610.2627 - val_loss: 883.1138\n",
      "Epoch 4469/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 496.6951 - val_loss: 816.4427\n",
      "Epoch 4470/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 445.9675 - val_loss: 869.4888\n",
      "Epoch 4471/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.4251 - val_loss: 858.4537\n",
      "Epoch 4472/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.1982 - val_loss: 803.8107\n",
      "Epoch 4473/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 440.4792 - val_loss: 800.8011\n",
      "Epoch 4474/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 412.6946 - val_loss: 973.5359\n",
      "Epoch 4475/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 402.8382 - val_loss: 927.0310\n",
      "Epoch 4476/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 407.4064 - val_loss: 1073.8789\n",
      "Epoch 4477/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 353.4766 - val_loss: 1113.2984\n",
      "Epoch 4478/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.1396 - val_loss: 995.0413\n",
      "Epoch 4479/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 491.4004 - val_loss: 606.7953\n",
      "Epoch 4480/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 624.6796 - val_loss: 847.1444\n",
      "Epoch 4481/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 449.5749 - val_loss: 826.7132\n",
      "Epoch 4482/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 456.8237 - val_loss: 1041.0345\n",
      "Epoch 4483/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 497.9849 - val_loss: 1033.0394\n",
      "Epoch 4484/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 475.7779 - val_loss: 773.4986\n",
      "Epoch 4485/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 404.5216 - val_loss: 819.5771\n",
      "Epoch 4486/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 343.3783 - val_loss: 944.7122\n",
      "Epoch 4487/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.1258 - val_loss: 888.3254\n",
      "Epoch 4488/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 318.6700 - val_loss: 883.0673\n",
      "Epoch 4489/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 325.7023 - val_loss: 850.6229\n",
      "Epoch 4490/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 334.4189 - val_loss: 872.3338\n",
      "Epoch 4491/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 384.0958 - val_loss: 1016.6415\n",
      "Epoch 4492/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 550.3392 - val_loss: 914.4111\n",
      "Epoch 4493/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 477.6230 - val_loss: 862.6776\n",
      "Epoch 4494/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 419.3700 - val_loss: 785.7156\n",
      "Epoch 4495/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 350.2817 - val_loss: 822.5711\n",
      "Epoch 4496/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 323.9551 - val_loss: 921.3307\n",
      "Epoch 4497/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 528.9532 - val_loss: 821.1758\n",
      "Epoch 4498/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 556.9257 - val_loss: 876.7332\n",
      "Epoch 4499/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 512.8360 - val_loss: 1002.8326\n",
      "Epoch 4500/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 455.8620 - val_loss: 840.5581\n",
      "Epoch 4501/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 449.3244 - val_loss: 751.8343\n",
      "Epoch 4502/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 394.2662 - val_loss: 825.7027\n",
      "Epoch 4503/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.0059 - val_loss: 794.5426\n",
      "Epoch 4504/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 318.5972 - val_loss: 837.6685\n",
      "Epoch 4505/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 314.6246 - val_loss: 822.9350\n",
      "Epoch 4506/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 308.2000 - val_loss: 937.6044\n",
      "Epoch 4507/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 334.7362 - val_loss: 788.3094\n",
      "Epoch 4508/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 361.1713 - val_loss: 1241.9576\n",
      "Epoch 4509/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 627.7319 - val_loss: 638.7627\n",
      "Epoch 4510/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 522.8028 - val_loss: 1115.4550\n",
      "Epoch 4511/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 516.8379 - val_loss: 858.0124\n",
      "Epoch 4512/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 498.7977 - val_loss: 805.9053\n",
      "Epoch 4513/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 408.1871 - val_loss: 895.9354\n",
      "Epoch 4514/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.8707 - val_loss: 921.6234\n",
      "Epoch 4515/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 345.5525 - val_loss: 963.0538\n",
      "Epoch 4516/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.4453 - val_loss: 898.0946\n",
      "Epoch 4517/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 383.5820 - val_loss: 778.8372\n",
      "Epoch 4518/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 386.8852 - val_loss: 746.2617\n",
      "Epoch 4519/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 659.0345 - val_loss: 908.4267\n",
      "Epoch 4520/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 504.0219 - val_loss: 809.0435\n",
      "Epoch 4521/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 480.5693 - val_loss: 870.5607\n",
      "Epoch 4522/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 447.6582 - val_loss: 855.2229\n",
      "Epoch 4523/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 421.1053 - val_loss: 915.8334\n",
      "Epoch 4524/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.9295 - val_loss: 897.2071\n",
      "Epoch 4525/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 373.5401 - val_loss: 848.7433\n",
      "Epoch 4526/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 527.4446 - val_loss: 783.2253\n",
      "Epoch 4527/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 512.3176 - val_loss: 878.1015\n",
      "Epoch 4528/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 486.2271 - val_loss: 888.2955\n",
      "Epoch 4529/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 449.2372 - val_loss: 877.9755\n",
      "Epoch 4530/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 406.6778 - val_loss: 963.6848\n",
      "Epoch 4531/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 384.1176 - val_loss: 993.3093\n",
      "Epoch 4532/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.6190 - val_loss: 889.8884\n",
      "Epoch 4533/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.4110 - val_loss: 1154.0414\n",
      "Epoch 4534/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 454.2428 - val_loss: 815.8918\n",
      "Epoch 4535/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 451.8594 - val_loss: 729.9168\n",
      "Epoch 4536/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 475.1600 - val_loss: 822.7915\n",
      "Epoch 4537/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 404.4925 - val_loss: 773.1983\n",
      "Epoch 4538/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 338.9297 - val_loss: 909.4809\n",
      "Epoch 4539/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 337.9312 - val_loss: 845.5673\n",
      "Epoch 4540/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 356.5574 - val_loss: 846.3939\n",
      "Epoch 4541/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 316.5324 - val_loss: 835.9459\n",
      "Epoch 4542/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 296.6388 - val_loss: 881.5371\n",
      "Epoch 4543/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 301.4840 - val_loss: 905.8400\n",
      "Epoch 4544/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 320.6920 - val_loss: 781.5762\n",
      "Epoch 4545/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 392.7211 - val_loss: 954.9915\n",
      "Epoch 4546/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 381.9182 - val_loss: 1115.2545\n",
      "Epoch 4547/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.3151 - val_loss: 916.6105\n",
      "Epoch 4548/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 401.2586 - val_loss: 767.4575\n",
      "Epoch 4549/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 338.1704 - val_loss: 777.0709\n",
      "Epoch 4550/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 347.1681 - val_loss: 782.4127\n",
      "Epoch 4551/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.1696 - val_loss: 789.3488\n",
      "Epoch 4552/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 319.0002 - val_loss: 815.4856\n",
      "Epoch 4553/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 328.4990 - val_loss: 722.7067\n",
      "Epoch 4554/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.1653 - val_loss: 1006.6357\n",
      "Epoch 4555/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 348.5174 - val_loss: 842.8591\n",
      "Epoch 4556/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 314.5401 - val_loss: 854.0831\n",
      "Epoch 4557/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.2898 - val_loss: 784.5538\n",
      "Epoch 4558/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.3554 - val_loss: 835.3316\n",
      "Epoch 4559/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 321.3702 - val_loss: 922.4152\n",
      "Epoch 4560/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 449.6924 - val_loss: 773.6447\n",
      "Epoch 4561/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 398.6134 - val_loss: 774.4895\n",
      "Epoch 4562/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 371.9552 - val_loss: 854.6028\n",
      "Epoch 4563/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 333.3085 - val_loss: 884.4161\n",
      "Epoch 4564/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 344.0540 - val_loss: 810.0916\n",
      "Epoch 4565/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 335.4143 - val_loss: 824.7124\n",
      "Epoch 4566/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 332.7008 - val_loss: 894.1249\n",
      "Epoch 4567/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 342.2776 - val_loss: 829.5026\n",
      "Epoch 4568/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 348.6647 - val_loss: 825.7324\n",
      "Epoch 4569/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 329.4321 - val_loss: 835.5167\n",
      "Epoch 4570/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 390.0065 - val_loss: 802.3643\n",
      "Epoch 4571/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 396.0170 - val_loss: 899.5458\n",
      "Epoch 4572/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 392.2120 - val_loss: 782.9518\n",
      "Epoch 4573/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 368.7410 - val_loss: 768.8540\n",
      "Epoch 4574/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 322.3236 - val_loss: 828.4598\n",
      "Epoch 4575/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 331.4880 - val_loss: 783.6903\n",
      "Epoch 4576/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 322.3673 - val_loss: 842.4635\n",
      "Epoch 4577/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 305.0959 - val_loss: 852.5473\n",
      "Epoch 4578/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 297.4860 - val_loss: 796.2714\n",
      "Epoch 4579/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 356.3599 - val_loss: 836.7988\n",
      "Epoch 4580/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 387.4369 - val_loss: 817.4370\n",
      "Epoch 4581/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 383.4139 - val_loss: 961.3233\n",
      "Epoch 4582/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 332.9794 - val_loss: 870.7617\n",
      "Epoch 4583/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 327.4680 - val_loss: 855.5990\n",
      "Epoch 4584/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 315.1632 - val_loss: 819.0767\n",
      "Epoch 4585/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 317.4982 - val_loss: 852.6729\n",
      "Epoch 4586/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.5539 - val_loss: 778.7615\n",
      "Epoch 4587/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 365.3701 - val_loss: 793.8670\n",
      "Epoch 4588/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.3366 - val_loss: 852.5721\n",
      "Epoch 4589/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 306.4135 - val_loss: 774.9525\n",
      "Epoch 4590/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 310.2506 - val_loss: 824.8096\n",
      "Epoch 4591/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 360.9832 - val_loss: 793.4110\n",
      "Epoch 4592/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.0461 - val_loss: 872.0440\n",
      "Epoch 4593/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 337.9826 - val_loss: 889.7658\n",
      "Epoch 4594/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 358.3997 - val_loss: 840.9287\n",
      "Epoch 4595/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 401.9480 - val_loss: 890.2095\n",
      "Epoch 4596/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 361.2919 - val_loss: 888.7809\n",
      "Epoch 4597/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 318.9278 - val_loss: 841.0572\n",
      "Epoch 4598/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 384.3778 - val_loss: 720.2071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4599/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 386.1424 - val_loss: 683.0812\n",
      "Epoch 4600/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 419.8559 - val_loss: 694.2747\n",
      "Epoch 4601/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 377.2851 - val_loss: 815.3134\n",
      "Epoch 4602/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 358.1376 - val_loss: 824.0550\n",
      "Epoch 4603/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 416.4444 - val_loss: 681.0880\n",
      "Epoch 4604/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 433.0458 - val_loss: 734.0949\n",
      "Epoch 4605/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 396.7958 - val_loss: 818.5646\n",
      "Epoch 4606/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.5194 - val_loss: 855.9134\n",
      "Epoch 4607/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 414.6159 - val_loss: 817.4804\n",
      "Epoch 4608/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 531.4278 - val_loss: 1064.6582\n",
      "Epoch 4609/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 461.5869 - val_loss: 832.1705\n",
      "Epoch 4610/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 432.6631 - val_loss: 769.6534\n",
      "Epoch 4611/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 365.2603 - val_loss: 756.4408\n",
      "Epoch 4612/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 424.4070 - val_loss: 835.0782\n",
      "Epoch 4613/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 477.6957 - val_loss: 886.9340\n",
      "Epoch 4614/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 457.7454 - val_loss: 1022.9443\n",
      "Epoch 4615/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 386.4145 - val_loss: 861.2508\n",
      "Epoch 4616/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.3243 - val_loss: 810.0538\n",
      "Epoch 4617/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 325.4038 - val_loss: 759.7125\n",
      "Epoch 4618/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 322.8730 - val_loss: 856.3265\n",
      "Epoch 4619/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.7921 - val_loss: 813.0076\n",
      "Epoch 4620/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 304.0569 - val_loss: 806.6116\n",
      "Epoch 4621/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 798.6338 - val_loss: 801.5871\n",
      "Epoch 4622/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 724.6006 - val_loss: 855.6718\n",
      "Epoch 4623/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 647.5272 - val_loss: 873.6306\n",
      "Epoch 4624/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 536.8017 - val_loss: 957.6366\n",
      "Epoch 4625/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 490.6511 - val_loss: 957.0385\n",
      "Epoch 4626/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 447.4463 - val_loss: 960.5610\n",
      "Epoch 4627/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 417.4164 - val_loss: 797.7967\n",
      "Epoch 4628/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 413.0381 - val_loss: 987.9217\n",
      "Epoch 4629/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 377.3026 - val_loss: 798.8375\n",
      "Epoch 4630/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 339.0588 - val_loss: 973.9930\n",
      "Epoch 4631/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.2729 - val_loss: 976.0825\n",
      "Epoch 4632/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 357.7696 - val_loss: 969.6465\n",
      "Epoch 4633/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 345.5213 - val_loss: 892.4863\n",
      "Epoch 4634/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 359.3309 - val_loss: 895.9952\n",
      "Epoch 4635/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 381.3639 - val_loss: 749.7174\n",
      "Epoch 4636/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.0698 - val_loss: 846.3362\n",
      "Epoch 4637/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 333.3739 - val_loss: 866.4594\n",
      "Epoch 4638/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 296.5932 - val_loss: 931.7850\n",
      "Epoch 4639/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 399.4247 - val_loss: 818.5618\n",
      "Epoch 4640/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 405.7506 - val_loss: 806.4117\n",
      "Epoch 4641/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 381.3266 - val_loss: 757.3351\n",
      "Epoch 4642/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 348.1366 - val_loss: 824.6362\n",
      "Epoch 4643/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 321.2132 - val_loss: 891.0166\n",
      "Epoch 4644/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 354.0432 - val_loss: 1108.3083\n",
      "Epoch 4645/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 377.2271 - val_loss: 874.8914\n",
      "Epoch 4646/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 378.2378 - val_loss: 803.2889\n",
      "Epoch 4647/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.5013 - val_loss: 754.1532\n",
      "Epoch 4648/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.3227 - val_loss: 775.7416\n",
      "Epoch 4649/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 437.9153 - val_loss: 749.3575\n",
      "Epoch 4650/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 491.5295 - val_loss: 785.5169\n",
      "Epoch 4651/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 382.9064 - val_loss: 837.5255\n",
      "Epoch 4652/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 360.2107 - val_loss: 919.5002\n",
      "Epoch 4653/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 328.0125 - val_loss: 806.5975\n",
      "Epoch 4654/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 403.6676 - val_loss: 771.0077\n",
      "Epoch 4655/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 409.8038 - val_loss: 872.6714\n",
      "Epoch 4656/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.6737 - val_loss: 815.7113\n",
      "Epoch 4657/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 350.4511 - val_loss: 838.8765\n",
      "Epoch 4658/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.9716 - val_loss: 776.1091\n",
      "Epoch 4659/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 343.0669 - val_loss: 795.9470\n",
      "Epoch 4660/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.5339 - val_loss: 759.4806\n",
      "Epoch 4661/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 337.6477 - val_loss: 809.5576\n",
      "Epoch 4662/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.3324 - val_loss: 866.6988\n",
      "Epoch 4663/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 346.1535 - val_loss: 938.5356\n",
      "Epoch 4664/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 466.0417 - val_loss: 778.8471\n",
      "Epoch 4665/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 435.6882 - val_loss: 894.2163\n",
      "Epoch 4666/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 407.9501 - val_loss: 846.5276\n",
      "Epoch 4667/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 348.9687 - val_loss: 835.7052\n",
      "Epoch 4668/10000\n",
      "630/630 [==============================] - 0s 85us/step - loss: 315.1081 - val_loss: 760.2609\n",
      "Epoch 4669/10000\n",
      "630/630 [==============================] - 0s 87us/step - loss: 338.2827 - val_loss: 822.7401\n",
      "Epoch 4670/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 327.4447 - val_loss: 919.7139\n",
      "Epoch 4671/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 312.7869 - val_loss: 819.5864\n",
      "Epoch 4672/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 307.8939 - val_loss: 814.5098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4673/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 310.1666 - val_loss: 783.2405\n",
      "Epoch 4674/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 375.6783 - val_loss: 756.6713\n",
      "Epoch 4675/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 401.9103 - val_loss: 773.0980\n",
      "Epoch 4676/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 394.5199 - val_loss: 751.1668\n",
      "Epoch 4677/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 353.7049 - val_loss: 883.5505\n",
      "Epoch 4678/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 378.0309 - val_loss: 787.4388\n",
      "Epoch 4679/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 373.4737 - val_loss: 907.7248\n",
      "Epoch 4680/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.3377 - val_loss: 4081.6834\n",
      "Epoch 4681/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 4032.3112 - val_loss: 1192.1427\n",
      "Epoch 4682/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1961.1711 - val_loss: 2061.1060\n",
      "Epoch 4683/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1658.2654 - val_loss: 1592.8498\n",
      "Epoch 4684/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1242.7088 - val_loss: 1422.0643\n",
      "Epoch 4685/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 983.2819 - val_loss: 1447.1365\n",
      "Epoch 4686/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 858.9826 - val_loss: 937.0768\n",
      "Epoch 4687/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 716.2469 - val_loss: 1013.1758\n",
      "Epoch 4688/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 629.8396 - val_loss: 1162.8554\n",
      "Epoch 4689/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 553.1720 - val_loss: 1091.3135\n",
      "Epoch 4690/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 530.6616 - val_loss: 1374.3132\n",
      "Epoch 4691/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 601.3384 - val_loss: 777.4425\n",
      "Epoch 4692/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 485.6773 - val_loss: 814.4838\n",
      "Epoch 4693/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 460.4977 - val_loss: 797.6926\n",
      "Epoch 4694/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 401.0231 - val_loss: 922.3658\n",
      "Epoch 4695/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 352.9147 - val_loss: 892.2308\n",
      "Epoch 4696/10000\n",
      "630/630 [==============================] - 0s 74us/step - loss: 355.9904 - val_loss: 932.1836\n",
      "Epoch 4697/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 341.8004 - val_loss: 1229.8640\n",
      "Epoch 4698/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 557.7998 - val_loss: 858.7266\n",
      "Epoch 4699/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 465.9457 - val_loss: 877.4108\n",
      "Epoch 4700/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 461.1382 - val_loss: 843.1970\n",
      "Epoch 4701/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 415.9641 - val_loss: 822.2112\n",
      "Epoch 4702/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 369.2527 - val_loss: 803.2113\n",
      "Epoch 4703/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 355.4469 - val_loss: 887.3081\n",
      "Epoch 4704/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 337.7124 - val_loss: 779.0528\n",
      "Epoch 4705/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 403.3417 - val_loss: 818.4750\n",
      "Epoch 4706/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 399.2796 - val_loss: 851.3265\n",
      "Epoch 4707/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 397.4263 - val_loss: 920.7011\n",
      "Epoch 4708/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 420.7942 - val_loss: 857.0891\n",
      "Epoch 4709/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 377.3279 - val_loss: 813.6468\n",
      "Epoch 4710/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 429.2020 - val_loss: 804.9224\n",
      "Epoch 4711/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 419.9657 - val_loss: 835.5211\n",
      "Epoch 4712/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.7782 - val_loss: 759.9183\n",
      "Epoch 4713/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 388.0576 - val_loss: 1036.8375\n",
      "Epoch 4714/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 356.2737 - val_loss: 955.9362\n",
      "Epoch 4715/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 355.3201 - val_loss: 811.3811\n",
      "Epoch 4716/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 357.0476 - val_loss: 833.6611\n",
      "Epoch 4717/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 346.3483 - val_loss: 878.4460\n",
      "Epoch 4718/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 363.8753 - val_loss: 837.8343\n",
      "Epoch 4719/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 566.6102 - val_loss: 875.4245\n",
      "Epoch 4720/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 692.0290 - val_loss: 745.4470\n",
      "Epoch 4721/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 502.1102 - val_loss: 947.6609\n",
      "Epoch 4722/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 457.7571 - val_loss: 846.1390\n",
      "Epoch 4723/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 400.4817 - val_loss: 808.0815\n",
      "Epoch 4724/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 382.6991 - val_loss: 797.2026\n",
      "Epoch 4725/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.2064 - val_loss: 831.4346\n",
      "Epoch 4726/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 315.2737 - val_loss: 885.9731\n",
      "Epoch 4727/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 325.1425 - val_loss: 824.5196\n",
      "Epoch 4728/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.2560 - val_loss: 861.1553\n",
      "Epoch 4729/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 294.5357 - val_loss: 830.8920\n",
      "Epoch 4730/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 310.1683 - val_loss: 745.3967\n",
      "Epoch 4731/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.3473 - val_loss: 742.0757\n",
      "Epoch 4732/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.9025 - val_loss: 757.8087\n",
      "Epoch 4733/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 323.9411 - val_loss: 829.5965\n",
      "Epoch 4734/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 518.3296 - val_loss: 930.9705\n",
      "Epoch 4735/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 548.5365 - val_loss: 722.6105\n",
      "Epoch 4736/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 443.8275 - val_loss: 712.4773\n",
      "Epoch 4737/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 711.9535 - val_loss: 652.7886\n",
      "Epoch 4738/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 619.3130 - val_loss: 1288.5628\n",
      "Epoch 4739/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 430.0508 - val_loss: 805.2971\n",
      "Epoch 4740/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 973.1746 - val_loss: 1225.7677\n",
      "Epoch 4741/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 849.2121 - val_loss: 808.7533\n",
      "Epoch 4742/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 710.7343 - val_loss: 1120.9945\n",
      "Epoch 4743/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 587.8981 - val_loss: 905.5583\n",
      "Epoch 4744/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 503.1716 - val_loss: 885.0230\n",
      "Epoch 4745/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 448.7968 - val_loss: 1009.4215\n",
      "Epoch 4746/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 397.0087 - val_loss: 920.9653\n",
      "Epoch 4747/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 359.0294 - val_loss: 997.0744\n",
      "Epoch 4748/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 347.2510 - val_loss: 1000.9190\n",
      "Epoch 4749/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 327.7455 - val_loss: 880.4151\n",
      "Epoch 4750/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 386.0645 - val_loss: 738.1925\n",
      "Epoch 4751/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 475.3001 - val_loss: 1013.1995\n",
      "Epoch 4752/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 395.3833 - val_loss: 1259.4324\n",
      "Epoch 4753/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.7122 - val_loss: 799.5033\n",
      "Epoch 4754/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 376.3679 - val_loss: 849.3149\n",
      "Epoch 4755/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 390.2894 - val_loss: 922.7773\n",
      "Epoch 4756/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.4373 - val_loss: 912.4991\n",
      "Epoch 4757/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.1231 - val_loss: 873.7704\n",
      "Epoch 4758/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 334.6810 - val_loss: 953.2773\n",
      "Epoch 4759/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 354.9221 - val_loss: 859.7116\n",
      "Epoch 4760/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 349.0685 - val_loss: 814.2927\n",
      "Epoch 4761/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 659.9995 - val_loss: 882.6529\n",
      "Epoch 4762/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 573.7077 - val_loss: 854.5296\n",
      "Epoch 4763/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 482.5123 - val_loss: 984.4435\n",
      "Epoch 4764/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 439.5229 - val_loss: 778.3958\n",
      "Epoch 4765/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 406.2400 - val_loss: 902.2637\n",
      "Epoch 4766/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 384.9619 - val_loss: 978.8223\n",
      "Epoch 4767/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 358.3783 - val_loss: 925.8416\n",
      "Epoch 4768/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 368.9142 - val_loss: 826.2143\n",
      "Epoch 4769/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.3857 - val_loss: 740.3366\n",
      "Epoch 4770/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.3359 - val_loss: 1031.7636\n",
      "Epoch 4771/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.3513 - val_loss: 888.2750\n",
      "Epoch 4772/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.0860 - val_loss: 954.6059\n",
      "Epoch 4773/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 339.2399 - val_loss: 869.8281\n",
      "Epoch 4774/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.5913 - val_loss: 846.2376\n",
      "Epoch 4775/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 312.5397 - val_loss: 811.4633\n",
      "Epoch 4776/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 298.1041 - val_loss: 923.2793\n",
      "Epoch 4777/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 314.7296 - val_loss: 990.6428\n",
      "Epoch 4778/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 335.4082 - val_loss: 958.7982\n",
      "Epoch 4779/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 342.5971 - val_loss: 760.9657\n",
      "Epoch 4780/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 371.2521 - val_loss: 966.8482\n",
      "Epoch 4781/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 339.6030 - val_loss: 806.0648\n",
      "Epoch 4782/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.0986 - val_loss: 845.3007\n",
      "Epoch 4783/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 323.2943 - val_loss: 865.4160\n",
      "Epoch 4784/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 329.6299 - val_loss: 868.4377\n",
      "Epoch 4785/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 331.5867 - val_loss: 827.9054\n",
      "Epoch 4786/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 356.3045 - val_loss: 796.2572\n",
      "Epoch 4787/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 330.2526 - val_loss: 791.8131\n",
      "Epoch 4788/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.1823 - val_loss: 815.6096\n",
      "Epoch 4789/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 400.8446 - val_loss: 905.6462\n",
      "Epoch 4790/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 426.0989 - val_loss: 966.2519\n",
      "Epoch 4791/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 420.6880 - val_loss: 804.8279\n",
      "Epoch 4792/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 375.1313 - val_loss: 956.1121\n",
      "Epoch 4793/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.5763 - val_loss: 1035.8833\n",
      "Epoch 4794/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 499.4805 - val_loss: 953.3334\n",
      "Epoch 4795/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 562.2688 - val_loss: 734.5043\n",
      "Epoch 4796/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 451.9635 - val_loss: 830.0004\n",
      "Epoch 4797/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 392.9144 - val_loss: 899.9477\n",
      "Epoch 4798/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 361.9144 - val_loss: 922.1626\n",
      "Epoch 4799/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 334.8935 - val_loss: 897.5281\n",
      "Epoch 4800/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.7436 - val_loss: 1247.0260\n",
      "Epoch 4801/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.9100 - val_loss: 660.6760\n",
      "Epoch 4802/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 388.9909 - val_loss: 678.3646\n",
      "Epoch 4803/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 576.1373 - val_loss: 1032.6720\n",
      "Epoch 4804/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 805.0003 - val_loss: 1011.7749\n",
      "Epoch 4805/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 595.2202 - val_loss: 825.3337\n",
      "Epoch 4806/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 550.0259 - val_loss: 950.6961\n",
      "Epoch 4807/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 452.2018 - val_loss: 921.6586\n",
      "Epoch 4808/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 387.2517 - val_loss: 796.4592\n",
      "Epoch 4809/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 361.4783 - val_loss: 1068.8665\n",
      "Epoch 4810/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 409.2421 - val_loss: 1077.8686\n",
      "Epoch 4811/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 398.0932 - val_loss: 817.9682\n",
      "Epoch 4812/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 340.5058 - val_loss: 819.3912\n",
      "Epoch 4813/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 361.2298 - val_loss: 857.8258\n",
      "Epoch 4814/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.4486 - val_loss: 877.4088\n",
      "Epoch 4815/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 323.6226 - val_loss: 926.5176\n",
      "Epoch 4816/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 316.9815 - val_loss: 971.8195\n",
      "Epoch 4817/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 565.9666 - val_loss: 970.0221\n",
      "Epoch 4818/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 698.5709 - val_loss: 812.4580\n",
      "Epoch 4819/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 513.2871 - val_loss: 813.5805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4820/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 509.4560 - val_loss: 844.2907\n",
      "Epoch 4821/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 405.0182 - val_loss: 987.5262\n",
      "Epoch 4822/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 343.4989 - val_loss: 848.0729\n",
      "Epoch 4823/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 324.4281 - val_loss: 903.7327\n",
      "Epoch 4824/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 343.7797 - val_loss: 916.8794\n",
      "Epoch 4825/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 358.5777 - val_loss: 822.1181\n",
      "Epoch 4826/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 325.6177 - val_loss: 870.1042\n",
      "Epoch 4827/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 316.9505 - val_loss: 1316.6412\n",
      "Epoch 4828/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 660.1710 - val_loss: 712.2648\n",
      "Epoch 4829/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 642.6627 - val_loss: 988.6082\n",
      "Epoch 4830/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 609.3646 - val_loss: 1084.1339\n",
      "Epoch 4831/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 589.8534 - val_loss: 997.0483\n",
      "Epoch 4832/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 562.3441 - val_loss: 912.5313\n",
      "Epoch 4833/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 507.2978 - val_loss: 946.2850\n",
      "Epoch 4834/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 477.6163 - val_loss: 840.1939\n",
      "Epoch 4835/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 436.9528 - val_loss: 866.2398\n",
      "Epoch 4836/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 428.8090 - val_loss: 1004.3157\n",
      "Epoch 4837/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 398.6569 - val_loss: 969.0218\n",
      "Epoch 4838/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 368.5902 - val_loss: 886.3878\n",
      "Epoch 4839/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 363.4681 - val_loss: 1097.9240\n",
      "Epoch 4840/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 433.4442 - val_loss: 878.9722\n",
      "Epoch 4841/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 392.5843 - val_loss: 809.9937\n",
      "Epoch 4842/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 385.4812 - val_loss: 813.6757\n",
      "Epoch 4843/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 431.3410 - val_loss: 753.7672\n",
      "Epoch 4844/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 424.4637 - val_loss: 798.3825\n",
      "Epoch 4845/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 382.5721 - val_loss: 738.1195\n",
      "Epoch 4846/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 357.6089 - val_loss: 792.3072\n",
      "Epoch 4847/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 315.0608 - val_loss: 884.2286\n",
      "Epoch 4848/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 431.4381 - val_loss: 922.6796\n",
      "Epoch 4849/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 475.3749 - val_loss: 740.9949\n",
      "Epoch 4850/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 437.2755 - val_loss: 861.6986\n",
      "Epoch 4851/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 377.7593 - val_loss: 976.8010\n",
      "Epoch 4852/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.3594 - val_loss: 870.4418\n",
      "Epoch 4853/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 334.1177 - val_loss: 900.5691\n",
      "Epoch 4854/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 342.2536 - val_loss: 835.8170\n",
      "Epoch 4855/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 348.5684 - val_loss: 762.7407\n",
      "Epoch 4856/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.3231 - val_loss: 862.4582\n",
      "Epoch 4857/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 330.1637 - val_loss: 769.9263\n",
      "Epoch 4858/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 343.7944 - val_loss: 797.4088\n",
      "Epoch 4859/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.7448 - val_loss: 914.5926\n",
      "Epoch 4860/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 318.1213 - val_loss: 930.1158\n",
      "Epoch 4861/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 331.3690 - val_loss: 867.9627\n",
      "Epoch 4862/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.5070 - val_loss: 769.7790\n",
      "Epoch 4863/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.8831 - val_loss: 890.4207\n",
      "Epoch 4864/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 325.674 - 0s 52us/step - loss: 304.3966 - val_loss: 820.0112\n",
      "Epoch 4865/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 327.1372 - val_loss: 937.6395\n",
      "Epoch 4866/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.2932 - val_loss: 1019.0054\n",
      "Epoch 4867/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 392.4482 - val_loss: 730.1290\n",
      "Epoch 4868/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 367.0049 - val_loss: 769.1013\n",
      "Epoch 4869/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 357.0637 - val_loss: 749.1355\n",
      "Epoch 4870/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 330.1337 - val_loss: 970.0484\n",
      "Epoch 4871/10000\n",
      "630/630 [==============================] - 0s 78us/step - loss: 317.5475 - val_loss: 825.6618\n",
      "Epoch 4872/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 320.3206 - val_loss: 847.7721\n",
      "Epoch 4873/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 342.0712 - val_loss: 767.1066\n",
      "Epoch 4874/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 324.4879 - val_loss: 901.5087\n",
      "Epoch 4875/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 682.6480 - val_loss: 919.5461\n",
      "Epoch 4876/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 1206.0990 - val_loss: 1320.3052\n",
      "Epoch 4877/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 915.7229 - val_loss: 886.6659\n",
      "Epoch 4878/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 883.1216 - val_loss: 1116.8886\n",
      "Epoch 4879/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 752.7349 - val_loss: 957.9967\n",
      "Epoch 4880/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 715.2195 - val_loss: 930.0994\n",
      "Epoch 4881/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 694.3206 - val_loss: 1055.1302\n",
      "Epoch 4882/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 635.5846 - val_loss: 971.3105\n",
      "Epoch 4883/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 582.1146 - val_loss: 858.2305\n",
      "Epoch 4884/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 553.7095 - val_loss: 865.8429\n",
      "Epoch 4885/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 538.2955 - val_loss: 929.6167\n",
      "Epoch 4886/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 518.7571 - val_loss: 952.3095\n",
      "Epoch 4887/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 486.7767 - val_loss: 872.8251\n",
      "Epoch 4888/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 455.1623 - val_loss: 932.9686\n",
      "Epoch 4889/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 476.6585 - val_loss: 862.2947\n",
      "Epoch 4890/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 425.5383 - val_loss: 816.4856\n",
      "Epoch 4891/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 399.3512 - val_loss: 810.5999\n",
      "Epoch 4892/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 388.2267 - val_loss: 854.1580\n",
      "Epoch 4893/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 355.0846 - val_loss: 836.5562\n",
      "Epoch 4894/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 341.9571 - val_loss: 927.9479\n",
      "Epoch 4895/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 320.3576 - val_loss: 980.5216\n",
      "Epoch 4896/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.9294 - val_loss: 1324.0265\n",
      "Epoch 4897/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 428.9557 - val_loss: 890.6679\n",
      "Epoch 4898/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.7412 - val_loss: 813.8626\n",
      "Epoch 4899/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 344.7649 - val_loss: 836.0672\n",
      "Epoch 4900/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 352.2975 - val_loss: 851.9199\n",
      "Epoch 4901/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 376.4162 - val_loss: 908.4693\n",
      "Epoch 4902/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.7279 - val_loss: 819.6247\n",
      "Epoch 4903/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 319.6052 - val_loss: 772.1685\n",
      "Epoch 4904/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 871.5024 - val_loss: 1352.6801\n",
      "Epoch 4905/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2301.0513 - val_loss: 1123.4179\n",
      "Epoch 4906/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1682.5056 - val_loss: 845.5590\n",
      "Epoch 4907/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1126.3234 - val_loss: 880.4653\n",
      "Epoch 4908/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 603.9407 - val_loss: 797.7506\n",
      "Epoch 4909/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 598.3973 - val_loss: 956.0008\n",
      "Epoch 4910/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 483.4047 - val_loss: 1100.2172\n",
      "Epoch 4911/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 447.1690 - val_loss: 1131.6294\n",
      "Epoch 4912/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 424.4804 - val_loss: 768.2839\n",
      "Epoch 4913/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 416.1812 - val_loss: 894.7734\n",
      "Epoch 4914/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 404.0378 - val_loss: 983.1179\n",
      "Epoch 4915/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 378.9664 - val_loss: 795.1230\n",
      "Epoch 4916/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 353.1752 - val_loss: 999.9641\n",
      "Epoch 4917/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 382.1987 - val_loss: 1771.1925\n",
      "Epoch 4918/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 626.9415 - val_loss: 822.1306\n",
      "Epoch 4919/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 428.9027 - val_loss: 842.2223\n",
      "Epoch 4920/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 396.3621 - val_loss: 891.1773\n",
      "Epoch 4921/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 357.1251 - val_loss: 952.4153\n",
      "Epoch 4922/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 407.756 - 0s 52us/step - loss: 325.4887 - val_loss: 884.7190\n",
      "Epoch 4923/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 305.4031 - val_loss: 816.5517\n",
      "Epoch 4924/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 849.8939 - val_loss: 878.8726\n",
      "Epoch 4925/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1008.9494 - val_loss: 978.4334\n",
      "Epoch 4926/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 838.5783 - val_loss: 806.4973\n",
      "Epoch 4927/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 545.0864 - val_loss: 957.5250\n",
      "Epoch 4928/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 526.5984 - val_loss: 894.1800\n",
      "Epoch 4929/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 386.7866 - val_loss: 902.2316\n",
      "Epoch 4930/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 360.2186 - val_loss: 950.6719\n",
      "Epoch 4931/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 336.6123 - val_loss: 852.5607\n",
      "Epoch 4932/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 400.0900 - val_loss: 797.6147\n",
      "Epoch 4933/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 366.8491 - val_loss: 848.8439\n",
      "Epoch 4934/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.4796 - val_loss: 774.8766\n",
      "Epoch 4935/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 482.8451 - val_loss: 1343.8248\n",
      "Epoch 4936/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1017.0986 - val_loss: 1343.8253\n",
      "Epoch 4937/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 729.4120 - val_loss: 1350.7205\n",
      "Epoch 4938/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 677.6496 - val_loss: 1316.8259\n",
      "Epoch 4939/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 584.6241 - val_loss: 1247.8895\n",
      "Epoch 4940/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 496.6262 - val_loss: 995.1216\n",
      "Epoch 4941/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 544.2788 - val_loss: 857.3192\n",
      "Epoch 4942/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 662.2892 - val_loss: 1174.5458\n",
      "Epoch 4943/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 766.3537 - val_loss: 1097.4892\n",
      "Epoch 4944/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 623.4877 - val_loss: 1230.8145\n",
      "Epoch 4945/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 480.8218 - val_loss: 1004.9716\n",
      "Epoch 4946/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 387.1293 - val_loss: 993.4726\n",
      "Epoch 4947/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.0075 - val_loss: 822.2132\n",
      "Epoch 4948/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.6393 - val_loss: 774.0989\n",
      "Epoch 4949/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.1521 - val_loss: 751.9042\n",
      "Epoch 4950/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 343.4811 - val_loss: 726.1279\n",
      "Epoch 4951/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 356.9889 - val_loss: 730.6262\n",
      "Epoch 4952/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 799.7071 - val_loss: 827.4894\n",
      "Epoch 4953/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1085.2057 - val_loss: 1337.9118\n",
      "Epoch 4954/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1032.7118 - val_loss: 1176.6672\n",
      "Epoch 4955/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 982.3732 - val_loss: 1163.4200\n",
      "Epoch 4956/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 937.3776 - val_loss: 1167.2464\n",
      "Epoch 4957/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 869.8050 - val_loss: 1187.8109\n",
      "Epoch 4958/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 794.5661 - val_loss: 1059.1423\n",
      "Epoch 4959/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 743.9643 - val_loss: 1091.0901\n",
      "Epoch 4960/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 720.9191 - val_loss: 1155.9892\n",
      "Epoch 4961/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 705.6216 - val_loss: 1021.6668\n",
      "Epoch 4962/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 681.9696 - val_loss: 1062.6712\n",
      "Epoch 4963/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 671.7736 - val_loss: 1051.6583\n",
      "Epoch 4964/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 644.3225 - val_loss: 1059.9631\n",
      "Epoch 4965/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 635.7239 - val_loss: 995.1772\n",
      "Epoch 4966/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 52us/step - loss: 620.7280 - val_loss: 1041.7755\n",
      "Epoch 4967/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 583.1324 - val_loss: 968.8312\n",
      "Epoch 4968/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 558.5154 - val_loss: 1028.7398\n",
      "Epoch 4969/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 565.7778 - val_loss: 925.6378\n",
      "Epoch 4970/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 541.0591 - val_loss: 910.6987\n",
      "Epoch 4971/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 533.5433 - val_loss: 893.3529\n",
      "Epoch 4972/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 506.2740 - val_loss: 886.0892\n",
      "Epoch 4973/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 476.0754 - val_loss: 866.8763\n",
      "Epoch 4974/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 463.4306 - val_loss: 934.3773\n",
      "Epoch 4975/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 498.6398 - val_loss: 988.7783\n",
      "Epoch 4976/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 489.5889 - val_loss: 927.5098\n",
      "Epoch 4977/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 473.7748 - val_loss: 873.8881\n",
      "Epoch 4978/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 437.8836 - val_loss: 939.9028\n",
      "Epoch 4979/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 455.3600 - val_loss: 918.4199\n",
      "Epoch 4980/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 460.0718 - val_loss: 829.8598\n",
      "Epoch 4981/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 529.5196 - val_loss: 810.1067\n",
      "Epoch 4982/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 460.8280 - val_loss: 873.2528\n",
      "Epoch 4983/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 578.3432 - val_loss: 882.9770\n",
      "Epoch 4984/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 474.4500 - val_loss: 898.3396\n",
      "Epoch 4985/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 465.3683 - val_loss: 1040.8105\n",
      "Epoch 4986/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 455.3217 - val_loss: 1074.1349\n",
      "Epoch 4987/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 417.3513 - val_loss: 1238.3668\n",
      "Epoch 4988/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 401.1478 - val_loss: 1120.5482\n",
      "Epoch 4989/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 413.6700 - val_loss: 969.3479\n",
      "Epoch 4990/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 393.7397 - val_loss: 1034.9903\n",
      "Epoch 4991/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 603.8497 - val_loss: 929.6206\n",
      "Epoch 4992/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 506.9488 - val_loss: 959.3221\n",
      "Epoch 4993/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 671.8261 - val_loss: 923.0456\n",
      "Epoch 4994/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 512.2488 - val_loss: 828.9215\n",
      "Epoch 4995/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 439.3064 - val_loss: 844.5493\n",
      "Epoch 4996/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 760.1654 - val_loss: 911.2390\n",
      "Epoch 4997/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 805.4260 - val_loss: 1076.1871\n",
      "Epoch 4998/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 637.5925 - val_loss: 693.1234\n",
      "Epoch 4999/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 605.7646 - val_loss: 919.5700\n",
      "Epoch 5000/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 603.7312 - val_loss: 936.5699\n",
      "Epoch 5001/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 533.0381 - val_loss: 889.0791\n",
      "Epoch 5002/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 524.8325 - val_loss: 848.9277\n",
      "Epoch 5003/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 541.5217 - val_loss: 865.6260\n",
      "Epoch 5004/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 534.1874 - val_loss: 942.3998\n",
      "Epoch 5005/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 525.2506 - val_loss: 1094.9838\n",
      "Epoch 5006/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 454.8618 - val_loss: 1005.4495\n",
      "Epoch 5007/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 433.5922 - val_loss: 817.3871\n",
      "Epoch 5008/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 382.0056 - val_loss: 910.1009\n",
      "Epoch 5009/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 384.3790 - val_loss: 1028.6614\n",
      "Epoch 5010/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 419.5456 - val_loss: 1079.5365\n",
      "Epoch 5011/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 445.6220 - val_loss: 919.6974\n",
      "Epoch 5012/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 399.7920 - val_loss: 920.4252\n",
      "Epoch 5013/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 399.0972 - val_loss: 1071.5305\n",
      "Epoch 5014/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 379.3311 - val_loss: 849.7868\n",
      "Epoch 5015/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.5629 - val_loss: 986.1094\n",
      "Epoch 5016/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 347.5184 - val_loss: 1096.7557\n",
      "Epoch 5017/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 390.6812 - val_loss: 1019.4434\n",
      "Epoch 5018/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 359.0808 - val_loss: 777.1414\n",
      "Epoch 5019/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 445.6963 - val_loss: 977.9853\n",
      "Epoch 5020/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 451.5184 - val_loss: 790.4959\n",
      "Epoch 5021/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 440.1267 - val_loss: 862.8545\n",
      "Epoch 5022/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 468.6080 - val_loss: 874.1973\n",
      "Epoch 5023/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 452.1918 - val_loss: 969.1479\n",
      "Epoch 5024/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 451.4780 - val_loss: 882.4615\n",
      "Epoch 5025/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 416.5197 - val_loss: 898.9611\n",
      "Epoch 5026/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 435.4879 - val_loss: 896.8653\n",
      "Epoch 5027/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 465.1097 - val_loss: 950.7441\n",
      "Epoch 5028/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 421.0904 - val_loss: 913.6844\n",
      "Epoch 5029/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 393.4564 - val_loss: 975.3912\n",
      "Epoch 5030/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 395.4072 - val_loss: 877.3179\n",
      "Epoch 5031/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 380.1435 - val_loss: 764.1728\n",
      "Epoch 5032/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 414.2725 - val_loss: 788.8575\n",
      "Epoch 5033/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 422.4396 - val_loss: 813.5246\n",
      "Epoch 5034/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 395.8609 - val_loss: 857.9058\n",
      "Epoch 5035/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 391.2966 - val_loss: 856.8630\n",
      "Epoch 5036/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 390.6794 - val_loss: 876.0158\n",
      "Epoch 5037/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 398.7100 - val_loss: 887.6168\n",
      "Epoch 5038/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 383.5142 - val_loss: 824.8399\n",
      "Epoch 5039/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 422.8379 - val_loss: 872.7215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5040/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 484.1691 - val_loss: 1036.2579\n",
      "Epoch 5041/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 413.2721 - val_loss: 943.9858\n",
      "Epoch 5042/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 363.4128 - val_loss: 912.2691\n",
      "Epoch 5043/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 356.8056 - val_loss: 1013.5961\n",
      "Epoch 5044/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 955.7215 - val_loss: 1488.4033\n",
      "Epoch 5045/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 800.0108 - val_loss: 927.9606\n",
      "Epoch 5046/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 691.3864 - val_loss: 1006.8701\n",
      "Epoch 5047/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 642.1289 - val_loss: 950.4331\n",
      "Epoch 5048/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 525.9125 - val_loss: 947.1423\n",
      "Epoch 5049/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 441.4230 - val_loss: 802.5020\n",
      "Epoch 5050/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 433.2006 - val_loss: 1137.3010\n",
      "Epoch 5051/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 522.8130 - val_loss: 1120.7412\n",
      "Epoch 5052/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 494.2225 - val_loss: 954.7472\n",
      "Epoch 5053/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 576.0155 - val_loss: 859.8513\n",
      "Epoch 5054/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 600.4834 - val_loss: 850.1271\n",
      "Epoch 5055/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 534.4845 - val_loss: 803.0869\n",
      "Epoch 5056/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 440.9510 - val_loss: 989.9895\n",
      "Epoch 5057/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 391.4007 - val_loss: 950.0273\n",
      "Epoch 5058/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.6536 - val_loss: 1069.5275\n",
      "Epoch 5059/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.8008 - val_loss: 1145.5011\n",
      "Epoch 5060/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 468.6995 - val_loss: 821.8182\n",
      "Epoch 5061/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 476.2677 - val_loss: 907.5863\n",
      "Epoch 5062/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 451.8537 - val_loss: 897.2671\n",
      "Epoch 5063/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 444.9902 - val_loss: 926.0846\n",
      "Epoch 5064/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 495.4559 - val_loss: 859.0568\n",
      "Epoch 5065/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 483.9445 - val_loss: 968.3416\n",
      "Epoch 5066/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 425.7577 - val_loss: 918.4560\n",
      "Epoch 5067/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 393.6083 - val_loss: 821.1789\n",
      "Epoch 5068/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 417.3983 - val_loss: 891.3180\n",
      "Epoch 5069/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 507.5222 - val_loss: 996.9397\n",
      "Epoch 5070/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 440.7088 - val_loss: 817.9823\n",
      "Epoch 5071/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 409.1172 - val_loss: 1030.5778\n",
      "Epoch 5072/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 350.1800 - val_loss: 933.6372\n",
      "Epoch 5073/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 461.9827 - val_loss: 889.7233\n",
      "Epoch 5074/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 412.1260 - val_loss: 907.6284\n",
      "Epoch 5075/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 444.7917 - val_loss: 793.3326\n",
      "Epoch 5076/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 432.7838 - val_loss: 1005.9863\n",
      "Epoch 5077/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 407.8683 - val_loss: 824.9220\n",
      "Epoch 5078/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 372.0984 - val_loss: 803.2945\n",
      "Epoch 5079/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 444.5198 - val_loss: 991.4181\n",
      "Epoch 5080/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 458.7569 - val_loss: 743.9898\n",
      "Epoch 5081/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 378.7594 - val_loss: 973.1745\n",
      "Epoch 5082/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 347.6881 - val_loss: 930.0119\n",
      "Epoch 5083/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 471.0366 - val_loss: 927.2218\n",
      "Epoch 5084/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 508.8737 - val_loss: 921.3441\n",
      "Epoch 5085/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 462.7968 - val_loss: 933.0383\n",
      "Epoch 5086/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 386.0443 - val_loss: 871.3868\n",
      "Epoch 5087/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 356.5443 - val_loss: 943.8132\n",
      "Epoch 5088/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 387.7989 - val_loss: 794.0517\n",
      "Epoch 5089/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 393.1860 - val_loss: 920.9136\n",
      "Epoch 5090/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 384.5675 - val_loss: 690.2491\n",
      "Epoch 5091/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 719.9657 - val_loss: 632.5182\n",
      "Epoch 5092/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 671.4917 - val_loss: 807.0835\n",
      "Epoch 5093/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 437.4445 - val_loss: 811.8667\n",
      "Epoch 5094/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 441.7504 - val_loss: 981.9895\n",
      "Epoch 5095/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.1620 - val_loss: 981.2070\n",
      "Epoch 5096/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 369.4090 - val_loss: 1025.6214\n",
      "Epoch 5097/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 848.6719 - val_loss: 916.7938\n",
      "Epoch 5098/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 653.3472 - val_loss: 1104.6717\n",
      "Epoch 5099/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 473.7432 - val_loss: 1002.6208\n",
      "Epoch 5100/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 416.7147 - val_loss: 892.0899\n",
      "Epoch 5101/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 419.9318 - val_loss: 920.8149\n",
      "Epoch 5102/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 377.1093 - val_loss: 889.1053\n",
      "Epoch 5103/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 376.9764 - val_loss: 879.9497\n",
      "Epoch 5104/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 368.9002 - val_loss: 810.1600\n",
      "Epoch 5105/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 363.9460 - val_loss: 793.8443\n",
      "Epoch 5106/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 354.2524 - val_loss: 725.0717\n",
      "Epoch 5107/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 420.5583 - val_loss: 916.4630\n",
      "Epoch 5108/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 390.9208 - val_loss: 898.9009\n",
      "Epoch 5109/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 358.7214 - val_loss: 914.6722\n",
      "Epoch 5110/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 353.6385 - val_loss: 936.0466\n",
      "Epoch 5111/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 349.3923 - val_loss: 960.0306\n",
      "Epoch 5112/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 413.5250 - val_loss: 897.7716\n",
      "Epoch 5113/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 355.4956 - val_loss: 861.1250\n",
      "Epoch 5114/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 332.6256 - val_loss: 1789.1503\n",
      "Epoch 5115/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 805.0966 - val_loss: 1301.8742\n",
      "Epoch 5116/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 802.1368 - val_loss: 1033.7749\n",
      "Epoch 5117/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 606.5879 - val_loss: 1079.1435\n",
      "Epoch 5118/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 500.1628 - val_loss: 692.2529\n",
      "Epoch 5119/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 450.1661 - val_loss: 1011.8452\n",
      "Epoch 5120/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.2875 - val_loss: 1178.3569\n",
      "Epoch 5121/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 407.8867 - val_loss: 886.5042\n",
      "Epoch 5122/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 376.7330 - val_loss: 842.4603\n",
      "Epoch 5123/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 435.7562 - val_loss: 1008.8052\n",
      "Epoch 5124/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 431.7139 - val_loss: 982.0073\n",
      "Epoch 5125/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 426.6158 - val_loss: 878.0344\n",
      "Epoch 5126/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 368.8165 - val_loss: 862.6693\n",
      "Epoch 5127/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.3320 - val_loss: 793.9670\n",
      "Epoch 5128/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 349.1926 - val_loss: 951.5328\n",
      "Epoch 5129/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 421.3800 - val_loss: 787.1909\n",
      "Epoch 5130/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 455.4928 - val_loss: 992.2436\n",
      "Epoch 5131/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 393.2208 - val_loss: 875.2176\n",
      "Epoch 5132/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 348.3357 - val_loss: 713.8741\n",
      "Epoch 5133/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 469.1444 - val_loss: 731.9473\n",
      "Epoch 5134/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 420.1749 - val_loss: 959.2379\n",
      "Epoch 5135/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 390.5987 - val_loss: 818.8404\n",
      "Epoch 5136/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 376.5395 - val_loss: 851.2187\n",
      "Epoch 5137/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 359.6767 - val_loss: 900.0659\n",
      "Epoch 5138/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.6679 - val_loss: 973.7283\n",
      "Epoch 5139/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.1950 - val_loss: 907.4093\n",
      "Epoch 5140/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 302.2751 - val_loss: 896.5872\n",
      "Epoch 5141/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.8529 - val_loss: 852.6847\n",
      "Epoch 5142/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.6727 - val_loss: 892.1996\n",
      "Epoch 5143/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 341.9093 - val_loss: 798.5673\n",
      "Epoch 5144/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 334.0889 - val_loss: 839.4306\n",
      "Epoch 5145/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.6474 - val_loss: 853.5942\n",
      "Epoch 5146/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 342.6856 - val_loss: 860.6242\n",
      "Epoch 5147/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 343.3999 - val_loss: 871.8945\n",
      "Epoch 5148/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 334.3220 - val_loss: 1002.2633\n",
      "Epoch 5149/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 360.3674 - val_loss: 766.5139\n",
      "Epoch 5150/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.2900 - val_loss: 855.6514\n",
      "Epoch 5151/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 316.4802 - val_loss: 818.9333\n",
      "Epoch 5152/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 315.6362 - val_loss: 834.1003\n",
      "Epoch 5153/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 327.3302 - val_loss: 813.9290\n",
      "Epoch 5154/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 339.9982 - val_loss: 897.6203\n",
      "Epoch 5155/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 418.8717 - val_loss: 932.5893\n",
      "Epoch 5156/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 395.2324 - val_loss: 901.6953\n",
      "Epoch 5157/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 331.6731 - val_loss: 853.3325\n",
      "Epoch 5158/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 505.4801 - val_loss: 1034.0436\n",
      "Epoch 5159/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 622.0511 - val_loss: 1002.2458\n",
      "Epoch 5160/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 649.4205 - val_loss: 973.2926\n",
      "Epoch 5161/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 574.8549 - val_loss: 909.5107\n",
      "Epoch 5162/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 500.1528 - val_loss: 949.1902\n",
      "Epoch 5163/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 404.4971 - val_loss: 930.1380\n",
      "Epoch 5164/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 400.2827 - val_loss: 974.1347\n",
      "Epoch 5165/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 484.5947 - val_loss: 959.6103\n",
      "Epoch 5166/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 381.2743 - val_loss: 847.7869\n",
      "Epoch 5167/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 338.5583 - val_loss: 894.0116\n",
      "Epoch 5168/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 477.0077 - val_loss: 899.9467\n",
      "Epoch 5169/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 420.7980 - val_loss: 836.0255\n",
      "Epoch 5170/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 395.7341 - val_loss: 1148.4611\n",
      "Epoch 5171/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 459.7028 - val_loss: 851.8496\n",
      "Epoch 5172/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 426.7034 - val_loss: 916.5799\n",
      "Epoch 5173/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 392.5253 - val_loss: 971.8430\n",
      "Epoch 5174/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 362.7417 - val_loss: 837.5888\n",
      "Epoch 5175/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 324.0084 - val_loss: 783.8706\n",
      "Epoch 5176/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 830.0593 - val_loss: 1035.3853\n",
      "Epoch 5177/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1591.7148 - val_loss: 1517.9422\n",
      "Epoch 5178/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1327.5533 - val_loss: 1232.5334\n",
      "Epoch 5179/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 978.6416 - val_loss: 1172.8575\n",
      "Epoch 5180/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 746.9804 - val_loss: 1046.7806\n",
      "Epoch 5181/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 648.0057 - val_loss: 994.7372\n",
      "Epoch 5182/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 634.1696 - val_loss: 977.8196\n",
      "Epoch 5183/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 563.2593 - val_loss: 998.3733\n",
      "Epoch 5184/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 518.8701 - val_loss: 909.2617\n",
      "Epoch 5185/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 501.1495 - val_loss: 912.9239\n",
      "Epoch 5186/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 461.3954 - val_loss: 910.9068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5187/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 443.9208 - val_loss: 791.6644\n",
      "Epoch 5188/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 400.0880 - val_loss: 764.6521\n",
      "Epoch 5189/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 404.9567 - val_loss: 1073.4447\n",
      "Epoch 5190/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 519.9734 - val_loss: 824.2808\n",
      "Epoch 5191/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 401.0227 - val_loss: 861.9458\n",
      "Epoch 5192/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 629.5266 - val_loss: 766.6896\n",
      "Epoch 5193/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 673.7665 - val_loss: 926.2040\n",
      "Epoch 5194/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1192.6374 - val_loss: 962.4367\n",
      "Epoch 5195/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 789.0996 - val_loss: 983.1187\n",
      "Epoch 5196/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 697.4124 - val_loss: 1465.4711\n",
      "Epoch 5197/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 526.6003 - val_loss: 916.5153\n",
      "Epoch 5198/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.6330 - val_loss: 859.1502\n",
      "Epoch 5199/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 487.3663 - val_loss: 1502.5828\n",
      "Epoch 5200/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 573.1852 - val_loss: 1031.2345\n",
      "Epoch 5201/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 537.3346 - val_loss: 1059.5413\n",
      "Epoch 5202/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 553.905 - 0s 52us/step - loss: 555.6788 - val_loss: 1056.7566\n",
      "Epoch 5203/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 486.4751 - val_loss: 848.1711\n",
      "Epoch 5204/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 449.7887 - val_loss: 982.1623\n",
      "Epoch 5205/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 411.8049 - val_loss: 1018.2013\n",
      "Epoch 5206/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 345.0630 - val_loss: 974.5146\n",
      "Epoch 5207/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 426.8929 - val_loss: 1081.4095\n",
      "Epoch 5208/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 409.9644 - val_loss: 966.4615\n",
      "Epoch 5209/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 387.2116 - val_loss: 878.7991\n",
      "Epoch 5210/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 343.5457 - val_loss: 950.6728\n",
      "Epoch 5211/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 332.9656 - val_loss: 808.2145\n",
      "Epoch 5212/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 323.0343 - val_loss: 970.7738\n",
      "Epoch 5213/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.6401 - val_loss: 826.8647\n",
      "Epoch 5214/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.9149 - val_loss: 883.6197\n",
      "Epoch 5215/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 452.6047 - val_loss: 1137.3644\n",
      "Epoch 5216/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 542.4366 - val_loss: 718.0034\n",
      "Epoch 5217/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 630.4650 - val_loss: 939.4962\n",
      "Epoch 5218/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 478.2545 - val_loss: 885.2267\n",
      "Epoch 5219/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 460.9232 - val_loss: 855.9366\n",
      "Epoch 5220/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 399.3658 - val_loss: 870.9156\n",
      "Epoch 5221/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.8596 - val_loss: 879.2131\n",
      "Epoch 5222/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 365.7805 - val_loss: 933.0168\n",
      "Epoch 5223/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 392.4462 - val_loss: 821.3439\n",
      "Epoch 5224/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.7313 - val_loss: 851.4771\n",
      "Epoch 5225/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 322.5566 - val_loss: 840.8052\n",
      "Epoch 5226/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 296.7444 - val_loss: 861.1486\n",
      "Epoch 5227/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.9932 - val_loss: 751.8689\n",
      "Epoch 5228/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 443.3386 - val_loss: 819.9415\n",
      "Epoch 5229/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 412.7420 - val_loss: 837.5101\n",
      "Epoch 5230/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.8923 - val_loss: 888.8213\n",
      "Epoch 5231/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 324.5580 - val_loss: 848.7857\n",
      "Epoch 5232/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 307.5027 - val_loss: 817.6065\n",
      "Epoch 5233/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 320.6881 - val_loss: 739.9742\n",
      "Epoch 5234/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 310.5829 - val_loss: 798.9319\n",
      "Epoch 5235/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 331.8245 - val_loss: 797.7545\n",
      "Epoch 5236/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 364.2673 - val_loss: 1284.0326\n",
      "Epoch 5237/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 545.7884 - val_loss: 964.1019\n",
      "Epoch 5238/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 411.2563 - val_loss: 1006.5535\n",
      "Epoch 5239/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 417.9154 - val_loss: 979.7455\n",
      "Epoch 5240/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 398.0501 - val_loss: 943.8207\n",
      "Epoch 5241/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.8823 - val_loss: 826.2973\n",
      "Epoch 5242/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 365.5829 - val_loss: 871.4501\n",
      "Epoch 5243/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 389.2530 - val_loss: 794.5323\n",
      "Epoch 5244/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 375.6713 - val_loss: 783.2917\n",
      "Epoch 5245/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 369.2934 - val_loss: 845.5917\n",
      "Epoch 5246/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 400.6579 - val_loss: 855.1540\n",
      "Epoch 5247/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.3672 - val_loss: 940.1584\n",
      "Epoch 5248/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 343.4391 - val_loss: 1428.3143\n",
      "Epoch 5249/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 814.7139 - val_loss: 1346.7856\n",
      "Epoch 5250/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 639.9374 - val_loss: 959.0988\n",
      "Epoch 5251/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 483.2562 - val_loss: 1062.0939\n",
      "Epoch 5252/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 571.3288 - val_loss: 888.6364\n",
      "Epoch 5253/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 431.4363 - val_loss: 875.0506\n",
      "Epoch 5254/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 415.4362 - val_loss: 790.3398\n",
      "Epoch 5255/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1509.4888 - val_loss: 2169.4542\n",
      "Epoch 5256/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1854.9005 - val_loss: 1563.2151\n",
      "Epoch 5257/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1712.2810 - val_loss: 1310.9608\n",
      "Epoch 5258/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1322.6671 - val_loss: 1011.3926\n",
      "Epoch 5259/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 877.3284 - val_loss: 1004.4839\n",
      "Epoch 5260/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 708.1814 - val_loss: 975.3090\n",
      "Epoch 5261/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 550.6161 - val_loss: 838.3998\n",
      "Epoch 5262/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 467.5354 - val_loss: 904.5817\n",
      "Epoch 5263/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 426.0981 - val_loss: 1073.6850\n",
      "Epoch 5264/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 391.2386 - val_loss: 872.3951\n",
      "Epoch 5265/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 356.1157 - val_loss: 812.7167\n",
      "Epoch 5266/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.7439 - val_loss: 881.1663\n",
      "Epoch 5267/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.0926 - val_loss: 799.0468\n",
      "Epoch 5268/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 371.1572 - val_loss: 828.5411\n",
      "Epoch 5269/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 360.3745 - val_loss: 765.4198\n",
      "Epoch 5270/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 342.2421 - val_loss: 734.3515\n",
      "Epoch 5271/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.2347 - val_loss: 826.6388\n",
      "Epoch 5272/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 391.1283 - val_loss: 868.1933\n",
      "Epoch 5273/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 391.9694 - val_loss: 1108.0387\n",
      "Epoch 5274/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.0613 - val_loss: 851.0668\n",
      "Epoch 5275/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 375.3724 - val_loss: 841.1344\n",
      "Epoch 5276/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 352.1470 - val_loss: 869.5718\n",
      "Epoch 5277/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 767.3545 - val_loss: 1341.0168\n",
      "Epoch 5278/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1018.4715 - val_loss: 998.8201\n",
      "Epoch 5279/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 754.4139 - val_loss: 904.1879\n",
      "Epoch 5280/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 549.4658 - val_loss: 864.7564\n",
      "Epoch 5281/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 450.8281 - val_loss: 771.8671\n",
      "Epoch 5282/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 464.1638 - val_loss: 1234.2270\n",
      "Epoch 5283/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 434.4365 - val_loss: 950.3175\n",
      "Epoch 5284/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 493.2712 - val_loss: 1025.1463\n",
      "Epoch 5285/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 430.4646 - val_loss: 853.2054\n",
      "Epoch 5286/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 397.4792 - val_loss: 802.6525\n",
      "Epoch 5287/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 352.5710 - val_loss: 831.5129\n",
      "Epoch 5288/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.0082 - val_loss: 928.2938\n",
      "Epoch 5289/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 693.6776 - val_loss: 1048.2586\n",
      "Epoch 5290/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 768.1213 - val_loss: 829.0676\n",
      "Epoch 5291/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 558.9048 - val_loss: 933.9607\n",
      "Epoch 5292/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 497.8774 - val_loss: 915.1493\n",
      "Epoch 5293/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 423.7991 - val_loss: 887.0828\n",
      "Epoch 5294/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 411.0569 - val_loss: 847.9766\n",
      "Epoch 5295/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 384.9440 - val_loss: 741.7840\n",
      "Epoch 5296/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 494.0281 - val_loss: 841.7614\n",
      "Epoch 5297/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 547.8366 - val_loss: 870.7548\n",
      "Epoch 5298/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 436.2169 - val_loss: 822.0082\n",
      "Epoch 5299/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 597.8160 - val_loss: 791.6752\n",
      "Epoch 5300/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 565.0365 - val_loss: 1194.2065\n",
      "Epoch 5301/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 488.2468 - val_loss: 787.8834\n",
      "Epoch 5302/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 446.9052 - val_loss: 769.2466\n",
      "Epoch 5303/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 420.5755 - val_loss: 931.7344\n",
      "Epoch 5304/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.3326 - val_loss: 964.7081\n",
      "Epoch 5305/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.6819 - val_loss: 843.8268\n",
      "Epoch 5306/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 347.4665 - val_loss: 887.9561\n",
      "Epoch 5307/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 322.2864 - val_loss: 919.2120\n",
      "Epoch 5308/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.4763 - val_loss: 810.3348\n",
      "Epoch 5309/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.5871 - val_loss: 1312.7390\n",
      "Epoch 5310/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 511.5680 - val_loss: 713.8113\n",
      "Epoch 5311/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 421.4248 - val_loss: 788.0945\n",
      "Epoch 5312/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 424.3307 - val_loss: 1391.6688\n",
      "Epoch 5313/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 608.1566 - val_loss: 693.9311\n",
      "Epoch 5314/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 505.3036 - val_loss: 840.2766\n",
      "Epoch 5315/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 447.8507 - val_loss: 835.9144\n",
      "Epoch 5316/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 400.9007 - val_loss: 877.1262\n",
      "Epoch 5317/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 340.6687 - val_loss: 994.3870\n",
      "Epoch 5318/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 307.4791 - val_loss: 978.0941\n",
      "Epoch 5319/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 327.0941 - val_loss: 868.0688\n",
      "Epoch 5320/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 297.5730 - val_loss: 858.1476\n",
      "Epoch 5321/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.5586 - val_loss: 836.9452\n",
      "Epoch 5322/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.6435 - val_loss: 1237.4447\n",
      "Epoch 5323/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 790.6322 - val_loss: 1152.5754\n",
      "Epoch 5324/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 869.1972 - val_loss: 947.0870\n",
      "Epoch 5325/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 640.0718 - val_loss: 1330.5119\n",
      "Epoch 5326/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 667.8885 - val_loss: 882.6778\n",
      "Epoch 5327/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 701.0072 - val_loss: 1339.0061\n",
      "Epoch 5328/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 682.8968 - val_loss: 1326.8643\n",
      "Epoch 5329/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 527.8646 - val_loss: 1517.0664\n",
      "Epoch 5330/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 586.3424 - val_loss: 711.3511\n",
      "Epoch 5331/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 500.5492 - val_loss: 838.5071\n",
      "Epoch 5332/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 434.8550 - val_loss: 761.1001\n",
      "Epoch 5333/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 443.2265 - val_loss: 1169.2661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5334/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.9305 - val_loss: 864.6100\n",
      "Epoch 5335/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 376.7782 - val_loss: 1074.6062\n",
      "Epoch 5336/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 594.4942 - val_loss: 878.3734\n",
      "Epoch 5337/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 531.5358 - val_loss: 945.8951\n",
      "Epoch 5338/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 428.2255 - val_loss: 859.4476\n",
      "Epoch 5339/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 420.1936 - val_loss: 910.5280\n",
      "Epoch 5340/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 384.9152 - val_loss: 841.0337\n",
      "Epoch 5341/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.5792 - val_loss: 898.3504\n",
      "Epoch 5342/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 400.9024 - val_loss: 865.9689\n",
      "Epoch 5343/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 379.4259 - val_loss: 769.5035\n",
      "Epoch 5344/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 392.8500 - val_loss: 951.7403\n",
      "Epoch 5345/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.7505 - val_loss: 933.9222\n",
      "Epoch 5346/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.4910 - val_loss: 1624.4057\n",
      "Epoch 5347/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1017.6463 - val_loss: 1356.9538\n",
      "Epoch 5348/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1449.2855 - val_loss: 1289.7474\n",
      "Epoch 5349/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1205.3261 - val_loss: 1063.0030\n",
      "Epoch 5350/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 796.5221 - val_loss: 964.9149\n",
      "Epoch 5351/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 659.8989 - val_loss: 815.2341\n",
      "Epoch 5352/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 507.1625 - val_loss: 890.2502\n",
      "Epoch 5353/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 417.3408 - val_loss: 893.5758\n",
      "Epoch 5354/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 368.3680 - val_loss: 1039.6821\n",
      "Epoch 5355/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 418.7215 - val_loss: 900.5074\n",
      "Epoch 5356/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 347.6198 - val_loss: 824.8154\n",
      "Epoch 5357/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 345.1599 - val_loss: 898.6524\n",
      "Epoch 5358/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 320.2221 - val_loss: 900.6018\n",
      "Epoch 5359/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 308.3506 - val_loss: 960.2838\n",
      "Epoch 5360/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 327.787 - 0s 54us/step - loss: 320.1611 - val_loss: 1019.0657\n",
      "Epoch 5361/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 326.5119 - val_loss: 1019.3896\n",
      "Epoch 5362/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 331.7504 - val_loss: 857.6428\n",
      "Epoch 5363/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 523.5380 - val_loss: 1091.7561\n",
      "Epoch 5364/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 607.2206 - val_loss: 895.8531\n",
      "Epoch 5365/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 470.2286 - val_loss: 753.0896\n",
      "Epoch 5366/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 431.9948 - val_loss: 885.8084\n",
      "Epoch 5367/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 387.5605 - val_loss: 844.0214\n",
      "Epoch 5368/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.0593 - val_loss: 852.8268\n",
      "Epoch 5369/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 300.1303 - val_loss: 875.5088\n",
      "Epoch 5370/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 568.6240 - val_loss: 888.9899\n",
      "Epoch 5371/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 459.7095 - val_loss: 881.0527\n",
      "Epoch 5372/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 457.4194 - val_loss: 854.1777\n",
      "Epoch 5373/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 431.4577 - val_loss: 884.7059\n",
      "Epoch 5374/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.4168 - val_loss: 857.0747\n",
      "Epoch 5375/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 318.4362 - val_loss: 932.3556\n",
      "Epoch 5376/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 312.9384 - val_loss: 823.7259\n",
      "Epoch 5377/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 449.7258 - val_loss: 792.5465\n",
      "Epoch 5378/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 414.3839 - val_loss: 905.8299\n",
      "Epoch 5379/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.7431 - val_loss: 880.9842\n",
      "Epoch 5380/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 371.0552 - val_loss: 881.6956\n",
      "Epoch 5381/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.0026 - val_loss: 787.2368\n",
      "Epoch 5382/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.6539 - val_loss: 791.1938\n",
      "Epoch 5383/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 388.9804 - val_loss: 979.5752\n",
      "Epoch 5384/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 338.5321 - val_loss: 832.6724\n",
      "Epoch 5385/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 352.6848 - val_loss: 779.7675\n",
      "Epoch 5386/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 304.4813 - val_loss: 852.7616\n",
      "Epoch 5387/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 317.3178 - val_loss: 832.8580\n",
      "Epoch 5388/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 308.1867 - val_loss: 858.2961\n",
      "Epoch 5389/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 299.8688 - val_loss: 866.0042\n",
      "Epoch 5390/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 304.0028 - val_loss: 875.5267\n",
      "Epoch 5391/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 292.6655 - val_loss: 800.5374\n",
      "Epoch 5392/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 307.5725 - val_loss: 760.2767\n",
      "Epoch 5393/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 319.2430 - val_loss: 786.8589\n",
      "Epoch 5394/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 307.2242 - val_loss: 774.0220\n",
      "Epoch 5395/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 356.3693 - val_loss: 727.5010\n",
      "Epoch 5396/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 454.2461 - val_loss: 1155.5383\n",
      "Epoch 5397/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 418.3273 - val_loss: 860.6123\n",
      "Epoch 5398/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 364.9429 - val_loss: 759.2727\n",
      "Epoch 5399/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 317.6453 - val_loss: 764.3039\n",
      "Epoch 5400/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.7782 - val_loss: 868.0352\n",
      "Epoch 5401/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 331.5491 - val_loss: 842.0815\n",
      "Epoch 5402/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.5998 - val_loss: 827.1437\n",
      "Epoch 5403/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 317.6712 - val_loss: 840.3835\n",
      "Epoch 5404/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.9151 - val_loss: 774.0295\n",
      "Epoch 5405/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.8832 - val_loss: 971.9845\n",
      "Epoch 5406/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 333.9621 - val_loss: 852.9440\n",
      "Epoch 5407/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 306.9326 - val_loss: 841.2942\n",
      "Epoch 5408/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 318.5994 - val_loss: 820.1395\n",
      "Epoch 5409/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 304.8167 - val_loss: 843.4422\n",
      "Epoch 5410/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 326.7090 - val_loss: 781.4991\n",
      "Epoch 5411/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 306.8789 - val_loss: 845.5100\n",
      "Epoch 5412/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 305.0517 - val_loss: 743.6156\n",
      "Epoch 5413/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 298.8348 - val_loss: 896.8272\n",
      "Epoch 5414/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 443.5495 - val_loss: 1697.5806\n",
      "Epoch 5415/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2080.7762 - val_loss: 1570.4390\n",
      "Epoch 5416/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2062.6760 - val_loss: 1690.9176\n",
      "Epoch 5417/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1961.8918 - val_loss: 1702.4310\n",
      "Epoch 5418/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 2091.7060 - val_loss: 1582.3271\n",
      "Epoch 5419/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1574.8815 - val_loss: 1824.6433\n",
      "Epoch 5420/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1216.3834 - val_loss: 1439.3135\n",
      "Epoch 5421/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 956.9425 - val_loss: 1390.3231\n",
      "Epoch 5422/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 789.4336 - val_loss: 1355.9446\n",
      "Epoch 5423/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 610.3278 - val_loss: 1050.3877\n",
      "Epoch 5424/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 526.7879 - val_loss: 774.8557\n",
      "Epoch 5425/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 624.9782 - val_loss: 809.1676\n",
      "Epoch 5426/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 704.9854 - val_loss: 863.0429\n",
      "Epoch 5427/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 550.9240 - val_loss: 834.8160\n",
      "Epoch 5428/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 547.0018 - val_loss: 739.6543\n",
      "Epoch 5429/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 449.5311 - val_loss: 841.4387\n",
      "Epoch 5430/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 416.5700 - val_loss: 839.7592\n",
      "Epoch 5431/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 602.2344 - val_loss: 806.1937\n",
      "Epoch 5432/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 657.3826 - val_loss: 1357.4315\n",
      "Epoch 5433/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 552.5564 - val_loss: 921.6696\n",
      "Epoch 5434/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 418.3817 - val_loss: 823.0765\n",
      "Epoch 5435/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 366.3152 - val_loss: 973.0370\n",
      "Epoch 5436/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 395.7000 - val_loss: 997.9970\n",
      "Epoch 5437/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 367.8984 - val_loss: 940.6328\n",
      "Epoch 5438/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.0277 - val_loss: 834.0195\n",
      "Epoch 5439/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 450.6547 - val_loss: 928.3507\n",
      "Epoch 5440/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 392.6446 - val_loss: 960.7999\n",
      "Epoch 5441/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 395.0379 - val_loss: 996.0874\n",
      "Epoch 5442/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 417.8571 - val_loss: 822.3700\n",
      "Epoch 5443/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 390.7035 - val_loss: 932.1605\n",
      "Epoch 5444/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 394.4713 - val_loss: 880.9927\n",
      "Epoch 5445/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 426.6815 - val_loss: 725.9872\n",
      "Epoch 5446/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 387.5582 - val_loss: 776.0214\n",
      "Epoch 5447/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 392.3719 - val_loss: 773.4927\n",
      "Epoch 5448/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.0622 - val_loss: 859.2760\n",
      "Epoch 5449/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 342.1233 - val_loss: 859.8186\n",
      "Epoch 5450/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.5824 - val_loss: 1118.3778\n",
      "Epoch 5451/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 450.9623 - val_loss: 871.6865\n",
      "Epoch 5452/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 394.6430 - val_loss: 846.8769\n",
      "Epoch 5453/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 360.7798 - val_loss: 1012.4607\n",
      "Epoch 5454/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 414.5365 - val_loss: 744.7660\n",
      "Epoch 5455/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.1606 - val_loss: 705.7457\n",
      "Epoch 5456/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 409.6062 - val_loss: 775.9275\n",
      "Epoch 5457/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 378.5784 - val_loss: 919.0928\n",
      "Epoch 5458/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 350.3393 - val_loss: 1056.2512\n",
      "Epoch 5459/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 520.3747 - val_loss: 897.0980\n",
      "Epoch 5460/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 556.4781 - val_loss: 720.9770\n",
      "Epoch 5461/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 475.4248 - val_loss: 898.4107\n",
      "Epoch 5462/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 452.8353 - val_loss: 1046.5555\n",
      "Epoch 5463/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 418.9221 - val_loss: 830.1284\n",
      "Epoch 5464/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 358.6115 - val_loss: 787.6959\n",
      "Epoch 5465/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 394.7422 - val_loss: 754.4283\n",
      "Epoch 5466/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 406.0145 - val_loss: 844.5450\n",
      "Epoch 5467/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 375.7110 - val_loss: 787.1996\n",
      "Epoch 5468/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 337.0499 - val_loss: 781.4581\n",
      "Epoch 5469/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 349.8983 - val_loss: 925.3980\n",
      "Epoch 5470/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 327.9743 - val_loss: 947.9240\n",
      "Epoch 5471/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 361.2421 - val_loss: 864.2998\n",
      "Epoch 5472/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 369.5758 - val_loss: 785.1398\n",
      "Epoch 5473/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 323.5703 - val_loss: 849.2221\n",
      "Epoch 5474/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 336.3155 - val_loss: 1062.5583\n",
      "Epoch 5475/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 449.1437 - val_loss: 857.6008\n",
      "Epoch 5476/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 423.5148 - val_loss: 793.6175\n",
      "Epoch 5477/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 398.9761 - val_loss: 888.0496\n",
      "Epoch 5478/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 521.0455 - val_loss: 1160.1945\n",
      "Epoch 5479/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 623.2131 - val_loss: 1040.3002\n",
      "Epoch 5480/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 443.4425 - val_loss: 804.0351\n",
      "Epoch 5481/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 402.1692 - val_loss: 770.5080\n",
      "Epoch 5482/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 337.3348 - val_loss: 834.6240\n",
      "Epoch 5483/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.1654 - val_loss: 915.4321\n",
      "Epoch 5484/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 331.9491 - val_loss: 876.6813\n",
      "Epoch 5485/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 331.5769 - val_loss: 936.7138\n",
      "Epoch 5486/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 364.5141 - val_loss: 1022.6827\n",
      "Epoch 5487/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 349.2291 - val_loss: 936.6070\n",
      "Epoch 5488/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.1534 - val_loss: 898.8379\n",
      "Epoch 5489/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 313.0365 - val_loss: 987.0240\n",
      "Epoch 5490/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 897.3189 - val_loss: 1454.7811\n",
      "Epoch 5491/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1398.3250 - val_loss: 1428.4665\n",
      "Epoch 5492/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1296.0108 - val_loss: 1137.1382\n",
      "Epoch 5493/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1109.3126 - val_loss: 1149.1510\n",
      "Epoch 5494/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 984.7096 - val_loss: 1146.7689\n",
      "Epoch 5495/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 854.5422 - val_loss: 1434.1011\n",
      "Epoch 5496/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 822.0415 - val_loss: 1309.1361\n",
      "Epoch 5497/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 766.4672 - val_loss: 1261.4371\n",
      "Epoch 5498/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 729.1845 - val_loss: 1219.8441\n",
      "Epoch 5499/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 705.1343 - val_loss: 1227.7486\n",
      "Epoch 5500/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 680.6648 - val_loss: 1261.8629\n",
      "Epoch 5501/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 660.2176 - val_loss: 1231.5739\n",
      "Epoch 5502/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 625.8864 - val_loss: 1182.9209\n",
      "Epoch 5503/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 606.3850 - val_loss: 1167.1915\n",
      "Epoch 5504/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 564.8134 - val_loss: 1156.6112\n",
      "Epoch 5505/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 558.7355 - val_loss: 1145.0320\n",
      "Epoch 5506/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 526.1607 - val_loss: 1162.0710\n",
      "Epoch 5507/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 505.4408 - val_loss: 1129.6950\n",
      "Epoch 5508/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 484.0302 - val_loss: 1022.7746\n",
      "Epoch 5509/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 455.0068 - val_loss: 894.5015\n",
      "Epoch 5510/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 420.9795 - val_loss: 947.5485\n",
      "Epoch 5511/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 405.4270 - val_loss: 825.9673\n",
      "Epoch 5512/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 399.4986 - val_loss: 788.1340\n",
      "Epoch 5513/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 395.2296 - val_loss: 776.5885\n",
      "Epoch 5514/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 482.3632 - val_loss: 900.0976\n",
      "Epoch 5515/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 395.7749 - val_loss: 881.4683\n",
      "Epoch 5516/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 375.6553 - val_loss: 861.4916\n",
      "Epoch 5517/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.3579 - val_loss: 903.2661\n",
      "Epoch 5518/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 318.4343 - val_loss: 949.9197\n",
      "Epoch 5519/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.0021 - val_loss: 739.0140\n",
      "Epoch 5520/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.2405 - val_loss: 762.8517\n",
      "Epoch 5521/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 385.4656 - val_loss: 765.5835\n",
      "Epoch 5522/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 396.7689 - val_loss: 756.1621\n",
      "Epoch 5523/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 588.3534 - val_loss: 1487.3413\n",
      "Epoch 5524/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 470.5899 - val_loss: 918.9205\n",
      "Epoch 5525/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 372.1246 - val_loss: 880.4761\n",
      "Epoch 5526/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 363.3509 - val_loss: 937.2174\n",
      "Epoch 5527/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 345.2203 - val_loss: 853.3438\n",
      "Epoch 5528/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 384.0495 - val_loss: 872.5878\n",
      "Epoch 5529/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 385.5473 - val_loss: 958.5502\n",
      "Epoch 5530/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 409.6977 - val_loss: 838.1435\n",
      "Epoch 5531/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 369.5363 - val_loss: 725.9187\n",
      "Epoch 5532/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 366.0447 - val_loss: 765.4019\n",
      "Epoch 5533/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 371.0652 - val_loss: 862.9152\n",
      "Epoch 5534/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 319.7340 - val_loss: 900.9401\n",
      "Epoch 5535/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 313.1364 - val_loss: 1165.9373\n",
      "Epoch 5536/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 445.0095 - val_loss: 897.5060\n",
      "Epoch 5537/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 453.5662 - val_loss: 765.4083\n",
      "Epoch 5538/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 377.6032 - val_loss: 773.0858\n",
      "Epoch 5539/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.7728 - val_loss: 976.6503\n",
      "Epoch 5540/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 355.5029 - val_loss: 926.1855\n",
      "Epoch 5541/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 348.6226 - val_loss: 786.4315\n",
      "Epoch 5542/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 345.1643 - val_loss: 732.0538\n",
      "Epoch 5543/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 373.8316 - val_loss: 781.5312\n",
      "Epoch 5544/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 343.3410 - val_loss: 754.9978\n",
      "Epoch 5545/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 352.6144 - val_loss: 841.1189\n",
      "Epoch 5546/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 321.4670 - val_loss: 742.1415\n",
      "Epoch 5547/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.0054 - val_loss: 878.1997\n",
      "Epoch 5548/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 345.7564 - val_loss: 888.2100\n",
      "Epoch 5549/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.3829 - val_loss: 760.8058\n",
      "Epoch 5550/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 341.6667 - val_loss: 869.7306\n",
      "Epoch 5551/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 344.1533 - val_loss: 839.2936\n",
      "Epoch 5552/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 769.8245 - val_loss: 1134.8677\n",
      "Epoch 5553/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 60us/step - loss: 884.7894 - val_loss: 1022.7960\n",
      "Epoch 5554/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 662.6986 - val_loss: 903.9401\n",
      "Epoch 5555/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 533.8514 - val_loss: 918.9295\n",
      "Epoch 5556/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 477.7927 - val_loss: 971.9367\n",
      "Epoch 5557/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 533.938 - 0s 54us/step - loss: 379.6068 - val_loss: 790.2245\n",
      "Epoch 5558/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 320.3929 - val_loss: 967.4602\n",
      "Epoch 5559/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 309.3002 - val_loss: 807.6204\n",
      "Epoch 5560/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 317.1444 - val_loss: 893.1806\n",
      "Epoch 5561/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 358.0643 - val_loss: 779.0030\n",
      "Epoch 5562/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 374.4775 - val_loss: 812.8466\n",
      "Epoch 5563/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.8374 - val_loss: 782.0170\n",
      "Epoch 5564/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 340.3976 - val_loss: 749.7926\n",
      "Epoch 5565/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 332.9852 - val_loss: 710.3267\n",
      "Epoch 5566/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.7070 - val_loss: 730.2113\n",
      "Epoch 5567/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 341.5695 - val_loss: 845.5734\n",
      "Epoch 5568/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 310.3450 - val_loss: 869.7583\n",
      "Epoch 5569/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 306.2923 - val_loss: 799.1945\n",
      "Epoch 5570/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 315.3143 - val_loss: 765.4138\n",
      "Epoch 5571/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 299.5837 - val_loss: 804.8902\n",
      "Epoch 5572/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 415.4258 - val_loss: 653.8902\n",
      "Epoch 5573/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 473.8089 - val_loss: 805.3892\n",
      "Epoch 5574/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 463.7386 - val_loss: 768.0366\n",
      "Epoch 5575/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 439.9529 - val_loss: 804.2604\n",
      "Epoch 5576/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 388.6784 - val_loss: 962.2652\n",
      "Epoch 5577/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 357.0532 - val_loss: 847.8385\n",
      "Epoch 5578/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 326.5427 - val_loss: 942.5966\n",
      "Epoch 5579/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 321.1977 - val_loss: 924.5500\n",
      "Epoch 5580/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 407.9682 - val_loss: 946.6413\n",
      "Epoch 5581/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 365.3470 - val_loss: 951.6878\n",
      "Epoch 5582/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 388.7666 - val_loss: 854.4315\n",
      "Epoch 5583/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 434.2774 - val_loss: 895.3395\n",
      "Epoch 5584/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 422.8865 - val_loss: 863.3113\n",
      "Epoch 5585/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 380.6847 - val_loss: 781.8961\n",
      "Epoch 5586/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 326.8549 - val_loss: 811.3520\n",
      "Epoch 5587/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 304.0977 - val_loss: 802.7291\n",
      "Epoch 5588/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 300.2897 - val_loss: 802.3844\n",
      "Epoch 5589/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 372.1544 - val_loss: 837.8419\n",
      "Epoch 5590/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 383.3628 - val_loss: 1170.5803\n",
      "Epoch 5591/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 417.6066 - val_loss: 871.7400\n",
      "Epoch 5592/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 346.9892 - val_loss: 776.6452\n",
      "Epoch 5593/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 329.3986 - val_loss: 770.2207\n",
      "Epoch 5594/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.6281 - val_loss: 757.4932\n",
      "Epoch 5595/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 315.3576 - val_loss: 834.5395\n",
      "Epoch 5596/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 320.2957 - val_loss: 858.0627\n",
      "Epoch 5597/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 388.8210 - val_loss: 902.9701\n",
      "Epoch 5598/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 350.1995 - val_loss: 758.1919\n",
      "Epoch 5599/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.3717 - val_loss: 783.0914\n",
      "Epoch 5600/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 337.4428 - val_loss: 730.6810\n",
      "Epoch 5601/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 374.9874 - val_loss: 779.0445\n",
      "Epoch 5602/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 360.9356 - val_loss: 1002.4780\n",
      "Epoch 5603/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.5616 - val_loss: 830.4980\n",
      "Epoch 5604/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.1245 - val_loss: 881.2010\n",
      "Epoch 5605/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 358.8618 - val_loss: 846.2289\n",
      "Epoch 5606/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.1324 - val_loss: 814.6144\n",
      "Epoch 5607/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.7109 - val_loss: 839.8156\n",
      "Epoch 5608/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 393.9600 - val_loss: 869.7346\n",
      "Epoch 5609/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 388.0442 - val_loss: 759.5453\n",
      "Epoch 5610/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 370.3361 - val_loss: 847.6965\n",
      "Epoch 5611/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 343.0396 - val_loss: 771.9111\n",
      "Epoch 5612/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 323.4256 - val_loss: 835.0274\n",
      "Epoch 5613/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 327.7858 - val_loss: 789.7012\n",
      "Epoch 5614/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.9295 - val_loss: 875.4550\n",
      "Epoch 5615/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 305.5781 - val_loss: 814.8445\n",
      "Epoch 5616/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 295.9925 - val_loss: 822.6217\n",
      "Epoch 5617/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 307.4671 - val_loss: 795.7127\n",
      "Epoch 5618/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 382.4378 - val_loss: 1086.3189\n",
      "Epoch 5619/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 405.7495 - val_loss: 932.7966\n",
      "Epoch 5620/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 400.2125 - val_loss: 734.0689\n",
      "Epoch 5621/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 378.8861 - val_loss: 932.0040\n",
      "Epoch 5622/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.7106 - val_loss: 908.6335\n",
      "Epoch 5623/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 374.1488 - val_loss: 925.4951\n",
      "Epoch 5624/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 414.4218 - val_loss: 858.1902\n",
      "Epoch 5625/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 393.4064 - val_loss: 850.5024\n",
      "Epoch 5626/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 332.0985 - val_loss: 788.9291\n",
      "Epoch 5627/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 299.2111 - val_loss: 883.9585\n",
      "Epoch 5628/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 299.7417 - val_loss: 823.5587\n",
      "Epoch 5629/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 313.1858 - val_loss: 771.7800\n",
      "Epoch 5630/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 307.2186 - val_loss: 767.9617\n",
      "Epoch 5631/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.3862 - val_loss: 965.4868\n",
      "Epoch 5632/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 306.6977 - val_loss: 846.7600\n",
      "Epoch 5633/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.0718 - val_loss: 821.8227\n",
      "Epoch 5634/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 344.8788 - val_loss: 756.0431\n",
      "Epoch 5635/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.9452 - val_loss: 749.2138\n",
      "Epoch 5636/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 308.9332 - val_loss: 774.8973\n",
      "Epoch 5637/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 392.7099 - val_loss: 892.0618\n",
      "Epoch 5638/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 413.5008 - val_loss: 824.1612\n",
      "Epoch 5639/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 409.2766 - val_loss: 882.4847\n",
      "Epoch 5640/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.9158 - val_loss: 866.1403\n",
      "Epoch 5641/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 332.9934 - val_loss: 896.9856\n",
      "Epoch 5642/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 359.2216 - val_loss: 1027.0266\n",
      "Epoch 5643/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 341.4028 - val_loss: 1040.3476\n",
      "Epoch 5644/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.3035 - val_loss: 830.9855\n",
      "Epoch 5645/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 335.5093 - val_loss: 767.8605\n",
      "Epoch 5646/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 351.9981 - val_loss: 699.4514\n",
      "Epoch 5647/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 384.7103 - val_loss: 758.6260\n",
      "Epoch 5648/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.8697 - val_loss: 762.8642\n",
      "Epoch 5649/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 343.6693 - val_loss: 773.5339\n",
      "Epoch 5650/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 357.0137 - val_loss: 788.3058\n",
      "Epoch 5651/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 325.1586 - val_loss: 816.3114\n",
      "Epoch 5652/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 331.1626 - val_loss: 913.1423\n",
      "Epoch 5653/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 323.0570 - val_loss: 754.0464\n",
      "Epoch 5654/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.0585 - val_loss: 796.9133\n",
      "Epoch 5655/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.0483 - val_loss: 773.6657\n",
      "Epoch 5656/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.0501 - val_loss: 766.2877\n",
      "Epoch 5657/10000\n",
      "630/630 [==============================] - 0s 92us/step - loss: 435.2273 - val_loss: 688.2975\n",
      "Epoch 5658/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 425.8324 - val_loss: 881.3274\n",
      "Epoch 5659/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 401.0553 - val_loss: 868.0048\n",
      "Epoch 5660/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 354.2977 - val_loss: 869.9225\n",
      "Epoch 5661/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 315.0091 - val_loss: 767.9218\n",
      "Epoch 5662/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 365.4067 - val_loss: 897.9179\n",
      "Epoch 5663/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 342.5871 - val_loss: 844.7193\n",
      "Epoch 5664/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 319.7010 - val_loss: 865.8848\n",
      "Epoch 5665/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 347.9099 - val_loss: 1480.3676\n",
      "Epoch 5666/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 606.7937 - val_loss: 928.9328\n",
      "Epoch 5667/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 558.2925 - val_loss: 1054.0531\n",
      "Epoch 5668/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 425.7796 - val_loss: 837.9704\n",
      "Epoch 5669/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 425.1592 - val_loss: 766.4101\n",
      "Epoch 5670/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 470.7096 - val_loss: 719.0760\n",
      "Epoch 5671/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 387.4093 - val_loss: 874.7951\n",
      "Epoch 5672/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 344.1341 - val_loss: 811.0557\n",
      "Epoch 5673/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 434.4621 - val_loss: 835.9596\n",
      "Epoch 5674/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 452.9730 - val_loss: 746.1579\n",
      "Epoch 5675/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 423.3539 - val_loss: 893.5000\n",
      "Epoch 5676/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 370.0488 - val_loss: 802.9751\n",
      "Epoch 5677/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 328.7618 - val_loss: 898.0552\n",
      "Epoch 5678/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 296.8667 - val_loss: 806.7308\n",
      "Epoch 5679/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 312.7644 - val_loss: 725.9479\n",
      "Epoch 5680/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 358.0513 - val_loss: 782.1854\n",
      "Epoch 5681/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 327.5586 - val_loss: 849.0659\n",
      "Epoch 5682/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 330.6884 - val_loss: 759.2464\n",
      "Epoch 5683/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 315.3170 - val_loss: 776.1896\n",
      "Epoch 5684/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 365.7934 - val_loss: 772.9918\n",
      "Epoch 5685/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 340.7202 - val_loss: 888.2174\n",
      "Epoch 5686/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.9050 - val_loss: 819.3960\n",
      "Epoch 5687/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 308.5487 - val_loss: 886.7981\n",
      "Epoch 5688/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 307.8782 - val_loss: 844.1753\n",
      "Epoch 5689/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 349.8788 - val_loss: 723.9634\n",
      "Epoch 5690/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 351.3673 - val_loss: 982.4153\n",
      "Epoch 5691/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 522.8161 - val_loss: 1000.1947\n",
      "Epoch 5692/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 541.7986 - val_loss: 873.8899\n",
      "Epoch 5693/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 423.0651 - val_loss: 763.4348\n",
      "Epoch 5694/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 376.5334 - val_loss: 782.2990\n",
      "Epoch 5695/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 356.7742 - val_loss: 856.3955\n",
      "Epoch 5696/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 328.1995 - val_loss: 896.7509\n",
      "Epoch 5697/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 360.0315 - val_loss: 770.1034\n",
      "Epoch 5698/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 337.9776 - val_loss: 862.7384\n",
      "Epoch 5699/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 337.9186 - val_loss: 845.3339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5700/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 458.2824 - val_loss: 818.2618\n",
      "Epoch 5701/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.8551 - val_loss: 800.0719\n",
      "Epoch 5702/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 380.0287 - val_loss: 846.8310\n",
      "Epoch 5703/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.7055 - val_loss: 979.9113\n",
      "Epoch 5704/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 689.0358 - val_loss: 1762.2809\n",
      "Epoch 5705/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1009.2648 - val_loss: 1448.2736\n",
      "Epoch 5706/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1093.3758 - val_loss: 1051.4560\n",
      "Epoch 5707/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1111.7098 - val_loss: 1112.3508\n",
      "Epoch 5708/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 793.0823 - val_loss: 1067.3218\n",
      "Epoch 5709/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 683.1817 - val_loss: 1080.4893\n",
      "Epoch 5710/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 648.9276 - val_loss: 1020.2074\n",
      "Epoch 5711/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 641.0624 - val_loss: 1018.5293\n",
      "Epoch 5712/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 620.6168 - val_loss: 830.0716\n",
      "Epoch 5713/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 786.1366 - val_loss: 776.9673\n",
      "Epoch 5714/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 606.6086 - val_loss: 870.7133\n",
      "Epoch 5715/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 549.8764 - val_loss: 861.8096\n",
      "Epoch 5716/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 533.6736 - val_loss: 905.9686\n",
      "Epoch 5717/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 444.6193 - val_loss: 1052.2829\n",
      "Epoch 5718/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 632.7685 - val_loss: 1350.7380\n",
      "Epoch 5719/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 761.9541 - val_loss: 1055.6591\n",
      "Epoch 5720/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 629.6018 - val_loss: 890.6910\n",
      "Epoch 5721/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 438.3184 - val_loss: 900.7591\n",
      "Epoch 5722/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 400.0434 - val_loss: 902.3732\n",
      "Epoch 5723/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 377.9271 - val_loss: 887.1724\n",
      "Epoch 5724/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 371.6289 - val_loss: 1373.2591\n",
      "Epoch 5725/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1045.0058 - val_loss: 1524.9562\n",
      "Epoch 5726/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1088.0416 - val_loss: 1420.1044\n",
      "Epoch 5727/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 811.3457 - val_loss: 1305.2027\n",
      "Epoch 5728/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 607.7341 - val_loss: 896.9958\n",
      "Epoch 5729/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 534.5597 - val_loss: 780.3193\n",
      "Epoch 5730/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 564.0337 - val_loss: 1700.8900\n",
      "Epoch 5731/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1686.8427 - val_loss: 1690.6225\n",
      "Epoch 5732/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1311.7803 - val_loss: 1971.7818\n",
      "Epoch 5733/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 936.0360 - val_loss: 1147.9265\n",
      "Epoch 5734/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 633.3293 - val_loss: 1359.2822\n",
      "Epoch 5735/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 644.2860 - val_loss: 1114.9748\n",
      "Epoch 5736/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 490.6078 - val_loss: 856.7523\n",
      "Epoch 5737/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 404.4310 - val_loss: 1051.4110\n",
      "Epoch 5738/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 400.5656 - val_loss: 853.4174\n",
      "Epoch 5739/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.2560 - val_loss: 844.6940\n",
      "Epoch 5740/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 347.6137 - val_loss: 1434.4931\n",
      "Epoch 5741/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 678.6626 - val_loss: 1127.3450\n",
      "Epoch 5742/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 607.2462 - val_loss: 1050.7434\n",
      "Epoch 5743/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 637.2615 - val_loss: 841.3800\n",
      "Epoch 5744/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 552.9906 - val_loss: 796.0021\n",
      "Epoch 5745/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 512.1309 - val_loss: 689.2426\n",
      "Epoch 5746/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 426.6428 - val_loss: 717.4898\n",
      "Epoch 5747/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 364.5942 - val_loss: 843.2711\n",
      "Epoch 5748/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 341.8495 - val_loss: 835.8576\n",
      "Epoch 5749/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 375.9107 - val_loss: 824.8781\n",
      "Epoch 5750/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 390.8924 - val_loss: 695.5062\n",
      "Epoch 5751/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 351.8842 - val_loss: 891.5164\n",
      "Epoch 5752/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 740.4591 - val_loss: 1016.8566\n",
      "Epoch 5753/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 886.8157 - val_loss: 941.2697\n",
      "Epoch 5754/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 750.2928 - val_loss: 876.7134\n",
      "Epoch 5755/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 682.4853 - val_loss: 858.4280\n",
      "Epoch 5756/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 525.7073 - val_loss: 739.3999\n",
      "Epoch 5757/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 473.4928 - val_loss: 800.3502\n",
      "Epoch 5758/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 416.2764 - val_loss: 833.8200\n",
      "Epoch 5759/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 410.4315 - val_loss: 1085.9587\n",
      "Epoch 5760/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 449.3063 - val_loss: 790.6957\n",
      "Epoch 5761/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 410.3912 - val_loss: 1093.1085\n",
      "Epoch 5762/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 512.3772 - val_loss: 817.6685\n",
      "Epoch 5763/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 456.5445 - val_loss: 740.6265\n",
      "Epoch 5764/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 430.3346 - val_loss: 728.0433\n",
      "Epoch 5765/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 411.3818 - val_loss: 756.8175\n",
      "Epoch 5766/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.4719 - val_loss: 895.7870\n",
      "Epoch 5767/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 452.1414 - val_loss: 733.9617\n",
      "Epoch 5768/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 409.4195 - val_loss: 788.3011\n",
      "Epoch 5769/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 459.3728 - val_loss: 849.4479\n",
      "Epoch 5770/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 833.7802 - val_loss: 765.3336\n",
      "Epoch 5771/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 593.8659 - val_loss: 862.2277\n",
      "Epoch 5772/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 487.2152 - val_loss: 899.0534\n",
      "Epoch 5773/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 408.9020 - val_loss: 913.8860\n",
      "Epoch 5774/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 372.2655 - val_loss: 832.1773\n",
      "Epoch 5775/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 422.5450 - val_loss: 960.5888\n",
      "Epoch 5776/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 392.5273 - val_loss: 919.3647\n",
      "Epoch 5777/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 408.2785 - val_loss: 780.8418\n",
      "Epoch 5778/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.3637 - val_loss: 774.1335\n",
      "Epoch 5779/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.0232 - val_loss: 793.4510\n",
      "Epoch 5780/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 355.4059 - val_loss: 853.0820\n",
      "Epoch 5781/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 353.1602 - val_loss: 814.6128\n",
      "Epoch 5782/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 421.5836 - val_loss: 881.6379\n",
      "Epoch 5783/10000\n",
      "630/630 [==============================] - 0s 78us/step - loss: 400.8993 - val_loss: 777.9382\n",
      "Epoch 5784/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 390.3021 - val_loss: 839.7164\n",
      "Epoch 5785/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 358.3261 - val_loss: 810.3523\n",
      "Epoch 5786/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 377.0656 - val_loss: 899.7901\n",
      "Epoch 5787/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 355.0606 - val_loss: 1204.3587\n",
      "Epoch 5788/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 862.1730 - val_loss: 1168.4960\n",
      "Epoch 5789/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 830.4618 - val_loss: 1137.3374\n",
      "Epoch 5790/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 673.0656 - val_loss: 982.1551\n",
      "Epoch 5791/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 548.8749 - val_loss: 1144.4854\n",
      "Epoch 5792/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 475.4768 - val_loss: 809.1366\n",
      "Epoch 5793/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 400.4171 - val_loss: 784.6394\n",
      "Epoch 5794/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 404.6880 - val_loss: 820.8758\n",
      "Epoch 5795/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 368.9701 - val_loss: 928.0911\n",
      "Epoch 5796/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 324.0172 - val_loss: 784.2413\n",
      "Epoch 5797/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 345.1529 - val_loss: 810.2952\n",
      "Epoch 5798/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 326.6689 - val_loss: 1425.6437\n",
      "Epoch 5799/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 715.7089 - val_loss: 1186.8997\n",
      "Epoch 5800/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 714.6672 - val_loss: 1134.6617\n",
      "Epoch 5801/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 587.7086 - val_loss: 849.2515\n",
      "Epoch 5802/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 480.4068 - val_loss: 738.6529\n",
      "Epoch 5803/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 394.8587 - val_loss: 875.5912\n",
      "Epoch 5804/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.2739 - val_loss: 821.6548\n",
      "Epoch 5805/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 313.8491 - val_loss: 823.0650\n",
      "Epoch 5806/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 289.5072 - val_loss: 844.5688\n",
      "Epoch 5807/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 298.8093 - val_loss: 821.7818\n",
      "Epoch 5808/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 294.3268 - val_loss: 878.3981\n",
      "Epoch 5809/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 320.9547 - val_loss: 894.7095\n",
      "Epoch 5810/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 305.4078 - val_loss: 789.7128\n",
      "Epoch 5811/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 297.3648 - val_loss: 786.4309\n",
      "Epoch 5812/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 283.5366 - val_loss: 780.4231\n",
      "Epoch 5813/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 312.0592 - val_loss: 882.3660\n",
      "Epoch 5814/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 416.5936 - val_loss: 777.8771\n",
      "Epoch 5815/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 396.0878 - val_loss: 883.8724\n",
      "Epoch 5816/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 358.4260 - val_loss: 795.7506\n",
      "Epoch 5817/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 372.7149 - val_loss: 903.8970\n",
      "Epoch 5818/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 406.8370 - val_loss: 863.8144\n",
      "Epoch 5819/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 486.3581 - val_loss: 1135.1253\n",
      "Epoch 5820/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 459.3095 - val_loss: 926.3810\n",
      "Epoch 5821/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 439.6350 - val_loss: 793.9886\n",
      "Epoch 5822/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 399.1089 - val_loss: 737.3929\n",
      "Epoch 5823/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 352.8553 - val_loss: 842.9278\n",
      "Epoch 5824/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 318.0118 - val_loss: 863.2688\n",
      "Epoch 5825/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 359.7203 - val_loss: 817.7659\n",
      "Epoch 5826/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 403.5355 - val_loss: 825.4906\n",
      "Epoch 5827/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 363.8815 - val_loss: 903.6599\n",
      "Epoch 5828/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 323.6590 - val_loss: 928.5239\n",
      "Epoch 5829/10000\n",
      "630/630 [==============================] - 0s 89us/step - loss: 326.0079 - val_loss: 742.0055\n",
      "Epoch 5830/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 304.1291 - val_loss: 788.8363\n",
      "Epoch 5831/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 337.1367 - val_loss: 812.2603\n",
      "Epoch 5832/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 330.0865 - val_loss: 877.8697\n",
      "Epoch 5833/10000\n",
      "630/630 [==============================] - 0s 79us/step - loss: 301.5010 - val_loss: 831.1177\n",
      "Epoch 5834/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 298.9542 - val_loss: 981.6806\n",
      "Epoch 5835/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 323.4349 - val_loss: 805.3804\n",
      "Epoch 5836/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 326.4030 - val_loss: 772.1076\n",
      "Epoch 5837/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 304.1732 - val_loss: 839.0144\n",
      "Epoch 5838/10000\n",
      "630/630 [==============================] - 0s 78us/step - loss: 290.3299 - val_loss: 795.8603\n",
      "Epoch 5839/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 301.1461 - val_loss: 912.7281\n",
      "Epoch 5840/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 304.9364 - val_loss: 854.9775\n",
      "Epoch 5841/10000\n",
      "630/630 [==============================] - 0s 82us/step - loss: 444.0683 - val_loss: 977.6040\n",
      "Epoch 5842/10000\n",
      "630/630 [==============================] - 0s 90us/step - loss: 774.6953 - val_loss: 967.4756\n",
      "Epoch 5843/10000\n",
      "630/630 [==============================] - 0s 78us/step - loss: 675.7158 - val_loss: 886.0277\n",
      "Epoch 5844/10000\n",
      "630/630 [==============================] - 0s 84us/step - loss: 618.5305 - val_loss: 1302.9281\n",
      "Epoch 5845/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 507.9783 - val_loss: 937.2649\n",
      "Epoch 5846/10000\n",
      "630/630 [==============================] - 0s 100us/step - loss: 424.6375 - val_loss: 818.1547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5847/10000\n",
      "630/630 [==============================] - 0s 98us/step - loss: 360.5711 - val_loss: 778.3068\n",
      "Epoch 5848/10000\n",
      "630/630 [==============================] - 0s 150us/step - loss: 354.7753 - val_loss: 757.8051\n",
      "Epoch 5849/10000\n",
      "630/630 [==============================] - 0s 147us/step - loss: 325.0969 - val_loss: 859.2140\n",
      "Epoch 5850/10000\n",
      "630/630 [==============================] - 0s 111us/step - loss: 324.8785 - val_loss: 783.4527\n",
      "Epoch 5851/10000\n",
      "630/630 [==============================] - 0s 92us/step - loss: 326.0070 - val_loss: 779.1558\n",
      "Epoch 5852/10000\n",
      "630/630 [==============================] - 0s 111us/step - loss: 387.5001 - val_loss: 891.7592\n",
      "Epoch 5853/10000\n",
      "630/630 [==============================] - 0s 79us/step - loss: 464.6042 - val_loss: 855.6420\n",
      "Epoch 5854/10000\n",
      "630/630 [==============================] - 0s 93us/step - loss: 549.1595 - val_loss: 948.3228\n",
      "Epoch 5855/10000\n",
      "630/630 [==============================] - 0s 79us/step - loss: 428.5627 - val_loss: 923.4872\n",
      "Epoch 5856/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 431.8777 - val_loss: 722.2165\n",
      "Epoch 5857/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 516.6350 - val_loss: 860.0947\n",
      "Epoch 5858/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 445.7679 - val_loss: 869.1175\n",
      "Epoch 5859/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 383.3911 - val_loss: 1257.1797\n",
      "Epoch 5860/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 457.5018 - val_loss: 744.7123\n",
      "Epoch 5861/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 373.3191 - val_loss: 773.3872\n",
      "Epoch 5862/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 1035.3095 - val_loss: 907.6082\n",
      "Epoch 5863/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 858.4491 - val_loss: 1050.0152\n",
      "Epoch 5864/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 672.9175 - val_loss: 1027.4285\n",
      "Epoch 5865/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 638.9557 - val_loss: 927.0812\n",
      "Epoch 5866/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 518.1920 - val_loss: 833.4737\n",
      "Epoch 5867/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 450.9455 - val_loss: 767.5685\n",
      "Epoch 5868/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 378.5323 - val_loss: 896.7500\n",
      "Epoch 5869/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 342.3498 - val_loss: 894.1444\n",
      "Epoch 5870/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 359.9204 - val_loss: 740.5455\n",
      "Epoch 5871/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 361.9322 - val_loss: 936.4636\n",
      "Epoch 5872/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.6443 - val_loss: 850.8400\n",
      "Epoch 5873/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 303.5364 - val_loss: 846.0761\n",
      "Epoch 5874/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 294.8019 - val_loss: 890.1768\n",
      "Epoch 5875/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 297.0128 - val_loss: 757.2470\n",
      "Epoch 5876/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 306.6190 - val_loss: 775.3189\n",
      "Epoch 5877/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 313.0931 - val_loss: 844.9701\n",
      "Epoch 5878/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 301.1483 - val_loss: 823.2485\n",
      "Epoch 5879/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 286.8287 - val_loss: 864.0686\n",
      "Epoch 5880/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 305.0030 - val_loss: 781.3947\n",
      "Epoch 5881/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 301.7807 - val_loss: 842.5968\n",
      "Epoch 5882/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 327.7757 - val_loss: 853.2852\n",
      "Epoch 5883/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.3060 - val_loss: 758.4040\n",
      "Epoch 5884/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 305.4987 - val_loss: 864.7276\n",
      "Epoch 5885/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 301.4523 - val_loss: 1048.2902\n",
      "Epoch 5886/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 764.8649 - val_loss: 961.7424\n",
      "Epoch 5887/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 834.8091 - val_loss: 970.9947\n",
      "Epoch 5888/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 711.3373 - val_loss: 984.5745\n",
      "Epoch 5889/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 619.8211 - val_loss: 912.9213\n",
      "Epoch 5890/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 599.1941 - val_loss: 1031.6451\n",
      "Epoch 5891/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 537.0487 - val_loss: 940.2462\n",
      "Epoch 5892/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 481.3923 - val_loss: 999.6245\n",
      "Epoch 5893/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 451.2496 - val_loss: 886.4351\n",
      "Epoch 5894/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 384.6534 - val_loss: 873.0258\n",
      "Epoch 5895/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 345.9276 - val_loss: 827.5844\n",
      "Epoch 5896/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 339.3321 - val_loss: 961.5156\n",
      "Epoch 5897/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 346.8388 - val_loss: 988.9492\n",
      "Epoch 5898/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 327.6939 - val_loss: 890.3543\n",
      "Epoch 5899/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 350.2029 - val_loss: 806.9568\n",
      "Epoch 5900/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 328.6990 - val_loss: 728.2878\n",
      "Epoch 5901/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 350.6165 - val_loss: 797.3188\n",
      "Epoch 5902/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.7022 - val_loss: 862.5320\n",
      "Epoch 5903/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 297.0619 - val_loss: 843.4192\n",
      "Epoch 5904/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 301.6845 - val_loss: 811.5604\n",
      "Epoch 5905/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 300.6745 - val_loss: 778.1595\n",
      "Epoch 5906/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 304.6843 - val_loss: 826.6898\n",
      "Epoch 5907/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 287.9077 - val_loss: 879.6759\n",
      "Epoch 5908/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 284.0735 - val_loss: 911.6856\n",
      "Epoch 5909/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 343.9199 - val_loss: 799.1465\n",
      "Epoch 5910/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 362.2160 - val_loss: 833.5050\n",
      "Epoch 5911/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 343.7876 - val_loss: 848.6899\n",
      "Epoch 5912/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 328.2368 - val_loss: 825.5357\n",
      "Epoch 5913/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 300.5207 - val_loss: 832.2095\n",
      "Epoch 5914/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 391.3346 - val_loss: 869.9512\n",
      "Epoch 5915/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 418.5121 - val_loss: 764.6270\n",
      "Epoch 5916/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 400.1328 - val_loss: 810.6088\n",
      "Epoch 5917/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 411.2835 - val_loss: 674.6710\n",
      "Epoch 5918/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 398.5193 - val_loss: 801.1778\n",
      "Epoch 5919/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 352.3606 - val_loss: 824.6317\n",
      "Epoch 5920/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 375.4001 - val_loss: 971.1695\n",
      "Epoch 5921/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 320.8791 - val_loss: 792.4200\n",
      "Epoch 5922/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.7042 - val_loss: 875.2599\n",
      "Epoch 5923/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 308.1106 - val_loss: 792.3891\n",
      "Epoch 5924/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 328.6044 - val_loss: 843.0829\n",
      "Epoch 5925/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.0520 - val_loss: 757.3649\n",
      "Epoch 5926/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 299.8101 - val_loss: 806.7137\n",
      "Epoch 5927/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 318.9523 - val_loss: 785.6133\n",
      "Epoch 5928/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 311.8207 - val_loss: 770.5348\n",
      "Epoch 5929/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 311.1510 - val_loss: 754.3562\n",
      "Epoch 5930/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 304.8284 - val_loss: 780.7335\n",
      "Epoch 5931/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.8063 - val_loss: 880.1667\n",
      "Epoch 5932/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 322.7502 - val_loss: 820.5807\n",
      "Epoch 5933/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 312.7193 - val_loss: 908.4047\n",
      "Epoch 5934/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 392.1108 - val_loss: 965.3861\n",
      "Epoch 5935/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 417.6553 - val_loss: 818.7827\n",
      "Epoch 5936/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 418.1024 - val_loss: 858.6461\n",
      "Epoch 5937/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 373.5045 - val_loss: 889.0460\n",
      "Epoch 5938/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.2300 - val_loss: 935.5025\n",
      "Epoch 5939/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.2761 - val_loss: 829.2305\n",
      "Epoch 5940/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 292.9408 - val_loss: 791.6624\n",
      "Epoch 5941/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 372.5970 - val_loss: 840.9883\n",
      "Epoch 5942/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 501.3014 - val_loss: 761.1341\n",
      "Epoch 5943/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 398.9734 - val_loss: 816.1161\n",
      "Epoch 5944/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 385.8565 - val_loss: 829.8223\n",
      "Epoch 5945/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.5494 - val_loss: 842.0070\n",
      "Epoch 5946/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.5870 - val_loss: 829.4033\n",
      "Epoch 5947/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.8316 - val_loss: 749.1563\n",
      "Epoch 5948/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 493.7442 - val_loss: 887.1367\n",
      "Epoch 5949/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.4869 - val_loss: 844.4167\n",
      "Epoch 5950/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 331.1910 - val_loss: 2214.3654\n",
      "Epoch 5951/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 848.2415 - val_loss: 939.6399\n",
      "Epoch 5952/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 734.6318 - val_loss: 1072.3264\n",
      "Epoch 5953/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 731.3486 - val_loss: 856.1138\n",
      "Epoch 5954/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 629.2055 - val_loss: 902.0501\n",
      "Epoch 5955/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 495.0230 - val_loss: 820.0414\n",
      "Epoch 5956/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 392.6486 - val_loss: 906.2748\n",
      "Epoch 5957/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 406.7827 - val_loss: 864.9537\n",
      "Epoch 5958/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 369.8797 - val_loss: 867.4801\n",
      "Epoch 5959/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.2546 - val_loss: 977.2714\n",
      "Epoch 5960/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.6453 - val_loss: 730.2956\n",
      "Epoch 5961/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 339.8765 - val_loss: 922.8805\n",
      "Epoch 5962/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 404.6890 - val_loss: 822.6044\n",
      "Epoch 5963/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 351.7168 - val_loss: 762.7141\n",
      "Epoch 5964/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 350.7174 - val_loss: 831.1395\n",
      "Epoch 5965/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 333.1152 - val_loss: 789.5582\n",
      "Epoch 5966/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 301.5294 - val_loss: 859.8393\n",
      "Epoch 5967/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 343.5551 - val_loss: 853.6347\n",
      "Epoch 5968/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.8057 - val_loss: 826.7912\n",
      "Epoch 5969/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 303.8419 - val_loss: 801.3705\n",
      "Epoch 5970/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 291.0676 - val_loss: 787.8996\n",
      "Epoch 5971/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 284.5044 - val_loss: 828.9427\n",
      "Epoch 5972/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 303.8518 - val_loss: 800.2212\n",
      "Epoch 5973/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 309.6961 - val_loss: 847.8654\n",
      "Epoch 5974/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 299.1948 - val_loss: 762.6776\n",
      "Epoch 5975/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 639.1186 - val_loss: 1063.5291\n",
      "Epoch 5976/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 722.8983 - val_loss: 849.2090\n",
      "Epoch 5977/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 549.0696 - val_loss: 851.7072\n",
      "Epoch 5978/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 479.1659 - val_loss: 867.3821\n",
      "Epoch 5979/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 431.2809 - val_loss: 869.1358\n",
      "Epoch 5980/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 408.3949 - val_loss: 919.1550\n",
      "Epoch 5981/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 404.5988 - val_loss: 1156.0953\n",
      "Epoch 5982/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 405.9003 - val_loss: 995.6511\n",
      "Epoch 5983/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 405.1959 - val_loss: 695.5557\n",
      "Epoch 5984/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 646.9587 - val_loss: 1324.9233\n",
      "Epoch 5985/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 808.1545 - val_loss: 1221.0077\n",
      "Epoch 5986/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 539.9831 - val_loss: 1065.9101\n",
      "Epoch 5987/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 487.6877 - val_loss: 1183.9340\n",
      "Epoch 5988/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 468.2510 - val_loss: 789.3501\n",
      "Epoch 5989/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.8681 - val_loss: 756.0487\n",
      "Epoch 5990/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 392.2519 - val_loss: 746.1313\n",
      "Epoch 5991/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 389.8580 - val_loss: 842.4616\n",
      "Epoch 5992/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.6410 - val_loss: 1020.1265\n",
      "Epoch 5993/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 472.6720 - val_loss: 887.0457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5994/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 412.1124 - val_loss: 843.8904\n",
      "Epoch 5995/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 413.7682 - val_loss: 745.7501\n",
      "Epoch 5996/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 489.2827 - val_loss: 1467.3104\n",
      "Epoch 5997/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 452.2493 - val_loss: 684.0088\n",
      "Epoch 5998/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 386.9945 - val_loss: 743.4072\n",
      "Epoch 5999/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 395.1434 - val_loss: 831.1878\n",
      "Epoch 6000/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 420.8656 - val_loss: 898.0091\n",
      "Epoch 6001/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 370.2356 - val_loss: 952.5955\n",
      "Epoch 6002/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 361.4062 - val_loss: 964.9573\n",
      "Epoch 6003/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 340.7763 - val_loss: 807.0881\n",
      "Epoch 6004/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 312.6026 - val_loss: 762.5756\n",
      "Epoch 6005/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 308.4614 - val_loss: 859.4609\n",
      "Epoch 6006/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 292.2806 - val_loss: 1006.2729\n",
      "Epoch 6007/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 451.0979 - val_loss: 750.3562\n",
      "Epoch 6008/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.2689 - val_loss: 860.3195\n",
      "Epoch 6009/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 330.3517 - val_loss: 1017.5905\n",
      "Epoch 6010/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 327.9954 - val_loss: 775.6587\n",
      "Epoch 6011/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 332.3574 - val_loss: 776.4252\n",
      "Epoch 6012/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 353.0521 - val_loss: 748.6697\n",
      "Epoch 6013/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 372.2909 - val_loss: 912.3759\n",
      "Epoch 6014/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.2295 - val_loss: 902.1940\n",
      "Epoch 6015/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.1683 - val_loss: 687.3127\n",
      "Epoch 6016/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 339.0100 - val_loss: 766.4876\n",
      "Epoch 6017/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 380.6467 - val_loss: 1324.8560\n",
      "Epoch 6018/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 447.3691 - val_loss: 802.4040\n",
      "Epoch 6019/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 368.9515 - val_loss: 751.4526\n",
      "Epoch 6020/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 349.7762 - val_loss: 759.0292\n",
      "Epoch 6021/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 339.4118 - val_loss: 833.7972\n",
      "Epoch 6022/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 298.1077 - val_loss: 818.7764\n",
      "Epoch 6023/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 297.1692 - val_loss: 808.2120\n",
      "Epoch 6024/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 296.7239 - val_loss: 855.1100\n",
      "Epoch 6025/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 338.5537 - val_loss: 819.6023\n",
      "Epoch 6026/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.0415 - val_loss: 778.9666\n",
      "Epoch 6027/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 362.0613 - val_loss: 861.2642\n",
      "Epoch 6028/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 358.8450 - val_loss: 726.5046\n",
      "Epoch 6029/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 315.9171 - val_loss: 765.6644\n",
      "Epoch 6030/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.4296 - val_loss: 807.8857\n",
      "Epoch 6031/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 336.7433 - val_loss: 958.9910\n",
      "Epoch 6032/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 311.0575 - val_loss: 813.1790\n",
      "Epoch 6033/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 383.3007 - val_loss: 773.5960\n",
      "Epoch 6034/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.0276 - val_loss: 817.1513\n",
      "Epoch 6035/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.6201 - val_loss: 846.5000\n",
      "Epoch 6036/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 387.1976 - val_loss: 840.9154\n",
      "Epoch 6037/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 342.9853 - val_loss: 776.9320\n",
      "Epoch 6038/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 352.9699 - val_loss: 773.9896\n",
      "Epoch 6039/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.6484 - val_loss: 1012.2670\n",
      "Epoch 6040/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 351.0054 - val_loss: 1427.7026\n",
      "Epoch 6041/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 509.7511 - val_loss: 698.2188\n",
      "Epoch 6042/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 410.2824 - val_loss: 855.9907\n",
      "Epoch 6043/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 379.4768 - val_loss: 904.1419\n",
      "Epoch 6044/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 360.8843 - val_loss: 810.5548\n",
      "Epoch 6045/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.6801 - val_loss: 835.1953\n",
      "Epoch 6046/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 291.5828 - val_loss: 808.0729\n",
      "Epoch 6047/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 298.7806 - val_loss: 761.7929\n",
      "Epoch 6048/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 291.4339 - val_loss: 864.5628\n",
      "Epoch 6049/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 279.2823 - val_loss: 832.4578\n",
      "Epoch 6050/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 301.8826 - val_loss: 750.1027\n",
      "Epoch 6051/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 292.4447 - val_loss: 735.5343\n",
      "Epoch 6052/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 305.2233 - val_loss: 751.8858\n",
      "Epoch 6053/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 317.5307 - val_loss: 763.4021\n",
      "Epoch 6054/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.1425 - val_loss: 814.0486\n",
      "Epoch 6055/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.1040 - val_loss: 793.4386\n",
      "Epoch 6056/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.4494 - val_loss: 774.8328\n",
      "Epoch 6057/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 346.1020 - val_loss: 624.7385\n",
      "Epoch 6058/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 663.7606 - val_loss: 964.4233\n",
      "Epoch 6059/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 515.6024 - val_loss: 762.5128\n",
      "Epoch 6060/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 482.7665 - val_loss: 798.7077\n",
      "Epoch 6061/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 426.9774 - val_loss: 904.0360\n",
      "Epoch 6062/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 368.2066 - val_loss: 906.4743\n",
      "Epoch 6063/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 356.0221 - val_loss: 799.9123\n",
      "Epoch 6064/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 321.0837 - val_loss: 901.4276\n",
      "Epoch 6065/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 358.8154 - val_loss: 959.2572\n",
      "Epoch 6066/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 329.9148 - val_loss: 752.6339\n",
      "Epoch 6067/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 329.9441 - val_loss: 864.8126\n",
      "Epoch 6068/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 353.1501 - val_loss: 817.8697\n",
      "Epoch 6069/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.3077 - val_loss: 871.1482\n",
      "Epoch 6070/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 324.8612 - val_loss: 749.8325\n",
      "Epoch 6071/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 408.3865 - val_loss: 755.8562\n",
      "Epoch 6072/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 521.3764 - val_loss: 947.9512\n",
      "Epoch 6073/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 412.2767 - val_loss: 862.8024\n",
      "Epoch 6074/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 373.1730 - val_loss: 779.7632\n",
      "Epoch 6075/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 332.7982 - val_loss: 804.3975\n",
      "Epoch 6076/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 352.2710 - val_loss: 767.3886\n",
      "Epoch 6077/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 337.8474 - val_loss: 815.5247\n",
      "Epoch 6078/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 339.9349 - val_loss: 816.2216\n",
      "Epoch 6079/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 327.3316 - val_loss: 780.1748\n",
      "Epoch 6080/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 315.6643 - val_loss: 866.4861\n",
      "Epoch 6081/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.3532 - val_loss: 872.7412\n",
      "Epoch 6082/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 341.2739 - val_loss: 818.3150\n",
      "Epoch 6083/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 374.1623 - val_loss: 835.1681\n",
      "Epoch 6084/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 328.0052 - val_loss: 933.7785\n",
      "Epoch 6085/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.4206 - val_loss: 828.4295\n",
      "Epoch 6086/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 322.6218 - val_loss: 826.3065\n",
      "Epoch 6087/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 293.8678 - val_loss: 813.9692\n",
      "Epoch 6088/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 285.5674 - val_loss: 836.2103\n",
      "Epoch 6089/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.9219 - val_loss: 852.2837\n",
      "Epoch 6090/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 348.8932 - val_loss: 880.3343\n",
      "Epoch 6091/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 315.6612 - val_loss: 812.0636\n",
      "Epoch 6092/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.3124 - val_loss: 686.1175\n",
      "Epoch 6093/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 363.8556 - val_loss: 812.0593\n",
      "Epoch 6094/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 350.5333 - val_loss: 820.9355\n",
      "Epoch 6095/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 337.9010 - val_loss: 827.2326\n",
      "Epoch 6096/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 304.5573 - val_loss: 819.8591\n",
      "Epoch 6097/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 453.5506 - val_loss: 892.2474\n",
      "Epoch 6098/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1362.6356 - val_loss: 1293.3206\n",
      "Epoch 6099/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1719.0220 - val_loss: 1687.3281\n",
      "Epoch 6100/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1119.7825 - val_loss: 981.1321\n",
      "Epoch 6101/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 719.9384 - val_loss: 921.9141\n",
      "Epoch 6102/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 569.1712 - val_loss: 878.3043\n",
      "Epoch 6103/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 458.9485 - val_loss: 861.7510\n",
      "Epoch 6104/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 364.2702 - val_loss: 834.0562\n",
      "Epoch 6105/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 337.1654 - val_loss: 977.7791\n",
      "Epoch 6106/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.3165 - val_loss: 832.5942\n",
      "Epoch 6107/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 325.6897 - val_loss: 783.0937\n",
      "Epoch 6108/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 322.4225 - val_loss: 789.2797\n",
      "Epoch 6109/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 383.1831 - val_loss: 914.7830\n",
      "Epoch 6110/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 337.3396 - val_loss: 835.7987\n",
      "Epoch 6111/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 397.2589 - val_loss: 643.7475\n",
      "Epoch 6112/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 604.0258 - val_loss: 812.4499\n",
      "Epoch 6113/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 415.4863 - val_loss: 783.8402\n",
      "Epoch 6114/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 359.5584 - val_loss: 1093.2636\n",
      "Epoch 6115/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 403.0944 - val_loss: 779.9683\n",
      "Epoch 6116/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 369.2733 - val_loss: 773.3164\n",
      "Epoch 6117/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 329.4085 - val_loss: 1139.1640\n",
      "Epoch 6118/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 515.2151 - val_loss: 762.1556\n",
      "Epoch 6119/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 502.8372 - val_loss: 998.0188\n",
      "Epoch 6120/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 506.5908 - val_loss: 873.1539\n",
      "Epoch 6121/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 503.1568 - val_loss: 859.1407\n",
      "Epoch 6122/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 457.6368 - val_loss: 940.5568\n",
      "Epoch 6123/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 392.1724 - val_loss: 866.5610\n",
      "Epoch 6124/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 335.8559 - val_loss: 850.1867\n",
      "Epoch 6125/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 300.8981 - val_loss: 798.5506\n",
      "Epoch 6126/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 303.8300 - val_loss: 904.9971\n",
      "Epoch 6127/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 293.7806 - val_loss: 1004.9309\n",
      "Epoch 6128/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.3725 - val_loss: 1057.5310\n",
      "Epoch 6129/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 385.4349 - val_loss: 879.0471\n",
      "Epoch 6130/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.3980 - val_loss: 804.4936\n",
      "Epoch 6131/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 343.4007 - val_loss: 751.7658\n",
      "Epoch 6132/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 378.2669 - val_loss: 862.8942\n",
      "Epoch 6133/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 381.9217 - val_loss: 893.1534\n",
      "Epoch 6134/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 341.0045 - val_loss: 788.3008\n",
      "Epoch 6135/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 415.5196 - val_loss: 858.7243\n",
      "Epoch 6136/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 409.5396 - val_loss: 812.4385\n",
      "Epoch 6137/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 380.4532 - val_loss: 861.1770\n",
      "Epoch 6138/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 386.1577 - val_loss: 773.8381\n",
      "Epoch 6139/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 384.9981 - val_loss: 965.1005\n",
      "Epoch 6140/10000\n",
      "630/630 [==============================] - 0s 82us/step - loss: 363.5002 - val_loss: 838.4262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6141/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 313.5990 - val_loss: 798.0051\n",
      "Epoch 6142/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 337.2833 - val_loss: 766.9703\n",
      "Epoch 6143/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 351.5171 - val_loss: 865.9570\n",
      "Epoch 6144/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 313.7795 - val_loss: 1012.6507\n",
      "Epoch 6145/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 327.7182 - val_loss: 805.5319\n",
      "Epoch 6146/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 343.1971 - val_loss: 847.0648\n",
      "Epoch 6147/10000\n",
      "630/630 [==============================] - 0s 98us/step - loss: 341.5932 - val_loss: 800.0824\n",
      "Epoch 6148/10000\n",
      "630/630 [==============================] - 0s 76us/step - loss: 388.0032 - val_loss: 823.3036\n",
      "Epoch 6149/10000\n",
      "630/630 [==============================] - 0s 74us/step - loss: 350.6310 - val_loss: 821.4892\n",
      "Epoch 6150/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.9232 - val_loss: 850.1873\n",
      "Epoch 6151/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 301.5503 - val_loss: 763.9945\n",
      "Epoch 6152/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 295.2188 - val_loss: 816.0582\n",
      "Epoch 6153/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 303.7971 - val_loss: 769.6984\n",
      "Epoch 6154/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 355.2726 - val_loss: 825.1808\n",
      "Epoch 6155/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.5472 - val_loss: 854.5337\n",
      "Epoch 6156/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 387.9014 - val_loss: 871.2815\n",
      "Epoch 6157/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 359.4295 - val_loss: 941.7306\n",
      "Epoch 6158/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 367.4647 - val_loss: 824.8354\n",
      "Epoch 6159/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 335.0466 - val_loss: 916.3527\n",
      "Epoch 6160/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 350.2052 - val_loss: 788.5283\n",
      "Epoch 6161/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 383.4017 - val_loss: 870.1189\n",
      "Epoch 6162/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.9686 - val_loss: 888.9991\n",
      "Epoch 6163/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.8744 - val_loss: 752.6607\n",
      "Epoch 6164/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.8616 - val_loss: 824.3473\n",
      "Epoch 6165/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 327.6899 - val_loss: 814.2112\n",
      "Epoch 6166/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 317.9657 - val_loss: 803.1666\n",
      "Epoch 6167/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.8496 - val_loss: 788.8735\n",
      "Epoch 6168/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 344.8046 - val_loss: 840.8411\n",
      "Epoch 6169/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 309.6207 - val_loss: 834.2920\n",
      "Epoch 6170/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 320.3058 - val_loss: 898.5283\n",
      "Epoch 6171/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 313.5953 - val_loss: 835.7385\n",
      "Epoch 6172/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 294.2491 - val_loss: 831.8454\n",
      "Epoch 6173/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 298.2300 - val_loss: 957.3483\n",
      "Epoch 6174/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.6935 - val_loss: 756.6197\n",
      "Epoch 6175/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 326.6728 - val_loss: 721.8784\n",
      "Epoch 6176/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 347.1676 - val_loss: 766.3500\n",
      "Epoch 6177/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.5344 - val_loss: 912.6945\n",
      "Epoch 6178/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 309.4333 - val_loss: 1555.7812\n",
      "Epoch 6179/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1289.7390 - val_loss: 1570.4429\n",
      "Epoch 6180/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 2315.4939 - val_loss: 1473.9754\n",
      "Epoch 6181/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 2006.7457 - val_loss: 1429.4504\n",
      "Epoch 6182/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 1523.0065 - val_loss: 1471.5222\n",
      "Epoch 6183/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 1279.2022 - val_loss: 1250.9507\n",
      "Epoch 6184/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 996.7283 - val_loss: 1036.4541\n",
      "Epoch 6185/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 934.3832 - val_loss: 1105.7105\n",
      "Epoch 6186/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 833.5013 - val_loss: 1087.7449\n",
      "Epoch 6187/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 754.2934 - val_loss: 1049.9349\n",
      "Epoch 6188/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 706.3242 - val_loss: 1039.2047\n",
      "Epoch 6189/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 661.6868 - val_loss: 1082.8319\n",
      "Epoch 6190/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 637.9305 - val_loss: 970.2308\n",
      "Epoch 6191/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 585.3117 - val_loss: 817.8157\n",
      "Epoch 6192/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 513.5044 - val_loss: 971.6753\n",
      "Epoch 6193/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 468.2129 - val_loss: 964.9359\n",
      "Epoch 6194/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 430.0098 - val_loss: 896.8138\n",
      "Epoch 6195/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 388.2978 - val_loss: 932.9138\n",
      "Epoch 6196/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 377.2624 - val_loss: 1132.1273\n",
      "Epoch 6197/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 460.7940 - val_loss: 1085.7243\n",
      "Epoch 6198/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 406.6007 - val_loss: 2886.7631\n",
      "Epoch 6199/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 2457.4910 - val_loss: 1788.2148\n",
      "Epoch 6200/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 2205.6060 - val_loss: 1421.6230\n",
      "Epoch 6201/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 1582.5625 - val_loss: 1485.2445\n",
      "Epoch 6202/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 1150.0260 - val_loss: 1270.5386\n",
      "Epoch 6203/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 827.7685 - val_loss: 1014.2305\n",
      "Epoch 6204/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 705.2760 - val_loss: 884.1147\n",
      "Epoch 6205/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 522.6529 - val_loss: 938.3625\n",
      "Epoch 6206/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 421.7922 - val_loss: 933.0317\n",
      "Epoch 6207/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 421.6005 - val_loss: 1113.2555\n",
      "Epoch 6208/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 451.7649 - val_loss: 1134.9561\n",
      "Epoch 6209/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 573.2932 - val_loss: 1166.7612\n",
      "Epoch 6210/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 703.5551 - val_loss: 798.4712\n",
      "Epoch 6211/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 590.3233 - val_loss: 807.1004\n",
      "Epoch 6212/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 436.9577 - val_loss: 881.5594\n",
      "Epoch 6213/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 404.6472 - val_loss: 929.3480\n",
      "Epoch 6214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 48us/step - loss: 394.7254 - val_loss: 865.0683\n",
      "Epoch 6215/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.5453 - val_loss: 817.2869\n",
      "Epoch 6216/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 359.1451 - val_loss: 919.4439\n",
      "Epoch 6217/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.0351 - val_loss: 1123.2622\n",
      "Epoch 6218/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 398.4567 - val_loss: 1093.1763\n",
      "Epoch 6219/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 387.4094 - val_loss: 866.0582\n",
      "Epoch 6220/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 382.2032 - val_loss: 805.2372\n",
      "Epoch 6221/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 343.8433 - val_loss: 779.6624\n",
      "Epoch 6222/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 315.0425 - val_loss: 876.7051\n",
      "Epoch 6223/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 380.1770 - val_loss: 989.4605\n",
      "Epoch 6224/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 414.7582 - val_loss: 872.9122\n",
      "Epoch 6225/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 525.8324 - val_loss: 899.0612\n",
      "Epoch 6226/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 523.4476 - val_loss: 914.4343\n",
      "Epoch 6227/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 542.1375 - val_loss: 953.1050\n",
      "Epoch 6228/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 496.0954 - val_loss: 879.5084\n",
      "Epoch 6229/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 460.7831 - val_loss: 927.7261\n",
      "Epoch 6230/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 442.8019 - val_loss: 901.5822\n",
      "Epoch 6231/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 411.1802 - val_loss: 907.5603\n",
      "Epoch 6232/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 390.0531 - val_loss: 865.9307\n",
      "Epoch 6233/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 354.4693 - val_loss: 821.7221\n",
      "Epoch 6234/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 388.1314 - val_loss: 789.3234\n",
      "Epoch 6235/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.5950 - val_loss: 961.0528\n",
      "Epoch 6236/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.9599 - val_loss: 920.6858\n",
      "Epoch 6237/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 433.2380 - val_loss: 729.7247\n",
      "Epoch 6238/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 397.3980 - val_loss: 778.8756\n",
      "Epoch 6239/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 346.1523 - val_loss: 856.1609\n",
      "Epoch 6240/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 320.6259 - val_loss: 887.6803\n",
      "Epoch 6241/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 309.5106 - val_loss: 887.8020\n",
      "Epoch 6242/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 313.2237 - val_loss: 770.4780\n",
      "Epoch 6243/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 367.0383 - val_loss: 871.9927\n",
      "Epoch 6244/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 392.8893 - val_loss: 841.1544\n",
      "Epoch 6245/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 367.4147 - val_loss: 846.0771\n",
      "Epoch 6246/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 342.4391 - val_loss: 789.7378\n",
      "Epoch 6247/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 310.7397 - val_loss: 863.0428\n",
      "Epoch 6248/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 300.8814 - val_loss: 839.2861\n",
      "Epoch 6249/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.7315 - val_loss: 781.6081\n",
      "Epoch 6250/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 312.6193 - val_loss: 880.4456\n",
      "Epoch 6251/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 343.9987 - val_loss: 807.0356\n",
      "Epoch 6252/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 344.7031 - val_loss: 813.7545\n",
      "Epoch 6253/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.2370 - val_loss: 884.6867\n",
      "Epoch 6254/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 345.1018 - val_loss: 815.4662\n",
      "Epoch 6255/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 320.8391 - val_loss: 820.4716\n",
      "Epoch 6256/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1162.6211 - val_loss: 1989.5270\n",
      "Epoch 6257/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 3057.8889 - val_loss: 2196.5245\n",
      "Epoch 6258/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2964.3165 - val_loss: 2349.7515\n",
      "Epoch 6259/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2481.9713 - val_loss: 1944.8840\n",
      "Epoch 6260/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1842.3291 - val_loss: 1221.5990\n",
      "Epoch 6261/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1394.5144 - val_loss: 1665.6775\n",
      "Epoch 6262/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 1048.5235 - val_loss: 1220.0663\n",
      "Epoch 6263/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 768.8410 - val_loss: 902.5990\n",
      "Epoch 6264/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 632.4416 - val_loss: 1068.9265\n",
      "Epoch 6265/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 484.7870 - val_loss: 750.2984\n",
      "Epoch 6266/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 481.8091 - val_loss: 776.4953\n",
      "Epoch 6267/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 438.1970 - val_loss: 928.3397\n",
      "Epoch 6268/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 361.1037 - val_loss: 813.8487\n",
      "Epoch 6269/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 429.8850 - val_loss: 1594.7340\n",
      "Epoch 6270/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 612.7573 - val_loss: 802.5276\n",
      "Epoch 6271/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 451.9716 - val_loss: 854.0952\n",
      "Epoch 6272/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 408.0086 - val_loss: 867.4465\n",
      "Epoch 6273/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 385.6655 - val_loss: 908.5822\n",
      "Epoch 6274/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 336.4135 - val_loss: 854.5892\n",
      "Epoch 6275/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 348.1373 - val_loss: 836.7797\n",
      "Epoch 6276/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 360.8341 - val_loss: 961.4438\n",
      "Epoch 6277/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 368.4751 - val_loss: 856.2254\n",
      "Epoch 6278/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 353.9456 - val_loss: 707.1178\n",
      "Epoch 6279/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 373.0124 - val_loss: 816.1321\n",
      "Epoch 6280/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 323.3671 - val_loss: 874.5308\n",
      "Epoch 6281/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 318.6989 - val_loss: 1090.4267\n",
      "Epoch 6282/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 427.5598 - val_loss: 873.0668\n",
      "Epoch 6283/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 528.0584 - val_loss: 1285.6942\n",
      "Epoch 6284/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 821.7090 - val_loss: 1360.3407\n",
      "Epoch 6285/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 641.7128 - val_loss: 1220.6155\n",
      "Epoch 6286/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 563.7477 - val_loss: 1019.7639\n",
      "Epoch 6287/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 49us/step - loss: 483.7719 - val_loss: 813.2585\n",
      "Epoch 6288/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 413.269 - 0s 51us/step - loss: 490.7599 - val_loss: 898.1108\n",
      "Epoch 6289/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 420.8295 - val_loss: 946.5350\n",
      "Epoch 6290/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 388.4602 - val_loss: 1058.0124\n",
      "Epoch 6291/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 413.1005 - val_loss: 819.7925\n",
      "Epoch 6292/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.7220 - val_loss: 824.3736\n",
      "Epoch 6293/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.8458 - val_loss: 821.6035\n",
      "Epoch 6294/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 311.2557 - val_loss: 882.1264\n",
      "Epoch 6295/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 311.5670 - val_loss: 806.7972\n",
      "Epoch 6296/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.8027 - val_loss: 843.9109\n",
      "Epoch 6297/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 341.2268 - val_loss: 779.5493\n",
      "Epoch 6298/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 316.2324 - val_loss: 825.0030\n",
      "Epoch 6299/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 320.0684 - val_loss: 755.0431\n",
      "Epoch 6300/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 333.7291 - val_loss: 983.9870\n",
      "Epoch 6301/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 391.8247 - val_loss: 907.6905\n",
      "Epoch 6302/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 327.9348 - val_loss: 804.4145\n",
      "Epoch 6303/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.2519 - val_loss: 871.2255\n",
      "Epoch 6304/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 353.1139 - val_loss: 818.2737\n",
      "Epoch 6305/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.4522 - val_loss: 810.7711\n",
      "Epoch 6306/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 372.0907 - val_loss: 865.4980\n",
      "Epoch 6307/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.4145 - val_loss: 837.7864\n",
      "Epoch 6308/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 341.7596 - val_loss: 911.5359\n",
      "Epoch 6309/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 327.9437 - val_loss: 839.1843\n",
      "Epoch 6310/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 337.7108 - val_loss: 798.6911\n",
      "Epoch 6311/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.8507 - val_loss: 846.8430\n",
      "Epoch 6312/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 372.7608 - val_loss: 759.0617\n",
      "Epoch 6313/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.7738 - val_loss: 754.4438\n",
      "Epoch 6314/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 350.7126 - val_loss: 837.6437\n",
      "Epoch 6315/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.1198 - val_loss: 1017.2727\n",
      "Epoch 6316/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.9134 - val_loss: 1007.1229\n",
      "Epoch 6317/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 557.7925 - val_loss: 870.5657\n",
      "Epoch 6318/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 459.3985 - val_loss: 790.4112\n",
      "Epoch 6319/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 524.2251 - val_loss: 762.9667\n",
      "Epoch 6320/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 436.0345 - val_loss: 926.4157\n",
      "Epoch 6321/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 399.1311 - val_loss: 885.0426\n",
      "Epoch 6322/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 375.7077 - val_loss: 775.5652\n",
      "Epoch 6323/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 455.9939 - val_loss: 884.5432\n",
      "Epoch 6324/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 428.2340 - val_loss: 879.3521\n",
      "Epoch 6325/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 376.4161 - val_loss: 837.0423\n",
      "Epoch 6326/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.5093 - val_loss: 885.4520\n",
      "Epoch 6327/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 321.2298 - val_loss: 741.7513\n",
      "Epoch 6328/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.2729 - val_loss: 970.3804\n",
      "Epoch 6329/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.4963 - val_loss: 939.3092\n",
      "Epoch 6330/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 333.3586 - val_loss: 902.9904\n",
      "Epoch 6331/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.4345 - val_loss: 903.5390\n",
      "Epoch 6332/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 377.7964 - val_loss: 1035.0498\n",
      "Epoch 6333/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 388.0949 - val_loss: 1006.1159\n",
      "Epoch 6334/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 368.4472 - val_loss: 1041.1818\n",
      "Epoch 6335/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 395.0557 - val_loss: 839.1769\n",
      "Epoch 6336/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 366.8434 - val_loss: 735.8323\n",
      "Epoch 6337/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 339.5000 - val_loss: 740.1074\n",
      "Epoch 6338/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 349.9242 - val_loss: 788.1716\n",
      "Epoch 6339/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.7492 - val_loss: 821.2829\n",
      "Epoch 6340/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 296.1655 - val_loss: 771.1685\n",
      "Epoch 6341/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 307.7357 - val_loss: 763.6788\n",
      "Epoch 6342/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 368.1843 - val_loss: 813.8884\n",
      "Epoch 6343/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.4660 - val_loss: 834.6533\n",
      "Epoch 6344/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 359.0347 - val_loss: 829.5340\n",
      "Epoch 6345/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.2208 - val_loss: 813.5205\n",
      "Epoch 6346/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.0615 - val_loss: 755.7442\n",
      "Epoch 6347/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 396.1554 - val_loss: 867.0552\n",
      "Epoch 6348/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 402.1843 - val_loss: 850.1981\n",
      "Epoch 6349/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 352.6058 - val_loss: 763.3533\n",
      "Epoch 6350/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 370.6785 - val_loss: 801.8760\n",
      "Epoch 6351/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 338.6876 - val_loss: 1065.8987\n",
      "Epoch 6352/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 453.8659 - val_loss: 842.9255\n",
      "Epoch 6353/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 412.7462 - val_loss: 736.3158\n",
      "Epoch 6354/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 402.8039 - val_loss: 814.6089\n",
      "Epoch 6355/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 350.2425 - val_loss: 797.1710\n",
      "Epoch 6356/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.7190 - val_loss: 887.9199\n",
      "Epoch 6357/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 327.9341 - val_loss: 748.5461\n",
      "Epoch 6358/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 444.4156 - val_loss: 1266.5446\n",
      "Epoch 6359/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 505.3802 - val_loss: 821.0969\n",
      "Epoch 6360/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 382.1531 - val_loss: 1018.6758\n",
      "Epoch 6361/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.4566 - val_loss: 780.2953\n",
      "Epoch 6362/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 412.8969 - val_loss: 824.9263\n",
      "Epoch 6363/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.5224 - val_loss: 893.1802\n",
      "Epoch 6364/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 357.2079 - val_loss: 834.4895\n",
      "Epoch 6365/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 347.3115 - val_loss: 832.1737\n",
      "Epoch 6366/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 315.9010 - val_loss: 795.4093\n",
      "Epoch 6367/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 355.1010 - val_loss: 762.0729\n",
      "Epoch 6368/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 352.9864 - val_loss: 742.0952\n",
      "Epoch 6369/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 458.9847 - val_loss: 877.6947\n",
      "Epoch 6370/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.5757 - val_loss: 893.1027\n",
      "Epoch 6371/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 342.4851 - val_loss: 859.4475\n",
      "Epoch 6372/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 348.4855 - val_loss: 757.3120\n",
      "Epoch 6373/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 322.2043 - val_loss: 842.4851\n",
      "Epoch 6374/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 295.3440 - val_loss: 706.8190\n",
      "Epoch 6375/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.9554 - val_loss: 923.7095\n",
      "Epoch 6376/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 343.2035 - val_loss: 799.4546\n",
      "Epoch 6377/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 342.7463 - val_loss: 776.3933\n",
      "Epoch 6378/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 338.7886 - val_loss: 835.1599\n",
      "Epoch 6379/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 354.1328 - val_loss: 774.7030\n",
      "Epoch 6380/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 350.4634 - val_loss: 879.4181\n",
      "Epoch 6381/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.8534 - val_loss: 767.6390\n",
      "Epoch 6382/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.8567 - val_loss: 773.3486\n",
      "Epoch 6383/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 305.7127 - val_loss: 832.8008\n",
      "Epoch 6384/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 321.6641 - val_loss: 915.7095\n",
      "Epoch 6385/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 317.5838 - val_loss: 880.1721\n",
      "Epoch 6386/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 307.8096 - val_loss: 724.3468\n",
      "Epoch 6387/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 322.5763 - val_loss: 711.6560\n",
      "Epoch 6388/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 424.7840 - val_loss: 825.6599\n",
      "Epoch 6389/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 479.8500 - val_loss: 848.7162\n",
      "Epoch 6390/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 386.1009 - val_loss: 729.4546\n",
      "Epoch 6391/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.4422 - val_loss: 882.8859\n",
      "Epoch 6392/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 305.2395 - val_loss: 874.4428\n",
      "Epoch 6393/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.4460 - val_loss: 811.9891\n",
      "Epoch 6394/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 322.9967 - val_loss: 952.1754\n",
      "Epoch 6395/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.3733 - val_loss: 800.4864\n",
      "Epoch 6396/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 300.5941 - val_loss: 764.4502\n",
      "Epoch 6397/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 300.4617 - val_loss: 776.3843\n",
      "Epoch 6398/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.9037 - val_loss: 770.9734\n",
      "Epoch 6399/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 353.8151 - val_loss: 775.3841\n",
      "Epoch 6400/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 340.4425 - val_loss: 896.2921\n",
      "Epoch 6401/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.2409 - val_loss: 851.6353\n",
      "Epoch 6402/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 334.8815 - val_loss: 810.8206\n",
      "Epoch 6403/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 318.6151 - val_loss: 874.5699\n",
      "Epoch 6404/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 305.8205 - val_loss: 913.6576\n",
      "Epoch 6405/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 317.0333 - val_loss: 801.9712\n",
      "Epoch 6406/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 314.5099 - val_loss: 791.7277\n",
      "Epoch 6407/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 293.6850 - val_loss: 826.2577\n",
      "Epoch 6408/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 295.1624 - val_loss: 774.8299\n",
      "Epoch 6409/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 325.2891 - val_loss: 799.6090\n",
      "Epoch 6410/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 353.2438 - val_loss: 1215.1033\n",
      "Epoch 6411/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 467.8132 - val_loss: 1213.4519\n",
      "Epoch 6412/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 645.5028 - val_loss: 1006.3410\n",
      "Epoch 6413/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 573.2910 - val_loss: 911.3846\n",
      "Epoch 6414/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 400.9583 - val_loss: 787.2206\n",
      "Epoch 6415/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 542.0927 - val_loss: 799.5396\n",
      "Epoch 6416/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 454.3180 - val_loss: 858.0925\n",
      "Epoch 6417/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.6210 - val_loss: 1135.7167\n",
      "Epoch 6418/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 395.3696 - val_loss: 987.9057\n",
      "Epoch 6419/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 422.7113 - val_loss: 907.2311\n",
      "Epoch 6420/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 391.6720 - val_loss: 1045.6919\n",
      "Epoch 6421/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.5096 - val_loss: 1000.5290\n",
      "Epoch 6422/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 354.2262 - val_loss: 961.9123\n",
      "Epoch 6423/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 383.6842 - val_loss: 936.1970\n",
      "Epoch 6424/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 339.1097 - val_loss: 930.2268\n",
      "Epoch 6425/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.2227 - val_loss: 1127.7375\n",
      "Epoch 6426/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 517.2914 - val_loss: 827.2393\n",
      "Epoch 6427/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 468.7612 - val_loss: 905.5178\n",
      "Epoch 6428/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 396.7512 - val_loss: 830.7730\n",
      "Epoch 6429/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 353.4125 - val_loss: 811.6039\n",
      "Epoch 6430/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.3833 - val_loss: 907.3245\n",
      "Epoch 6431/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 296.8251 - val_loss: 884.5357\n",
      "Epoch 6432/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 305.6120 - val_loss: 865.9513\n",
      "Epoch 6433/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.9664 - val_loss: 756.6493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6434/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 336.7079 - val_loss: 844.2597\n",
      "Epoch 6435/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.6219 - val_loss: 764.1668\n",
      "Epoch 6436/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 325.0002 - val_loss: 830.2668\n",
      "Epoch 6437/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 320.5451 - val_loss: 879.6269\n",
      "Epoch 6438/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.5226 - val_loss: 981.7993\n",
      "Epoch 6439/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.0331 - val_loss: 889.2181\n",
      "Epoch 6440/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.9969 - val_loss: 918.0439\n",
      "Epoch 6441/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 336.9395 - val_loss: 833.5700\n",
      "Epoch 6442/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 308.6034 - val_loss: 925.0922\n",
      "Epoch 6443/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 369.1887 - val_loss: 818.4080\n",
      "Epoch 6444/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.6065 - val_loss: 748.1378\n",
      "Epoch 6445/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.2627 - val_loss: 776.4273\n",
      "Epoch 6446/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 293.1027 - val_loss: 840.6916\n",
      "Epoch 6447/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 313.6967 - val_loss: 782.4422\n",
      "Epoch 6448/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 342.3841 - val_loss: 751.8009\n",
      "Epoch 6449/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 334.0637 - val_loss: 755.9928\n",
      "Epoch 6450/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 380.8884 - val_loss: 951.4830\n",
      "Epoch 6451/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 363.3723 - val_loss: 748.8163\n",
      "Epoch 6452/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.9728 - val_loss: 867.5930\n",
      "Epoch 6453/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 302.1637 - val_loss: 847.9155\n",
      "Epoch 6454/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 292.7280 - val_loss: 781.9713\n",
      "Epoch 6455/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 289.6037 - val_loss: 1744.3133\n",
      "Epoch 6456/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1076.7111 - val_loss: 1474.8606\n",
      "Epoch 6457/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1495.9220 - val_loss: 1171.1377\n",
      "Epoch 6458/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1385.1070 - val_loss: 1026.0965\n",
      "Epoch 6459/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1382.1383 - val_loss: 954.6824\n",
      "Epoch 6460/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1103.5795 - val_loss: 1230.8927\n",
      "Epoch 6461/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 984.0581 - val_loss: 1070.9349\n",
      "Epoch 6462/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 931.5534 - val_loss: 1104.4362\n",
      "Epoch 6463/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 842.4578 - val_loss: 1111.0969\n",
      "Epoch 6464/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 770.8613 - val_loss: 1154.7632\n",
      "Epoch 6465/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 717.0512 - val_loss: 1036.2577\n",
      "Epoch 6466/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 730.3566 - val_loss: 927.7547\n",
      "Epoch 6467/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 715.3057 - val_loss: 1055.1335\n",
      "Epoch 6468/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 704.2402 - val_loss: 985.5115\n",
      "Epoch 6469/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 675.2741 - val_loss: 972.3948\n",
      "Epoch 6470/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 632.5459 - val_loss: 918.5154\n",
      "Epoch 6471/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 598.1150 - val_loss: 986.6182\n",
      "Epoch 6472/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 568.3990 - val_loss: 924.7093\n",
      "Epoch 6473/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 546.5736 - val_loss: 987.0907\n",
      "Epoch 6474/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 532.7567 - val_loss: 911.4831\n",
      "Epoch 6475/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 507.9263 - val_loss: 978.4800\n",
      "Epoch 6476/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 497.5894 - val_loss: 949.2059\n",
      "Epoch 6477/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 453.6788 - val_loss: 958.4132\n",
      "Epoch 6478/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 440.6969 - val_loss: 943.3322\n",
      "Epoch 6479/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 404.1542 - val_loss: 884.1531\n",
      "Epoch 6480/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 399.7490 - val_loss: 808.4208\n",
      "Epoch 6481/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 393.1204 - val_loss: 798.0533\n",
      "Epoch 6482/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 361.2178 - val_loss: 851.1307\n",
      "Epoch 6483/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.3610 - val_loss: 838.2319\n",
      "Epoch 6484/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 295.7797 - val_loss: 864.3329\n",
      "Epoch 6485/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 374.3320 - val_loss: 731.1991\n",
      "Epoch 6486/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 364.5506 - val_loss: 868.1581\n",
      "Epoch 6487/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 378.6572 - val_loss: 895.4558\n",
      "Epoch 6488/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.8352 - val_loss: 742.3287\n",
      "Epoch 6489/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 351.3598 - val_loss: 854.4527\n",
      "Epoch 6490/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 362.5158 - val_loss: 960.2430\n",
      "Epoch 6491/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.3110 - val_loss: 843.8843\n",
      "Epoch 6492/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 301.3423 - val_loss: 825.9492\n",
      "Epoch 6493/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 300.0112 - val_loss: 793.1920\n",
      "Epoch 6494/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.6963 - val_loss: 846.9486\n",
      "Epoch 6495/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 453.0193 - val_loss: 917.6672\n",
      "Epoch 6496/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 377.5091 - val_loss: 800.4764\n",
      "Epoch 6497/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 345.2678 - val_loss: 810.1575\n",
      "Epoch 6498/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 377.0215 - val_loss: 888.2901\n",
      "Epoch 6499/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 350.8902 - val_loss: 985.7325\n",
      "Epoch 6500/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 376.5397 - val_loss: 997.6610\n",
      "Epoch 6501/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 367.4585 - val_loss: 756.9113\n",
      "Epoch 6502/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 327.7856 - val_loss: 759.6435\n",
      "Epoch 6503/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 301.1514 - val_loss: 792.7124\n",
      "Epoch 6504/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.2852 - val_loss: 876.6450\n",
      "Epoch 6505/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 387.7789 - val_loss: 830.2283\n",
      "Epoch 6506/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 360.6865 - val_loss: 950.5210\n",
      "Epoch 6507/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 382.7475 - val_loss: 904.4689\n",
      "Epoch 6508/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 560.4835 - val_loss: 671.4460\n",
      "Epoch 6509/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 598.4753 - val_loss: 1271.7519\n",
      "Epoch 6510/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 629.8602 - val_loss: 772.0785\n",
      "Epoch 6511/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 632.2259 - val_loss: 1002.3988\n",
      "Epoch 6512/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 454.7423 - val_loss: 853.1860\n",
      "Epoch 6513/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 379.0425 - val_loss: 750.9951\n",
      "Epoch 6514/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 354.7139 - val_loss: 894.1678\n",
      "Epoch 6515/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 390.5367 - val_loss: 866.4271\n",
      "Epoch 6516/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 443.3310 - val_loss: 723.9689\n",
      "Epoch 6517/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 433.6354 - val_loss: 821.1050\n",
      "Epoch 6518/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 397.9841 - val_loss: 906.8654\n",
      "Epoch 6519/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 346.5838 - val_loss: 833.5903\n",
      "Epoch 6520/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.5771 - val_loss: 835.1202\n",
      "Epoch 6521/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 328.9382 - val_loss: 782.8845\n",
      "Epoch 6522/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 397.1698 - val_loss: 736.5801\n",
      "Epoch 6523/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 417.2673 - val_loss: 1073.5540\n",
      "Epoch 6524/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.4931 - val_loss: 685.5415\n",
      "Epoch 6525/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 342.1520 - val_loss: 790.1879\n",
      "Epoch 6526/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 387.2579 - val_loss: 943.4260\n",
      "Epoch 6527/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 478.3305 - val_loss: 718.9705\n",
      "Epoch 6528/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 398.4388 - val_loss: 863.8855\n",
      "Epoch 6529/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 377.0212 - val_loss: 892.1866\n",
      "Epoch 6530/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.1541 - val_loss: 794.4781\n",
      "Epoch 6531/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2498.8759 - val_loss: 4076.3299\n",
      "Epoch 6532/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 6466.0259 - val_loss: 4601.6457\n",
      "Epoch 6533/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 6339.4096 - val_loss: 3329.4557\n",
      "Epoch 6534/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 5743.7147 - val_loss: 3960.5213\n",
      "Epoch 6535/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 4852.8320 - val_loss: 3422.8955\n",
      "Epoch 6536/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 3901.1125 - val_loss: 2203.5698\n",
      "Epoch 6537/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3333.8515 - val_loss: 2147.5749\n",
      "Epoch 6538/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2627.8436 - val_loss: 1936.4304\n",
      "Epoch 6539/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 2057.1177 - val_loss: 1618.4457\n",
      "Epoch 6540/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1647.5853 - val_loss: 1288.8096\n",
      "Epoch 6541/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1240.6554 - val_loss: 1094.8647\n",
      "Epoch 6542/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 929.9020 - val_loss: 1107.5100\n",
      "Epoch 6543/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 687.9020 - val_loss: 1065.7898\n",
      "Epoch 6544/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 589.5864 - val_loss: 1016.7425\n",
      "Epoch 6545/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 550.3070 - val_loss: 978.9638\n",
      "Epoch 6546/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 488.8740 - val_loss: 870.5691\n",
      "Epoch 6547/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 451.6916 - val_loss: 816.1828\n",
      "Epoch 6548/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 418.6168 - val_loss: 804.6808\n",
      "Epoch 6549/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 388.4069 - val_loss: 887.9119\n",
      "Epoch 6550/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.1157 - val_loss: 808.4303\n",
      "Epoch 6551/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 354.4895 - val_loss: 814.0684\n",
      "Epoch 6552/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 354.5588 - val_loss: 714.8798\n",
      "Epoch 6553/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 649.2595 - val_loss: 707.6573\n",
      "Epoch 6554/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 796.2073 - val_loss: 1831.2643\n",
      "Epoch 6555/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 758.2268 - val_loss: 657.6952\n",
      "Epoch 6556/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 560.7301 - val_loss: 735.4432\n",
      "Epoch 6557/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 785.6490 - val_loss: 663.5519\n",
      "Epoch 6558/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 640.2543 - val_loss: 911.5763\n",
      "Epoch 6559/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 523.6265 - val_loss: 835.5613\n",
      "Epoch 6560/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 422.0787 - val_loss: 912.0947\n",
      "Epoch 6561/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 415.9253 - val_loss: 911.2795\n",
      "Epoch 6562/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 390.9232 - val_loss: 939.1914\n",
      "Epoch 6563/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 410.2616 - val_loss: 765.2985\n",
      "Epoch 6564/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 403.6740 - val_loss: 858.8336\n",
      "Epoch 6565/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 365.3720 - val_loss: 1117.5134\n",
      "Epoch 6566/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 359.6019 - val_loss: 926.0856\n",
      "Epoch 6567/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 366.3229 - val_loss: 1059.7843\n",
      "Epoch 6568/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 374.8421 - val_loss: 892.7768\n",
      "Epoch 6569/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 362.5681 - val_loss: 908.4724\n",
      "Epoch 6570/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 333.1082 - val_loss: 842.3320\n",
      "Epoch 6571/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.8140 - val_loss: 842.1106\n",
      "Epoch 6572/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 362.7794 - val_loss: 872.8912\n",
      "Epoch 6573/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 348.3151 - val_loss: 905.1499\n",
      "Epoch 6574/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.5760 - val_loss: 894.4137\n",
      "Epoch 6575/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.5067 - val_loss: 1011.1646\n",
      "Epoch 6576/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.7357 - val_loss: 1027.4017\n",
      "Epoch 6577/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 611.3935 - val_loss: 1045.6758\n",
      "Epoch 6578/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 684.4259 - val_loss: 935.2329\n",
      "Epoch 6579/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 686.5335 - val_loss: 905.6956\n",
      "Epoch 6580/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 588.8210 - val_loss: 969.7319\n",
      "Epoch 6581/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 548.0643 - val_loss: 889.3050\n",
      "Epoch 6582/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 500.3525 - val_loss: 969.3161\n",
      "Epoch 6583/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 454.8046 - val_loss: 866.6092\n",
      "Epoch 6584/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 410.5017 - val_loss: 933.3745\n",
      "Epoch 6585/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.4826 - val_loss: 848.4151\n",
      "Epoch 6586/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 362.8355 - val_loss: 927.4610\n",
      "Epoch 6587/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 329.4345 - val_loss: 815.6442\n",
      "Epoch 6588/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.1242 - val_loss: 812.8056\n",
      "Epoch 6589/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 314.3981 - val_loss: 1090.8539\n",
      "Epoch 6590/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 540.6714 - val_loss: 1166.0379\n",
      "Epoch 6591/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 509.7260 - val_loss: 1059.4746\n",
      "Epoch 6592/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 531.6611 - val_loss: 659.1035\n",
      "Epoch 6593/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 540.4223 - val_loss: 886.9034\n",
      "Epoch 6594/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 468.4934 - val_loss: 752.5781\n",
      "Epoch 6595/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.9849 - val_loss: 985.5363\n",
      "Epoch 6596/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 387.6674 - val_loss: 969.0500\n",
      "Epoch 6597/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.5641 - val_loss: 936.2852\n",
      "Epoch 6598/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.5404 - val_loss: 866.2488\n",
      "Epoch 6599/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 575.8950 - val_loss: 837.4084\n",
      "Epoch 6600/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 901.8018 - val_loss: 803.9165\n",
      "Epoch 6601/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 564.3742 - val_loss: 794.8956\n",
      "Epoch 6602/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 443.3612 - val_loss: 970.5562\n",
      "Epoch 6603/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 373.0018 - val_loss: 838.2985\n",
      "Epoch 6604/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 338.5560 - val_loss: 860.9213\n",
      "Epoch 6605/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 313.8706 - val_loss: 810.2065\n",
      "Epoch 6606/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 429.3923 - val_loss: 821.4537\n",
      "Epoch 6607/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 485.9382 - val_loss: 1100.1184\n",
      "Epoch 6608/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 454.2870 - val_loss: 765.4965\n",
      "Epoch 6609/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 410.3702 - val_loss: 775.5193\n",
      "Epoch 6610/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.8475 - val_loss: 891.1604\n",
      "Epoch 6611/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.4101 - val_loss: 1016.1047\n",
      "Epoch 6612/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 417.0951 - val_loss: 840.8140\n",
      "Epoch 6613/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.9578 - val_loss: 829.3640\n",
      "Epoch 6614/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 323.1636 - val_loss: 829.7711\n",
      "Epoch 6615/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 320.9321 - val_loss: 916.5993\n",
      "Epoch 6616/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 417.5782 - val_loss: 1406.1637\n",
      "Epoch 6617/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 875.5313 - val_loss: 1116.9352\n",
      "Epoch 6618/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 657.5418 - val_loss: 834.8241\n",
      "Epoch 6619/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 537.4644 - val_loss: 932.1232\n",
      "Epoch 6620/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 450.3736 - val_loss: 866.3431\n",
      "Epoch 6621/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 364.5670 - val_loss: 893.8887\n",
      "Epoch 6622/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 303.9244 - val_loss: 917.0307\n",
      "Epoch 6623/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 318.3677 - val_loss: 815.8055\n",
      "Epoch 6624/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 311.0189 - val_loss: 778.0747\n",
      "Epoch 6625/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 321.0746 - val_loss: 776.4138\n",
      "Epoch 6626/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.1017 - val_loss: 795.8452\n",
      "Epoch 6627/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 294.6410 - val_loss: 847.5241\n",
      "Epoch 6628/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.5342 - val_loss: 994.5436\n",
      "Epoch 6629/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 377.2516 - val_loss: 960.1474\n",
      "Epoch 6630/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 380.7172 - val_loss: 837.5641\n",
      "Epoch 6631/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 341.9164 - val_loss: 776.7787\n",
      "Epoch 6632/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 323.3778 - val_loss: 721.6727\n",
      "Epoch 6633/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 351.3307 - val_loss: 823.2495\n",
      "Epoch 6634/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 345.5796 - val_loss: 1000.7718\n",
      "Epoch 6635/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 354.6886 - val_loss: 732.0286\n",
      "Epoch 6636/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.2120 - val_loss: 883.3921\n",
      "Epoch 6637/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 352.2680 - val_loss: 825.9562\n",
      "Epoch 6638/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 316.3230 - val_loss: 850.4541\n",
      "Epoch 6639/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 311.7419 - val_loss: 831.7688\n",
      "Epoch 6640/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 299.9831 - val_loss: 821.0990\n",
      "Epoch 6641/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 289.3318 - val_loss: 817.2173\n",
      "Epoch 6642/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 301.7115 - val_loss: 787.0625\n",
      "Epoch 6643/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 296.3623 - val_loss: 800.6493\n",
      "Epoch 6644/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 301.4879 - val_loss: 807.2808\n",
      "Epoch 6645/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 328.2806 - val_loss: 839.4716\n",
      "Epoch 6646/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 322.7922 - val_loss: 848.2304\n",
      "Epoch 6647/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.1414 - val_loss: 867.0726\n",
      "Epoch 6648/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 314.8060 - val_loss: 772.5401\n",
      "Epoch 6649/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 311.5249 - val_loss: 763.5857\n",
      "Epoch 6650/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 300.3675 - val_loss: 823.3555\n",
      "Epoch 6651/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 295.1702 - val_loss: 763.9305\n",
      "Epoch 6652/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 304.3655 - val_loss: 838.1294\n",
      "Epoch 6653/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 419.4731 - val_loss: 724.6195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6654/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 571.9977 - val_loss: 654.7578\n",
      "Epoch 6655/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 568.2528 - val_loss: 907.9114\n",
      "Epoch 6656/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 440.4806 - val_loss: 911.9987\n",
      "Epoch 6657/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 414.6160 - val_loss: 828.1197\n",
      "Epoch 6658/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 373.1008 - val_loss: 885.0785\n",
      "Epoch 6659/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 370.7128 - val_loss: 832.6017\n",
      "Epoch 6660/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 331.9182 - val_loss: 801.8427\n",
      "Epoch 6661/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.6135 - val_loss: 725.6205\n",
      "Epoch 6662/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.9137 - val_loss: 823.4832\n",
      "Epoch 6663/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 339.0380 - val_loss: 826.1576\n",
      "Epoch 6664/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 302.3838 - val_loss: 873.3162\n",
      "Epoch 6665/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 322.0383 - val_loss: 823.8520\n",
      "Epoch 6666/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 300.7438 - val_loss: 851.1986\n",
      "Epoch 6667/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 324.6260 - val_loss: 830.4810\n",
      "Epoch 6668/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.7429 - val_loss: 948.9581\n",
      "Epoch 6669/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 484.8501 - val_loss: 856.2454\n",
      "Epoch 6670/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 419.2370 - val_loss: 775.8121\n",
      "Epoch 6671/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 393.7163 - val_loss: 962.9412\n",
      "Epoch 6672/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 431.8209 - val_loss: 789.8473\n",
      "Epoch 6673/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.6081 - val_loss: 850.3261\n",
      "Epoch 6674/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 326.8971 - val_loss: 768.3433\n",
      "Epoch 6675/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 302.9922 - val_loss: 836.9397\n",
      "Epoch 6676/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 347.5920 - val_loss: 853.3022\n",
      "Epoch 6677/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 343.3296 - val_loss: 790.4502\n",
      "Epoch 6678/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 303.0125 - val_loss: 890.1253\n",
      "Epoch 6679/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.9336 - val_loss: 759.4915\n",
      "Epoch 6680/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 298.9539 - val_loss: 779.9259\n",
      "Epoch 6681/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 544.1818 - val_loss: 869.6436\n",
      "Epoch 6682/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 475.1222 - val_loss: 812.6061\n",
      "Epoch 6683/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 425.5771 - val_loss: 870.3448\n",
      "Epoch 6684/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 362.8490 - val_loss: 778.2819\n",
      "Epoch 6685/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 324.1905 - val_loss: 865.9132\n",
      "Epoch 6686/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 311.4594 - val_loss: 773.1337\n",
      "Epoch 6687/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.2469 - val_loss: 764.5841\n",
      "Epoch 6688/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 319.4630 - val_loss: 785.8903\n",
      "Epoch 6689/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 294.2991 - val_loss: 792.8544\n",
      "Epoch 6690/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 283.9415 - val_loss: 811.4207\n",
      "Epoch 6691/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 312.8084 - val_loss: 774.1228\n",
      "Epoch 6692/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 306.4436 - val_loss: 826.8500\n",
      "Epoch 6693/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 303.6917 - val_loss: 803.4102\n",
      "Epoch 6694/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 350.5500 - val_loss: 778.2914\n",
      "Epoch 6695/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 436.0152 - val_loss: 872.8270\n",
      "Epoch 6696/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 425.2557 - val_loss: 775.3638\n",
      "Epoch 6697/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 443.3686 - val_loss: 885.4198\n",
      "Epoch 6698/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 485.0812 - val_loss: 891.4090\n",
      "Epoch 6699/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 392.7689 - val_loss: 722.0514\n",
      "Epoch 6700/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 403.6494 - val_loss: 925.0480\n",
      "Epoch 6701/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.7412 - val_loss: 914.2925\n",
      "Epoch 6702/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 375.5295 - val_loss: 760.7474\n",
      "Epoch 6703/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 391.4053 - val_loss: 756.5439\n",
      "Epoch 6704/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 359.9663 - val_loss: 812.4059\n",
      "Epoch 6705/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 320.5671 - val_loss: 821.8615\n",
      "Epoch 6706/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 295.1528 - val_loss: 877.1174\n",
      "Epoch 6707/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 349.5687 - val_loss: 863.5853\n",
      "Epoch 6708/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 348.5857 - val_loss: 735.2152\n",
      "Epoch 6709/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 303.5323 - val_loss: 834.5808\n",
      "Epoch 6710/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 296.7595 - val_loss: 882.0085\n",
      "Epoch 6711/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 341.2499 - val_loss: 895.1732\n",
      "Epoch 6712/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 319.8200 - val_loss: 857.3807\n",
      "Epoch 6713/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 338.9186 - val_loss: 801.4975\n",
      "Epoch 6714/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 337.6763 - val_loss: 854.0155\n",
      "Epoch 6715/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 326.7011 - val_loss: 862.6622\n",
      "Epoch 6716/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.4277 - val_loss: 863.5397\n",
      "Epoch 6717/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 318.5782 - val_loss: 736.9314\n",
      "Epoch 6718/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 314.6467 - val_loss: 730.9344\n",
      "Epoch 6719/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 332.0786 - val_loss: 792.4382\n",
      "Epoch 6720/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 320.1225 - val_loss: 851.7858\n",
      "Epoch 6721/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 294.2759 - val_loss: 792.2541\n",
      "Epoch 6722/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 291.9520 - val_loss: 788.1278\n",
      "Epoch 6723/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 275.7904 - val_loss: 833.6872\n",
      "Epoch 6724/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.1530 - val_loss: 750.6663\n",
      "Epoch 6725/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 327.1786 - val_loss: 848.7643\n",
      "Epoch 6726/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 298.0860 - val_loss: 893.3492\n",
      "Epoch 6727/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 306.4009 - val_loss: 914.4985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6728/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 449.5785 - val_loss: 783.3809\n",
      "Epoch 6729/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 465.4520 - val_loss: 801.4412\n",
      "Epoch 6730/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 387.1107 - val_loss: 901.6707\n",
      "Epoch 6731/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.5825 - val_loss: 941.7150\n",
      "Epoch 6732/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 366.3998 - val_loss: 873.5912\n",
      "Epoch 6733/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 322.9281 - val_loss: 819.1756\n",
      "Epoch 6734/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 318.3365 - val_loss: 790.6182\n",
      "Epoch 6735/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 298.3942 - val_loss: 821.6043\n",
      "Epoch 6736/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 308.3577 - val_loss: 970.8274\n",
      "Epoch 6737/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 376.450 - 0s 47us/step - loss: 331.8364 - val_loss: 843.0952\n",
      "Epoch 6738/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 308.5191 - val_loss: 851.3439\n",
      "Epoch 6739/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 319.8690 - val_loss: 774.0864\n",
      "Epoch 6740/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 312.4141 - val_loss: 904.2312\n",
      "Epoch 6741/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 389.6117 - val_loss: 830.5191\n",
      "Epoch 6742/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.7097 - val_loss: 739.3150\n",
      "Epoch 6743/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 308.3268 - val_loss: 863.9993\n",
      "Epoch 6744/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 436.2775 - val_loss: 787.5086\n",
      "Epoch 6745/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 378.3506 - val_loss: 834.0160\n",
      "Epoch 6746/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 362.2795 - val_loss: 752.5272\n",
      "Epoch 6747/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.8506 - val_loss: 841.8252\n",
      "Epoch 6748/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 317.0242 - val_loss: 967.4020\n",
      "Epoch 6749/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 332.6275 - val_loss: 880.6461\n",
      "Epoch 6750/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 300.1864 - val_loss: 791.9485\n",
      "Epoch 6751/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 490.3620 - val_loss: 1372.1356\n",
      "Epoch 6752/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1189.3126 - val_loss: 1547.4671\n",
      "Epoch 6753/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 1185.4306 - val_loss: 1469.1342\n",
      "Epoch 6754/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 992.7575 - val_loss: 1308.5927\n",
      "Epoch 6755/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 767.1756 - val_loss: 885.1952\n",
      "Epoch 6756/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 603.7492 - val_loss: 949.4001\n",
      "Epoch 6757/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 475.1660 - val_loss: 927.9651\n",
      "Epoch 6758/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 402.3067 - val_loss: 952.9014\n",
      "Epoch 6759/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 351.1039 - val_loss: 1087.1947\n",
      "Epoch 6760/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 327.9284 - val_loss: 827.2002\n",
      "Epoch 6761/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 362.3592 - val_loss: 709.1970\n",
      "Epoch 6762/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 323.2617 - val_loss: 752.9597\n",
      "Epoch 6763/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 682.5979 - val_loss: 1438.2835\n",
      "Epoch 6764/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2657.9936 - val_loss: 1723.1126\n",
      "Epoch 6765/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 2659.9904 - val_loss: 1552.2888\n",
      "Epoch 6766/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 2127.0927 - val_loss: 1528.6552\n",
      "Epoch 6767/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1533.6813 - val_loss: 1307.4776\n",
      "Epoch 6768/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1256.6112 - val_loss: 1189.5618\n",
      "Epoch 6769/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1081.5327 - val_loss: 1477.6187\n",
      "Epoch 6770/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1008.2445 - val_loss: 1226.7032\n",
      "Epoch 6771/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 936.3101 - val_loss: 1125.3132\n",
      "Epoch 6772/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 866.6819 - val_loss: 1070.7778\n",
      "Epoch 6773/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 828.9376 - val_loss: 1013.4781\n",
      "Epoch 6774/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 788.5567 - val_loss: 1144.7525\n",
      "Epoch 6775/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 718.3604 - val_loss: 1021.2229\n",
      "Epoch 6776/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 677.1934 - val_loss: 1090.1482\n",
      "Epoch 6777/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 661.7701 - val_loss: 956.3739\n",
      "Epoch 6778/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 634.5386 - val_loss: 1034.2864\n",
      "Epoch 6779/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 603.0709 - val_loss: 1039.3848\n",
      "Epoch 6780/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 603.9956 - val_loss: 989.9659\n",
      "Epoch 6781/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 557.4377 - val_loss: 974.2995\n",
      "Epoch 6782/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 539.5950 - val_loss: 988.9001\n",
      "Epoch 6783/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 546.8487 - val_loss: 957.8073\n",
      "Epoch 6784/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 573.1728 - val_loss: 901.0437\n",
      "Epoch 6785/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 512.4357 - val_loss: 785.8256\n",
      "Epoch 6786/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 470.8999 - val_loss: 859.8076\n",
      "Epoch 6787/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 442.4600 - val_loss: 861.6550\n",
      "Epoch 6788/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 421.9390 - val_loss: 923.4779\n",
      "Epoch 6789/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 404.9901 - val_loss: 829.2242\n",
      "Epoch 6790/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 401.3253 - val_loss: 965.7993\n",
      "Epoch 6791/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 398.9559 - val_loss: 824.0662\n",
      "Epoch 6792/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 379.4216 - val_loss: 952.8490\n",
      "Epoch 6793/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 430.4900 - val_loss: 831.2205\n",
      "Epoch 6794/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 368.5061 - val_loss: 749.0041\n",
      "Epoch 6795/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.9638 - val_loss: 864.4708\n",
      "Epoch 6796/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.8981 - val_loss: 1004.2266\n",
      "Epoch 6797/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 476.8836 - val_loss: 802.6274\n",
      "Epoch 6798/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 404.1163 - val_loss: 821.1739\n",
      "Epoch 6799/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.1843 - val_loss: 876.1988\n",
      "Epoch 6800/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.9901 - val_loss: 851.1506\n",
      "Epoch 6801/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 49us/step - loss: 293.0866 - val_loss: 902.0506\n",
      "Epoch 6802/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 300.6593 - val_loss: 826.9009\n",
      "Epoch 6803/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 284.0312 - val_loss: 936.1176\n",
      "Epoch 6804/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 407.8666 - val_loss: 820.9454\n",
      "Epoch 6805/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 456.5367 - val_loss: 742.5675\n",
      "Epoch 6806/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 458.0898 - val_loss: 832.5607\n",
      "Epoch 6807/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 422.6796 - val_loss: 872.9534\n",
      "Epoch 6808/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 417.0624 - val_loss: 860.5534\n",
      "Epoch 6809/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 389.7447 - val_loss: 912.8569\n",
      "Epoch 6810/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.0498 - val_loss: 841.0293\n",
      "Epoch 6811/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 320.4011 - val_loss: 884.3876\n",
      "Epoch 6812/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 300.2811 - val_loss: 912.7770\n",
      "Epoch 6813/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.9845 - val_loss: 877.8998\n",
      "Epoch 6814/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 309.8275 - val_loss: 872.8062\n",
      "Epoch 6815/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 368.3391 - val_loss: 974.5503\n",
      "Epoch 6816/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 427.9060 - val_loss: 863.6347\n",
      "Epoch 6817/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 489.7195 - val_loss: 831.2609\n",
      "Epoch 6818/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 443.7374 - val_loss: 938.0801\n",
      "Epoch 6819/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 365.0307 - val_loss: 851.0111\n",
      "Epoch 6820/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 340.7283 - val_loss: 802.8622\n",
      "Epoch 6821/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 311.9634 - val_loss: 849.0544\n",
      "Epoch 6822/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 320.2169 - val_loss: 1335.2780\n",
      "Epoch 6823/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 504.6900 - val_loss: 855.3878\n",
      "Epoch 6824/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 421.2392 - val_loss: 1054.3345\n",
      "Epoch 6825/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 385.1183 - val_loss: 834.6202\n",
      "Epoch 6826/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.1007 - val_loss: 890.4532\n",
      "Epoch 6827/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 311.5337 - val_loss: 856.2295\n",
      "Epoch 6828/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 457.5828 - val_loss: 933.4422\n",
      "Epoch 6829/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 401.0352 - val_loss: 774.1408\n",
      "Epoch 6830/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 345.0214 - val_loss: 853.0494\n",
      "Epoch 6831/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 336.8993 - val_loss: 762.1315\n",
      "Epoch 6832/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.0497 - val_loss: 914.5118\n",
      "Epoch 6833/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 331.6918 - val_loss: 834.0780\n",
      "Epoch 6834/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 313.9595 - val_loss: 924.6689\n",
      "Epoch 6835/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 432.9122 - val_loss: 856.7419\n",
      "Epoch 6836/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 383.8730 - val_loss: 1017.2995\n",
      "Epoch 6837/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 357.8765 - val_loss: 985.8716\n",
      "Epoch 6838/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 326.5140 - val_loss: 776.6184\n",
      "Epoch 6839/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 319.7401 - val_loss: 763.3313\n",
      "Epoch 6840/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 296.7078 - val_loss: 826.1407\n",
      "Epoch 6841/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 297.2902 - val_loss: 763.6553\n",
      "Epoch 6842/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 291.3148 - val_loss: 866.4409\n",
      "Epoch 6843/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 277.4157 - val_loss: 787.0862\n",
      "Epoch 6844/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 316.0482 - val_loss: 797.0381\n",
      "Epoch 6845/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 339.5202 - val_loss: 838.0643\n",
      "Epoch 6846/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 311.4439 - val_loss: 758.2008\n",
      "Epoch 6847/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.5318 - val_loss: 809.0357\n",
      "Epoch 6848/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 295.1829 - val_loss: 792.7383\n",
      "Epoch 6849/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 295.4386 - val_loss: 866.6788\n",
      "Epoch 6850/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 288.4698 - val_loss: 770.6409\n",
      "Epoch 6851/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 301.2491 - val_loss: 745.3613\n",
      "Epoch 6852/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 350.9714 - val_loss: 872.3012\n",
      "Epoch 6853/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 443.7916 - val_loss: 847.4240\n",
      "Epoch 6854/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 360.6079 - val_loss: 765.1028\n",
      "Epoch 6855/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 347.2070 - val_loss: 872.7672\n",
      "Epoch 6856/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 326.8438 - val_loss: 858.0619\n",
      "Epoch 6857/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 304.9726 - val_loss: 830.3157\n",
      "Epoch 6858/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 382.3809 - val_loss: 834.7332\n",
      "Epoch 6859/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 344.2775 - val_loss: 876.9775\n",
      "Epoch 6860/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 316.4668 - val_loss: 861.0185\n",
      "Epoch 6861/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 300.0071 - val_loss: 776.5107\n",
      "Epoch 6862/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.9569 - val_loss: 708.5266\n",
      "Epoch 6863/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.8227 - val_loss: 960.1076\n",
      "Epoch 6864/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 411.1845 - val_loss: 823.2499\n",
      "Epoch 6865/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 405.4310 - val_loss: 932.0411\n",
      "Epoch 6866/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 387.3804 - val_loss: 1091.8998\n",
      "Epoch 6867/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 374.4346 - val_loss: 1223.9818\n",
      "Epoch 6868/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 615.9108 - val_loss: 1163.0890\n",
      "Epoch 6869/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 597.8407 - val_loss: 1036.9543\n",
      "Epoch 6870/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 514.9785 - val_loss: 800.9820\n",
      "Epoch 6871/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 465.9267 - val_loss: 760.9421\n",
      "Epoch 6872/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 412.6612 - val_loss: 885.8822\n",
      "Epoch 6873/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 383.3223 - val_loss: 822.0498\n",
      "Epoch 6874/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 343.3433 - val_loss: 811.8990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6875/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 344.9155 - val_loss: 845.2007\n",
      "Epoch 6876/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 441.9332 - val_loss: 643.8504\n",
      "Epoch 6877/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 590.3973 - val_loss: 1076.5257\n",
      "Epoch 6878/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 486.1866 - val_loss: 877.9157\n",
      "Epoch 6879/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.8317 - val_loss: 780.6831\n",
      "Epoch 6880/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 463.8247 - val_loss: 847.3251\n",
      "Epoch 6881/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 489.4637 - val_loss: 768.6028\n",
      "Epoch 6882/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 461.3854 - val_loss: 833.6672\n",
      "Epoch 6883/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 422.3960 - val_loss: 857.2637\n",
      "Epoch 6884/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 342.8671 - val_loss: 868.1107\n",
      "Epoch 6885/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 334.0095 - val_loss: 807.5065\n",
      "Epoch 6886/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 323.7174 - val_loss: 784.0164\n",
      "Epoch 6887/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 291.3231 - val_loss: 851.3518\n",
      "Epoch 6888/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.5144 - val_loss: 794.7805\n",
      "Epoch 6889/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 341.9891 - val_loss: 758.7564\n",
      "Epoch 6890/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 315.2218 - val_loss: 806.5431\n",
      "Epoch 6891/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 289.8766 - val_loss: 928.1317\n",
      "Epoch 6892/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 314.9066 - val_loss: 863.2355\n",
      "Epoch 6893/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 344.1262 - val_loss: 770.6465\n",
      "Epoch 6894/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 322.7556 - val_loss: 762.6076\n",
      "Epoch 6895/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 340.3911 - val_loss: 736.7065\n",
      "Epoch 6896/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 312.1546 - val_loss: 927.9706\n",
      "Epoch 6897/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 307.7583 - val_loss: 741.3385\n",
      "Epoch 6898/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 309.1200 - val_loss: 827.8515\n",
      "Epoch 6899/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 317.2098 - val_loss: 870.6797\n",
      "Epoch 6900/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 313.2909 - val_loss: 761.5464\n",
      "Epoch 6901/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 285.3937 - val_loss: 773.4665\n",
      "Epoch 6902/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 295.3696 - val_loss: 777.3378\n",
      "Epoch 6903/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 304.8194 - val_loss: 745.8555\n",
      "Epoch 6904/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.3503 - val_loss: 991.7488\n",
      "Epoch 6905/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.3512 - val_loss: 1068.4248\n",
      "Epoch 6906/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 805.3958 - val_loss: 1218.0719\n",
      "Epoch 6907/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 882.2500 - val_loss: 912.6270\n",
      "Epoch 6908/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 632.0742 - val_loss: 914.0864\n",
      "Epoch 6909/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 522.1191 - val_loss: 878.9491\n",
      "Epoch 6910/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 464.9280 - val_loss: 829.9199\n",
      "Epoch 6911/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 427.2651 - val_loss: 843.0502\n",
      "Epoch 6912/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 423.1656 - val_loss: 1040.1102\n",
      "Epoch 6913/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 345.5065 - val_loss: 862.2799\n",
      "Epoch 6914/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 437.2905 - val_loss: 773.4068\n",
      "Epoch 6915/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 416.0902 - val_loss: 803.5629\n",
      "Epoch 6916/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 403.5826 - val_loss: 855.0147\n",
      "Epoch 6917/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 375.8511 - val_loss: 892.1815\n",
      "Epoch 6918/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.4405 - val_loss: 1317.7684\n",
      "Epoch 6919/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 605.6709 - val_loss: 915.7978\n",
      "Epoch 6920/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 461.4344 - val_loss: 965.5552\n",
      "Epoch 6921/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 504.2820 - val_loss: 842.1824\n",
      "Epoch 6922/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 463.0851 - val_loss: 770.2708\n",
      "Epoch 6923/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 422.9710 - val_loss: 894.9965\n",
      "Epoch 6924/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 353.5704 - val_loss: 870.6077\n",
      "Epoch 6925/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.6119 - val_loss: 819.3678\n",
      "Epoch 6926/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 307.0075 - val_loss: 925.1849\n",
      "Epoch 6927/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.2955 - val_loss: 761.1926\n",
      "Epoch 6928/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 290.7486 - val_loss: 794.2906\n",
      "Epoch 6929/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.4554 - val_loss: 912.2387\n",
      "Epoch 6930/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 494.8719 - val_loss: 902.7855\n",
      "Epoch 6931/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 408.5672 - val_loss: 684.0848\n",
      "Epoch 6932/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 472.0437 - val_loss: 755.3119\n",
      "Epoch 6933/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 391.5560 - val_loss: 764.8390\n",
      "Epoch 6934/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 350.5664 - val_loss: 791.6591\n",
      "Epoch 6935/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 345.4325 - val_loss: 957.6995\n",
      "Epoch 6936/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 679.9381 - val_loss: 776.3410\n",
      "Epoch 6937/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 492.5077 - val_loss: 1036.5443\n",
      "Epoch 6938/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 447.8526 - val_loss: 875.7204\n",
      "Epoch 6939/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 394.8303 - val_loss: 791.4943\n",
      "Epoch 6940/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 346.0732 - val_loss: 1154.1249\n",
      "Epoch 6941/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 403.2664 - val_loss: 937.1655\n",
      "Epoch 6942/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 486.4055 - val_loss: 966.8894\n",
      "Epoch 6943/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 418.2496 - val_loss: 866.4363\n",
      "Epoch 6944/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 401.6409 - val_loss: 833.3480\n",
      "Epoch 6945/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 339.5901 - val_loss: 824.4641\n",
      "Epoch 6946/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 380.8301 - val_loss: 812.1049\n",
      "Epoch 6947/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 480.0746 - val_loss: 760.6578\n",
      "Epoch 6948/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 56us/step - loss: 429.6259 - val_loss: 910.1026\n",
      "Epoch 6949/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 403.1613 - val_loss: 873.7370\n",
      "Epoch 6950/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.6578 - val_loss: 862.8426\n",
      "Epoch 6951/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 449.2529 - val_loss: 745.9088\n",
      "Epoch 6952/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 472.1257 - val_loss: 772.4523\n",
      "Epoch 6953/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 433.7217 - val_loss: 926.0081\n",
      "Epoch 6954/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 412.7766 - val_loss: 797.4734\n",
      "Epoch 6955/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 374.8244 - val_loss: 784.2028\n",
      "Epoch 6956/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 328.2086 - val_loss: 928.4444\n",
      "Epoch 6957/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 334.0999 - val_loss: 807.0230\n",
      "Epoch 6958/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 393.9938 - val_loss: 971.9445\n",
      "Epoch 6959/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 580.0812 - val_loss: 1113.2664\n",
      "Epoch 6960/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 493.0918 - val_loss: 831.6550\n",
      "Epoch 6961/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 393.5158 - val_loss: 798.5478\n",
      "Epoch 6962/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 324.8366 - val_loss: 914.1269\n",
      "Epoch 6963/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 308.3558 - val_loss: 909.3711\n",
      "Epoch 6964/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 318.0010 - val_loss: 834.7683\n",
      "Epoch 6965/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 339.3670 - val_loss: 897.1408\n",
      "Epoch 6966/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.0363 - val_loss: 848.0377\n",
      "Epoch 6967/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 404.2938 - val_loss: 826.1501\n",
      "Epoch 6968/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 414.5474 - val_loss: 815.0867\n",
      "Epoch 6969/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 350.4135 - val_loss: 831.6245\n",
      "Epoch 6970/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 315.9049 - val_loss: 826.8072\n",
      "Epoch 6971/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 305.4909 - val_loss: 810.5940\n",
      "Epoch 6972/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.5877 - val_loss: 728.1704\n",
      "Epoch 6973/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 382.4135 - val_loss: 773.9856\n",
      "Epoch 6974/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.6548 - val_loss: 880.8818\n",
      "Epoch 6975/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 364.0390 - val_loss: 780.5933\n",
      "Epoch 6976/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 341.7083 - val_loss: 858.2690\n",
      "Epoch 6977/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.9016 - val_loss: 965.1986\n",
      "Epoch 6978/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 319.7983 - val_loss: 980.1803\n",
      "Epoch 6979/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 311.6146 - val_loss: 847.3430\n",
      "Epoch 6980/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 322.8473 - val_loss: 764.2878\n",
      "Epoch 6981/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 317.0633 - val_loss: 835.9164\n",
      "Epoch 6982/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 313.5546 - val_loss: 856.0040\n",
      "Epoch 6983/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.6235 - val_loss: 790.2394\n",
      "Epoch 6984/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 455.5963 - val_loss: 770.8502\n",
      "Epoch 6985/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 415.3718 - val_loss: 822.6018\n",
      "Epoch 6986/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 395.1319 - val_loss: 822.6103\n",
      "Epoch 6987/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 336.5134 - val_loss: 804.9366\n",
      "Epoch 6988/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 367.7585 - val_loss: 802.6173\n",
      "Epoch 6989/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 346.7118 - val_loss: 964.7778\n",
      "Epoch 6990/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 342.6476 - val_loss: 1058.4592\n",
      "Epoch 6991/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 378.3536 - val_loss: 1038.8322\n",
      "Epoch 6992/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 386.4689 - val_loss: 968.1980\n",
      "Epoch 6993/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 369.0628 - val_loss: 731.5875\n",
      "Epoch 6994/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 344.0353 - val_loss: 708.1066\n",
      "Epoch 6995/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.4709 - val_loss: 871.5255\n",
      "Epoch 6996/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 586.9800 - val_loss: 682.4897\n",
      "Epoch 6997/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 575.8430 - val_loss: 994.4442\n",
      "Epoch 6998/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 545.0530 - val_loss: 855.3384\n",
      "Epoch 6999/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 458.5492 - val_loss: 827.8829\n",
      "Epoch 7000/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 397.7079 - val_loss: 947.6290\n",
      "Epoch 7001/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 971.7443 - val_loss: 1958.2742\n",
      "Epoch 7002/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 3392.4107 - val_loss: 2604.2862\n",
      "Epoch 7003/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 3897.7999 - val_loss: 2259.3991\n",
      "Epoch 7004/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 3449.7656 - val_loss: 2049.0585\n",
      "Epoch 7005/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2858.9145 - val_loss: 1809.5593\n",
      "Epoch 7006/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2267.1252 - val_loss: 1646.3562\n",
      "Epoch 7007/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1794.7123 - val_loss: 1443.6477\n",
      "Epoch 7008/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1442.3991 - val_loss: 1447.3139\n",
      "Epoch 7009/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1199.3449 - val_loss: 1135.2113\n",
      "Epoch 7010/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1026.6372 - val_loss: 1090.3332\n",
      "Epoch 7011/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 864.0571 - val_loss: 1102.7231\n",
      "Epoch 7012/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 790.8514 - val_loss: 1333.3992\n",
      "Epoch 7013/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 731.9367 - val_loss: 1042.7728\n",
      "Epoch 7014/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 630.3442 - val_loss: 1080.0691\n",
      "Epoch 7015/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 561.8440 - val_loss: 1076.6537\n",
      "Epoch 7016/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 526.3191 - val_loss: 944.2451\n",
      "Epoch 7017/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 473.0442 - val_loss: 914.8702\n",
      "Epoch 7018/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 533.8249 - val_loss: 987.7685\n",
      "Epoch 7019/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 599.1066 - val_loss: 988.7543\n",
      "Epoch 7020/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 536.3465 - val_loss: 900.9783\n",
      "Epoch 7021/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 493.6264 - val_loss: 1003.5781\n",
      "Epoch 7022/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 590.2956 - val_loss: 909.6290\n",
      "Epoch 7023/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 763.5645 - val_loss: 1072.7067\n",
      "Epoch 7024/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 611.0103 - val_loss: 1014.5522\n",
      "Epoch 7025/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 573.0512 - val_loss: 904.6338\n",
      "Epoch 7026/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 606.1664 - val_loss: 1102.6591\n",
      "Epoch 7027/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1795.7376 - val_loss: 1762.2880\n",
      "Epoch 7028/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2493.6385 - val_loss: 1872.6689\n",
      "Epoch 7029/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2160.7615 - val_loss: 1822.6879\n",
      "Epoch 7030/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1668.2605 - val_loss: 1441.2095\n",
      "Epoch 7031/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1312.3594 - val_loss: 1350.9700\n",
      "Epoch 7032/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1153.9411 - val_loss: 1276.1715\n",
      "Epoch 7033/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1039.3773 - val_loss: 1274.9170\n",
      "Epoch 7034/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 962.4188 - val_loss: 1129.5573\n",
      "Epoch 7035/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 861.2053 - val_loss: 1121.5696\n",
      "Epoch 7036/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 795.7299 - val_loss: 1103.6661\n",
      "Epoch 7037/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 703.8144 - val_loss: 1054.5255\n",
      "Epoch 7038/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 651.2546 - val_loss: 980.3564\n",
      "Epoch 7039/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 599.4595 - val_loss: 969.9197\n",
      "Epoch 7040/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 548.8305 - val_loss: 984.8156\n",
      "Epoch 7041/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 529.7443 - val_loss: 971.2138\n",
      "Epoch 7042/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 506.9393 - val_loss: 941.7566\n",
      "Epoch 7043/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 494.7265 - val_loss: 901.7428\n",
      "Epoch 7044/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 456.9868 - val_loss: 883.3337\n",
      "Epoch 7045/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 433.4000 - val_loss: 909.3014\n",
      "Epoch 7046/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 412.6403 - val_loss: 1264.0096\n",
      "Epoch 7047/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 706.4230 - val_loss: 730.0764\n",
      "Epoch 7048/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 719.6111 - val_loss: 1033.5173\n",
      "Epoch 7049/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 506.5293 - val_loss: 997.5763\n",
      "Epoch 7050/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 456.8495 - val_loss: 777.3601\n",
      "Epoch 7051/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 504.8019 - val_loss: 1238.1636\n",
      "Epoch 7052/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 457.6574 - val_loss: 872.4695\n",
      "Epoch 7053/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 402.9368 - val_loss: 849.8309\n",
      "Epoch 7054/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.9834 - val_loss: 995.9777\n",
      "Epoch 7055/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 459.5045 - val_loss: 949.3589\n",
      "Epoch 7056/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 397.4779 - val_loss: 903.0243\n",
      "Epoch 7057/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 391.2394 - val_loss: 916.2991\n",
      "Epoch 7058/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 393.3041 - val_loss: 952.6322\n",
      "Epoch 7059/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 417.5205 - val_loss: 934.9173\n",
      "Epoch 7060/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 544.2221 - val_loss: 781.9193\n",
      "Epoch 7061/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 575.1214 - val_loss: 917.3175\n",
      "Epoch 7062/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 445.4428 - val_loss: 1020.2373\n",
      "Epoch 7063/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 373.3214 - val_loss: 909.2719\n",
      "Epoch 7064/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 344.2227 - val_loss: 861.9561\n",
      "Epoch 7065/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 359.7261 - val_loss: 798.1510\n",
      "Epoch 7066/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 345.5349 - val_loss: 864.9974\n",
      "Epoch 7067/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 326.8750 - val_loss: 764.9155\n",
      "Epoch 7068/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.4241 - val_loss: 920.3863\n",
      "Epoch 7069/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 316.8123 - val_loss: 888.2007\n",
      "Epoch 7070/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 302.6670 - val_loss: 956.4039\n",
      "Epoch 7071/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 365.2774 - val_loss: 786.0237\n",
      "Epoch 7072/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 346.1373 - val_loss: 781.7018\n",
      "Epoch 7073/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.4658 - val_loss: 917.4110\n",
      "Epoch 7074/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.3910 - val_loss: 847.2472\n",
      "Epoch 7075/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.6339 - val_loss: 873.3579\n",
      "Epoch 7076/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.3578 - val_loss: 911.4777\n",
      "Epoch 7077/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 342.3125 - val_loss: 711.8315\n",
      "Epoch 7078/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 362.3563 - val_loss: 907.4422\n",
      "Epoch 7079/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 322.0763 - val_loss: 838.9936\n",
      "Epoch 7080/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 312.0971 - val_loss: 890.2941\n",
      "Epoch 7081/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 299.8207 - val_loss: 809.7824\n",
      "Epoch 7082/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 288.3291 - val_loss: 759.1259\n",
      "Epoch 7083/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 299.1340 - val_loss: 929.5700\n",
      "Epoch 7084/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 310.1193 - val_loss: 938.5403\n",
      "Epoch 7085/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 405.5459 - val_loss: 899.2274\n",
      "Epoch 7086/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 463.0130 - val_loss: 782.3090\n",
      "Epoch 7087/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 424.5401 - val_loss: 894.2185\n",
      "Epoch 7088/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 419.5101 - val_loss: 818.1814\n",
      "Epoch 7089/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.6729 - val_loss: 800.3683\n",
      "Epoch 7090/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 367.6042 - val_loss: 839.5649\n",
      "Epoch 7091/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 348.1272 - val_loss: 796.1626\n",
      "Epoch 7092/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 297.1557 - val_loss: 847.5753\n",
      "Epoch 7093/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.8351 - val_loss: 812.9521\n",
      "Epoch 7094/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 350.7695 - val_loss: 754.9779\n",
      "Epoch 7095/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.0740 - val_loss: 814.0257\n",
      "Epoch 7096/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 394.8604 - val_loss: 912.7816\n",
      "Epoch 7097/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 354.5059 - val_loss: 933.1239\n",
      "Epoch 7098/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 352.4800 - val_loss: 843.0326\n",
      "Epoch 7099/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.3132 - val_loss: 877.4187\n",
      "Epoch 7100/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 332.8769 - val_loss: 779.5805\n",
      "Epoch 7101/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 372.3953 - val_loss: 940.5626\n",
      "Epoch 7102/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 380.7095 - val_loss: 970.7494\n",
      "Epoch 7103/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.2506 - val_loss: 805.4265\n",
      "Epoch 7104/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 340.9929 - val_loss: 734.1077\n",
      "Epoch 7105/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 431.7936 - val_loss: 827.0782\n",
      "Epoch 7106/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 475.5987 - val_loss: 1211.9636\n",
      "Epoch 7107/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 479.1678 - val_loss: 1009.3367\n",
      "Epoch 7108/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 395.4764 - val_loss: 995.2650\n",
      "Epoch 7109/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 362.7121 - val_loss: 858.2024\n",
      "Epoch 7110/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 336.3668 - val_loss: 831.3124\n",
      "Epoch 7111/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 320.6422 - val_loss: 839.7417\n",
      "Epoch 7112/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 296.6958 - val_loss: 794.1689\n",
      "Epoch 7113/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 304.8303 - val_loss: 751.8317\n",
      "Epoch 7114/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 325.2320 - val_loss: 797.7756\n",
      "Epoch 7115/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.6479 - val_loss: 743.0853\n",
      "Epoch 7116/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 388.7277 - val_loss: 836.8413\n",
      "Epoch 7117/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 451.3002 - val_loss: 901.5675\n",
      "Epoch 7118/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 424.5515 - val_loss: 759.1823\n",
      "Epoch 7119/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 386.1949 - val_loss: 799.6191\n",
      "Epoch 7120/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.3737 - val_loss: 881.0076\n",
      "Epoch 7121/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 320.2743 - val_loss: 848.4055\n",
      "Epoch 7122/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 294.4034 - val_loss: 843.1984\n",
      "Epoch 7123/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 286.6743 - val_loss: 843.0038\n",
      "Epoch 7124/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.7763 - val_loss: 776.4966\n",
      "Epoch 7125/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.1483 - val_loss: 844.0171\n",
      "Epoch 7126/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.2278 - val_loss: 831.3288\n",
      "Epoch 7127/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 327.1160 - val_loss: 758.2573\n",
      "Epoch 7128/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.4128 - val_loss: 975.0782\n",
      "Epoch 7129/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 494.3591 - val_loss: 700.9679\n",
      "Epoch 7130/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 537.9738 - val_loss: 864.1101\n",
      "Epoch 7131/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 459.8257 - val_loss: 775.2872\n",
      "Epoch 7132/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 402.8888 - val_loss: 798.7249\n",
      "Epoch 7133/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 369.8607 - val_loss: 793.5846\n",
      "Epoch 7134/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 607.8162 - val_loss: 878.8878\n",
      "Epoch 7135/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 484.1155 - val_loss: 1255.2604\n",
      "Epoch 7136/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 466.8850 - val_loss: 848.0335\n",
      "Epoch 7137/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 408.0247 - val_loss: 851.4097\n",
      "Epoch 7138/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 331.9412 - val_loss: 800.2892\n",
      "Epoch 7139/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.7951 - val_loss: 795.6038\n",
      "Epoch 7140/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 447.1213 - val_loss: 840.9794\n",
      "Epoch 7141/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 390.5862 - val_loss: 892.1804\n",
      "Epoch 7142/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 368.8022 - val_loss: 775.8998\n",
      "Epoch 7143/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 341.3950 - val_loss: 828.5175\n",
      "Epoch 7144/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 292.2582 - val_loss: 831.8232\n",
      "Epoch 7145/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 281.2826 - val_loss: 850.3249\n",
      "Epoch 7146/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 281.8815 - val_loss: 776.9168\n",
      "Epoch 7147/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 297.2162 - val_loss: 784.5270\n",
      "Epoch 7148/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 296.6495 - val_loss: 820.3718\n",
      "Epoch 7149/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 294.3367 - val_loss: 826.8276\n",
      "Epoch 7150/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 352.1155 - val_loss: 834.0719\n",
      "Epoch 7151/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 404.0257 - val_loss: 957.9353\n",
      "Epoch 7152/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 382.4200 - val_loss: 779.1283\n",
      "Epoch 7153/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 392.9356 - val_loss: 796.1194\n",
      "Epoch 7154/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 383.8908 - val_loss: 838.8006\n",
      "Epoch 7155/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 390.1721 - val_loss: 1339.2389\n",
      "Epoch 7156/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 812.7473 - val_loss: 731.4545\n",
      "Epoch 7157/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 687.6760 - val_loss: 1010.1885\n",
      "Epoch 7158/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 616.9933 - val_loss: 900.5422\n",
      "Epoch 7159/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 505.2320 - val_loss: 895.1799\n",
      "Epoch 7160/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 446.7266 - val_loss: 869.4650\n",
      "Epoch 7161/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 430.7948 - val_loss: 910.3975\n",
      "Epoch 7162/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.4949 - val_loss: 854.9407\n",
      "Epoch 7163/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 406.7934 - val_loss: 802.2337\n",
      "Epoch 7164/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 401.9809 - val_loss: 801.0768\n",
      "Epoch 7165/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 391.0136 - val_loss: 872.0985\n",
      "Epoch 7166/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 352.6963 - val_loss: 925.0757\n",
      "Epoch 7167/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 336.3274 - val_loss: 899.0811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7168/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 300.8746 - val_loss: 917.2504\n",
      "Epoch 7169/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 293.6107 - val_loss: 859.9069\n",
      "Epoch 7170/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 318.0366 - val_loss: 783.1729\n",
      "Epoch 7171/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 337.3655 - val_loss: 804.1084\n",
      "Epoch 7172/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 319.8049 - val_loss: 836.3741\n",
      "Epoch 7173/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 295.5344 - val_loss: 867.9307\n",
      "Epoch 7174/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 295.8931 - val_loss: 868.1902\n",
      "Epoch 7175/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 287.5696 - val_loss: 840.9659\n",
      "Epoch 7176/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 285.2458 - val_loss: 771.1322\n",
      "Epoch 7177/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 275.4297 - val_loss: 813.7234\n",
      "Epoch 7178/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 289.8346 - val_loss: 825.5837\n",
      "Epoch 7179/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 289.8742 - val_loss: 812.0419\n",
      "Epoch 7180/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 290.1855 - val_loss: 795.1184\n",
      "Epoch 7181/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.4995 - val_loss: 916.4781\n",
      "Epoch 7182/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 326.5652 - val_loss: 854.4565\n",
      "Epoch 7183/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 356.9655 - val_loss: 809.3912\n",
      "Epoch 7184/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 306.2678 - val_loss: 814.8311\n",
      "Epoch 7185/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.8956 - val_loss: 861.1550\n",
      "Epoch 7186/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 329.9612 - val_loss: 797.4111\n",
      "Epoch 7187/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 333.7869 - val_loss: 780.9523\n",
      "Epoch 7188/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 302.0656 - val_loss: 876.0208\n",
      "Epoch 7189/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 293.5404 - val_loss: 785.5834\n",
      "Epoch 7190/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 405.1611 - val_loss: 837.5431\n",
      "Epoch 7191/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 348.0729 - val_loss: 844.8381\n",
      "Epoch 7192/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.0881 - val_loss: 852.2014\n",
      "Epoch 7193/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 295.9960 - val_loss: 752.1910\n",
      "Epoch 7194/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 290.5530 - val_loss: 748.3119\n",
      "Epoch 7195/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 349.5111 - val_loss: 760.2566\n",
      "Epoch 7196/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 345.4346 - val_loss: 755.5095\n",
      "Epoch 7197/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 365.5089 - val_loss: 815.3104\n",
      "Epoch 7198/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 343.8751 - val_loss: 829.6727\n",
      "Epoch 7199/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 423.8280 - val_loss: 728.3441\n",
      "Epoch 7200/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.5140 - val_loss: 784.9910\n",
      "Epoch 7201/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 322.2234 - val_loss: 817.3879\n",
      "Epoch 7202/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 305.5428 - val_loss: 855.8362\n",
      "Epoch 7203/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 330.9437 - val_loss: 860.9389\n",
      "Epoch 7204/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 331.1457 - val_loss: 766.1040\n",
      "Epoch 7205/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 326.8837 - val_loss: 707.4105\n",
      "Epoch 7206/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 304.9664 - val_loss: 811.6698\n",
      "Epoch 7207/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 290.1480 - val_loss: 788.3123\n",
      "Epoch 7208/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 280.2281 - val_loss: 779.7880\n",
      "Epoch 7209/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 284.0227 - val_loss: 817.6594\n",
      "Epoch 7210/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 286.7096 - val_loss: 754.9466\n",
      "Epoch 7211/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 335.2453 - val_loss: 723.2101\n",
      "Epoch 7212/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 413.5229 - val_loss: 738.3390\n",
      "Epoch 7213/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 360.4168 - val_loss: 762.7876\n",
      "Epoch 7214/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.1533 - val_loss: 1239.5267\n",
      "Epoch 7215/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 553.7910 - val_loss: 777.3010\n",
      "Epoch 7216/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 484.5995 - val_loss: 784.2655\n",
      "Epoch 7217/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 401.8586 - val_loss: 774.6760\n",
      "Epoch 7218/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 355.7978 - val_loss: 732.1734\n",
      "Epoch 7219/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 322.9178 - val_loss: 912.0550\n",
      "Epoch 7220/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 319.9544 - val_loss: 759.0317\n",
      "Epoch 7221/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 327.5303 - val_loss: 827.5097\n",
      "Epoch 7222/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 311.5596 - val_loss: 758.1810\n",
      "Epoch 7223/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 316.6629 - val_loss: 842.0782\n",
      "Epoch 7224/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 315.5394 - val_loss: 840.9814\n",
      "Epoch 7225/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 292.1368 - val_loss: 849.8009\n",
      "Epoch 7226/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 371.7411 - val_loss: 943.9689\n",
      "Epoch 7227/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 603.2949 - val_loss: 879.0450\n",
      "Epoch 7228/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 482.8195 - val_loss: 737.8083\n",
      "Epoch 7229/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 467.5108 - val_loss: 883.1650\n",
      "Epoch 7230/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 383.8352 - val_loss: 785.0303\n",
      "Epoch 7231/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 323.7271 - val_loss: 722.4337\n",
      "Epoch 7232/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 399.8437 - val_loss: 941.3955\n",
      "Epoch 7233/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 398.3842 - val_loss: 772.8450\n",
      "Epoch 7234/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.0347 - val_loss: 881.3315\n",
      "Epoch 7235/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.6476 - val_loss: 1175.7519\n",
      "Epoch 7236/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 449.2595 - val_loss: 820.3437\n",
      "Epoch 7237/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 455.028 - 0s 62us/step - loss: 403.0439 - val_loss: 690.5474\n",
      "Epoch 7238/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 409.9542 - val_loss: 814.8636\n",
      "Epoch 7239/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 360.2215 - val_loss: 883.1695\n",
      "Epoch 7240/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 350.3127 - val_loss: 833.7124\n",
      "Epoch 7241/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 379.3294 - val_loss: 770.0447\n",
      "Epoch 7242/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.9129 - val_loss: 876.2664\n",
      "Epoch 7243/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 338.6406 - val_loss: 852.9992\n",
      "Epoch 7244/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1058.1380 - val_loss: 2736.5271\n",
      "Epoch 7245/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 4713.8279 - val_loss: 3641.2266\n",
      "Epoch 7246/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 6001.7392 - val_loss: 3759.8717\n",
      "Epoch 7247/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 5455.4773 - val_loss: 2841.8702\n",
      "Epoch 7248/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 4829.5042 - val_loss: 3042.2452\n",
      "Epoch 7249/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 4053.4712 - val_loss: 2801.8759\n",
      "Epoch 7250/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 3505.3415 - val_loss: 2059.0232\n",
      "Epoch 7251/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3058.5554 - val_loss: 2458.8104\n",
      "Epoch 7252/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2631.6038 - val_loss: 1966.8022\n",
      "Epoch 7253/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2266.4033 - val_loss: 1721.4106\n",
      "Epoch 7254/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2073.1554 - val_loss: 1602.0033\n",
      "Epoch 7255/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1868.0140 - val_loss: 1632.5507\n",
      "Epoch 7256/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1754.9984 - val_loss: 1479.5394\n",
      "Epoch 7257/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1679.2982 - val_loss: 1393.3501\n",
      "Epoch 7258/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1560.8698 - val_loss: 1534.3613\n",
      "Epoch 7259/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 1461.0786 - val_loss: 1444.0889\n",
      "Epoch 7260/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1378.3777 - val_loss: 1346.3262\n",
      "Epoch 7261/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1241.1557 - val_loss: 1342.5776\n",
      "Epoch 7262/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1178.6794 - val_loss: 1390.7036\n",
      "Epoch 7263/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 1102.2506 - val_loss: 1231.2075\n",
      "Epoch 7264/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1005.5821 - val_loss: 1236.1355\n",
      "Epoch 7265/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 939.9680 - val_loss: 1136.2811\n",
      "Epoch 7266/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 910.2591 - val_loss: 1210.9744\n",
      "Epoch 7267/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 860.3055 - val_loss: 1142.2072\n",
      "Epoch 7268/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 815.5850 - val_loss: 1111.7389\n",
      "Epoch 7269/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 773.7181 - val_loss: 1115.6752\n",
      "Epoch 7270/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 717.9540 - val_loss: 1054.5433\n",
      "Epoch 7271/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 677.1719 - val_loss: 1062.5096\n",
      "Epoch 7272/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 631.6969 - val_loss: 1007.6378\n",
      "Epoch 7273/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 618.4841 - val_loss: 1140.0407\n",
      "Epoch 7274/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 594.2285 - val_loss: 1154.8867\n",
      "Epoch 7275/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 517.0384 - val_loss: 1067.5575\n",
      "Epoch 7276/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 474.7977 - val_loss: 955.0473\n",
      "Epoch 7277/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 422.1199 - val_loss: 1406.4555\n",
      "Epoch 7278/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 502.7500 - val_loss: 923.5473\n",
      "Epoch 7279/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 436.1486 - val_loss: 828.5939\n",
      "Epoch 7280/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 353.5657 - val_loss: 962.5238\n",
      "Epoch 7281/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 476.0196 - val_loss: 1043.1505\n",
      "Epoch 7282/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 540.2237 - val_loss: 1030.3771\n",
      "Epoch 7283/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 439.3033 - val_loss: 797.6371\n",
      "Epoch 7284/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 372.0255 - val_loss: 825.1865\n",
      "Epoch 7285/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 359.0758 - val_loss: 859.2447\n",
      "Epoch 7286/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.8655 - val_loss: 746.2046\n",
      "Epoch 7287/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 378.5848 - val_loss: 853.8731\n",
      "Epoch 7288/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 360.0507 - val_loss: 991.3379\n",
      "Epoch 7289/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 374.0499 - val_loss: 963.2323\n",
      "Epoch 7290/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 360.0039 - val_loss: 891.1323\n",
      "Epoch 7291/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 331.1189 - val_loss: 749.8083\n",
      "Epoch 7292/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 305.8228 - val_loss: 634.2064\n",
      "Epoch 7293/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 464.8066 - val_loss: 690.7537\n",
      "Epoch 7294/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 453.7564 - val_loss: 1053.9189\n",
      "Epoch 7295/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 364.3707 - val_loss: 871.1243\n",
      "Epoch 7296/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 342.3799 - val_loss: 799.5571\n",
      "Epoch 7297/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 322.7797 - val_loss: 711.5513\n",
      "Epoch 7298/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 317.7342 - val_loss: 765.9746\n",
      "Epoch 7299/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 386.6581 - val_loss: 756.0228\n",
      "Epoch 7300/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 374.0994 - val_loss: 708.5393\n",
      "Epoch 7301/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 399.5612 - val_loss: 685.1887\n",
      "Epoch 7302/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 482.4600 - val_loss: 808.6862\n",
      "Epoch 7303/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 769.2179 - val_loss: 749.5924\n",
      "Epoch 7304/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 475.6412 - val_loss: 1004.2505\n",
      "Epoch 7305/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 459.5267 - val_loss: 1088.5988\n",
      "Epoch 7306/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 460.5266 - val_loss: 980.3528\n",
      "Epoch 7307/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 454.9178 - val_loss: 828.1803\n",
      "Epoch 7308/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 389.1587 - val_loss: 874.9908\n",
      "Epoch 7309/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.4866 - val_loss: 811.8580\n",
      "Epoch 7310/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.0160 - val_loss: 851.2962\n",
      "Epoch 7311/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 322.3025 - val_loss: 802.7962\n",
      "Epoch 7312/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 306.9882 - val_loss: 811.5440\n",
      "Epoch 7313/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.5204 - val_loss: 815.8195\n",
      "Epoch 7314/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 302.5501 - val_loss: 876.1731\n",
      "Epoch 7315/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 306.1179 - val_loss: 826.8814\n",
      "Epoch 7316/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 306.7114 - val_loss: 784.3983\n",
      "Epoch 7317/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 353.2630 - val_loss: 776.1891\n",
      "Epoch 7318/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 313.4658 - val_loss: 807.1514\n",
      "Epoch 7319/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.5646 - val_loss: 897.5519\n",
      "Epoch 7320/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 300.3990 - val_loss: 861.0197\n",
      "Epoch 7321/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 297.2188 - val_loss: 751.0187\n",
      "Epoch 7322/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 322.8091 - val_loss: 788.8248\n",
      "Epoch 7323/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.1718 - val_loss: 759.5389\n",
      "Epoch 7324/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.5666 - val_loss: 773.1381\n",
      "Epoch 7325/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 307.0737 - val_loss: 1831.3868\n",
      "Epoch 7326/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 795.3623 - val_loss: 1261.0376\n",
      "Epoch 7327/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 792.2103 - val_loss: 1320.0441\n",
      "Epoch 7328/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 705.8716 - val_loss: 1211.0319\n",
      "Epoch 7329/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 584.3577 - val_loss: 1142.3051\n",
      "Epoch 7330/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 530.3495 - val_loss: 775.3592\n",
      "Epoch 7331/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 722.1132 - val_loss: 889.8522\n",
      "Epoch 7332/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 885.1908 - val_loss: 1078.8165\n",
      "Epoch 7333/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 758.8775 - val_loss: 978.1634\n",
      "Epoch 7334/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 740.6953 - val_loss: 761.7025\n",
      "Epoch 7335/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 571.6685 - val_loss: 1035.7261\n",
      "Epoch 7336/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 811.4316 - val_loss: 1196.0785\n",
      "Epoch 7337/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 712.6253 - val_loss: 1050.1460\n",
      "Epoch 7338/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 537.3258 - val_loss: 794.3669\n",
      "Epoch 7339/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 446.3909 - val_loss: 826.4803\n",
      "Epoch 7340/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 375.5885 - val_loss: 817.5279\n",
      "Epoch 7341/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 341.8446 - val_loss: 1008.6497\n",
      "Epoch 7342/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 417.6665 - val_loss: 946.8015\n",
      "Epoch 7343/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 362.5757 - val_loss: 853.7191\n",
      "Epoch 7344/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 348.1063 - val_loss: 901.2767\n",
      "Epoch 7345/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 330.0121 - val_loss: 821.0925\n",
      "Epoch 7346/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 388.0338 - val_loss: 814.8794\n",
      "Epoch 7347/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 416.4415 - val_loss: 936.5779\n",
      "Epoch 7348/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 420.5422 - val_loss: 856.7969\n",
      "Epoch 7349/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 345.8458 - val_loss: 764.5443\n",
      "Epoch 7350/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.0029 - val_loss: 867.8062\n",
      "Epoch 7351/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.8034 - val_loss: 1124.9249\n",
      "Epoch 7352/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 673.1012 - val_loss: 1143.9168\n",
      "Epoch 7353/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 533.7267 - val_loss: 923.0289\n",
      "Epoch 7354/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 403.7095 - val_loss: 748.3386\n",
      "Epoch 7355/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 373.7796 - val_loss: 820.8311\n",
      "Epoch 7356/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 317.2181 - val_loss: 743.4618\n",
      "Epoch 7357/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 369.0106 - val_loss: 669.9728\n",
      "Epoch 7358/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 372.1331 - val_loss: 702.0619\n",
      "Epoch 7359/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 416.2721 - val_loss: 2509.5536\n",
      "Epoch 7360/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2248.1605 - val_loss: 1942.8118\n",
      "Epoch 7361/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2140.1018 - val_loss: 1952.0231\n",
      "Epoch 7362/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1748.0855 - val_loss: 1772.8630\n",
      "Epoch 7363/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1260.0138 - val_loss: 1391.6912\n",
      "Epoch 7364/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 869.1189 - val_loss: 1301.0668\n",
      "Epoch 7365/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 729.8257 - val_loss: 1350.7632\n",
      "Epoch 7366/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 614.7388 - val_loss: 1313.5184\n",
      "Epoch 7367/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 581.1730 - val_loss: 1199.2867\n",
      "Epoch 7368/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 556.5731 - val_loss: 1173.0969\n",
      "Epoch 7369/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 575.3836 - val_loss: 1532.3553\n",
      "Epoch 7370/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 659.6963 - val_loss: 1118.1411\n",
      "Epoch 7371/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 610.5837 - val_loss: 1235.2455\n",
      "Epoch 7372/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 506.5331 - val_loss: 1210.0507\n",
      "Epoch 7373/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 483.6480 - val_loss: 1453.2957\n",
      "Epoch 7374/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 531.9512 - val_loss: 1242.0986\n",
      "Epoch 7375/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 482.9996 - val_loss: 1141.6786\n",
      "Epoch 7376/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 490.7772 - val_loss: 1096.6599\n",
      "Epoch 7377/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 478.6024 - val_loss: 1124.8500\n",
      "Epoch 7378/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 436.6332 - val_loss: 1106.6360\n",
      "Epoch 7379/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 456.8451 - val_loss: 1103.8755\n",
      "Epoch 7380/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 455.6806 - val_loss: 1132.2884\n",
      "Epoch 7381/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 451.1254 - val_loss: 1078.2459\n",
      "Epoch 7382/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 463.8857 - val_loss: 854.1301\n",
      "Epoch 7383/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 600.6428 - val_loss: 1235.4055\n",
      "Epoch 7384/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 612.7331 - val_loss: 671.4342\n",
      "Epoch 7385/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 503.2298 - val_loss: 900.6488\n",
      "Epoch 7386/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 407.2963 - val_loss: 948.7611\n",
      "Epoch 7387/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 358.8634 - val_loss: 820.6546\n",
      "Epoch 7388/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 336.7968 - val_loss: 838.5815\n",
      "Epoch 7389/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.5782 - val_loss: 849.1678\n",
      "Epoch 7390/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 345.0748 - val_loss: 654.7731\n",
      "Epoch 7391/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 372.2202 - val_loss: 782.9927\n",
      "Epoch 7392/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 416.3946 - val_loss: 1022.8554\n",
      "Epoch 7393/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 491.1414 - val_loss: 776.7127\n",
      "Epoch 7394/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 398.3683 - val_loss: 816.0389\n",
      "Epoch 7395/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 348.9429 - val_loss: 798.8402\n",
      "Epoch 7396/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 353.1158 - val_loss: 706.8866\n",
      "Epoch 7397/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 436.3480 - val_loss: 772.7673\n",
      "Epoch 7398/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 389.7604 - val_loss: 998.5058\n",
      "Epoch 7399/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 378.2673 - val_loss: 920.9055\n",
      "Epoch 7400/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 327.1331 - val_loss: 803.9639\n",
      "Epoch 7401/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.2965 - val_loss: 780.7960\n",
      "Epoch 7402/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 364.9534 - val_loss: 744.9849\n",
      "Epoch 7403/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 418.9992 - val_loss: 759.1006\n",
      "Epoch 7404/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 412.9876 - val_loss: 877.5621\n",
      "Epoch 7405/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 390.5009 - val_loss: 748.0583\n",
      "Epoch 7406/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 357.8776 - val_loss: 864.6640\n",
      "Epoch 7407/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 322.5418 - val_loss: 873.6135\n",
      "Epoch 7408/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 306.1771 - val_loss: 800.9177\n",
      "Epoch 7409/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 294.5293 - val_loss: 753.1607\n",
      "Epoch 7410/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 300.4554 - val_loss: 1074.9786\n",
      "Epoch 7411/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 485.0096 - val_loss: 842.4432\n",
      "Epoch 7412/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 446.6811 - val_loss: 893.4362\n",
      "Epoch 7413/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 481.0754 - val_loss: 849.3534\n",
      "Epoch 7414/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.0945 - val_loss: 926.5062\n",
      "Epoch 7415/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 331.6867 - val_loss: 816.1709\n",
      "Epoch 7416/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 300.3266 - val_loss: 800.4125\n",
      "Epoch 7417/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 308.3466 - val_loss: 766.8541\n",
      "Epoch 7418/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 305.3027 - val_loss: 819.0762\n",
      "Epoch 7419/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 294.0176 - val_loss: 789.3556\n",
      "Epoch 7420/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 282.7370 - val_loss: 805.1306\n",
      "Epoch 7421/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 273.7205 - val_loss: 761.0531\n",
      "Epoch 7422/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 417.6111 - val_loss: 823.6733\n",
      "Epoch 7423/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 385.3079 - val_loss: 751.2647\n",
      "Epoch 7424/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 367.8717 - val_loss: 769.1588\n",
      "Epoch 7425/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 334.6118 - val_loss: 794.7323\n",
      "Epoch 7426/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.1776 - val_loss: 784.5921\n",
      "Epoch 7427/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.7732 - val_loss: 835.6172\n",
      "Epoch 7428/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.2336 - val_loss: 757.4680\n",
      "Epoch 7429/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 344.8691 - val_loss: 758.4409\n",
      "Epoch 7430/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.3209 - val_loss: 750.4922\n",
      "Epoch 7431/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 465.2669 - val_loss: 823.5567\n",
      "Epoch 7432/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 429.8306 - val_loss: 774.7602\n",
      "Epoch 7433/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.1432 - val_loss: 789.9476\n",
      "Epoch 7434/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 486.9380 - val_loss: 845.5551\n",
      "Epoch 7435/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 548.7377 - val_loss: 850.5924\n",
      "Epoch 7436/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 410.0961 - val_loss: 964.4784\n",
      "Epoch 7437/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 487.6927 - val_loss: 874.8132\n",
      "Epoch 7438/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 400.6202 - val_loss: 854.4479\n",
      "Epoch 7439/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 338.0937 - val_loss: 802.9635\n",
      "Epoch 7440/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 304.8275 - val_loss: 819.9417\n",
      "Epoch 7441/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 306.0884 - val_loss: 851.7531\n",
      "Epoch 7442/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 310.3620 - val_loss: 824.2538\n",
      "Epoch 7443/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 332.3533 - val_loss: 944.6983\n",
      "Epoch 7444/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 309.5924 - val_loss: 895.2455\n",
      "Epoch 7445/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 305.5345 - val_loss: 935.0515\n",
      "Epoch 7446/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 306.9035 - val_loss: 880.8644\n",
      "Epoch 7447/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 302.5985 - val_loss: 771.8112\n",
      "Epoch 7448/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 298.2212 - val_loss: 839.2024\n",
      "Epoch 7449/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 299.9316 - val_loss: 871.0143\n",
      "Epoch 7450/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 289.1945 - val_loss: 864.7364\n",
      "Epoch 7451/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 296.7009 - val_loss: 703.8884\n",
      "Epoch 7452/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 348.2070 - val_loss: 776.4985\n",
      "Epoch 7453/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 354.1610 - val_loss: 787.2410\n",
      "Epoch 7454/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 333.0650 - val_loss: 804.7311\n",
      "Epoch 7455/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 306.3126 - val_loss: 949.4078\n",
      "Epoch 7456/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 363.0693 - val_loss: 789.4626\n",
      "Epoch 7457/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.3833 - val_loss: 841.4537\n",
      "Epoch 7458/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 342.3520 - val_loss: 885.8615\n",
      "Epoch 7459/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.5876 - val_loss: 799.2048\n",
      "Epoch 7460/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 302.6870 - val_loss: 759.7331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7461/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 298.2515 - val_loss: 702.4307\n",
      "Epoch 7462/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 289.4286 - val_loss: 816.2028\n",
      "Epoch 7463/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 279.2249 - val_loss: 815.2307\n",
      "Epoch 7464/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 288.9601 - val_loss: 849.1032\n",
      "Epoch 7465/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 277.8050 - val_loss: 924.3047\n",
      "Epoch 7466/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 312.3515 - val_loss: 780.1285\n",
      "Epoch 7467/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 301.9169 - val_loss: 840.8676\n",
      "Epoch 7468/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.8180 - val_loss: 768.3908\n",
      "Epoch 7469/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 306.8902 - val_loss: 835.4933\n",
      "Epoch 7470/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 293.7965 - val_loss: 830.5764\n",
      "Epoch 7471/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 292.7657 - val_loss: 767.7700\n",
      "Epoch 7472/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 282.2986 - val_loss: 831.2055\n",
      "Epoch 7473/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.9171 - val_loss: 755.2724\n",
      "Epoch 7474/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 385.1808 - val_loss: 801.0453\n",
      "Epoch 7475/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 407.4269 - val_loss: 775.6025\n",
      "Epoch 7476/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.9895 - val_loss: 872.6295\n",
      "Epoch 7477/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 288.2852 - val_loss: 884.2775\n",
      "Epoch 7478/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 295.2404 - val_loss: 822.1004\n",
      "Epoch 7479/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 296.5007 - val_loss: 878.6257\n",
      "Epoch 7480/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 298.4659 - val_loss: 789.1407\n",
      "Epoch 7481/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 297.4205 - val_loss: 749.9194\n",
      "Epoch 7482/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 332.7204 - val_loss: 702.7569\n",
      "Epoch 7483/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 322.6671 - val_loss: 707.6597\n",
      "Epoch 7484/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 299.7075 - val_loss: 839.7184\n",
      "Epoch 7485/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 299.9734 - val_loss: 999.9162\n",
      "Epoch 7486/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 376.8575 - val_loss: 1129.8899\n",
      "Epoch 7487/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 382.8627 - val_loss: 783.0751\n",
      "Epoch 7488/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.2648 - val_loss: 829.7134\n",
      "Epoch 7489/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 326.0002 - val_loss: 861.5961\n",
      "Epoch 7490/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 316.2816 - val_loss: 788.1744\n",
      "Epoch 7491/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 372.2957 - val_loss: 785.6661\n",
      "Epoch 7492/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 361.2315 - val_loss: 933.1401\n",
      "Epoch 7493/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.6089 - val_loss: 880.7954\n",
      "Epoch 7494/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.4268 - val_loss: 956.8905\n",
      "Epoch 7495/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.8075 - val_loss: 961.5818\n",
      "Epoch 7496/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 393.3338 - val_loss: 844.6083\n",
      "Epoch 7497/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 378.4397 - val_loss: 766.2177\n",
      "Epoch 7498/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 349.9917 - val_loss: 711.1769\n",
      "Epoch 7499/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.1242 - val_loss: 854.1766\n",
      "Epoch 7500/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.7302 - val_loss: 813.8100\n",
      "Epoch 7501/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 303.9083 - val_loss: 878.9149\n",
      "Epoch 7502/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.7398 - val_loss: 775.2198\n",
      "Epoch 7503/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 304.0009 - val_loss: 859.9427\n",
      "Epoch 7504/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 295.3590 - val_loss: 795.3380\n",
      "Epoch 7505/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 301.8573 - val_loss: 774.7096\n",
      "Epoch 7506/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 345.4451 - val_loss: 721.6130\n",
      "Epoch 7507/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.3024 - val_loss: 813.0567\n",
      "Epoch 7508/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.4657 - val_loss: 871.1808\n",
      "Epoch 7509/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.2361 - val_loss: 915.5077\n",
      "Epoch 7510/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.2731 - val_loss: 696.0102\n",
      "Epoch 7511/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 317.0031 - val_loss: 767.0429\n",
      "Epoch 7512/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 298.2975 - val_loss: 800.1590\n",
      "Epoch 7513/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 294.1537 - val_loss: 805.5196\n",
      "Epoch 7514/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.0428 - val_loss: 825.9006\n",
      "Epoch 7515/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 289.4505 - val_loss: 774.9304\n",
      "Epoch 7516/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 283.0556 - val_loss: 828.7608\n",
      "Epoch 7517/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 303.2066 - val_loss: 736.5368\n",
      "Epoch 7518/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 291.2097 - val_loss: 897.8978\n",
      "Epoch 7519/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 299.7531 - val_loss: 751.9237\n",
      "Epoch 7520/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 288.5582 - val_loss: 817.7846\n",
      "Epoch 7521/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 279.4875 - val_loss: 763.5879\n",
      "Epoch 7522/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 293.9000 - val_loss: 757.3863\n",
      "Epoch 7523/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 333.8827 - val_loss: 841.1430\n",
      "Epoch 7524/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 328.0287 - val_loss: 825.9755\n",
      "Epoch 7525/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 302.1654 - val_loss: 822.2680\n",
      "Epoch 7526/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 278.8465 - val_loss: 799.5361\n",
      "Epoch 7527/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 295.5198 - val_loss: 826.1992\n",
      "Epoch 7528/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 431.2234 - val_loss: 833.8384\n",
      "Epoch 7529/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 377.3554 - val_loss: 774.2552\n",
      "Epoch 7530/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 328.9805 - val_loss: 741.6154\n",
      "Epoch 7531/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 379.4225 - val_loss: 1119.6073\n",
      "Epoch 7532/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 408.0214 - val_loss: 935.1653\n",
      "Epoch 7533/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 404.0394 - val_loss: 764.3112\n",
      "Epoch 7534/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.0250 - val_loss: 801.8232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7535/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 307.4978 - val_loss: 914.8767\n",
      "Epoch 7536/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.0733 - val_loss: 829.4958\n",
      "Epoch 7537/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 319.1256 - val_loss: 806.4027\n",
      "Epoch 7538/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 314.4094 - val_loss: 759.6607\n",
      "Epoch 7539/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 289.0200 - val_loss: 820.8361\n",
      "Epoch 7540/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 312.6678 - val_loss: 741.5191\n",
      "Epoch 7541/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 299.0142 - val_loss: 826.3635\n",
      "Epoch 7542/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 323.1227 - val_loss: 803.2001\n",
      "Epoch 7543/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.0431 - val_loss: 848.4151\n",
      "Epoch 7544/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 315.5867 - val_loss: 835.2814\n",
      "Epoch 7545/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 297.1322 - val_loss: 909.9544\n",
      "Epoch 7546/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 304.2824 - val_loss: 803.4549\n",
      "Epoch 7547/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.9800 - val_loss: 817.7562\n",
      "Epoch 7548/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 289.2012 - val_loss: 797.6120\n",
      "Epoch 7549/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.9329 - val_loss: 713.8413\n",
      "Epoch 7550/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 503.1650 - val_loss: 1128.3856\n",
      "Epoch 7551/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 606.2069 - val_loss: 1120.8143\n",
      "Epoch 7552/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 546.4402 - val_loss: 1159.1876\n",
      "Epoch 7553/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 493.6924 - val_loss: 921.3575\n",
      "Epoch 7554/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 599.9403 - val_loss: 902.9491\n",
      "Epoch 7555/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 454.1084 - val_loss: 885.5974\n",
      "Epoch 7556/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 418.1558 - val_loss: 810.3115\n",
      "Epoch 7557/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.7757 - val_loss: 923.6976\n",
      "Epoch 7558/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 364.7832 - val_loss: 812.5467\n",
      "Epoch 7559/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 332.3808 - val_loss: 805.6540\n",
      "Epoch 7560/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 699.8198 - val_loss: 1190.3719\n",
      "Epoch 7561/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1050.6943 - val_loss: 879.7346\n",
      "Epoch 7562/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1224.6475 - val_loss: 672.2875\n",
      "Epoch 7563/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 770.6525 - val_loss: 1325.3788\n",
      "Epoch 7564/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 643.8633 - val_loss: 1201.8379\n",
      "Epoch 7565/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 616.3721 - val_loss: 1190.7018\n",
      "Epoch 7566/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 502.5308 - val_loss: 1142.4392\n",
      "Epoch 7567/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 477.7056 - val_loss: 1089.8961\n",
      "Epoch 7568/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 447.5464 - val_loss: 890.7225\n",
      "Epoch 7569/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 402.1956 - val_loss: 812.5680\n",
      "Epoch 7570/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 372.6842 - val_loss: 834.2320\n",
      "Epoch 7571/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.6305 - val_loss: 1024.0202\n",
      "Epoch 7572/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 321.1576 - val_loss: 828.1094\n",
      "Epoch 7573/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.6449 - val_loss: 920.0761\n",
      "Epoch 7574/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 303.1675 - val_loss: 727.9744\n",
      "Epoch 7575/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 520.5297 - val_loss: 882.7188\n",
      "Epoch 7576/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 505.1781 - val_loss: 798.0601\n",
      "Epoch 7577/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 417.4546 - val_loss: 725.8404\n",
      "Epoch 7578/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 402.7640 - val_loss: 880.1236\n",
      "Epoch 7579/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 370.3992 - val_loss: 971.9183\n",
      "Epoch 7580/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.6670 - val_loss: 907.4837\n",
      "Epoch 7581/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.8319 - val_loss: 793.5652\n",
      "Epoch 7582/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.9972 - val_loss: 828.6586\n",
      "Epoch 7583/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 338.0212 - val_loss: 820.0031\n",
      "Epoch 7584/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 344.5565 - val_loss: 961.3310\n",
      "Epoch 7585/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.7233 - val_loss: 902.2044\n",
      "Epoch 7586/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.0047 - val_loss: 840.7131\n",
      "Epoch 7587/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 348.3456 - val_loss: 699.5400\n",
      "Epoch 7588/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 320.6773 - val_loss: 799.3007\n",
      "Epoch 7589/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 315.4325 - val_loss: 770.8699\n",
      "Epoch 7590/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 337.4554 - val_loss: 765.6895\n",
      "Epoch 7591/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 375.0080 - val_loss: 910.6803\n",
      "Epoch 7592/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.6681 - val_loss: 792.6693\n",
      "Epoch 7593/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 328.3065 - val_loss: 747.7190\n",
      "Epoch 7594/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.5982 - val_loss: 716.7176\n",
      "Epoch 7595/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 347.6692 - val_loss: 815.0640\n",
      "Epoch 7596/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 380.5651 - val_loss: 874.5569\n",
      "Epoch 7597/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 388.3219 - val_loss: 757.9138\n",
      "Epoch 7598/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 370.5280 - val_loss: 845.9701\n",
      "Epoch 7599/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 346.1408 - val_loss: 750.5168\n",
      "Epoch 7600/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 319.5791 - val_loss: 894.5527\n",
      "Epoch 7601/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 441.4634 - val_loss: 969.0748\n",
      "Epoch 7602/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 404.1084 - val_loss: 854.9582\n",
      "Epoch 7603/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 351.5807 - val_loss: 794.4776\n",
      "Epoch 7604/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 312.7692 - val_loss: 912.3517\n",
      "Epoch 7605/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.2851 - val_loss: 794.5714\n",
      "Epoch 7606/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.0407 - val_loss: 877.3483\n",
      "Epoch 7607/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 355.8837 - val_loss: 993.8628\n",
      "Epoch 7608/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 53us/step - loss: 335.0364 - val_loss: 840.0977\n",
      "Epoch 7609/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 313.6149 - val_loss: 801.8237\n",
      "Epoch 7610/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 299.8305 - val_loss: 840.7813\n",
      "Epoch 7611/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 339.6354 - val_loss: 728.9982\n",
      "Epoch 7612/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 356.1888 - val_loss: 741.3152\n",
      "Epoch 7613/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 370.9116 - val_loss: 836.1998\n",
      "Epoch 7614/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.3672 - val_loss: 864.2711\n",
      "Epoch 7615/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 302.6114 - val_loss: 909.3100\n",
      "Epoch 7616/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 331.4201 - val_loss: 861.6811\n",
      "Epoch 7617/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.9317 - val_loss: 944.9706\n",
      "Epoch 7618/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 348.8531 - val_loss: 916.8781\n",
      "Epoch 7619/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.1719 - val_loss: 886.3577\n",
      "Epoch 7620/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 346.5874 - val_loss: 987.9677\n",
      "Epoch 7621/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 420.5176 - val_loss: 980.0073\n",
      "Epoch 7622/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 449.0047 - val_loss: 877.0695\n",
      "Epoch 7623/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 380.2252 - val_loss: 1029.9036\n",
      "Epoch 7624/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 371.1933 - val_loss: 789.5459\n",
      "Epoch 7625/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 363.7726 - val_loss: 870.3558\n",
      "Epoch 7626/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 372.9139 - val_loss: 739.5087\n",
      "Epoch 7627/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 375.0686 - val_loss: 838.3472\n",
      "Epoch 7628/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 373.5840 - val_loss: 729.8027\n",
      "Epoch 7629/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.7021 - val_loss: 1063.6107\n",
      "Epoch 7630/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.0574 - val_loss: 811.4641\n",
      "Epoch 7631/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 485.6842 - val_loss: 944.8305\n",
      "Epoch 7632/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 422.1433 - val_loss: 869.9686\n",
      "Epoch 7633/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 402.8982 - val_loss: 880.6344\n",
      "Epoch 7634/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 353.5719 - val_loss: 834.3785\n",
      "Epoch 7635/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.8480 - val_loss: 724.7331\n",
      "Epoch 7636/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 352.2487 - val_loss: 892.3341\n",
      "Epoch 7637/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 381.4162 - val_loss: 854.3536\n",
      "Epoch 7638/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 400.1439 - val_loss: 767.0528\n",
      "Epoch 7639/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.5514 - val_loss: 819.5856\n",
      "Epoch 7640/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 373.1121 - val_loss: 823.3708\n",
      "Epoch 7641/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.4085 - val_loss: 873.9375\n",
      "Epoch 7642/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 711.8760 - val_loss: 1244.0416\n",
      "Epoch 7643/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1149.1759 - val_loss: 1113.6883\n",
      "Epoch 7644/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 910.3036 - val_loss: 951.3205\n",
      "Epoch 7645/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 804.7241 - val_loss: 849.6100\n",
      "Epoch 7646/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 592.9654 - val_loss: 1024.0738\n",
      "Epoch 7647/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 512.2264 - val_loss: 875.9302\n",
      "Epoch 7648/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 416.4222 - val_loss: 842.3917\n",
      "Epoch 7649/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 344.3746 - val_loss: 932.8367\n",
      "Epoch 7650/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.8622 - val_loss: 942.7511\n",
      "Epoch 7651/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 321.1185 - val_loss: 867.0310\n",
      "Epoch 7652/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.5235 - val_loss: 749.3225\n",
      "Epoch 7653/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.5604 - val_loss: 858.4268\n",
      "Epoch 7654/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 284.0520 - val_loss: 812.2395\n",
      "Epoch 7655/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.6822 - val_loss: 748.4144\n",
      "Epoch 7656/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.3277 - val_loss: 1013.3660\n",
      "Epoch 7657/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 393.9603 - val_loss: 829.9810\n",
      "Epoch 7658/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 423.0678 - val_loss: 1002.7242\n",
      "Epoch 7659/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 428.2870 - val_loss: 811.2281\n",
      "Epoch 7660/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 412.7220 - val_loss: 830.7013\n",
      "Epoch 7661/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 409.8460 - val_loss: 843.0947\n",
      "Epoch 7662/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 352.8156 - val_loss: 826.0171\n",
      "Epoch 7663/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.7083 - val_loss: 791.7569\n",
      "Epoch 7664/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 336.8369 - val_loss: 846.1402\n",
      "Epoch 7665/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 346.5337 - val_loss: 838.6178\n",
      "Epoch 7666/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 347.5980 - val_loss: 753.1006\n",
      "Epoch 7667/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 376.7845 - val_loss: 727.5606\n",
      "Epoch 7668/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 337.7389 - val_loss: 872.2258\n",
      "Epoch 7669/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.9121 - val_loss: 849.0642\n",
      "Epoch 7670/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.0101 - val_loss: 877.1977\n",
      "Epoch 7671/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.5066 - val_loss: 789.1836\n",
      "Epoch 7672/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 319.4097 - val_loss: 855.5218\n",
      "Epoch 7673/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 298.7816 - val_loss: 743.0299\n",
      "Epoch 7674/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 303.9122 - val_loss: 834.3083\n",
      "Epoch 7675/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 318.3279 - val_loss: 802.6230\n",
      "Epoch 7676/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.6734 - val_loss: 816.5275\n",
      "Epoch 7677/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.4263 - val_loss: 788.2477\n",
      "Epoch 7678/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 351.4676 - val_loss: 756.4073\n",
      "Epoch 7679/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.8735 - val_loss: 846.1535\n",
      "Epoch 7680/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 319.8861 - val_loss: 812.6080\n",
      "Epoch 7681/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.3007 - val_loss: 785.5330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7682/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 317.3676 - val_loss: 807.8870\n",
      "Epoch 7683/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 317.4426 - val_loss: 904.0125\n",
      "Epoch 7684/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 311.7470 - val_loss: 858.4377\n",
      "Epoch 7685/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 300.8956 - val_loss: 850.6720\n",
      "Epoch 7686/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 374.4109 - val_loss: 1170.1095\n",
      "Epoch 7687/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 397.5813 - val_loss: 1241.5142\n",
      "Epoch 7688/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 471.0903 - val_loss: 716.9377\n",
      "Epoch 7689/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.8986 - val_loss: 824.2988\n",
      "Epoch 7690/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.8725 - val_loss: 778.5453\n",
      "Epoch 7691/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 338.3103 - val_loss: 870.6728\n",
      "Epoch 7692/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 327.9471 - val_loss: 878.6516\n",
      "Epoch 7693/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.5688 - val_loss: 759.7733\n",
      "Epoch 7694/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 332.6338 - val_loss: 855.9784\n",
      "Epoch 7695/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 417.4603 - val_loss: 916.4790\n",
      "Epoch 7696/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2569.2400 - val_loss: 3482.1615\n",
      "Epoch 7697/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 3401.6290 - val_loss: 2228.5579\n",
      "Epoch 7698/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2984.9286 - val_loss: 1583.9055\n",
      "Epoch 7699/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2128.3097 - val_loss: 1657.9315\n",
      "Epoch 7700/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1734.2710 - val_loss: 1440.5387\n",
      "Epoch 7701/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1477.4281 - val_loss: 1262.4742\n",
      "Epoch 7702/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1216.7003 - val_loss: 1430.4642\n",
      "Epoch 7703/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1165.2832 - val_loss: 1392.8165\n",
      "Epoch 7704/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1078.8098 - val_loss: 1228.2538\n",
      "Epoch 7705/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 989.3811 - val_loss: 1144.0327\n",
      "Epoch 7706/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 937.1685 - val_loss: 1100.5025\n",
      "Epoch 7707/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 900.0288 - val_loss: 1032.7620\n",
      "Epoch 7708/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 861.7661 - val_loss: 982.6813\n",
      "Epoch 7709/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 789.8554 - val_loss: 1003.9554\n",
      "Epoch 7710/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 746.9996 - val_loss: 956.1544\n",
      "Epoch 7711/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 710.4890 - val_loss: 961.7237\n",
      "Epoch 7712/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 657.0610 - val_loss: 937.6100\n",
      "Epoch 7713/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 650.4975 - val_loss: 912.6485\n",
      "Epoch 7714/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 598.0248 - val_loss: 856.8110\n",
      "Epoch 7715/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 555.2075 - val_loss: 789.8898\n",
      "Epoch 7716/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 564.3454 - val_loss: 897.0952\n",
      "Epoch 7717/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 547.8909 - val_loss: 931.7869\n",
      "Epoch 7718/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 485.1648 - val_loss: 904.1270\n",
      "Epoch 7719/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 465.2564 - val_loss: 901.4762\n",
      "Epoch 7720/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 409.7320 - val_loss: 780.4218\n",
      "Epoch 7721/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 383.1871 - val_loss: 912.7674\n",
      "Epoch 7722/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 374.7439 - val_loss: 846.3526\n",
      "Epoch 7723/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 341.7678 - val_loss: 879.0840\n",
      "Epoch 7724/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.7193 - val_loss: 758.0254\n",
      "Epoch 7725/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 303.3544 - val_loss: 864.1965\n",
      "Epoch 7726/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 300.4473 - val_loss: 805.7222\n",
      "Epoch 7727/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 364.3101 - val_loss: 747.1826\n",
      "Epoch 7728/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 358.9655 - val_loss: 723.0877\n",
      "Epoch 7729/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.4824 - val_loss: 773.8316\n",
      "Epoch 7730/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 310.9618 - val_loss: 810.8592\n",
      "Epoch 7731/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.7867 - val_loss: 812.4789\n",
      "Epoch 7732/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 439.7996 - val_loss: 769.7517\n",
      "Epoch 7733/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 384.1268 - val_loss: 825.4919\n",
      "Epoch 7734/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 356.7070 - val_loss: 830.7709\n",
      "Epoch 7735/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 313.1725 - val_loss: 856.8625\n",
      "Epoch 7736/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 331.9959 - val_loss: 867.7831\n",
      "Epoch 7737/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 363.8238 - val_loss: 749.7567\n",
      "Epoch 7738/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.6094 - val_loss: 757.6183\n",
      "Epoch 7739/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.8858 - val_loss: 832.3342\n",
      "Epoch 7740/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.0015 - val_loss: 716.2684\n",
      "Epoch 7741/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 338.0668 - val_loss: 798.9602\n",
      "Epoch 7742/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.1786 - val_loss: 736.8089\n",
      "Epoch 7743/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 310.9883 - val_loss: 815.9519\n",
      "Epoch 7744/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 297.8799 - val_loss: 786.8056\n",
      "Epoch 7745/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 282.8867 - val_loss: 810.1385\n",
      "Epoch 7746/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 295.5545 - val_loss: 814.7056\n",
      "Epoch 7747/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 345.6819 - val_loss: 1015.9215\n",
      "Epoch 7748/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 678.4515 - val_loss: 905.3016\n",
      "Epoch 7749/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 578.8548 - val_loss: 783.6384\n",
      "Epoch 7750/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 462.3154 - val_loss: 867.4758\n",
      "Epoch 7751/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.2245 - val_loss: 814.9919\n",
      "Epoch 7752/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 332.1194 - val_loss: 830.4240\n",
      "Epoch 7753/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 310.4073 - val_loss: 897.4568\n",
      "Epoch 7754/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 316.5859 - val_loss: 799.7167\n",
      "Epoch 7755/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 295.5626 - val_loss: 769.3193\n",
      "Epoch 7756/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 287.9721 - val_loss: 711.8118\n",
      "Epoch 7757/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 283.8323 - val_loss: 748.7876\n",
      "Epoch 7758/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 308.2671 - val_loss: 795.3729\n",
      "Epoch 7759/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.0997 - val_loss: 865.8804\n",
      "Epoch 7760/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 291.8282 - val_loss: 778.2682\n",
      "Epoch 7761/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.9363 - val_loss: 823.0350\n",
      "Epoch 7762/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 330.8941 - val_loss: 848.7595\n",
      "Epoch 7763/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 310.9286 - val_loss: 777.5308\n",
      "Epoch 7764/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 287.6439 - val_loss: 787.2699\n",
      "Epoch 7765/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 288.1455 - val_loss: 845.0802\n",
      "Epoch 7766/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 315.7736 - val_loss: 775.6830\n",
      "Epoch 7767/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.0412 - val_loss: 1011.6199\n",
      "Epoch 7768/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 409.1182 - val_loss: 1032.8660\n",
      "Epoch 7769/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.7076 - val_loss: 722.9566\n",
      "Epoch 7770/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 318.2133 - val_loss: 828.2081\n",
      "Epoch 7771/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 299.0548 - val_loss: 788.7326\n",
      "Epoch 7772/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 309.0608 - val_loss: 873.4307\n",
      "Epoch 7773/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.7579 - val_loss: 778.5471\n",
      "Epoch 7774/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.3244 - val_loss: 770.8304\n",
      "Epoch 7775/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.1212 - val_loss: 818.1188\n",
      "Epoch 7776/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.9573 - val_loss: 815.3706\n",
      "Epoch 7777/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 308.2789 - val_loss: 823.2414\n",
      "Epoch 7778/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 312.3972 - val_loss: 1100.0526\n",
      "Epoch 7779/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 391.1369 - val_loss: 938.6302\n",
      "Epoch 7780/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 389.5104 - val_loss: 1245.7780\n",
      "Epoch 7781/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 399.5124 - val_loss: 870.5938\n",
      "Epoch 7782/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 351.0831 - val_loss: 808.0180\n",
      "Epoch 7783/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 318.8115 - val_loss: 789.3682\n",
      "Epoch 7784/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.1983 - val_loss: 814.0017\n",
      "Epoch 7785/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 519.3175 - val_loss: 671.1184\n",
      "Epoch 7786/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 445.1103 - val_loss: 751.6294\n",
      "Epoch 7787/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 490.8138 - val_loss: 843.2732\n",
      "Epoch 7788/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 447.2752 - val_loss: 875.1895\n",
      "Epoch 7789/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 376.3065 - val_loss: 823.3600\n",
      "Epoch 7790/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.2970 - val_loss: 752.8430\n",
      "Epoch 7791/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 308.6616 - val_loss: 749.0769\n",
      "Epoch 7792/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.6235 - val_loss: 816.9124\n",
      "Epoch 7793/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.0932 - val_loss: 764.3826\n",
      "Epoch 7794/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 298.1517 - val_loss: 772.4855\n",
      "Epoch 7795/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 283.4904 - val_loss: 786.9645\n",
      "Epoch 7796/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 319.6092 - val_loss: 845.4656\n",
      "Epoch 7797/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.4409 - val_loss: 976.7850\n",
      "Epoch 7798/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.2897 - val_loss: 1064.0910\n",
      "Epoch 7799/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 390.1251 - val_loss: 919.9240\n",
      "Epoch 7800/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 376.3435 - val_loss: 749.3138\n",
      "Epoch 7801/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 339.7137 - val_loss: 751.5540\n",
      "Epoch 7802/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 313.0117 - val_loss: 759.3245\n",
      "Epoch 7803/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 308.0815 - val_loss: 767.1135\n",
      "Epoch 7804/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 391.8637 - val_loss: 770.7204\n",
      "Epoch 7805/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 417.6351 - val_loss: 842.4030\n",
      "Epoch 7806/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 387.5728 - val_loss: 794.6646\n",
      "Epoch 7807/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 353.2497 - val_loss: 751.9442\n",
      "Epoch 7808/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 349.4985 - val_loss: 865.8325\n",
      "Epoch 7809/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 408.9415 - val_loss: 895.4174\n",
      "Epoch 7810/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 412.1913 - val_loss: 877.5806\n",
      "Epoch 7811/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 370.4672 - val_loss: 838.4178\n",
      "Epoch 7812/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.5792 - val_loss: 786.4807\n",
      "Epoch 7813/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 336.7132 - val_loss: 781.4682\n",
      "Epoch 7814/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 321.4913 - val_loss: 904.3421\n",
      "Epoch 7815/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 321.4649 - val_loss: 1016.8034\n",
      "Epoch 7816/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 391.0157 - val_loss: 749.9270\n",
      "Epoch 7817/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 330.7147 - val_loss: 769.9161\n",
      "Epoch 7818/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.1058 - val_loss: 852.1054\n",
      "Epoch 7819/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.1494 - val_loss: 916.5675\n",
      "Epoch 7820/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 346.0646 - val_loss: 726.6978\n",
      "Epoch 7821/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 356.9367 - val_loss: 834.5399\n",
      "Epoch 7822/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 386.8612 - val_loss: 708.2995\n",
      "Epoch 7823/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 401.1906 - val_loss: 682.0957\n",
      "Epoch 7824/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 403.9623 - val_loss: 765.9134\n",
      "Epoch 7825/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 392.3136 - val_loss: 932.7355\n",
      "Epoch 7826/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 472.2435 - val_loss: 1039.1939\n",
      "Epoch 7827/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 441.7281 - val_loss: 1040.4688\n",
      "Epoch 7828/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 551.6035 - val_loss: 956.6743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7829/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 450.5192 - val_loss: 759.5911\n",
      "Epoch 7830/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 398.3819 - val_loss: 792.2001\n",
      "Epoch 7831/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.6936 - val_loss: 842.3632\n",
      "Epoch 7832/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 315.1286 - val_loss: 884.8154\n",
      "Epoch 7833/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.9626 - val_loss: 848.4174\n",
      "Epoch 7834/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 356.8200 - val_loss: 765.7044\n",
      "Epoch 7835/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.2170 - val_loss: 864.5101\n",
      "Epoch 7836/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 323.4104 - val_loss: 876.4924\n",
      "Epoch 7837/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 297.8122 - val_loss: 837.1425\n",
      "Epoch 7838/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 296.3529 - val_loss: 822.9804\n",
      "Epoch 7839/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 300.9801 - val_loss: 817.0199\n",
      "Epoch 7840/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 294.6543 - val_loss: 746.7145\n",
      "Epoch 7841/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 292.0773 - val_loss: 814.6194\n",
      "Epoch 7842/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.3593 - val_loss: 777.1544\n",
      "Epoch 7843/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 296.0287 - val_loss: 883.5627\n",
      "Epoch 7844/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 305.7814 - val_loss: 809.2458\n",
      "Epoch 7845/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 304.0190 - val_loss: 800.0476\n",
      "Epoch 7846/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 310.1818 - val_loss: 739.9174\n",
      "Epoch 7847/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 304.9316 - val_loss: 804.4318\n",
      "Epoch 7848/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 286.1448 - val_loss: 822.9933\n",
      "Epoch 7849/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 301.8825 - val_loss: 928.9034\n",
      "Epoch 7850/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.3467 - val_loss: 750.6932\n",
      "Epoch 7851/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 381.0014 - val_loss: 745.9992\n",
      "Epoch 7852/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.0928 - val_loss: 906.6577\n",
      "Epoch 7853/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.8876 - val_loss: 1005.2212\n",
      "Epoch 7854/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 330.5029 - val_loss: 960.4568\n",
      "Epoch 7855/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 322.3386 - val_loss: 804.0490\n",
      "Epoch 7856/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.2303 - val_loss: 821.9068\n",
      "Epoch 7857/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 349.7281 - val_loss: 691.6333\n",
      "Epoch 7858/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.6158 - val_loss: 780.6761\n",
      "Epoch 7859/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.4634 - val_loss: 707.6199\n",
      "Epoch 7860/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 521.7826 - val_loss: 915.2411\n",
      "Epoch 7861/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 550.7936 - val_loss: 911.4894\n",
      "Epoch 7862/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 453.4647 - val_loss: 918.5355\n",
      "Epoch 7863/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 405.4608 - val_loss: 742.3467\n",
      "Epoch 7864/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 367.5534 - val_loss: 697.7629\n",
      "Epoch 7865/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 334.7259 - val_loss: 829.2575\n",
      "Epoch 7866/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 298.1008 - val_loss: 838.5930\n",
      "Epoch 7867/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 303.7802 - val_loss: 834.7435\n",
      "Epoch 7868/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 320.8544 - val_loss: 849.2227\n",
      "Epoch 7869/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 308.9201 - val_loss: 700.5164\n",
      "Epoch 7870/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 515.8621 - val_loss: 775.9977\n",
      "Epoch 7871/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 468.2085 - val_loss: 903.3309\n",
      "Epoch 7872/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 425.8197 - val_loss: 971.6793\n",
      "Epoch 7873/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 392.4318 - val_loss: 1053.3109\n",
      "Epoch 7874/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 397.6004 - val_loss: 905.1112\n",
      "Epoch 7875/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.8321 - val_loss: 805.8763\n",
      "Epoch 7876/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 355.9722 - val_loss: 847.2620\n",
      "Epoch 7877/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 342.2505 - val_loss: 836.6825\n",
      "Epoch 7878/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.8953 - val_loss: 783.7367\n",
      "Epoch 7879/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 320.9321 - val_loss: 709.1413\n",
      "Epoch 7880/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 307.8427 - val_loss: 797.5941\n",
      "Epoch 7881/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.6127 - val_loss: 850.2331\n",
      "Epoch 7882/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 325.6894 - val_loss: 775.6493\n",
      "Epoch 7883/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 317.8262 - val_loss: 810.5265\n",
      "Epoch 7884/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 307.3964 - val_loss: 796.7381\n",
      "Epoch 7885/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 291.7300 - val_loss: 763.9564\n",
      "Epoch 7886/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 280.3373 - val_loss: 868.6506\n",
      "Epoch 7887/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 303.4503 - val_loss: 745.4906\n",
      "Epoch 7888/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 280.6574 - val_loss: 804.8241\n",
      "Epoch 7889/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.9257 - val_loss: 883.5512\n",
      "Epoch 7890/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.8341 - val_loss: 745.7637\n",
      "Epoch 7891/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 324.9456 - val_loss: 777.3511\n",
      "Epoch 7892/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 351.0623 - val_loss: 871.9020\n",
      "Epoch 7893/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 362.5624 - val_loss: 924.6575\n",
      "Epoch 7894/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 357.5760 - val_loss: 797.5151\n",
      "Epoch 7895/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 352.0346 - val_loss: 728.2936\n",
      "Epoch 7896/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 331.3539 - val_loss: 733.7533\n",
      "Epoch 7897/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.6782 - val_loss: 762.8070\n",
      "Epoch 7898/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.2805 - val_loss: 874.7643\n",
      "Epoch 7899/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.3115 - val_loss: 830.5417\n",
      "Epoch 7900/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.7885 - val_loss: 768.2286\n",
      "Epoch 7901/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 285.4499 - val_loss: 848.2344\n",
      "Epoch 7902/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 323.7717 - val_loss: 831.4014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7903/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 321.5079 - val_loss: 895.9812\n",
      "Epoch 7904/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.6111 - val_loss: 848.4541\n",
      "Epoch 7905/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 389.6570 - val_loss: 773.3873\n",
      "Epoch 7906/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 386.3343 - val_loss: 852.6332\n",
      "Epoch 7907/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 355.0411 - val_loss: 810.7928\n",
      "Epoch 7908/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.6470 - val_loss: 775.3415\n",
      "Epoch 7909/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 448.0924 - val_loss: 892.5077\n",
      "Epoch 7910/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 531.8157 - val_loss: 881.8350\n",
      "Epoch 7911/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 485.4891 - val_loss: 778.6995\n",
      "Epoch 7912/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 453.9182 - val_loss: 769.9387\n",
      "Epoch 7913/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 407.2296 - val_loss: 881.0388\n",
      "Epoch 7914/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 372.7658 - val_loss: 903.3029\n",
      "Epoch 7915/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 342.9634 - val_loss: 883.0313\n",
      "Epoch 7916/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 312.6105 - val_loss: 854.5198\n",
      "Epoch 7917/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 335.1173 - val_loss: 945.9392\n",
      "Epoch 7918/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.2232 - val_loss: 1804.0925\n",
      "Epoch 7919/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1899.2533 - val_loss: 1554.6609\n",
      "Epoch 7920/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1905.9747 - val_loss: 1442.8366\n",
      "Epoch 7921/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1419.8881 - val_loss: 1265.9457\n",
      "Epoch 7922/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 887.5879 - val_loss: 1068.2271\n",
      "Epoch 7923/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 590.8774 - val_loss: 838.0969\n",
      "Epoch 7924/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 849.9905 - val_loss: 729.8755\n",
      "Epoch 7925/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1110.1832 - val_loss: 847.5225\n",
      "Epoch 7926/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 722.2821 - val_loss: 952.5727\n",
      "Epoch 7927/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 713.9934 - val_loss: 1059.2202\n",
      "Epoch 7928/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 560.2814 - val_loss: 1013.5629\n",
      "Epoch 7929/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 489.2302 - val_loss: 1180.0788\n",
      "Epoch 7930/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 443.3548 - val_loss: 929.2282\n",
      "Epoch 7931/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 398.1259 - val_loss: 903.0922\n",
      "Epoch 7932/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 473.591 - 0s 67us/step - loss: 356.2697 - val_loss: 722.7995\n",
      "Epoch 7933/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 332.0115 - val_loss: 843.6645\n",
      "Epoch 7934/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.3561 - val_loss: 700.4925\n",
      "Epoch 7935/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.9940 - val_loss: 882.2469\n",
      "Epoch 7936/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 374.4332 - val_loss: 924.8148\n",
      "Epoch 7937/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 388.0344 - val_loss: 999.1423\n",
      "Epoch 7938/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 415.8741 - val_loss: 1004.8057\n",
      "Epoch 7939/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 376.9937 - val_loss: 949.8230\n",
      "Epoch 7940/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 390.4874 - val_loss: 874.4894\n",
      "Epoch 7941/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 392.8685 - val_loss: 940.4028\n",
      "Epoch 7942/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.7772 - val_loss: 932.0667\n",
      "Epoch 7943/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.2119 - val_loss: 830.2587\n",
      "Epoch 7944/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 304.7873 - val_loss: 819.7102\n",
      "Epoch 7945/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 311.4472 - val_loss: 871.9075\n",
      "Epoch 7946/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.6224 - val_loss: 1067.8712\n",
      "Epoch 7947/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 652.8477 - val_loss: 911.5882\n",
      "Epoch 7948/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 550.4282 - val_loss: 713.3833\n",
      "Epoch 7949/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 466.1640 - val_loss: 870.7031\n",
      "Epoch 7950/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 408.5880 - val_loss: 842.0715\n",
      "Epoch 7951/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 370.7761 - val_loss: 971.0911\n",
      "Epoch 7952/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 324.0793 - val_loss: 841.7470\n",
      "Epoch 7953/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 313.6821 - val_loss: 892.2087\n",
      "Epoch 7954/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 302.3104 - val_loss: 802.8276\n",
      "Epoch 7955/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 295.5063 - val_loss: 849.0503\n",
      "Epoch 7956/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 275.7610 - val_loss: 787.3338\n",
      "Epoch 7957/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 320.6487 - val_loss: 754.0065\n",
      "Epoch 7958/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 295.6391 - val_loss: 821.2970\n",
      "Epoch 7959/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 323.5946 - val_loss: 779.2773\n",
      "Epoch 7960/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 308.9118 - val_loss: 872.8783\n",
      "Epoch 7961/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 347.5851 - val_loss: 770.9306\n",
      "Epoch 7962/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 335.2370 - val_loss: 792.1728\n",
      "Epoch 7963/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.9038 - val_loss: 870.5529\n",
      "Epoch 7964/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 329.3136 - val_loss: 841.1092\n",
      "Epoch 7965/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.9294 - val_loss: 807.8322\n",
      "Epoch 7966/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 307.5249 - val_loss: 882.0465\n",
      "Epoch 7967/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 384.6873 - val_loss: 922.2409\n",
      "Epoch 7968/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 474.4132 - val_loss: 715.8295\n",
      "Epoch 7969/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 428.4314 - val_loss: 846.9733\n",
      "Epoch 7970/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 409.2695 - val_loss: 902.1880\n",
      "Epoch 7971/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 372.6374 - val_loss: 872.9297\n",
      "Epoch 7972/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 322.9326 - val_loss: 863.6352\n",
      "Epoch 7973/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 352.4729 - val_loss: 1023.8368\n",
      "Epoch 7974/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 357.6400 - val_loss: 963.8240\n",
      "Epoch 7975/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 326.7930 - val_loss: 932.5916\n",
      "Epoch 7976/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 57us/step - loss: 305.6229 - val_loss: 856.9748\n",
      "Epoch 7977/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 381.2843 - val_loss: 1115.7528\n",
      "Epoch 7978/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 436.0238 - val_loss: 671.4534\n",
      "Epoch 7979/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 509.7193 - val_loss: 1353.9277\n",
      "Epoch 7980/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 906.0675 - val_loss: 849.3481\n",
      "Epoch 7981/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 702.5118 - val_loss: 1024.7567\n",
      "Epoch 7982/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 494.6275 - val_loss: 902.1467\n",
      "Epoch 7983/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 435.4177 - val_loss: 1149.0503\n",
      "Epoch 7984/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 388.9048 - val_loss: 988.6697\n",
      "Epoch 7985/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 357.8244 - val_loss: 800.4235\n",
      "Epoch 7986/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.9964 - val_loss: 832.9535\n",
      "Epoch 7987/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 293.0112 - val_loss: 772.5647\n",
      "Epoch 7988/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 289.7159 - val_loss: 767.8769\n",
      "Epoch 7989/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 595.9779 - val_loss: 1128.2589\n",
      "Epoch 7990/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1802.4905 - val_loss: 1429.1339\n",
      "Epoch 7991/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1448.4438 - val_loss: 1098.3267\n",
      "Epoch 7992/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 886.5505 - val_loss: 933.7860\n",
      "Epoch 7993/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 629.7867 - val_loss: 1061.0685\n",
      "Epoch 7994/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 520.8322 - val_loss: 907.6341\n",
      "Epoch 7995/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 471.0693 - val_loss: 887.6521\n",
      "Epoch 7996/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 387.1599 - val_loss: 894.2099\n",
      "Epoch 7997/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 364.3816 - val_loss: 802.0952\n",
      "Epoch 7998/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 372.7757 - val_loss: 762.3241\n",
      "Epoch 7999/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 353.4191 - val_loss: 707.4438\n",
      "Epoch 8000/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 507.8631 - val_loss: 674.1448\n",
      "Epoch 8001/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 467.9504 - val_loss: 742.3331\n",
      "Epoch 8002/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 459.1291 - val_loss: 806.1281\n",
      "Epoch 8003/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 410.2332 - val_loss: 906.8013\n",
      "Epoch 8004/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 359.3223 - val_loss: 764.6348\n",
      "Epoch 8005/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 392.2607 - val_loss: 763.5231\n",
      "Epoch 8006/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 646.7021 - val_loss: 605.3433\n",
      "Epoch 8007/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 448.9145 - val_loss: 1088.6364\n",
      "Epoch 8008/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 434.4624 - val_loss: 702.2559\n",
      "Epoch 8009/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 478.7379 - val_loss: 921.5978\n",
      "Epoch 8010/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 681.6721 - val_loss: 726.7024\n",
      "Epoch 8011/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 580.9359 - val_loss: 856.2188\n",
      "Epoch 8012/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 503.3241 - val_loss: 905.1192\n",
      "Epoch 8013/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 443.5626 - val_loss: 764.6817\n",
      "Epoch 8014/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 418.6358 - val_loss: 962.4258\n",
      "Epoch 8015/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 357.7216 - val_loss: 922.9863\n",
      "Epoch 8016/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 370.9314 - val_loss: 745.3136\n",
      "Epoch 8017/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 417.4977 - val_loss: 836.7342\n",
      "Epoch 8018/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 416.0494 - val_loss: 780.9687\n",
      "Epoch 8019/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 354.8161 - val_loss: 932.2442\n",
      "Epoch 8020/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 338.9334 - val_loss: 850.5551\n",
      "Epoch 8021/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 338.7155 - val_loss: 873.5450\n",
      "Epoch 8022/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 322.0258 - val_loss: 862.7018\n",
      "Epoch 8023/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 293.9937 - val_loss: 789.5592\n",
      "Epoch 8024/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 311.1235 - val_loss: 752.0971\n",
      "Epoch 8025/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 310.0833 - val_loss: 787.9928\n",
      "Epoch 8026/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 301.2727 - val_loss: 814.6589\n",
      "Epoch 8027/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 297.2878 - val_loss: 912.7572\n",
      "Epoch 8028/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 313.8182 - val_loss: 817.4740\n",
      "Epoch 8029/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 343.4974 - val_loss: 850.5616\n",
      "Epoch 8030/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 325.7940 - val_loss: 817.7315\n",
      "Epoch 8031/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 453.4692 - val_loss: 867.2727\n",
      "Epoch 8032/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 424.3526 - val_loss: 760.4612\n",
      "Epoch 8033/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 384.0633 - val_loss: 771.9293\n",
      "Epoch 8034/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 355.1298 - val_loss: 854.2736\n",
      "Epoch 8035/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.6139 - val_loss: 907.1772\n",
      "Epoch 8036/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 302.5623 - val_loss: 863.7682\n",
      "Epoch 8037/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 307.2621 - val_loss: 756.5391\n",
      "Epoch 8038/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.7197 - val_loss: 739.0194\n",
      "Epoch 8039/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.4590 - val_loss: 726.7345\n",
      "Epoch 8040/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 305.9348 - val_loss: 781.6249\n",
      "Epoch 8041/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 314.6301 - val_loss: 741.3082\n",
      "Epoch 8042/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 297.9644 - val_loss: 862.4033\n",
      "Epoch 8043/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 288.4627 - val_loss: 815.6796\n",
      "Epoch 8044/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.3376 - val_loss: 731.3827\n",
      "Epoch 8045/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.6864 - val_loss: 733.8598\n",
      "Epoch 8046/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 310.7213 - val_loss: 891.0532\n",
      "Epoch 8047/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 334.8392 - val_loss: 829.6193\n",
      "Epoch 8048/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.6435 - val_loss: 802.8096\n",
      "Epoch 8049/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 302.5197 - val_loss: 848.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8050/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 313.8184 - val_loss: 875.0937\n",
      "Epoch 8051/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.1693 - val_loss: 761.2163\n",
      "Epoch 8052/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 345.3668 - val_loss: 749.3707\n",
      "Epoch 8053/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.5379 - val_loss: 1128.3213\n",
      "Epoch 8054/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 354.9718 - val_loss: 1072.1813\n",
      "Epoch 8055/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 368.0045 - val_loss: 1023.6342\n",
      "Epoch 8056/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 339.5781 - val_loss: 743.3812\n",
      "Epoch 8057/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.5718 - val_loss: 869.2576\n",
      "Epoch 8058/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.5958 - val_loss: 760.8721\n",
      "Epoch 8059/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 322.3682 - val_loss: 803.9163\n",
      "Epoch 8060/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 310.4269 - val_loss: 722.1054\n",
      "Epoch 8061/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 321.3638 - val_loss: 892.3792\n",
      "Epoch 8062/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 306.5586 - val_loss: 779.3986\n",
      "Epoch 8063/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 296.3961 - val_loss: 794.3348\n",
      "Epoch 8064/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 286.2491 - val_loss: 807.8532\n",
      "Epoch 8065/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 300.7307 - val_loss: 878.7205\n",
      "Epoch 8066/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 330.9787 - val_loss: 996.1439\n",
      "Epoch 8067/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.1690 - val_loss: 850.3759\n",
      "Epoch 8068/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 354.4475 - val_loss: 951.6154\n",
      "Epoch 8069/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 364.4181 - val_loss: 708.3077\n",
      "Epoch 8070/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 373.1452 - val_loss: 872.9889\n",
      "Epoch 8071/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 330.9019 - val_loss: 793.7241\n",
      "Epoch 8072/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.2098 - val_loss: 827.4556\n",
      "Epoch 8073/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.5778 - val_loss: 781.6443\n",
      "Epoch 8074/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 331.6548 - val_loss: 867.1710\n",
      "Epoch 8075/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 350.3509 - val_loss: 784.5335\n",
      "Epoch 8076/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.3657 - val_loss: 772.4889\n",
      "Epoch 8077/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 347.8221 - val_loss: 758.0670\n",
      "Epoch 8078/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.5090 - val_loss: 918.3027\n",
      "Epoch 8079/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 660.2945 - val_loss: 753.7641\n",
      "Epoch 8080/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 673.1115 - val_loss: 856.4029\n",
      "Epoch 8081/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 520.3576 - val_loss: 838.8993\n",
      "Epoch 8082/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 462.9696 - val_loss: 896.9098\n",
      "Epoch 8083/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 408.1469 - val_loss: 979.2989\n",
      "Epoch 8084/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 354.7514 - val_loss: 930.1755\n",
      "Epoch 8085/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.3761 - val_loss: 1439.2513\n",
      "Epoch 8086/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 943.8276 - val_loss: 811.4887\n",
      "Epoch 8087/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 846.7422 - val_loss: 775.6421\n",
      "Epoch 8088/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 635.4459 - val_loss: 821.0165\n",
      "Epoch 8089/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 597.2445 - val_loss: 1042.3426\n",
      "Epoch 8090/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 539.7852 - val_loss: 980.7313\n",
      "Epoch 8091/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 457.9892 - val_loss: 805.5570\n",
      "Epoch 8092/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 391.9336 - val_loss: 809.8251\n",
      "Epoch 8093/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 386.4332 - val_loss: 903.8915\n",
      "Epoch 8094/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 361.3232 - val_loss: 812.0540\n",
      "Epoch 8095/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 366.0317 - val_loss: 819.7319\n",
      "Epoch 8096/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 345.7380 - val_loss: 974.0818\n",
      "Epoch 8097/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 342.5085 - val_loss: 777.1917\n",
      "Epoch 8098/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 327.1728 - val_loss: 717.5275\n",
      "Epoch 8099/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 387.4344 - val_loss: 1900.6356\n",
      "Epoch 8100/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 810.0534 - val_loss: 875.6747\n",
      "Epoch 8101/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 601.7308 - val_loss: 792.6447\n",
      "Epoch 8102/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 550.6861 - val_loss: 844.9838\n",
      "Epoch 8103/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 467.6873 - val_loss: 823.6646\n",
      "Epoch 8104/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 407.9832 - val_loss: 816.5681\n",
      "Epoch 8105/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.0147 - val_loss: 867.7705\n",
      "Epoch 8106/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.6997 - val_loss: 801.5764\n",
      "Epoch 8107/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 480.9205 - val_loss: 938.4003\n",
      "Epoch 8108/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 430.9154 - val_loss: 911.0192\n",
      "Epoch 8109/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 402.9745 - val_loss: 758.2747\n",
      "Epoch 8110/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 360.1192 - val_loss: 714.3676\n",
      "Epoch 8111/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 357.1302 - val_loss: 702.5547\n",
      "Epoch 8112/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 395.2966 - val_loss: 1173.6631\n",
      "Epoch 8113/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 418.6211 - val_loss: 995.4405\n",
      "Epoch 8114/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 385.4306 - val_loss: 905.8167\n",
      "Epoch 8115/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 497.1791 - val_loss: 868.6962\n",
      "Epoch 8116/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 519.4027 - val_loss: 706.7508\n",
      "Epoch 8117/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 465.2079 - val_loss: 745.7913\n",
      "Epoch 8118/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 407.7661 - val_loss: 730.2248\n",
      "Epoch 8119/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.7928 - val_loss: 898.6952\n",
      "Epoch 8120/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 362.7088 - val_loss: 851.2960\n",
      "Epoch 8121/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 348.9595 - val_loss: 858.0024\n",
      "Epoch 8122/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 325.8205 - val_loss: 767.2266\n",
      "Epoch 8123/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 330.0900 - val_loss: 837.1909\n",
      "Epoch 8124/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 360.4680 - val_loss: 697.3984\n",
      "Epoch 8125/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.6535 - val_loss: 779.3988\n",
      "Epoch 8126/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.9707 - val_loss: 809.8919\n",
      "Epoch 8127/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 319.0426 - val_loss: 851.8653\n",
      "Epoch 8128/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 300.2661 - val_loss: 811.0355\n",
      "Epoch 8129/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 288.9925 - val_loss: 817.0408\n",
      "Epoch 8130/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 326.0335 - val_loss: 786.3919\n",
      "Epoch 8131/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 308.2561 - val_loss: 762.8729\n",
      "Epoch 8132/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 306.0809 - val_loss: 795.0696\n",
      "Epoch 8133/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 291.6708 - val_loss: 779.5101\n",
      "Epoch 8134/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 309.4186 - val_loss: 865.6426\n",
      "Epoch 8135/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 334.1558 - val_loss: 956.0683\n",
      "Epoch 8136/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 360.9740 - val_loss: 856.0841\n",
      "Epoch 8137/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 314.9174 - val_loss: 779.3778\n",
      "Epoch 8138/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 316.6785 - val_loss: 832.1148\n",
      "Epoch 8139/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.5920 - val_loss: 903.1024\n",
      "Epoch 8140/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 380.1977 - val_loss: 711.6322\n",
      "Epoch 8141/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 361.7863 - val_loss: 848.8109\n",
      "Epoch 8142/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 324.9785 - val_loss: 787.1592\n",
      "Epoch 8143/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.1150 - val_loss: 816.3814\n",
      "Epoch 8144/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.4354 - val_loss: 801.9857\n",
      "Epoch 8145/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 309.2092 - val_loss: 823.0810\n",
      "Epoch 8146/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 314.1165 - val_loss: 840.8681\n",
      "Epoch 8147/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 302.9160 - val_loss: 802.4844\n",
      "Epoch 8148/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 287.7736 - val_loss: 833.9217\n",
      "Epoch 8149/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.8078 - val_loss: 797.3515\n",
      "Epoch 8150/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.5174 - val_loss: 861.8817\n",
      "Epoch 8151/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 368.7379 - val_loss: 961.1862\n",
      "Epoch 8152/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 505.6414 - val_loss: 802.3733\n",
      "Epoch 8153/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 392.3342 - val_loss: 803.9205\n",
      "Epoch 8154/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 371.3481 - val_loss: 898.4663\n",
      "Epoch 8155/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 359.1735 - val_loss: 802.0910\n",
      "Epoch 8156/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.9348 - val_loss: 853.8094\n",
      "Epoch 8157/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 318.7919 - val_loss: 724.6394\n",
      "Epoch 8158/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 348.0595 - val_loss: 818.6986\n",
      "Epoch 8159/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 364.8881 - val_loss: 765.6097\n",
      "Epoch 8160/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 352.0220 - val_loss: 825.1718\n",
      "Epoch 8161/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.0083 - val_loss: 811.2660\n",
      "Epoch 8162/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 476.0052 - val_loss: 740.0196\n",
      "Epoch 8163/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 633.0548 - val_loss: 1093.4512\n",
      "Epoch 8164/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 566.7263 - val_loss: 732.0206\n",
      "Epoch 8165/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 495.5600 - val_loss: 810.3300\n",
      "Epoch 8166/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 432.5531 - val_loss: 855.6502\n",
      "Epoch 8167/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.1347 - val_loss: 980.3860\n",
      "Epoch 8168/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 333.9573 - val_loss: 844.9722\n",
      "Epoch 8169/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 300.7872 - val_loss: 821.4144\n",
      "Epoch 8170/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 383.1840 - val_loss: 958.3558\n",
      "Epoch 8171/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 465.9934 - val_loss: 868.6092\n",
      "Epoch 8172/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 445.2085 - val_loss: 865.8824\n",
      "Epoch 8173/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 417.6732 - val_loss: 804.7017\n",
      "Epoch 8174/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 394.6785 - val_loss: 804.1720\n",
      "Epoch 8175/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 334.6842 - val_loss: 809.0631\n",
      "Epoch 8176/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 320.9157 - val_loss: 768.1716\n",
      "Epoch 8177/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 312.2297 - val_loss: 868.3632\n",
      "Epoch 8178/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 294.2255 - val_loss: 902.1369\n",
      "Epoch 8179/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.0781 - val_loss: 843.3597\n",
      "Epoch 8180/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 292.7010 - val_loss: 752.0274\n",
      "Epoch 8181/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 288.7603 - val_loss: 746.3647\n",
      "Epoch 8182/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 321.4252 - val_loss: 894.4515\n",
      "Epoch 8183/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 335.2122 - val_loss: 981.8158\n",
      "Epoch 8184/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.7250 - val_loss: 1084.0441\n",
      "Epoch 8185/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 816.9369 - val_loss: 667.5743\n",
      "Epoch 8186/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 715.0983 - val_loss: 1475.9469\n",
      "Epoch 8187/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 556.6331 - val_loss: 1083.1336\n",
      "Epoch 8188/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 470.6832 - val_loss: 841.9387\n",
      "Epoch 8189/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 402.3122 - val_loss: 861.3947\n",
      "Epoch 8190/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 338.7173 - val_loss: 782.0298\n",
      "Epoch 8191/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.5401 - val_loss: 771.2422\n",
      "Epoch 8192/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 332.7642 - val_loss: 829.0611\n",
      "Epoch 8193/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 327.1912 - val_loss: 773.5586\n",
      "Epoch 8194/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.0519 - val_loss: 789.8709\n",
      "Epoch 8195/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.9397 - val_loss: 760.9915\n",
      "Epoch 8196/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 323.3849 - val_loss: 864.2870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8197/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 334.7556 - val_loss: 866.4393\n",
      "Epoch 8198/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 320.1720 - val_loss: 823.5240\n",
      "Epoch 8199/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 374.0973 - val_loss: 745.6279\n",
      "Epoch 8200/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 500.5979 - val_loss: 971.8896\n",
      "Epoch 8201/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 444.9189 - val_loss: 867.4662\n",
      "Epoch 8202/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 398.2188 - val_loss: 891.3355\n",
      "Epoch 8203/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 364.8012 - val_loss: 887.1897\n",
      "Epoch 8204/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 379.8479 - val_loss: 838.6665\n",
      "Epoch 8205/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 347.7883 - val_loss: 1009.3512\n",
      "Epoch 8206/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.8418 - val_loss: 893.9301\n",
      "Epoch 8207/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.8499 - val_loss: 759.3789\n",
      "Epoch 8208/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 319.5507 - val_loss: 799.7517\n",
      "Epoch 8209/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 327.8218 - val_loss: 738.0963\n",
      "Epoch 8210/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.2437 - val_loss: 881.8114\n",
      "Epoch 8211/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.0672 - val_loss: 748.1637\n",
      "Epoch 8212/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 293.0517 - val_loss: 902.3839\n",
      "Epoch 8213/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.4791 - val_loss: 723.1885\n",
      "Epoch 8214/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 438.1123 - val_loss: 694.6207\n",
      "Epoch 8215/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 394.9247 - val_loss: 733.0369\n",
      "Epoch 8216/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 353.0821 - val_loss: 843.6034\n",
      "Epoch 8217/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.3501 - val_loss: 811.6605\n",
      "Epoch 8218/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.2018 - val_loss: 795.2153\n",
      "Epoch 8219/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 316.7133 - val_loss: 766.4586\n",
      "Epoch 8220/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 335.0659 - val_loss: 839.2812\n",
      "Epoch 8221/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 311.9683 - val_loss: 835.2017\n",
      "Epoch 8222/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 301.3817 - val_loss: 801.4697\n",
      "Epoch 8223/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 305.2704 - val_loss: 816.7606\n",
      "Epoch 8224/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 324.0338 - val_loss: 812.5103\n",
      "Epoch 8225/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.0063 - val_loss: 904.4620\n",
      "Epoch 8226/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 360.4558 - val_loss: 947.8071\n",
      "Epoch 8227/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 369.0116 - val_loss: 909.5849\n",
      "Epoch 8228/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.1245 - val_loss: 899.0771\n",
      "Epoch 8229/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 345.4259 - val_loss: 883.6194\n",
      "Epoch 8230/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 359.8890 - val_loss: 732.2511\n",
      "Epoch 8231/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.3694 - val_loss: 657.7291\n",
      "Epoch 8232/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 320.2036 - val_loss: 690.0012\n",
      "Epoch 8233/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 342.9221 - val_loss: 767.8808\n",
      "Epoch 8234/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.0330 - val_loss: 735.1118\n",
      "Epoch 8235/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 298.3582 - val_loss: 876.8893\n",
      "Epoch 8236/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 316.2045 - val_loss: 808.6970\n",
      "Epoch 8237/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 343.6289 - val_loss: 742.5408\n",
      "Epoch 8238/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 320.4759 - val_loss: 782.9480\n",
      "Epoch 8239/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 317.4990 - val_loss: 789.9705\n",
      "Epoch 8240/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.6201 - val_loss: 911.2047\n",
      "Epoch 8241/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 356.4731 - val_loss: 952.6665\n",
      "Epoch 8242/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.4179 - val_loss: 777.1277\n",
      "Epoch 8243/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 392.7682 - val_loss: 771.2881\n",
      "Epoch 8244/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 345.4192 - val_loss: 819.2599\n",
      "Epoch 8245/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.1030 - val_loss: 902.7141\n",
      "Epoch 8246/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1783.5102 - val_loss: 1920.5521\n",
      "Epoch 8247/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 3427.5719 - val_loss: 2760.5106\n",
      "Epoch 8248/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3231.2172 - val_loss: 4522.1189\n",
      "Epoch 8249/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3602.2166 - val_loss: 3943.4775\n",
      "Epoch 8250/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2413.4535 - val_loss: 1724.8467\n",
      "Epoch 8251/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1518.0718 - val_loss: 1430.8812\n",
      "Epoch 8252/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1151.5962 - val_loss: 1325.3483\n",
      "Epoch 8253/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 907.6054 - val_loss: 1203.8060\n",
      "Epoch 8254/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 793.3799 - val_loss: 1199.3211\n",
      "Epoch 8255/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 705.5943 - val_loss: 1242.7939\n",
      "Epoch 8256/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 636.2231 - val_loss: 1219.5824\n",
      "Epoch 8257/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 558.6618 - val_loss: 1175.4139\n",
      "Epoch 8258/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 505.1471 - val_loss: 655.8037\n",
      "Epoch 8259/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 552.0649 - val_loss: 1143.8716\n",
      "Epoch 8260/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 508.1139 - val_loss: 641.4320\n",
      "Epoch 8261/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 495.7304 - val_loss: 737.4176\n",
      "Epoch 8262/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 418.7041 - val_loss: 863.3434\n",
      "Epoch 8263/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 379.2873 - val_loss: 943.5407\n",
      "Epoch 8264/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 366.0334 - val_loss: 829.7391\n",
      "Epoch 8265/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.3265 - val_loss: 744.5163\n",
      "Epoch 8266/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 404.1688 - val_loss: 972.8894\n",
      "Epoch 8267/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 434.0424 - val_loss: 831.6055\n",
      "Epoch 8268/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 395.1938 - val_loss: 862.9209\n",
      "Epoch 8269/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 374.0227 - val_loss: 1297.8351\n",
      "Epoch 8270/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 996.5832 - val_loss: 1467.7589\n",
      "Epoch 8271/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 831.9233 - val_loss: 965.7654\n",
      "Epoch 8272/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 541.8687 - val_loss: 756.1573\n",
      "Epoch 8273/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 450.5009 - val_loss: 1049.4153\n",
      "Epoch 8274/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 400.8069 - val_loss: 809.5175\n",
      "Epoch 8275/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.1806 - val_loss: 709.1381\n",
      "Epoch 8276/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.2451 - val_loss: 777.0464\n",
      "Epoch 8277/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 401.0960 - val_loss: 1032.7961\n",
      "Epoch 8278/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 910.7265 - val_loss: 811.9484\n",
      "Epoch 8279/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 588.4239 - val_loss: 720.2653\n",
      "Epoch 8280/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 464.7717 - val_loss: 944.1045\n",
      "Epoch 8281/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 373.6232 - val_loss: 760.0633\n",
      "Epoch 8282/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 359.7376 - val_loss: 945.3552\n",
      "Epoch 8283/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 359.4563 - val_loss: 836.8537\n",
      "Epoch 8284/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.8787 - val_loss: 762.8079\n",
      "Epoch 8285/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 323.9200 - val_loss: 847.0377\n",
      "Epoch 8286/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.4144 - val_loss: 919.8763\n",
      "Epoch 8287/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 386.2485 - val_loss: 699.9191\n",
      "Epoch 8288/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 381.6255 - val_loss: 703.2772\n",
      "Epoch 8289/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 431.3193 - val_loss: 1031.3041\n",
      "Epoch 8290/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 413.9553 - val_loss: 701.4938\n",
      "Epoch 8291/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 378.5977 - val_loss: 947.8745\n",
      "Epoch 8292/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 355.0350 - val_loss: 974.1852\n",
      "Epoch 8293/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 357.2898 - val_loss: 888.5800\n",
      "Epoch 8294/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 370.6912 - val_loss: 755.7064\n",
      "Epoch 8295/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.3123 - val_loss: 1181.0668\n",
      "Epoch 8296/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 584.3256 - val_loss: 804.6230\n",
      "Epoch 8297/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 525.2209 - val_loss: 903.6666\n",
      "Epoch 8298/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 459.2230 - val_loss: 871.1537\n",
      "Epoch 8299/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 393.1494 - val_loss: 668.1089\n",
      "Epoch 8300/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 398.3789 - val_loss: 729.5308\n",
      "Epoch 8301/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 362.2875 - val_loss: 792.0255\n",
      "Epoch 8302/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.2630 - val_loss: 807.5104\n",
      "Epoch 8303/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 432.8251 - val_loss: 1113.8894\n",
      "Epoch 8304/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 401.6469 - val_loss: 1035.6494\n",
      "Epoch 8305/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 360.4479 - val_loss: 835.3429\n",
      "Epoch 8306/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 388.5196 - val_loss: 791.1637\n",
      "Epoch 8307/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 388.4841 - val_loss: 821.4029\n",
      "Epoch 8308/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 363.7898 - val_loss: 845.7953\n",
      "Epoch 8309/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 397.0872 - val_loss: 792.1683\n",
      "Epoch 8310/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 459.9171 - val_loss: 907.8044\n",
      "Epoch 8311/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 442.8185 - val_loss: 814.5132\n",
      "Epoch 8312/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 399.5275 - val_loss: 798.2279\n",
      "Epoch 8313/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 383.5642 - val_loss: 859.5202\n",
      "Epoch 8314/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 374.0691 - val_loss: 828.6498\n",
      "Epoch 8315/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 365.9465 - val_loss: 752.8315\n",
      "Epoch 8316/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 334.3938 - val_loss: 831.0916\n",
      "Epoch 8317/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 293.9024 - val_loss: 735.5868\n",
      "Epoch 8318/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.6027 - val_loss: 651.2605\n",
      "Epoch 8319/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 398.8155 - val_loss: 930.0201\n",
      "Epoch 8320/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 342.9871 - val_loss: 817.6075\n",
      "Epoch 8321/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 406.8649 - val_loss: 1095.5589\n",
      "Epoch 8322/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1635.4006 - val_loss: 2039.0768\n",
      "Epoch 8323/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2897.2996 - val_loss: 2392.9708\n",
      "Epoch 8324/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2572.9265 - val_loss: 1912.0282\n",
      "Epoch 8325/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1833.3303 - val_loss: 916.9238\n",
      "Epoch 8326/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1214.4467 - val_loss: 1299.5219\n",
      "Epoch 8327/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 961.3737 - val_loss: 1184.2991\n",
      "Epoch 8328/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 720.4906 - val_loss: 966.0429\n",
      "Epoch 8329/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 645.4870 - val_loss: 984.9094\n",
      "Epoch 8330/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 545.9550 - val_loss: 998.3757\n",
      "Epoch 8331/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 475.2741 - val_loss: 920.0868\n",
      "Epoch 8332/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 391.8967 - val_loss: 917.8466\n",
      "Epoch 8333/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 341.8436 - val_loss: 881.0007\n",
      "Epoch 8334/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 323.7641 - val_loss: 870.3381\n",
      "Epoch 8335/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 362.6701 - val_loss: 874.0186\n",
      "Epoch 8336/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 350.6012 - val_loss: 878.9288\n",
      "Epoch 8337/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 570.8121 - val_loss: 730.2574\n",
      "Epoch 8338/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 806.7864 - val_loss: 863.9711\n",
      "Epoch 8339/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 487.9823 - val_loss: 894.0929\n",
      "Epoch 8340/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 474.7554 - val_loss: 843.6731\n",
      "Epoch 8341/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 462.6237 - val_loss: 858.9955\n",
      "Epoch 8342/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 383.8890 - val_loss: 902.1141\n",
      "Epoch 8343/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 386.9705 - val_loss: 818.3990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8344/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 359.6565 - val_loss: 754.1478\n",
      "Epoch 8345/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.9871 - val_loss: 914.5536\n",
      "Epoch 8346/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 353.4153 - val_loss: 706.0951\n",
      "Epoch 8347/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 342.4148 - val_loss: 840.0291\n",
      "Epoch 8348/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.3148 - val_loss: 759.4970\n",
      "Epoch 8349/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 386.8975 - val_loss: 849.1520\n",
      "Epoch 8350/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 339.6363 - val_loss: 872.4364\n",
      "Epoch 8351/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 305.9059 - val_loss: 776.3090\n",
      "Epoch 8352/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 327.9912 - val_loss: 867.9402\n",
      "Epoch 8353/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 326.7008 - val_loss: 881.1022\n",
      "Epoch 8354/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.9668 - val_loss: 838.7719\n",
      "Epoch 8355/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 343.7748 - val_loss: 822.0217\n",
      "Epoch 8356/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.6257 - val_loss: 845.5271\n",
      "Epoch 8357/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.9923 - val_loss: 805.6835\n",
      "Epoch 8358/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 376.8471 - val_loss: 1009.2988\n",
      "Epoch 8359/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 359.9469 - val_loss: 995.1047\n",
      "Epoch 8360/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 542.6826 - val_loss: 827.1691\n",
      "Epoch 8361/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 436.4809 - val_loss: 986.3983\n",
      "Epoch 8362/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 406.8693 - val_loss: 841.4946\n",
      "Epoch 8363/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 357.7566 - val_loss: 766.5710\n",
      "Epoch 8364/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 327.0294 - val_loss: 928.5473\n",
      "Epoch 8365/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 396.6619 - val_loss: 759.1002\n",
      "Epoch 8366/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 408.0478 - val_loss: 794.2954\n",
      "Epoch 8367/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 408.5961 - val_loss: 866.9175\n",
      "Epoch 8368/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 369.6959 - val_loss: 854.0268\n",
      "Epoch 8369/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.8491 - val_loss: 835.3701\n",
      "Epoch 8370/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 319.5974 - val_loss: 813.7535\n",
      "Epoch 8371/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 340.1379 - val_loss: 820.8381\n",
      "Epoch 8372/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 314.9792 - val_loss: 865.6484\n",
      "Epoch 8373/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 314.8606 - val_loss: 840.5914\n",
      "Epoch 8374/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 307.3908 - val_loss: 788.5896\n",
      "Epoch 8375/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 294.0059 - val_loss: 767.8980\n",
      "Epoch 8376/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.3651 - val_loss: 784.6017\n",
      "Epoch 8377/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 335.8997 - val_loss: 682.6883\n",
      "Epoch 8378/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.4956 - val_loss: 902.8690\n",
      "Epoch 8379/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 332.6922 - val_loss: 719.8732\n",
      "Epoch 8380/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.6132 - val_loss: 983.5267\n",
      "Epoch 8381/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 378.5520 - val_loss: 811.5845\n",
      "Epoch 8382/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 365.0690 - val_loss: 872.5634\n",
      "Epoch 8383/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 335.8959 - val_loss: 800.7285\n",
      "Epoch 8384/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 357.2261 - val_loss: 802.8556\n",
      "Epoch 8385/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 384.9075 - val_loss: 882.0618\n",
      "Epoch 8386/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 350.2253 - val_loss: 776.3766\n",
      "Epoch 8387/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 340.2778 - val_loss: 807.5476\n",
      "Epoch 8388/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 315.4002 - val_loss: 735.5729\n",
      "Epoch 8389/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 311.2737 - val_loss: 794.0696\n",
      "Epoch 8390/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 342.2842 - val_loss: 769.4795\n",
      "Epoch 8391/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.3363 - val_loss: 721.3461\n",
      "Epoch 8392/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.9035 - val_loss: 844.7523\n",
      "Epoch 8393/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.5128 - val_loss: 689.6299\n",
      "Epoch 8394/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.7442 - val_loss: 702.5725\n",
      "Epoch 8395/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 334.1505 - val_loss: 725.7912\n",
      "Epoch 8396/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 338.2740 - val_loss: 949.1176\n",
      "Epoch 8397/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 316.1292 - val_loss: 778.9129\n",
      "Epoch 8398/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.0884 - val_loss: 853.6193\n",
      "Epoch 8399/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 351.0573 - val_loss: 789.8691\n",
      "Epoch 8400/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 383.8401 - val_loss: 729.9205\n",
      "Epoch 8401/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 341.4283 - val_loss: 763.7993\n",
      "Epoch 8402/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 327.2998 - val_loss: 843.5666\n",
      "Epoch 8403/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 368.2020 - val_loss: 877.4753\n",
      "Epoch 8404/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 345.5842 - val_loss: 842.7259\n",
      "Epoch 8405/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 348.4484 - val_loss: 1019.4122\n",
      "Epoch 8406/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 371.0697 - val_loss: 832.0773\n",
      "Epoch 8407/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 354.8415 - val_loss: 848.4977\n",
      "Epoch 8408/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 342.4168 - val_loss: 770.3977\n",
      "Epoch 8409/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 316.6920 - val_loss: 849.4528\n",
      "Epoch 8410/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 310.9432 - val_loss: 695.8678\n",
      "Epoch 8411/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 315.8694 - val_loss: 704.1044\n",
      "Epoch 8412/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 307.8588 - val_loss: 828.3318\n",
      "Epoch 8413/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.7478 - val_loss: 1082.5656\n",
      "Epoch 8414/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 822.7385 - val_loss: 808.3700\n",
      "Epoch 8415/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 700.7215 - val_loss: 795.6119\n",
      "Epoch 8416/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 582.3546 - val_loss: 865.5591\n",
      "Epoch 8417/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 485.1342 - val_loss: 729.2339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8418/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 405.5805 - val_loss: 977.8577\n",
      "Epoch 8419/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 361.1318 - val_loss: 929.2049\n",
      "Epoch 8420/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 356.3192 - val_loss: 829.7268\n",
      "Epoch 8421/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.3015 - val_loss: 800.5221\n",
      "Epoch 8422/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.2625 - val_loss: 803.9721\n",
      "Epoch 8423/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 316.3710 - val_loss: 859.0837\n",
      "Epoch 8424/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.4979 - val_loss: 782.7461\n",
      "Epoch 8425/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 363.0306 - val_loss: 759.9496\n",
      "Epoch 8426/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.2126 - val_loss: 782.9549\n",
      "Epoch 8427/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 307.8626 - val_loss: 797.7457\n",
      "Epoch 8428/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 327.9105 - val_loss: 778.6181\n",
      "Epoch 8429/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.3819 - val_loss: 653.6633\n",
      "Epoch 8430/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 325.7088 - val_loss: 751.7819\n",
      "Epoch 8431/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 328.9410 - val_loss: 852.9697\n",
      "Epoch 8432/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 322.8237 - val_loss: 733.4762\n",
      "Epoch 8433/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 316.2751 - val_loss: 728.1914\n",
      "Epoch 8434/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 321.9857 - val_loss: 809.1870\n",
      "Epoch 8435/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 326.8650 - val_loss: 798.2014\n",
      "Epoch 8436/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 304.0122 - val_loss: 751.7384\n",
      "Epoch 8437/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 308.6317 - val_loss: 785.5336\n",
      "Epoch 8438/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.7693 - val_loss: 806.2025\n",
      "Epoch 8439/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.9922 - val_loss: 777.5525\n",
      "Epoch 8440/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 303.5798 - val_loss: 834.2116\n",
      "Epoch 8441/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 324.7970 - val_loss: 1043.6141\n",
      "Epoch 8442/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.9311 - val_loss: 760.8727\n",
      "Epoch 8443/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.3240 - val_loss: 867.2137\n",
      "Epoch 8444/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.3541 - val_loss: 784.1130\n",
      "Epoch 8445/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 298.1511 - val_loss: 740.5856\n",
      "Epoch 8446/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 294.2876 - val_loss: 849.8566\n",
      "Epoch 8447/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 389.9306 - val_loss: 777.4718\n",
      "Epoch 8448/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 365.6839 - val_loss: 763.0498\n",
      "Epoch 8449/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 328.4052 - val_loss: 924.7098\n",
      "Epoch 8450/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 304.2594 - val_loss: 801.0720\n",
      "Epoch 8451/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 368.0974 - val_loss: 759.9935\n",
      "Epoch 8452/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 386.0824 - val_loss: 841.8197\n",
      "Epoch 8453/10000\n",
      "630/630 [==============================] - 0s 74us/step - loss: 334.5680 - val_loss: 913.3589\n",
      "Epoch 8454/10000\n",
      "630/630 [==============================] - 0s 84us/step - loss: 368.5117 - val_loss: 846.1949\n",
      "Epoch 8455/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 360.6527 - val_loss: 752.7118\n",
      "Epoch 8456/10000\n",
      "630/630 [==============================] - 0s 93us/step - loss: 331.0302 - val_loss: 719.0150\n",
      "Epoch 8457/10000\n",
      "630/630 [==============================] - 0s 74us/step - loss: 347.6156 - val_loss: 850.8358\n",
      "Epoch 8458/10000\n",
      "630/630 [==============================] - 0s 94us/step - loss: 348.6310 - val_loss: 753.8462\n",
      "Epoch 8459/10000\n",
      "630/630 [==============================] - 0s 80us/step - loss: 320.8966 - val_loss: 871.0183\n",
      "Epoch 8460/10000\n",
      "630/630 [==============================] - 0s 75us/step - loss: 313.1252 - val_loss: 752.6578\n",
      "Epoch 8461/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 318.4393 - val_loss: 747.3439\n",
      "Epoch 8462/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 325.1934 - val_loss: 860.2146\n",
      "Epoch 8463/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 327.5011 - val_loss: 787.8102\n",
      "Epoch 8464/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 324.1328 - val_loss: 786.6214\n",
      "Epoch 8465/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 288.2261 - val_loss: 773.7859\n",
      "Epoch 8466/10000\n",
      "630/630 [==============================] - 0s 75us/step - loss: 359.7262 - val_loss: 918.5499\n",
      "Epoch 8467/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 556.6198 - val_loss: 1030.6137\n",
      "Epoch 8468/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 467.3415 - val_loss: 787.8946\n",
      "Epoch 8469/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 381.7119 - val_loss: 915.3144\n",
      "Epoch 8470/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 333.4113 - val_loss: 902.8854\n",
      "Epoch 8471/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 372.1293 - val_loss: 767.9581\n",
      "Epoch 8472/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 491.3643 - val_loss: 766.1826\n",
      "Epoch 8473/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 458.4665 - val_loss: 856.8127\n",
      "Epoch 8474/10000\n",
      "630/630 [==============================] - 0s 76us/step - loss: 411.0840 - val_loss: 794.2452\n",
      "Epoch 8475/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 350.9172 - val_loss: 858.5169\n",
      "Epoch 8476/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 316.5331 - val_loss: 851.9381\n",
      "Epoch 8477/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 368.2586 - val_loss: 834.2057\n",
      "Epoch 8478/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 368.8748 - val_loss: 790.7909\n",
      "Epoch 8479/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.9899 - val_loss: 840.9248\n",
      "Epoch 8480/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 320.9493 - val_loss: 893.7069\n",
      "Epoch 8481/10000\n",
      "630/630 [==============================] - 0s 80us/step - loss: 325.0660 - val_loss: 761.6762\n",
      "Epoch 8482/10000\n",
      "630/630 [==============================] - 0s 79us/step - loss: 323.8703 - val_loss: 938.8936\n",
      "Epoch 8483/10000\n",
      "630/630 [==============================] - 0s 83us/step - loss: 315.5557 - val_loss: 768.9274\n",
      "Epoch 8484/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 431.9631 - val_loss: 828.0905\n",
      "Epoch 8485/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 374.7550 - val_loss: 748.4770\n",
      "Epoch 8486/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 353.0738 - val_loss: 759.4072\n",
      "Epoch 8487/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 342.6517 - val_loss: 723.9578\n",
      "Epoch 8488/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 352.8352 - val_loss: 680.6755\n",
      "Epoch 8489/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 356.0665 - val_loss: 780.8783\n",
      "Epoch 8490/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.5177 - val_loss: 692.8409\n",
      "Epoch 8491/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 350.1505 - val_loss: 698.9537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8492/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 307.5191 - val_loss: 798.5743\n",
      "Epoch 8493/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 312.4447 - val_loss: 776.8942\n",
      "Epoch 8494/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.5421 - val_loss: 747.6109\n",
      "Epoch 8495/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 305.6553 - val_loss: 813.9418\n",
      "Epoch 8496/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 292.0804 - val_loss: 787.3854\n",
      "Epoch 8497/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.2418 - val_loss: 809.9532\n",
      "Epoch 8498/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.8028 - val_loss: 780.8948\n",
      "Epoch 8499/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 359.1823 - val_loss: 834.3777\n",
      "Epoch 8500/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 331.9214 - val_loss: 837.3784\n",
      "Epoch 8501/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 303.8378 - val_loss: 853.1988\n",
      "Epoch 8502/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 296.5038 - val_loss: 823.2582\n",
      "Epoch 8503/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 302.0427 - val_loss: 815.4432\n",
      "Epoch 8504/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 348.0750 - val_loss: 792.9428\n",
      "Epoch 8505/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 391.8120 - val_loss: 758.0857\n",
      "Epoch 8506/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 379.5958 - val_loss: 837.3576\n",
      "Epoch 8507/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.8612 - val_loss: 768.8672\n",
      "Epoch 8508/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 322.6333 - val_loss: 767.6838\n",
      "Epoch 8509/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 332.2026 - val_loss: 788.4744\n",
      "Epoch 8510/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 322.8808 - val_loss: 762.5874\n",
      "Epoch 8511/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 298.2217 - val_loss: 913.6832\n",
      "Epoch 8512/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 280.8175 - val_loss: 876.3292\n",
      "Epoch 8513/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 301.0054 - val_loss: 858.7035\n",
      "Epoch 8514/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 349.9491 - val_loss: 893.9427\n",
      "Epoch 8515/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 366.9264 - val_loss: 879.2157\n",
      "Epoch 8516/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 366.0996 - val_loss: 769.7314\n",
      "Epoch 8517/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 328.3374 - val_loss: 825.0184\n",
      "Epoch 8518/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 327.4163 - val_loss: 1213.6715\n",
      "Epoch 8519/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 401.9562 - val_loss: 944.7541\n",
      "Epoch 8520/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 334.8805 - val_loss: 1075.6109\n",
      "Epoch 8521/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 337.6608 - val_loss: 897.6173\n",
      "Epoch 8522/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.4857 - val_loss: 807.7223\n",
      "Epoch 8523/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 325.4770 - val_loss: 818.1469\n",
      "Epoch 8524/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 316.5862 - val_loss: 947.4114\n",
      "Epoch 8525/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 303.0774 - val_loss: 763.0746\n",
      "Epoch 8526/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 307.7594 - val_loss: 778.9435\n",
      "Epoch 8527/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 292.3943 - val_loss: 721.0960\n",
      "Epoch 8528/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 374.3866 - val_loss: 697.9881\n",
      "Epoch 8529/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 368.6653 - val_loss: 667.8704\n",
      "Epoch 8530/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.2282 - val_loss: 1003.1436\n",
      "Epoch 8531/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 356.0745 - val_loss: 842.6396\n",
      "Epoch 8532/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 334.7798 - val_loss: 805.3477\n",
      "Epoch 8533/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 327.4207 - val_loss: 863.4355\n",
      "Epoch 8534/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 328.9472 - val_loss: 822.8816\n",
      "Epoch 8535/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 322.3894 - val_loss: 794.5973\n",
      "Epoch 8536/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 288.5882 - val_loss: 737.2534\n",
      "Epoch 8537/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 324.7809 - val_loss: 773.1567\n",
      "Epoch 8538/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.8963 - val_loss: 784.8651\n",
      "Epoch 8539/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 330.8888 - val_loss: 1162.7819\n",
      "Epoch 8540/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 866.6361 - val_loss: 1080.6369\n",
      "Epoch 8541/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 733.5430 - val_loss: 818.4565\n",
      "Epoch 8542/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 634.5926 - val_loss: 1010.3023\n",
      "Epoch 8543/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 527.1292 - val_loss: 955.4420\n",
      "Epoch 8544/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 470.9049 - val_loss: 1007.0843\n",
      "Epoch 8545/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 426.2541 - val_loss: 855.7175\n",
      "Epoch 8546/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 365.8719 - val_loss: 899.1419\n",
      "Epoch 8547/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 321.0584 - val_loss: 750.5846\n",
      "Epoch 8548/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 299.5154 - val_loss: 793.4613\n",
      "Epoch 8549/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.1525 - val_loss: 755.7403\n",
      "Epoch 8550/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2078.2237 - val_loss: 2433.9557\n",
      "Epoch 8551/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 3251.7631 - val_loss: 2613.7968\n",
      "Epoch 8552/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 3229.3939 - val_loss: 2332.5102\n",
      "Epoch 8553/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 2311.3883 - val_loss: 2044.8293\n",
      "Epoch 8554/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1664.5876 - val_loss: 1633.7744\n",
      "Epoch 8555/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1186.5993 - val_loss: 1542.7930\n",
      "Epoch 8556/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 758.1242 - val_loss: 1063.3553\n",
      "Epoch 8557/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 744.2429 - val_loss: 827.7927\n",
      "Epoch 8558/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 515.8190 - val_loss: 773.2817\n",
      "Epoch 8559/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 485.0849 - val_loss: 1054.7174\n",
      "Epoch 8560/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 415.4260 - val_loss: 755.7240\n",
      "Epoch 8561/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 418.1113 - val_loss: 834.4961\n",
      "Epoch 8562/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 425.2337 - val_loss: 919.6469\n",
      "Epoch 8563/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.8122 - val_loss: 930.8176\n",
      "Epoch 8564/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 362.8937 - val_loss: 1063.6513\n",
      "Epoch 8565/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 367.3457 - val_loss: 852.3639\n",
      "Epoch 8566/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 358.7463 - val_loss: 828.6930\n",
      "Epoch 8567/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 348.2943 - val_loss: 734.7452\n",
      "Epoch 8568/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 331.9779 - val_loss: 846.0601\n",
      "Epoch 8569/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 360.5659 - val_loss: 855.2077\n",
      "Epoch 8570/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 328.4877 - val_loss: 732.9373\n",
      "Epoch 8571/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 337.5255 - val_loss: 934.0397\n",
      "Epoch 8572/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 357.1693 - val_loss: 668.6829\n",
      "Epoch 8573/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 351.7512 - val_loss: 627.2397\n",
      "Epoch 8574/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 327.6396 - val_loss: 676.3686\n",
      "Epoch 8575/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 292.2685 - val_loss: 799.9252\n",
      "Epoch 8576/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 276.8439 - val_loss: 804.3063\n",
      "Epoch 8577/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 290.3043 - val_loss: 793.0560\n",
      "Epoch 8578/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 277.4827 - val_loss: 781.8455\n",
      "Epoch 8579/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 277.3220 - val_loss: 767.4565\n",
      "Epoch 8580/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 284.9810 - val_loss: 755.4795\n",
      "Epoch 8581/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 286.3929 - val_loss: 803.8105\n",
      "Epoch 8582/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 277.1123 - val_loss: 857.4481\n",
      "Epoch 8583/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 295.9483 - val_loss: 731.4885\n",
      "Epoch 8584/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 300.4194 - val_loss: 796.2928\n",
      "Epoch 8585/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 293.7276 - val_loss: 888.9545\n",
      "Epoch 8586/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.5971 - val_loss: 766.1825\n",
      "Epoch 8587/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 346.0673 - val_loss: 761.3724\n",
      "Epoch 8588/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 314.7691 - val_loss: 818.8340\n",
      "Epoch 8589/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 295.7472 - val_loss: 754.7959\n",
      "Epoch 8590/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 359.9890 - val_loss: 818.5325\n",
      "Epoch 8591/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 362.4123 - val_loss: 817.7342\n",
      "Epoch 8592/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 327.5323 - val_loss: 723.6857\n",
      "Epoch 8593/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 379.5794 - val_loss: 713.5871\n",
      "Epoch 8594/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 353.8846 - val_loss: 811.3383\n",
      "Epoch 8595/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 328.5920 - val_loss: 816.7854\n",
      "Epoch 8596/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 309.3168 - val_loss: 815.8490\n",
      "Epoch 8597/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.1719 - val_loss: 706.7228\n",
      "Epoch 8598/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 318.2480 - val_loss: 723.2677\n",
      "Epoch 8599/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 310.7005 - val_loss: 815.2109\n",
      "Epoch 8600/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 299.8037 - val_loss: 774.0635\n",
      "Epoch 8601/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 298.2718 - val_loss: 806.0155\n",
      "Epoch 8602/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 366.1439 - val_loss: 785.5556\n",
      "Epoch 8603/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 356.3623 - val_loss: 720.0086\n",
      "Epoch 8604/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 337.8757 - val_loss: 911.1305\n",
      "Epoch 8605/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.9918 - val_loss: 706.8308\n",
      "Epoch 8606/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 305.5358 - val_loss: 744.0731\n",
      "Epoch 8607/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 318.0827 - val_loss: 734.7473\n",
      "Epoch 8608/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.0470 - val_loss: 869.4966\n",
      "Epoch 8609/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.4616 - val_loss: 827.9992\n",
      "Epoch 8610/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.6439 - val_loss: 816.3423\n",
      "Epoch 8611/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 295.4853 - val_loss: 954.5536\n",
      "Epoch 8612/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 338.3492 - val_loss: 853.0333\n",
      "Epoch 8613/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 303.5726 - val_loss: 778.8213\n",
      "Epoch 8614/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 312.6870 - val_loss: 845.6307\n",
      "Epoch 8615/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 334.5548 - val_loss: 790.0636\n",
      "Epoch 8616/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 300.8859 - val_loss: 858.6253\n",
      "Epoch 8617/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 317.3084 - val_loss: 773.8391\n",
      "Epoch 8618/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 318.2988 - val_loss: 804.1082\n",
      "Epoch 8619/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 311.6282 - val_loss: 703.1749\n",
      "Epoch 8620/10000\n",
      "630/630 [==============================] - 0s 86us/step - loss: 312.4008 - val_loss: 737.5680\n",
      "Epoch 8621/10000\n",
      "630/630 [==============================] - 0s 75us/step - loss: 315.4169 - val_loss: 884.2369\n",
      "Epoch 8622/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 424.5381 - val_loss: 780.7661\n",
      "Epoch 8623/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 411.1457 - val_loss: 863.8236\n",
      "Epoch 8624/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 350.0242 - val_loss: 705.9971\n",
      "Epoch 8625/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 295.7744 - val_loss: 827.6839\n",
      "Epoch 8626/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 313.6405 - val_loss: 930.1117\n",
      "Epoch 8627/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.3330 - val_loss: 903.8565\n",
      "Epoch 8628/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 356.2742 - val_loss: 883.0674\n",
      "Epoch 8629/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 457.3939 - val_loss: 779.5740\n",
      "Epoch 8630/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 407.8291 - val_loss: 794.8494\n",
      "Epoch 8631/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 378.0614 - val_loss: 797.8167\n",
      "Epoch 8632/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 315.4999 - val_loss: 830.9099\n",
      "Epoch 8633/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 309.6065 - val_loss: 745.2205\n",
      "Epoch 8634/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.6468 - val_loss: 861.8406\n",
      "Epoch 8635/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 326.2394 - val_loss: 773.6636\n",
      "Epoch 8636/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.1200 - val_loss: 772.7825\n",
      "Epoch 8637/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 417.0930 - val_loss: 738.6066\n",
      "Epoch 8638/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.0412 - val_loss: 799.5516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8639/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 438.5350 - val_loss: 746.1806\n",
      "Epoch 8640/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 432.7709 - val_loss: 755.6587\n",
      "Epoch 8641/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 382.8271 - val_loss: 724.9078\n",
      "Epoch 8642/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 367.7909 - val_loss: 746.4941\n",
      "Epoch 8643/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 469.3915 - val_loss: 644.1154\n",
      "Epoch 8644/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 622.9236 - val_loss: 1136.3454\n",
      "Epoch 8645/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 495.3127 - val_loss: 934.7995\n",
      "Epoch 8646/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 393.0602 - val_loss: 820.5977\n",
      "Epoch 8647/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 391.1938 - val_loss: 727.8618\n",
      "Epoch 8648/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 425.2352 - val_loss: 3966.0873\n",
      "Epoch 8649/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2260.0460 - val_loss: 1313.8839\n",
      "Epoch 8650/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1697.4160 - val_loss: 1137.7096\n",
      "Epoch 8651/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1251.9819 - val_loss: 862.3611\n",
      "Epoch 8652/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 894.6866 - val_loss: 990.9537\n",
      "Epoch 8653/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 748.7715 - val_loss: 1082.2474\n",
      "Epoch 8654/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 673.3577 - val_loss: 921.9221\n",
      "Epoch 8655/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 540.5402 - val_loss: 946.4000\n",
      "Epoch 8656/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 527.2620 - val_loss: 926.6355\n",
      "Epoch 8657/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 429.5208 - val_loss: 918.1719\n",
      "Epoch 8658/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.4716 - val_loss: 871.4091\n",
      "Epoch 8659/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 344.3211 - val_loss: 851.7584\n",
      "Epoch 8660/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 303.6776 - val_loss: 802.1687\n",
      "Epoch 8661/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 399.5185 - val_loss: 916.8727\n",
      "Epoch 8662/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 410.2422 - val_loss: 779.3445\n",
      "Epoch 8663/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 497.4167 - val_loss: 875.6648\n",
      "Epoch 8664/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 358.6925 - val_loss: 859.6697\n",
      "Epoch 8665/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.9472 - val_loss: 870.1622\n",
      "Epoch 8666/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.9291 - val_loss: 865.9560\n",
      "Epoch 8667/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 406.0599 - val_loss: 1565.3878\n",
      "Epoch 8668/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1284.3903 - val_loss: 1875.4110\n",
      "Epoch 8669/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1843.2047 - val_loss: 1393.9435\n",
      "Epoch 8670/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1404.2239 - val_loss: 1273.0858\n",
      "Epoch 8671/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 966.9955 - val_loss: 1028.3329\n",
      "Epoch 8672/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 627.9925 - val_loss: 914.9701\n",
      "Epoch 8673/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 548.9520 - val_loss: 806.1745\n",
      "Epoch 8674/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 496.5143 - val_loss: 951.6439\n",
      "Epoch 8675/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.7264 - val_loss: 909.9045\n",
      "Epoch 8676/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 326.9696 - val_loss: 921.5256\n",
      "Epoch 8677/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.6096 - val_loss: 704.1393\n",
      "Epoch 8678/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 518.0249 - val_loss: 712.3780\n",
      "Epoch 8679/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 426.5010 - val_loss: 782.5698\n",
      "Epoch 8680/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 414.7876 - val_loss: 873.1229\n",
      "Epoch 8681/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.7254 - val_loss: 780.6605\n",
      "Epoch 8682/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 361.6545 - val_loss: 816.1474\n",
      "Epoch 8683/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 334.0239 - val_loss: 732.1600\n",
      "Epoch 8684/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.6184 - val_loss: 942.6425\n",
      "Epoch 8685/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 288.8224 - val_loss: 745.9849\n",
      "Epoch 8686/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 296.0418 - val_loss: 854.5360\n",
      "Epoch 8687/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 289.9274 - val_loss: 777.8721\n",
      "Epoch 8688/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 277.3066 - val_loss: 817.6328\n",
      "Epoch 8689/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 269.5089 - val_loss: 786.2437\n",
      "Epoch 8690/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 277.6163 - val_loss: 761.6082\n",
      "Epoch 8691/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.9247 - val_loss: 873.9212\n",
      "Epoch 8692/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.3940 - val_loss: 730.2409\n",
      "Epoch 8693/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 313.1116 - val_loss: 737.3693\n",
      "Epoch 8694/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 306.5073 - val_loss: 737.0358\n",
      "Epoch 8695/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 304.1642 - val_loss: 785.9585\n",
      "Epoch 8696/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 291.9484 - val_loss: 855.1704\n",
      "Epoch 8697/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 283.1829 - val_loss: 795.1482\n",
      "Epoch 8698/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 436.1957 - val_loss: 776.7916\n",
      "Epoch 8699/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 568.2666 - val_loss: 1116.6202\n",
      "Epoch 8700/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 646.6314 - val_loss: 1046.9327\n",
      "Epoch 8701/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 747.4937 - val_loss: 758.0303\n",
      "Epoch 8702/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 464.0554 - val_loss: 935.4909\n",
      "Epoch 8703/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 414.0264 - val_loss: 824.7014\n",
      "Epoch 8704/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 347.3995 - val_loss: 932.9209\n",
      "Epoch 8705/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 340.0043 - val_loss: 691.1983\n",
      "Epoch 8706/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.8741 - val_loss: 779.4484\n",
      "Epoch 8707/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.7251 - val_loss: 746.7145\n",
      "Epoch 8708/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 338.4399 - val_loss: 860.5205\n",
      "Epoch 8709/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 331.7615 - val_loss: 832.8386\n",
      "Epoch 8710/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 373.5820 - val_loss: 948.9817\n",
      "Epoch 8711/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 372.8669 - val_loss: 696.0547\n",
      "Epoch 8712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 382.6096 - val_loss: 873.4939\n",
      "Epoch 8713/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 408.2896 - val_loss: 982.9538\n",
      "Epoch 8714/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 350.8934 - val_loss: 893.0399\n",
      "Epoch 8715/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 316.5951 - val_loss: 879.5518\n",
      "Epoch 8716/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 340.0975 - val_loss: 716.4848\n",
      "Epoch 8717/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 343.5421 - val_loss: 835.9136\n",
      "Epoch 8718/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.9308 - val_loss: 766.8904\n",
      "Epoch 8719/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 318.5728 - val_loss: 768.7484\n",
      "Epoch 8720/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 337.9211 - val_loss: 812.5228\n",
      "Epoch 8721/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.7026 - val_loss: 832.2166\n",
      "Epoch 8722/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 377.1693 - val_loss: 792.6325\n",
      "Epoch 8723/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.3343 - val_loss: 858.5385\n",
      "Epoch 8724/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 335.3079 - val_loss: 802.1857\n",
      "Epoch 8725/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 334.3092 - val_loss: 819.4712\n",
      "Epoch 8726/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 326.4272 - val_loss: 762.1524\n",
      "Epoch 8727/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.8245 - val_loss: 766.8353\n",
      "Epoch 8728/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 317.2825 - val_loss: 925.7907\n",
      "Epoch 8729/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 343.8189 - val_loss: 786.3524\n",
      "Epoch 8730/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.2655 - val_loss: 808.5853\n",
      "Epoch 8731/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.8122 - val_loss: 1116.7939\n",
      "Epoch 8732/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 504.4238 - val_loss: 781.2302\n",
      "Epoch 8733/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 433.7246 - val_loss: 953.0117\n",
      "Epoch 8734/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 389.6051 - val_loss: 742.8227\n",
      "Epoch 8735/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 348.5755 - val_loss: 883.8404\n",
      "Epoch 8736/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.2763 - val_loss: 923.7386\n",
      "Epoch 8737/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 302.8117 - val_loss: 875.4367\n",
      "Epoch 8738/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 333.0010 - val_loss: 737.0570\n",
      "Epoch 8739/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.4779 - val_loss: 845.6402\n",
      "Epoch 8740/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 316.6750 - val_loss: 884.4636\n",
      "Epoch 8741/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 307.5990 - val_loss: 924.9616\n",
      "Epoch 8742/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 335.9611 - val_loss: 814.9637\n",
      "Epoch 8743/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 351.1683 - val_loss: 758.6366\n",
      "Epoch 8744/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 331.3253 - val_loss: 807.9706\n",
      "Epoch 8745/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.7534 - val_loss: 829.7590\n",
      "Epoch 8746/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 315.9522 - val_loss: 692.6709\n",
      "Epoch 8747/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 348.9884 - val_loss: 863.9590\n",
      "Epoch 8748/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.4592 - val_loss: 856.3331\n",
      "Epoch 8749/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.0151 - val_loss: 844.3124\n",
      "Epoch 8750/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 302.1342 - val_loss: 1654.3989\n",
      "Epoch 8751/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1768.5894 - val_loss: 2106.3784\n",
      "Epoch 8752/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 3016.8935 - val_loss: 2540.1641\n",
      "Epoch 8753/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2942.5991 - val_loss: 2054.2269\n",
      "Epoch 8754/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 2211.3460 - val_loss: 1860.8477\n",
      "Epoch 8755/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1733.4779 - val_loss: 1552.9234\n",
      "Epoch 8756/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1187.8440 - val_loss: 1410.6232\n",
      "Epoch 8757/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 853.7713 - val_loss: 1301.9246\n",
      "Epoch 8758/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 726.0204 - val_loss: 1310.9616\n",
      "Epoch 8759/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 658.3278 - val_loss: 1199.1308\n",
      "Epoch 8760/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 566.6120 - val_loss: 1241.7507\n",
      "Epoch 8761/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 528.1503 - val_loss: 773.6018\n",
      "Epoch 8762/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 440.7692 - val_loss: 863.2989\n",
      "Epoch 8763/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 370.0472 - val_loss: 891.6359\n",
      "Epoch 8764/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.1443 - val_loss: 810.1684\n",
      "Epoch 8765/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 349.0935 - val_loss: 886.3650\n",
      "Epoch 8766/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 310.4443 - val_loss: 772.4344\n",
      "Epoch 8767/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 335.2711 - val_loss: 857.1890\n",
      "Epoch 8768/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 307.6262 - val_loss: 718.4228\n",
      "Epoch 8769/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.3015 - val_loss: 975.2868\n",
      "Epoch 8770/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 423.7431 - val_loss: 790.2021\n",
      "Epoch 8771/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 438.1631 - val_loss: 694.2394\n",
      "Epoch 8772/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.3377 - val_loss: 715.0773\n",
      "Epoch 8773/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 447.4267 - val_loss: 2060.3579\n",
      "Epoch 8774/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1914.9920 - val_loss: 1401.7517\n",
      "Epoch 8775/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1653.0491 - val_loss: 1585.1493\n",
      "Epoch 8776/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 1189.0847 - val_loss: 993.0044\n",
      "Epoch 8777/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 793.4725 - val_loss: 939.2543\n",
      "Epoch 8778/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 473.6319 - val_loss: 767.9119\n",
      "Epoch 8779/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 430.3123 - val_loss: 844.6816\n",
      "Epoch 8780/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 383.3837 - val_loss: 1021.6007\n",
      "Epoch 8781/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.3217 - val_loss: 982.8007\n",
      "Epoch 8782/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 506.7972 - val_loss: 919.1114\n",
      "Epoch 8783/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 481.0872 - val_loss: 789.0442\n",
      "Epoch 8784/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 386.9542 - val_loss: 949.9844\n",
      "Epoch 8785/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 50us/step - loss: 386.5326 - val_loss: 892.6369\n",
      "Epoch 8786/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 346.5653 - val_loss: 940.6721\n",
      "Epoch 8787/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 325.9546 - val_loss: 770.3830\n",
      "Epoch 8788/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 320.0497 - val_loss: 800.8722\n",
      "Epoch 8789/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 317.8085 - val_loss: 789.2096\n",
      "Epoch 8790/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 288.0313 - val_loss: 770.6520\n",
      "Epoch 8791/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 321.6434 - val_loss: 799.2059\n",
      "Epoch 8792/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 316.6480 - val_loss: 719.5015\n",
      "Epoch 8793/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 304.5431 - val_loss: 682.8676\n",
      "Epoch 8794/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 325.3325 - val_loss: 865.4070\n",
      "Epoch 8795/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 385.2493 - val_loss: 1137.2939\n",
      "Epoch 8796/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 444.8420 - val_loss: 766.8945\n",
      "Epoch 8797/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 439.0890 - val_loss: 688.8982\n",
      "Epoch 8798/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 396.5413 - val_loss: 815.4527\n",
      "Epoch 8799/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.2030 - val_loss: 913.4520\n",
      "Epoch 8800/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.8844 - val_loss: 828.3875\n",
      "Epoch 8801/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 330.2990 - val_loss: 928.2890\n",
      "Epoch 8802/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 347.3018 - val_loss: 1024.6965\n",
      "Epoch 8803/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 357.3961 - val_loss: 943.2900\n",
      "Epoch 8804/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 368.9134 - val_loss: 787.0179\n",
      "Epoch 8805/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.2636 - val_loss: 856.2041\n",
      "Epoch 8806/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 399.2950 - val_loss: 883.2037\n",
      "Epoch 8807/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.7617 - val_loss: 762.7326\n",
      "Epoch 8808/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 308.7903 - val_loss: 856.3898\n",
      "Epoch 8809/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.9654 - val_loss: 769.8289\n",
      "Epoch 8810/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.3762 - val_loss: 780.1859\n",
      "Epoch 8811/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 290.7507 - val_loss: 740.1028\n",
      "Epoch 8812/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 301.3700 - val_loss: 760.2494\n",
      "Epoch 8813/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 284.5322 - val_loss: 742.3627\n",
      "Epoch 8814/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 289.1371 - val_loss: 727.0248\n",
      "Epoch 8815/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 296.9541 - val_loss: 956.9353\n",
      "Epoch 8816/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 526.0576 - val_loss: 873.1906\n",
      "Epoch 8817/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 555.2071 - val_loss: 951.5158\n",
      "Epoch 8818/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 478.6395 - val_loss: 714.3782\n",
      "Epoch 8819/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 421.9901 - val_loss: 900.2494\n",
      "Epoch 8820/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 389.4965 - val_loss: 797.0633\n",
      "Epoch 8821/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 360.5556 - val_loss: 730.6306\n",
      "Epoch 8822/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 416.8617 - val_loss: 821.1136\n",
      "Epoch 8823/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 354.4094 - val_loss: 784.9268\n",
      "Epoch 8824/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 323.8632 - val_loss: 876.4200\n",
      "Epoch 8825/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 341.6822 - val_loss: 796.1737\n",
      "Epoch 8826/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 307.2108 - val_loss: 699.6655\n",
      "Epoch 8827/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.2548 - val_loss: 720.4860\n",
      "Epoch 8828/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 304.7707 - val_loss: 811.2534\n",
      "Epoch 8829/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 330.0021 - val_loss: 789.8870\n",
      "Epoch 8830/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 324.1670 - val_loss: 800.6465\n",
      "Epoch 8831/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 338.1677 - val_loss: 965.8386\n",
      "Epoch 8832/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 373.5423 - val_loss: 715.9327\n",
      "Epoch 8833/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 339.1336 - val_loss: 681.8494\n",
      "Epoch 8834/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 380.5797 - val_loss: 713.6512\n",
      "Epoch 8835/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.4336 - val_loss: 749.7364\n",
      "Epoch 8836/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 346.1452 - val_loss: 846.8198\n",
      "Epoch 8837/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.0580 - val_loss: 866.0085\n",
      "Epoch 8838/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.6172 - val_loss: 814.8216\n",
      "Epoch 8839/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 321.0193 - val_loss: 702.9156\n",
      "Epoch 8840/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 287.8927 - val_loss: 809.7247\n",
      "Epoch 8841/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 287.4900 - val_loss: 786.3883\n",
      "Epoch 8842/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 365.0880 - val_loss: 803.7200\n",
      "Epoch 8843/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.3082 - val_loss: 845.9567\n",
      "Epoch 8844/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.1093 - val_loss: 808.2537\n",
      "Epoch 8845/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 296.9149 - val_loss: 771.2632\n",
      "Epoch 8846/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 307.8429 - val_loss: 780.7068\n",
      "Epoch 8847/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.1409 - val_loss: 821.7686\n",
      "Epoch 8848/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 318.5146 - val_loss: 762.0075\n",
      "Epoch 8849/10000\n",
      "630/630 [==============================] - 0s 72us/step - loss: 290.4259 - val_loss: 862.5378\n",
      "Epoch 8850/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 336.8267 - val_loss: 741.7667\n",
      "Epoch 8851/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 341.5239 - val_loss: 736.5342\n",
      "Epoch 8852/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 367.2411 - val_loss: 789.3834\n",
      "Epoch 8853/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.5980 - val_loss: 864.6971\n",
      "Epoch 8854/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 293.0867 - val_loss: 807.1442\n",
      "Epoch 8855/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 304.2028 - val_loss: 815.0448\n",
      "Epoch 8856/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.4961 - val_loss: 833.1948\n",
      "Epoch 8857/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 318.6254 - val_loss: 764.6361\n",
      "Epoch 8858/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 320.8394 - val_loss: 729.7102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8859/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 349.9630 - val_loss: 728.4609\n",
      "Epoch 8860/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 336.5012 - val_loss: 827.3917\n",
      "Epoch 8861/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 336.7087 - val_loss: 803.4873\n",
      "Epoch 8862/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 486.3521 - val_loss: 788.4742\n",
      "Epoch 8863/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 400.0861 - val_loss: 927.9504\n",
      "Epoch 8864/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 363.2596 - val_loss: 789.2699\n",
      "Epoch 8865/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 303.5079 - val_loss: 843.7591\n",
      "Epoch 8866/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 283.6604 - val_loss: 813.5712\n",
      "Epoch 8867/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 284.4408 - val_loss: 858.3225\n",
      "Epoch 8868/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 304.0235 - val_loss: 866.7772\n",
      "Epoch 8869/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 310.1139 - val_loss: 902.2374\n",
      "Epoch 8870/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 334.3025 - val_loss: 849.0554\n",
      "Epoch 8871/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 334.8714 - val_loss: 845.1616\n",
      "Epoch 8872/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 320.8622 - val_loss: 779.6174\n",
      "Epoch 8873/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 325.7667 - val_loss: 741.9699\n",
      "Epoch 8874/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 336.1528 - val_loss: 760.4815\n",
      "Epoch 8875/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.9431 - val_loss: 936.7072\n",
      "Epoch 8876/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 381.2964 - val_loss: 764.7206\n",
      "Epoch 8877/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 352.3034 - val_loss: 797.9195\n",
      "Epoch 8878/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.6009 - val_loss: 796.4970\n",
      "Epoch 8879/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 373.8173 - val_loss: 761.8916\n",
      "Epoch 8880/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 370.7299 - val_loss: 807.1928\n",
      "Epoch 8881/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 357.1932 - val_loss: 862.0781\n",
      "Epoch 8882/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 363.7000 - val_loss: 702.5222\n",
      "Epoch 8883/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 319.1102 - val_loss: 793.4865\n",
      "Epoch 8884/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.5761 - val_loss: 884.9728\n",
      "Epoch 8885/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 370.1681 - val_loss: 984.2011\n",
      "Epoch 8886/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 373.1846 - val_loss: 1026.7423\n",
      "Epoch 8887/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.3524 - val_loss: 946.8440\n",
      "Epoch 8888/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 478.2396 - val_loss: 1819.3587\n",
      "Epoch 8889/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 1953.9077 - val_loss: 2100.9174\n",
      "Epoch 8890/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 2935.1305 - val_loss: 2267.5245\n",
      "Epoch 8891/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 2453.2427 - val_loss: 1649.6582\n",
      "Epoch 8892/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1888.7361 - val_loss: 1422.6915\n",
      "Epoch 8893/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1190.9588 - val_loss: 1039.4881\n",
      "Epoch 8894/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 767.9204 - val_loss: 911.1539\n",
      "Epoch 8895/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 574.8487 - val_loss: 745.4848\n",
      "Epoch 8896/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 496.9499 - val_loss: 753.0721\n",
      "Epoch 8897/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 527.1042 - val_loss: 660.4578\n",
      "Epoch 8898/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 543.2751 - val_loss: 1420.4480\n",
      "Epoch 8899/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 798.8626 - val_loss: 1398.2285\n",
      "Epoch 8900/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 525.6158 - val_loss: 972.0153\n",
      "Epoch 8901/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 433.8823 - val_loss: 832.8371\n",
      "Epoch 8902/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.5122 - val_loss: 809.3385\n",
      "Epoch 8903/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 395.4058 - val_loss: 2126.8216\n",
      "Epoch 8904/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1781.7094 - val_loss: 2122.8229\n",
      "Epoch 8905/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 2168.4284 - val_loss: 2007.2995\n",
      "Epoch 8906/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 1809.4127 - val_loss: 1313.6488\n",
      "Epoch 8907/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 1278.5698 - val_loss: 1074.8034\n",
      "Epoch 8908/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 912.1801 - val_loss: 1013.7194\n",
      "Epoch 8909/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 664.5524 - val_loss: 826.1672\n",
      "Epoch 8910/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 565.4573 - val_loss: 849.7456\n",
      "Epoch 8911/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 461.9498 - val_loss: 816.0323\n",
      "Epoch 8912/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 387.5390 - val_loss: 825.9280\n",
      "Epoch 8913/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 328.3835 - val_loss: 1226.2761\n",
      "Epoch 8914/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1022.3349 - val_loss: 2118.9350\n",
      "Epoch 8915/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1534.3907 - val_loss: 1066.1115\n",
      "Epoch 8916/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1223.7777 - val_loss: 1211.8375\n",
      "Epoch 8917/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 775.3506 - val_loss: 1174.5645\n",
      "Epoch 8918/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 646.3920 - val_loss: 1119.9684\n",
      "Epoch 8919/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 556.3848 - val_loss: 1077.5131\n",
      "Epoch 8920/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 423.6059 - val_loss: 934.6670\n",
      "Epoch 8921/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 389.9663 - val_loss: 724.7510\n",
      "Epoch 8922/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 407.2236 - val_loss: 719.8472\n",
      "Epoch 8923/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 414.0365 - val_loss: 882.2625\n",
      "Epoch 8924/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 346.2504 - val_loss: 835.2086\n",
      "Epoch 8925/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 343.0058 - val_loss: 737.4920\n",
      "Epoch 8926/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 317.6630 - val_loss: 771.7170\n",
      "Epoch 8927/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 290.3152 - val_loss: 814.2740\n",
      "Epoch 8928/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 390.9547 - val_loss: 932.5368\n",
      "Epoch 8929/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 380.8649 - val_loss: 750.1077\n",
      "Epoch 8930/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 359.0938 - val_loss: 787.6391\n",
      "Epoch 8931/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 330.5308 - val_loss: 777.6662\n",
      "Epoch 8932/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 54us/step - loss: 317.8107 - val_loss: 890.4860\n",
      "Epoch 8933/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.0766 - val_loss: 1004.4747\n",
      "Epoch 8934/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 503.3713 - val_loss: 838.3144\n",
      "Epoch 8935/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 377.3341 - val_loss: 827.6280\n",
      "Epoch 8936/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.5420 - val_loss: 804.3828\n",
      "Epoch 8937/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 320.7110 - val_loss: 788.2284\n",
      "Epoch 8938/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.9839 - val_loss: 895.6116\n",
      "Epoch 8939/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 337.6471 - val_loss: 901.7918\n",
      "Epoch 8940/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.1817 - val_loss: 757.1340\n",
      "Epoch 8941/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 355.5118 - val_loss: 798.1883\n",
      "Epoch 8942/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 335.1362 - val_loss: 843.9694\n",
      "Epoch 8943/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 327.7628 - val_loss: 823.3778\n",
      "Epoch 8944/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 309.3803 - val_loss: 778.2560\n",
      "Epoch 8945/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.2259 - val_loss: 796.9295\n",
      "Epoch 8946/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 376.0450 - val_loss: 850.8737\n",
      "Epoch 8947/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 372.9441 - val_loss: 809.0918\n",
      "Epoch 8948/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 331.3354 - val_loss: 758.8116\n",
      "Epoch 8949/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 315.4981 - val_loss: 801.5243\n",
      "Epoch 8950/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.3945 - val_loss: 654.3456\n",
      "Epoch 8951/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 594.1827 - val_loss: 1186.6383\n",
      "Epoch 8952/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 460.9130 - val_loss: 916.7633\n",
      "Epoch 8953/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 398.6509 - val_loss: 759.7978\n",
      "Epoch 8954/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 374.6849 - val_loss: 739.2398\n",
      "Epoch 8955/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 342.0210 - val_loss: 752.4050\n",
      "Epoch 8956/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 366.1098 - val_loss: 852.4724\n",
      "Epoch 8957/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 305.5235 - val_loss: 707.5404\n",
      "Epoch 8958/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.1802 - val_loss: 869.3859\n",
      "Epoch 8959/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 316.2200 - val_loss: 829.9244\n",
      "Epoch 8960/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 302.5534 - val_loss: 762.3403\n",
      "Epoch 8961/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 309.1199 - val_loss: 745.7790\n",
      "Epoch 8962/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.3512 - val_loss: 857.4394\n",
      "Epoch 8963/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 386.1236 - val_loss: 783.9423\n",
      "Epoch 8964/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 355.5809 - val_loss: 793.5135\n",
      "Epoch 8965/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.6228 - val_loss: 844.8708\n",
      "Epoch 8966/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 303.4454 - val_loss: 798.0316\n",
      "Epoch 8967/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 298.3776 - val_loss: 816.3423\n",
      "Epoch 8968/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 293.5322 - val_loss: 770.5367\n",
      "Epoch 8969/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 290.9907 - val_loss: 831.5768\n",
      "Epoch 8970/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 285.9278 - val_loss: 842.1470\n",
      "Epoch 8971/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 288.6225 - val_loss: 785.7001\n",
      "Epoch 8972/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 299.4164 - val_loss: 796.2270\n",
      "Epoch 8973/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 298.3352 - val_loss: 767.4832\n",
      "Epoch 8974/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 309.9594 - val_loss: 773.5732\n",
      "Epoch 8975/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 294.2951 - val_loss: 839.9470\n",
      "Epoch 8976/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 305.1795 - val_loss: 854.6115\n",
      "Epoch 8977/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 310.3378 - val_loss: 790.9345\n",
      "Epoch 8978/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 307.0556 - val_loss: 830.7203\n",
      "Epoch 8979/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.3764 - val_loss: 791.9490\n",
      "Epoch 8980/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 310.5155 - val_loss: 768.2940\n",
      "Epoch 8981/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.0494 - val_loss: 717.3601\n",
      "Epoch 8982/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 330.1463 - val_loss: 817.0219\n",
      "Epoch 8983/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 318.6449 - val_loss: 769.1861\n",
      "Epoch 8984/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 300.7152 - val_loss: 827.0498\n",
      "Epoch 8985/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.7427 - val_loss: 776.0731\n",
      "Epoch 8986/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 317.7798 - val_loss: 807.7994\n",
      "Epoch 8987/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 310.2616 - val_loss: 829.1651\n",
      "Epoch 8988/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 328.1082 - val_loss: 1152.3639\n",
      "Epoch 8989/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 351.2118 - val_loss: 806.2228\n",
      "Epoch 8990/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 376.0865 - val_loss: 932.4399\n",
      "Epoch 8991/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.5898 - val_loss: 825.1633\n",
      "Epoch 8992/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 293.3933 - val_loss: 787.2058\n",
      "Epoch 8993/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 292.4772 - val_loss: 751.3653\n",
      "Epoch 8994/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 286.2061 - val_loss: 787.5878\n",
      "Epoch 8995/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 283.8406 - val_loss: 750.2572\n",
      "Epoch 8996/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 429.7415 - val_loss: 786.1188\n",
      "Epoch 8997/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 477.2460 - val_loss: 767.5187\n",
      "Epoch 8998/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 368.7391 - val_loss: 740.0094\n",
      "Epoch 8999/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 335.8036 - val_loss: 806.2079\n",
      "Epoch 9000/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 329.6638 - val_loss: 829.4592\n",
      "Epoch 9001/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 490.5279 - val_loss: 927.5426\n",
      "Epoch 9002/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 960.9363 - val_loss: 1063.3013\n",
      "Epoch 9003/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 690.0758 - val_loss: 963.5056\n",
      "Epoch 9004/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 510.9801 - val_loss: 847.9201\n",
      "Epoch 9005/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 512.1766 - val_loss: 794.2053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9006/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 409.9927 - val_loss: 869.5477\n",
      "Epoch 9007/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.4511 - val_loss: 900.3634\n",
      "Epoch 9008/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.1855 - val_loss: 714.2581\n",
      "Epoch 9009/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 375.1988 - val_loss: 750.4003\n",
      "Epoch 9010/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 356.5410 - val_loss: 862.5728\n",
      "Epoch 9011/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 400.6950 - val_loss: 798.1182\n",
      "Epoch 9012/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 434.8091 - val_loss: 908.7910\n",
      "Epoch 9013/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 353.6859 - val_loss: 759.0440\n",
      "Epoch 9014/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.1976 - val_loss: 856.6552\n",
      "Epoch 9015/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 319.2895 - val_loss: 812.7249\n",
      "Epoch 9016/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 309.4515 - val_loss: 737.8415\n",
      "Epoch 9017/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 290.7543 - val_loss: 779.1777\n",
      "Epoch 9018/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 292.6881 - val_loss: 781.8848\n",
      "Epoch 9019/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 316.4520 - val_loss: 890.8773\n",
      "Epoch 9020/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 376.5706 - val_loss: 753.1270\n",
      "Epoch 9021/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.4157 - val_loss: 807.8840\n",
      "Epoch 9022/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 309.5404 - val_loss: 719.6827\n",
      "Epoch 9023/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 319.2057 - val_loss: 929.0577\n",
      "Epoch 9024/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 307.5443 - val_loss: 745.3848\n",
      "Epoch 9025/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 301.6085 - val_loss: 763.1834\n",
      "Epoch 9026/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 365.6000 - val_loss: 679.2106\n",
      "Epoch 9027/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 332.8970 - val_loss: 930.6346\n",
      "Epoch 9028/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 342.5777 - val_loss: 926.4301\n",
      "Epoch 9029/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 529.9626 - val_loss: 870.3207\n",
      "Epoch 9030/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 433.1066 - val_loss: 730.7938\n",
      "Epoch 9031/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 410.5180 - val_loss: 795.6669\n",
      "Epoch 9032/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 349.1494 - val_loss: 902.4018\n",
      "Epoch 9033/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.2091 - val_loss: 797.3697\n",
      "Epoch 9034/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.6118 - val_loss: 876.6627\n",
      "Epoch 9035/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 333.0353 - val_loss: 818.1966\n",
      "Epoch 9036/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 330.2061 - val_loss: 751.9341\n",
      "Epoch 9037/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.9830 - val_loss: 829.7192\n",
      "Epoch 9038/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 295.8655 - val_loss: 694.6295\n",
      "Epoch 9039/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 272.3905 - val_loss: 773.9894\n",
      "Epoch 9040/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 276.8961 - val_loss: 733.0419\n",
      "Epoch 9041/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 281.8631 - val_loss: 748.9819\n",
      "Epoch 9042/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.4699 - val_loss: 832.5840\n",
      "Epoch 9043/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 296.9601 - val_loss: 962.8330\n",
      "Epoch 9044/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 334.1582 - val_loss: 891.6400\n",
      "Epoch 9045/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 353.4309 - val_loss: 822.6680\n",
      "Epoch 9046/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 304.7167 - val_loss: 837.5816\n",
      "Epoch 9047/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 332.3872 - val_loss: 859.4407\n",
      "Epoch 9048/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 323.8749 - val_loss: 796.5573\n",
      "Epoch 9049/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 317.9185 - val_loss: 772.7167\n",
      "Epoch 9050/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 310.5155 - val_loss: 822.6615\n",
      "Epoch 9051/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 345.5131 - val_loss: 756.5798\n",
      "Epoch 9052/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 320.2667 - val_loss: 752.2413\n",
      "Epoch 9053/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.0161 - val_loss: 750.4235\n",
      "Epoch 9054/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 289.9342 - val_loss: 744.0296\n",
      "Epoch 9055/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 358.5656 - val_loss: 863.7184\n",
      "Epoch 9056/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 321.6490 - val_loss: 773.7108\n",
      "Epoch 9057/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 292.0264 - val_loss: 826.5123\n",
      "Epoch 9058/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.7837 - val_loss: 866.3727\n",
      "Epoch 9059/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 317.0500 - val_loss: 909.9336\n",
      "Epoch 9060/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 313.4689 - val_loss: 882.4338\n",
      "Epoch 9061/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 310.3912 - val_loss: 763.6054\n",
      "Epoch 9062/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 331.1389 - val_loss: 830.1701\n",
      "Epoch 9063/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 301.9402 - val_loss: 761.3416\n",
      "Epoch 9064/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 287.2242 - val_loss: 773.4201\n",
      "Epoch 9065/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 332.6292 - val_loss: 747.3005\n",
      "Epoch 9066/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 331.1074 - val_loss: 737.1516\n",
      "Epoch 9067/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 324.5757 - val_loss: 688.8165\n",
      "Epoch 9068/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 337.9796 - val_loss: 861.8117\n",
      "Epoch 9069/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 338.3969 - val_loss: 857.5120\n",
      "Epoch 9070/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 328.5107 - val_loss: 735.0136\n",
      "Epoch 9071/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 495.4481 - val_loss: 971.5771\n",
      "Epoch 9072/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 467.7410 - val_loss: 944.2055\n",
      "Epoch 9073/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 359.0529 - val_loss: 805.1237\n",
      "Epoch 9074/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 329.8232 - val_loss: 852.3667\n",
      "Epoch 9075/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 327.8566 - val_loss: 813.7360\n",
      "Epoch 9076/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 326.1841 - val_loss: 738.5324\n",
      "Epoch 9077/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 294.9788 - val_loss: 823.4336\n",
      "Epoch 9078/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 305.2541 - val_loss: 706.1633\n",
      "Epoch 9079/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 290.9418 - val_loss: 670.5976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9080/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1782.2127 - val_loss: 1331.1302\n",
      "Epoch 9081/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 2364.0698 - val_loss: 1354.3966\n",
      "Epoch 9082/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 2018.3349 - val_loss: 1504.0299\n",
      "Epoch 9083/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1695.8310 - val_loss: 1542.5274\n",
      "Epoch 9084/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1514.9898 - val_loss: 1557.8845\n",
      "Epoch 9085/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1328.1594 - val_loss: 1473.9821\n",
      "Epoch 9086/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1186.4102 - val_loss: 1402.4786\n",
      "Epoch 9087/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1100.7866 - val_loss: 1446.3270\n",
      "Epoch 9088/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1048.1716 - val_loss: 1471.7965\n",
      "Epoch 9089/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 990.1617 - val_loss: 1152.0943\n",
      "Epoch 9090/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 1042.9927 - val_loss: 1117.9879\n",
      "Epoch 9091/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 905.3972 - val_loss: 1190.0749\n",
      "Epoch 9092/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 890.4912 - val_loss: 1137.9504\n",
      "Epoch 9093/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 832.6949 - val_loss: 1058.1387\n",
      "Epoch 9094/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 797.5662 - val_loss: 1092.7115\n",
      "Epoch 9095/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 756.8824 - val_loss: 1095.2609\n",
      "Epoch 9096/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 737.1860 - val_loss: 1064.1935\n",
      "Epoch 9097/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 698.9693 - val_loss: 1044.7149\n",
      "Epoch 9098/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 683.1717 - val_loss: 1053.4510\n",
      "Epoch 9099/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 688.0329 - val_loss: 1034.5140\n",
      "Epoch 9100/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 675.9204 - val_loss: 1008.5897\n",
      "Epoch 9101/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 626.1985 - val_loss: 1005.5989\n",
      "Epoch 9102/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 612.6698 - val_loss: 978.2559\n",
      "Epoch 9103/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 590.1155 - val_loss: 1002.1412\n",
      "Epoch 9104/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 560.5048 - val_loss: 811.5938\n",
      "Epoch 9105/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 831.5453 - val_loss: 1098.5400\n",
      "Epoch 9106/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1080.4888 - val_loss: 1271.1909\n",
      "Epoch 9107/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 840.8044 - val_loss: 1191.1918\n",
      "Epoch 9108/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 793.9974 - val_loss: 1087.0507\n",
      "Epoch 9109/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 636.0095 - val_loss: 992.2578\n",
      "Epoch 9110/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 549.2224 - val_loss: 934.7994\n",
      "Epoch 9111/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 505.6328 - val_loss: 939.3280\n",
      "Epoch 9112/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 435.4217 - val_loss: 1014.1311\n",
      "Epoch 9113/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 535.9614 - val_loss: 1028.9386\n",
      "Epoch 9114/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 553.8767 - val_loss: 1555.5323\n",
      "Epoch 9115/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 668.0443 - val_loss: 957.0989\n",
      "Epoch 9116/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 624.4160 - val_loss: 1044.5699\n",
      "Epoch 9117/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1164.6614 - val_loss: 1042.5768\n",
      "Epoch 9118/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 745.8302 - val_loss: 844.6246\n",
      "Epoch 9119/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 822.4568 - val_loss: 1564.3103\n",
      "Epoch 9120/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 794.6834 - val_loss: 1437.5276\n",
      "Epoch 9121/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 722.5799 - val_loss: 957.0986\n",
      "Epoch 9122/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 621.8359 - val_loss: 960.9964\n",
      "Epoch 9123/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 598.2313 - val_loss: 1000.3151\n",
      "Epoch 9124/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 532.1916 - val_loss: 993.6116\n",
      "Epoch 9125/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 473.1173 - val_loss: 862.6534\n",
      "Epoch 9126/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 533.8345 - val_loss: 994.6429\n",
      "Epoch 9127/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 518.5719 - val_loss: 1082.4575\n",
      "Epoch 9128/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 601.8623 - val_loss: 966.9081\n",
      "Epoch 9129/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 722.9207 - val_loss: 1017.6359\n",
      "Epoch 9130/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 553.9387 - val_loss: 997.5991\n",
      "Epoch 9131/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 477.5428 - val_loss: 979.2157\n",
      "Epoch 9132/10000\n",
      "630/630 [==============================] - 0s 73us/step - loss: 414.0442 - val_loss: 956.5569\n",
      "Epoch 9133/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 385.9628 - val_loss: 960.5222\n",
      "Epoch 9134/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 492.9650 - val_loss: 1132.2375\n",
      "Epoch 9135/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 648.0381 - val_loss: 957.8464\n",
      "Epoch 9136/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 487.4816 - val_loss: 1244.0556\n",
      "Epoch 9137/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 510.4106 - val_loss: 1019.7136\n",
      "Epoch 9138/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 439.0160 - val_loss: 968.5842\n",
      "Epoch 9139/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 562.8851 - val_loss: 941.1890\n",
      "Epoch 9140/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 546.7454 - val_loss: 930.9151\n",
      "Epoch 9141/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 459.2234 - val_loss: 897.2515\n",
      "Epoch 9142/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 407.2740 - val_loss: 884.7796\n",
      "Epoch 9143/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 382.7513 - val_loss: 813.0247\n",
      "Epoch 9144/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 381.8209 - val_loss: 864.5956\n",
      "Epoch 9145/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 321.8825 - val_loss: 849.9198\n",
      "Epoch 9146/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 352.9243 - val_loss: 1033.2329\n",
      "Epoch 9147/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 420.8165 - val_loss: 967.4376\n",
      "Epoch 9148/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 381.4125 - val_loss: 1042.3709\n",
      "Epoch 9149/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 434.6651 - val_loss: 873.9139\n",
      "Epoch 9150/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 421.1300 - val_loss: 789.8392\n",
      "Epoch 9151/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 440.3445 - val_loss: 921.2416\n",
      "Epoch 9152/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 379.9007 - val_loss: 953.2718\n",
      "Epoch 9153/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 59us/step - loss: 351.2032 - val_loss: 757.0420\n",
      "Epoch 9154/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 346.4273 - val_loss: 1015.1954\n",
      "Epoch 9155/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 393.9610 - val_loss: 797.6986\n",
      "Epoch 9156/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 406.7335 - val_loss: 999.9698\n",
      "Epoch 9157/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 361.9048 - val_loss: 1024.2703\n",
      "Epoch 9158/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 378.5705 - val_loss: 880.9378\n",
      "Epoch 9159/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 341.3271 - val_loss: 988.9254\n",
      "Epoch 9160/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 389.6468 - val_loss: 987.7594\n",
      "Epoch 9161/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 602.9491 - val_loss: 989.6012\n",
      "Epoch 9162/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 556.7499 - val_loss: 706.2666\n",
      "Epoch 9163/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 606.6881 - val_loss: 810.0025\n",
      "Epoch 9164/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 508.6378 - val_loss: 852.4596\n",
      "Epoch 9165/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 410.4065 - val_loss: 951.2169\n",
      "Epoch 9166/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 358.4763 - val_loss: 897.8175\n",
      "Epoch 9167/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 312.9656 - val_loss: 732.5750\n",
      "Epoch 9168/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.1643 - val_loss: 965.6805\n",
      "Epoch 9169/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.0415 - val_loss: 870.7602\n",
      "Epoch 9170/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.9314 - val_loss: 752.9387\n",
      "Epoch 9171/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.5542 - val_loss: 771.3146\n",
      "Epoch 9172/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 332.7714 - val_loss: 843.2506\n",
      "Epoch 9173/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 329.4094 - val_loss: 887.9129\n",
      "Epoch 9174/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 352.9206 - val_loss: 855.0349\n",
      "Epoch 9175/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 346.6181 - val_loss: 922.5061\n",
      "Epoch 9176/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 307.7979 - val_loss: 806.9968\n",
      "Epoch 9177/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 298.6416 - val_loss: 787.1195\n",
      "Epoch 9178/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 317.3987 - val_loss: 801.9258\n",
      "Epoch 9179/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 314.6871 - val_loss: 737.6136\n",
      "Epoch 9180/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 324.1391 - val_loss: 756.3727\n",
      "Epoch 9181/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 318.9405 - val_loss: 825.4661\n",
      "Epoch 9182/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.6199 - val_loss: 764.0610\n",
      "Epoch 9183/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 346.3619 - val_loss: 765.3963\n",
      "Epoch 9184/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 435.7642 - val_loss: 876.3249\n",
      "Epoch 9185/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 406.3017 - val_loss: 773.7665\n",
      "Epoch 9186/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 352.2134 - val_loss: 818.9049\n",
      "Epoch 9187/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 293.3233 - val_loss: 853.9872\n",
      "Epoch 9188/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 299.2200 - val_loss: 832.1504\n",
      "Epoch 9189/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 300.6171 - val_loss: 1349.7964\n",
      "Epoch 9190/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 628.5020 - val_loss: 789.8390\n",
      "Epoch 9191/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 557.8765 - val_loss: 1219.1020\n",
      "Epoch 9192/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 780.4594 - val_loss: 840.1087\n",
      "Epoch 9193/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 919.8820 - val_loss: 840.8380\n",
      "Epoch 9194/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 890.4135 - val_loss: 834.6474\n",
      "Epoch 9195/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 637.2926 - val_loss: 798.2268\n",
      "Epoch 9196/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 545.6360 - val_loss: 974.9163\n",
      "Epoch 9197/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 431.2576 - val_loss: 837.8863\n",
      "Epoch 9198/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 350.8863 - val_loss: 1057.5595\n",
      "Epoch 9199/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 352.1759 - val_loss: 1014.6437\n",
      "Epoch 9200/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 471.0614 - val_loss: 1091.4880\n",
      "Epoch 9201/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 514.0706 - val_loss: 831.2587\n",
      "Epoch 9202/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 436.0961 - val_loss: 953.0462\n",
      "Epoch 9203/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 371.9824 - val_loss: 822.6159\n",
      "Epoch 9204/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.6630 - val_loss: 973.7424\n",
      "Epoch 9205/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.9763 - val_loss: 885.8647\n",
      "Epoch 9206/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 308.1251 - val_loss: 860.7959\n",
      "Epoch 9207/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 295.5412 - val_loss: 854.2342\n",
      "Epoch 9208/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 307.8123 - val_loss: 817.6838\n",
      "Epoch 9209/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.8050 - val_loss: 950.9780\n",
      "Epoch 9210/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 327.5375 - val_loss: 925.9134\n",
      "Epoch 9211/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 741.0279 - val_loss: 762.7111\n",
      "Epoch 9212/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 1011.3216 - val_loss: 775.6381\n",
      "Epoch 9213/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 743.2765 - val_loss: 875.0058\n",
      "Epoch 9214/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 597.6714 - val_loss: 868.6237\n",
      "Epoch 9215/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 481.8280 - val_loss: 835.4093\n",
      "Epoch 9216/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 394.2986 - val_loss: 805.1753\n",
      "Epoch 9217/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 362.8016 - val_loss: 844.6709\n",
      "Epoch 9218/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 321.3025 - val_loss: 876.7373\n",
      "Epoch 9219/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 311.3854 - val_loss: 856.5697\n",
      "Epoch 9220/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 322.1812 - val_loss: 943.0508\n",
      "Epoch 9221/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 314.4649 - val_loss: 837.4061\n",
      "Epoch 9222/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.9974 - val_loss: 792.8089\n",
      "Epoch 9223/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 309.3540 - val_loss: 1072.6837\n",
      "Epoch 9224/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 351.8948 - val_loss: 838.8908\n",
      "Epoch 9225/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.9679 - val_loss: 702.6156\n",
      "Epoch 9226/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 327.6254 - val_loss: 826.7781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9227/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.7117 - val_loss: 778.7364\n",
      "Epoch 9228/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 318.8781 - val_loss: 768.2669\n",
      "Epoch 9229/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 285.1939 - val_loss: 744.8205\n",
      "Epoch 9230/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 274.4828 - val_loss: 770.8991\n",
      "Epoch 9231/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 296.0518 - val_loss: 790.2088\n",
      "Epoch 9232/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 291.9290 - val_loss: 804.6386\n",
      "Epoch 9233/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 277.8309 - val_loss: 721.1326\n",
      "Epoch 9234/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 313.5818 - val_loss: 725.6061\n",
      "Epoch 9235/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 316.8606 - val_loss: 788.5306\n",
      "Epoch 9236/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 298.3613 - val_loss: 820.1484\n",
      "Epoch 9237/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 303.4328 - val_loss: 767.8285\n",
      "Epoch 9238/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 300.1437 - val_loss: 776.8423\n",
      "Epoch 9239/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 310.3949 - val_loss: 736.1561\n",
      "Epoch 9240/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 304.5493 - val_loss: 762.5624\n",
      "Epoch 9241/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 283.0299 - val_loss: 703.2635\n",
      "Epoch 9242/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 380.0145 - val_loss: 734.2962\n",
      "Epoch 9243/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 478.6128 - val_loss: 1156.2756\n",
      "Epoch 9244/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 477.2011 - val_loss: 869.5249\n",
      "Epoch 9245/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 595.4560 - val_loss: 802.4255\n",
      "Epoch 9246/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 643.1753 - val_loss: 802.5729\n",
      "Epoch 9247/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 431.9415 - val_loss: 739.8811\n",
      "Epoch 9248/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 440.3994 - val_loss: 766.5647\n",
      "Epoch 9249/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 550.0622 - val_loss: 929.3504\n",
      "Epoch 9250/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 608.1251 - val_loss: 790.2626\n",
      "Epoch 9251/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 463.1910 - val_loss: 823.5309\n",
      "Epoch 9252/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 426.6107 - val_loss: 838.9304\n",
      "Epoch 9253/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 382.0628 - val_loss: 862.9658\n",
      "Epoch 9254/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 339.8029 - val_loss: 811.7298\n",
      "Epoch 9255/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 286.7100 - val_loss: 1052.8801\n",
      "Epoch 9256/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 346.5760 - val_loss: 889.4369\n",
      "Epoch 9257/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.5975 - val_loss: 790.4037\n",
      "Epoch 9258/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 308.8646 - val_loss: 784.9988\n",
      "Epoch 9259/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 328.0999 - val_loss: 911.9683\n",
      "Epoch 9260/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 520.7320 - val_loss: 794.2650\n",
      "Epoch 9261/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 458.3463 - val_loss: 978.2691\n",
      "Epoch 9262/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 454.6020 - val_loss: 958.5776\n",
      "Epoch 9263/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 356.1431 - val_loss: 765.2451\n",
      "Epoch 9264/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 353.0275 - val_loss: 865.9795\n",
      "Epoch 9265/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 329.7328 - val_loss: 820.6168\n",
      "Epoch 9266/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 346.5367 - val_loss: 812.6669\n",
      "Epoch 9267/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 304.5922 - val_loss: 745.1857\n",
      "Epoch 9268/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 329.3632 - val_loss: 787.6398\n",
      "Epoch 9269/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 307.0518 - val_loss: 799.3403\n",
      "Epoch 9270/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 293.8001 - val_loss: 768.4569\n",
      "Epoch 9271/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 313.6764 - val_loss: 835.8262\n",
      "Epoch 9272/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 295.6006 - val_loss: 799.7228\n",
      "Epoch 9273/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 308.4559 - val_loss: 875.8846\n",
      "Epoch 9274/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 545.7495 - val_loss: 896.6736\n",
      "Epoch 9275/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 542.5840 - val_loss: 906.4774\n",
      "Epoch 9276/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 481.8675 - val_loss: 889.7986\n",
      "Epoch 9277/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 469.5361 - val_loss: 743.5907\n",
      "Epoch 9278/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 405.5592 - val_loss: 783.9670\n",
      "Epoch 9279/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 320.6311 - val_loss: 873.9387\n",
      "Epoch 9280/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 313.9629 - val_loss: 806.4190\n",
      "Epoch 9281/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 371.2962 - val_loss: 806.8777\n",
      "Epoch 9282/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 350.2118 - val_loss: 865.0040\n",
      "Epoch 9283/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 320.2565 - val_loss: 834.0640\n",
      "Epoch 9284/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 315.3476 - val_loss: 731.7540\n",
      "Epoch 9285/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 318.4516 - val_loss: 825.9540\n",
      "Epoch 9286/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 308.9194 - val_loss: 777.0045\n",
      "Epoch 9287/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 302.7569 - val_loss: 860.6958\n",
      "Epoch 9288/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 296.4747 - val_loss: 768.2434\n",
      "Epoch 9289/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 312.3338 - val_loss: 768.1456\n",
      "Epoch 9290/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 306.5665 - val_loss: 873.1635\n",
      "Epoch 9291/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 287.9564 - val_loss: 868.9383\n",
      "Epoch 9292/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 327.4540 - val_loss: 748.4373\n",
      "Epoch 9293/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 464.9321 - val_loss: 979.1195\n",
      "Epoch 9294/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 705.8021 - val_loss: 890.1392\n",
      "Epoch 9295/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 522.0617 - val_loss: 806.9365\n",
      "Epoch 9296/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 395.9166 - val_loss: 873.7728\n",
      "Epoch 9297/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 348.3005 - val_loss: 859.4837\n",
      "Epoch 9298/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 323.9010 - val_loss: 750.0768\n",
      "Epoch 9299/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 339.2859 - val_loss: 750.2587\n",
      "Epoch 9300/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 301.6569 - val_loss: 794.4485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9301/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 298.9633 - val_loss: 893.0853\n",
      "Epoch 9302/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 336.7206 - val_loss: 895.8403\n",
      "Epoch 9303/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 331.5240 - val_loss: 866.6813\n",
      "Epoch 9304/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 316.4779 - val_loss: 803.6463\n",
      "Epoch 9305/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 304.6275 - val_loss: 841.1640\n",
      "Epoch 9306/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 311.1742 - val_loss: 1013.5203\n",
      "Epoch 9307/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 327.5299 - val_loss: 923.9735\n",
      "Epoch 9308/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 326.1110 - val_loss: 782.4364\n",
      "Epoch 9309/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 439.6705 - val_loss: 763.4262\n",
      "Epoch 9310/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 432.6813 - val_loss: 807.5835\n",
      "Epoch 9311/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 379.5204 - val_loss: 789.5332\n",
      "Epoch 9312/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 311.6147 - val_loss: 958.0491\n",
      "Epoch 9313/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 317.2697 - val_loss: 712.8157\n",
      "Epoch 9314/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 320.5463 - val_loss: 731.7764\n",
      "Epoch 9315/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 294.6066 - val_loss: 752.3736\n",
      "Epoch 9316/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 287.7068 - val_loss: 993.5937\n",
      "Epoch 9317/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 505.5579 - val_loss: 801.6932\n",
      "Epoch 9318/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 537.4241 - val_loss: 747.6125\n",
      "Epoch 9319/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 462.6747 - val_loss: 798.6630\n",
      "Epoch 9320/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 386.4191 - val_loss: 867.0099\n",
      "Epoch 9321/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.8058 - val_loss: 813.8583\n",
      "Epoch 9322/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 301.0362 - val_loss: 877.6929\n",
      "Epoch 9323/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 305.8286 - val_loss: 708.9316\n",
      "Epoch 9324/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 316.5122 - val_loss: 763.9714\n",
      "Epoch 9325/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 300.5394 - val_loss: 824.4473\n",
      "Epoch 9326/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 410.0654 - val_loss: 914.4561\n",
      "Epoch 9327/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 463.3505 - val_loss: 801.9457\n",
      "Epoch 9328/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 390.1066 - val_loss: 818.1323\n",
      "Epoch 9329/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 330.9036 - val_loss: 966.9584\n",
      "Epoch 9330/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 913.2367 - val_loss: 2250.9737\n",
      "Epoch 9331/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 2393.9866 - val_loss: 2284.2655\n",
      "Epoch 9332/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 1826.1549 - val_loss: 1731.8011\n",
      "Epoch 9333/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1219.7921 - val_loss: 1271.0891\n",
      "Epoch 9334/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 851.7900 - val_loss: 1013.0292\n",
      "Epoch 9335/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 600.8285 - val_loss: 842.0409\n",
      "Epoch 9336/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 578.5900 - val_loss: 887.7533\n",
      "Epoch 9337/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 477.8149 - val_loss: 950.7360\n",
      "Epoch 9338/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 490.6337 - val_loss: 727.6558\n",
      "Epoch 9339/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 701.2637 - val_loss: 702.1339\n",
      "Epoch 9340/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 574.6103 - val_loss: 849.0485\n",
      "Epoch 9341/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 549.9749 - val_loss: 859.1564\n",
      "Epoch 9342/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 511.3129 - val_loss: 839.1651\n",
      "Epoch 9343/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 485.6051 - val_loss: 881.0511\n",
      "Epoch 9344/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 448.4563 - val_loss: 989.2396\n",
      "Epoch 9345/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 415.9028 - val_loss: 826.9811\n",
      "Epoch 9346/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 407.4020 - val_loss: 718.5635\n",
      "Epoch 9347/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 381.2331 - val_loss: 928.2937\n",
      "Epoch 9348/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 369.0573 - val_loss: 649.3987\n",
      "Epoch 9349/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 462.0078 - val_loss: 805.9132\n",
      "Epoch 9350/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 478.4279 - val_loss: 788.5337\n",
      "Epoch 9351/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 861.9486 - val_loss: 1209.5884\n",
      "Epoch 9352/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 862.4826 - val_loss: 1173.7219\n",
      "Epoch 9353/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 713.0367 - val_loss: 1191.9769\n",
      "Epoch 9354/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 685.6976 - val_loss: 1482.7190\n",
      "Epoch 9355/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 832.6418 - val_loss: 770.0351\n",
      "Epoch 9356/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 610.3570 - val_loss: 800.5759\n",
      "Epoch 9357/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 563.0471 - val_loss: 888.7696\n",
      "Epoch 9358/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 466.9835 - val_loss: 839.2931\n",
      "Epoch 9359/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 448.3441 - val_loss: 845.2536\n",
      "Epoch 9360/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 413.5851 - val_loss: 898.2169\n",
      "Epoch 9361/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 389.1974 - val_loss: 799.2179\n",
      "Epoch 9362/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 375.0583 - val_loss: 724.6555\n",
      "Epoch 9363/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 435.8968 - val_loss: 791.7182\n",
      "Epoch 9364/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 395.2386 - val_loss: 795.8603\n",
      "Epoch 9365/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 392.8209 - val_loss: 900.6353\n",
      "Epoch 9366/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 382.7327 - val_loss: 989.7479\n",
      "Epoch 9367/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 357.7879 - val_loss: 826.0814\n",
      "Epoch 9368/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 399.8270 - val_loss: 835.3397\n",
      "Epoch 9369/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 402.6229 - val_loss: 636.5419\n",
      "Epoch 9370/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 950.8581 - val_loss: 1304.5157\n",
      "Epoch 9371/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 849.0927 - val_loss: 782.0559\n",
      "Epoch 9372/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 700.2482 - val_loss: 1050.8408\n",
      "Epoch 9373/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 770.6250 - val_loss: 1097.6523\n",
      "Epoch 9374/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 690.6533 - val_loss: 884.6725\n",
      "Epoch 9375/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 448.0258 - val_loss: 878.6927\n",
      "Epoch 9376/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 406.1679 - val_loss: 816.7403\n",
      "Epoch 9377/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 402.6200 - val_loss: 762.9536\n",
      "Epoch 9378/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 388.6022 - val_loss: 680.8045\n",
      "Epoch 9379/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 410.4014 - val_loss: 747.7547\n",
      "Epoch 9380/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 401.2435 - val_loss: 1019.3332\n",
      "Epoch 9381/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 587.9275 - val_loss: 1208.3165\n",
      "Epoch 9382/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 444.1403 - val_loss: 882.7975\n",
      "Epoch 9383/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 409.1395 - val_loss: 1052.1852\n",
      "Epoch 9384/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 399.9944 - val_loss: 959.3043\n",
      "Epoch 9385/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 410.6050 - val_loss: 870.4090\n",
      "Epoch 9386/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 416.5887 - val_loss: 795.6778\n",
      "Epoch 9387/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 367.0261 - val_loss: 842.5626\n",
      "Epoch 9388/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 325.3970 - val_loss: 726.0434\n",
      "Epoch 9389/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 354.9890 - val_loss: 843.7294\n",
      "Epoch 9390/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 316.7624 - val_loss: 775.8234\n",
      "Epoch 9391/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 324.6882 - val_loss: 787.9602\n",
      "Epoch 9392/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 339.9448 - val_loss: 709.5625\n",
      "Epoch 9393/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 440.1290 - val_loss: 984.5834\n",
      "Epoch 9394/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 422.2346 - val_loss: 859.7899\n",
      "Epoch 9395/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 399.2391 - val_loss: 800.6744\n",
      "Epoch 9396/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 365.5068 - val_loss: 802.4647\n",
      "Epoch 9397/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 317.5594 - val_loss: 737.4266\n",
      "Epoch 9398/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 499.2336 - val_loss: 842.5752\n",
      "Epoch 9399/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 414.3033 - val_loss: 842.5908\n",
      "Epoch 9400/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 398.7199 - val_loss: 959.9090\n",
      "Epoch 9401/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 428.2237 - val_loss: 899.6902\n",
      "Epoch 9402/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 386.9048 - val_loss: 885.3047\n",
      "Epoch 9403/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 514.2292 - val_loss: 984.2641\n",
      "Epoch 9404/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 532.1469 - val_loss: 1023.1828\n",
      "Epoch 9405/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 682.0666 - val_loss: 997.0372\n",
      "Epoch 9406/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 711.1245 - val_loss: 852.6702\n",
      "Epoch 9407/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 637.7052 - val_loss: 852.1701\n",
      "Epoch 9408/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 596.8459 - val_loss: 1075.6499\n",
      "Epoch 9409/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 572.1438 - val_loss: 1119.3271\n",
      "Epoch 9410/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 575.3091 - val_loss: 1080.5863\n",
      "Epoch 9411/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 531.0591 - val_loss: 1002.2500\n",
      "Epoch 9412/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 477.6419 - val_loss: 890.2306\n",
      "Epoch 9413/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 458.8040 - val_loss: 984.9039\n",
      "Epoch 9414/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 446.1196 - val_loss: 988.6827\n",
      "Epoch 9415/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 406.0379 - val_loss: 960.7366\n",
      "Epoch 9416/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 392.9369 - val_loss: 943.9194\n",
      "Epoch 9417/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 356.3726 - val_loss: 725.7965\n",
      "Epoch 9418/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 475.8934 - val_loss: 964.7575\n",
      "Epoch 9419/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 431.9548 - val_loss: 1010.8357\n",
      "Epoch 9420/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 454.9591 - val_loss: 969.0784\n",
      "Epoch 9421/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 435.2788 - val_loss: 848.6487\n",
      "Epoch 9422/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 365.2083 - val_loss: 1076.0478\n",
      "Epoch 9423/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 381.8117 - val_loss: 853.0108\n",
      "Epoch 9424/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 356.7402 - val_loss: 957.7278\n",
      "Epoch 9425/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 340.2155 - val_loss: 917.0000\n",
      "Epoch 9426/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 352.2780 - val_loss: 1725.2846\n",
      "Epoch 9427/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2255.6460 - val_loss: 2037.3259\n",
      "Epoch 9428/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 2098.6268 - val_loss: 1873.1776\n",
      "Epoch 9429/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1707.6976 - val_loss: 1387.5063\n",
      "Epoch 9430/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1252.4939 - val_loss: 1474.3497\n",
      "Epoch 9431/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 955.1615 - val_loss: 1619.9821\n",
      "Epoch 9432/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 864.1962 - val_loss: 1268.4236\n",
      "Epoch 9433/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 766.1198 - val_loss: 980.7122\n",
      "Epoch 9434/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 681.8031 - val_loss: 851.3284\n",
      "Epoch 9435/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 666.5654 - val_loss: 835.9560\n",
      "Epoch 9436/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 616.9386 - val_loss: 1051.3771\n",
      "Epoch 9437/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 549.5050 - val_loss: 897.2476\n",
      "Epoch 9438/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 504.3332 - val_loss: 847.7805\n",
      "Epoch 9439/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 464.6974 - val_loss: 899.1903\n",
      "Epoch 9440/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 440.8314 - val_loss: 842.4182\n",
      "Epoch 9441/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 408.0795 - val_loss: 828.7560\n",
      "Epoch 9442/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 411.0876 - val_loss: 864.4614\n",
      "Epoch 9443/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 378.6227 - val_loss: 893.0149\n",
      "Epoch 9444/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 398.7300 - val_loss: 886.7731\n",
      "Epoch 9445/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 376.9959 - val_loss: 956.1982\n",
      "Epoch 9446/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 387.3727 - val_loss: 872.4379\n",
      "Epoch 9447/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 480.6822 - val_loss: 843.5057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9448/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 474.0098 - val_loss: 893.5699\n",
      "Epoch 9449/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 470.1210 - val_loss: 847.2414\n",
      "Epoch 9450/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 429.8231 - val_loss: 836.0720\n",
      "Epoch 9451/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 410.3356 - val_loss: 901.2946\n",
      "Epoch 9452/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 379.3910 - val_loss: 797.0073\n",
      "Epoch 9453/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 359.7541 - val_loss: 796.5930\n",
      "Epoch 9454/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 324.6474 - val_loss: 881.7158\n",
      "Epoch 9455/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 338.5297 - val_loss: 1112.2022\n",
      "Epoch 9456/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 460.5867 - val_loss: 727.3245\n",
      "Epoch 9457/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 386.6740 - val_loss: 768.7197\n",
      "Epoch 9458/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 390.0773 - val_loss: 890.8922\n",
      "Epoch 9459/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 380.6783 - val_loss: 955.9616\n",
      "Epoch 9460/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 382.3940 - val_loss: 940.3118\n",
      "Epoch 9461/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 376.7810 - val_loss: 923.5048\n",
      "Epoch 9462/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 352.0782 - val_loss: 986.0252\n",
      "Epoch 9463/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 326.4126 - val_loss: 771.2873\n",
      "Epoch 9464/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 364.0529 - val_loss: 1476.2388\n",
      "Epoch 9465/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 525.9183 - val_loss: 851.8675\n",
      "Epoch 9466/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 514.0102 - val_loss: 765.2406\n",
      "Epoch 9467/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 428.7711 - val_loss: 796.4504\n",
      "Epoch 9468/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 384.5019 - val_loss: 914.2552\n",
      "Epoch 9469/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 329.3284 - val_loss: 1013.8989\n",
      "Epoch 9470/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 363.3219 - val_loss: 923.5986\n",
      "Epoch 9471/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 584.2580 - val_loss: 948.0405\n",
      "Epoch 9472/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 526.6294 - val_loss: 704.5301\n",
      "Epoch 9473/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 447.9934 - val_loss: 735.1153\n",
      "Epoch 9474/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 406.7086 - val_loss: 728.3012\n",
      "Epoch 9475/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 383.1764 - val_loss: 837.0477\n",
      "Epoch 9476/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 390.1521 - val_loss: 788.8721\n",
      "Epoch 9477/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 473.2456 - val_loss: 1081.9217\n",
      "Epoch 9478/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 384.8807 - val_loss: 960.3337\n",
      "Epoch 9479/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 344.0989 - val_loss: 846.3167\n",
      "Epoch 9480/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 358.8536 - val_loss: 844.7162\n",
      "Epoch 9481/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 345.1520 - val_loss: 660.5057\n",
      "Epoch 9482/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 473.6738 - val_loss: 1062.3807\n",
      "Epoch 9483/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 413.8277 - val_loss: 938.4591\n",
      "Epoch 9484/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 390.6254 - val_loss: 892.8243\n",
      "Epoch 9485/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 484.1552 - val_loss: 991.4479\n",
      "Epoch 9486/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 390.2473 - val_loss: 926.2127\n",
      "Epoch 9487/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 374.9372 - val_loss: 964.8573\n",
      "Epoch 9488/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 364.4180 - val_loss: 913.0880\n",
      "Epoch 9489/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 354.0742 - val_loss: 1182.4078\n",
      "Epoch 9490/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 455.6223 - val_loss: 900.0964\n",
      "Epoch 9491/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 443.2156 - val_loss: 697.3441\n",
      "Epoch 9492/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 389.4121 - val_loss: 793.3621\n",
      "Epoch 9493/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 373.3152 - val_loss: 757.3873\n",
      "Epoch 9494/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 332.9704 - val_loss: 914.8669\n",
      "Epoch 9495/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 312.5604 - val_loss: 880.7579\n",
      "Epoch 9496/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 404.4036 - val_loss: 1138.5653\n",
      "Epoch 9497/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1421.3763 - val_loss: 1321.9022\n",
      "Epoch 9498/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1522.7459 - val_loss: 1241.2380\n",
      "Epoch 9499/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1052.2828 - val_loss: 959.0429\n",
      "Epoch 9500/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 842.4945 - val_loss: 1017.8712\n",
      "Epoch 9501/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 687.9371 - val_loss: 1049.1332\n",
      "Epoch 9502/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 621.8543 - val_loss: 1037.4160\n",
      "Epoch 9503/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 565.8035 - val_loss: 949.9774\n",
      "Epoch 9504/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 511.0006 - val_loss: 849.8434\n",
      "Epoch 9505/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 466.2389 - val_loss: 799.8796\n",
      "Epoch 9506/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 422.7490 - val_loss: 808.7613\n",
      "Epoch 9507/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 394.0279 - val_loss: 809.0223\n",
      "Epoch 9508/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 358.9550 - val_loss: 753.8606\n",
      "Epoch 9509/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 335.3099 - val_loss: 773.1842\n",
      "Epoch 9510/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 315.8280 - val_loss: 839.2214\n",
      "Epoch 9511/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 316.6037 - val_loss: 809.4908\n",
      "Epoch 9512/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 330.0739 - val_loss: 790.4164\n",
      "Epoch 9513/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 328.1764 - val_loss: 881.8342\n",
      "Epoch 9514/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 400.5036 - val_loss: 1090.3254\n",
      "Epoch 9515/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 359.0268 - val_loss: 835.5211\n",
      "Epoch 9516/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 383.0239 - val_loss: 867.6273\n",
      "Epoch 9517/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 521.6911 - val_loss: 958.1617\n",
      "Epoch 9518/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 501.3894 - val_loss: 865.3276\n",
      "Epoch 9519/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 392.3028 - val_loss: 821.1286\n",
      "Epoch 9520/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 348.5792 - val_loss: 941.7467\n",
      "Epoch 9521/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 48us/step - loss: 335.3599 - val_loss: 893.2223\n",
      "Epoch 9522/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.0782 - val_loss: 868.3987\n",
      "Epoch 9523/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 309.7342 - val_loss: 770.2466\n",
      "Epoch 9524/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 316.6120 - val_loss: 979.4729\n",
      "Epoch 9525/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 375.0856 - val_loss: 869.0258\n",
      "Epoch 9526/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 416.1588 - val_loss: 853.3819\n",
      "Epoch 9527/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 444.6462 - val_loss: 956.9412\n",
      "Epoch 9528/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 442.7828 - val_loss: 993.6715\n",
      "Epoch 9529/10000\n",
      "630/630 [==============================] - 0s 46us/step - loss: 497.3378 - val_loss: 1085.1035\n",
      "Epoch 9530/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 421.8962 - val_loss: 863.3235\n",
      "Epoch 9531/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 359.9675 - val_loss: 805.4212\n",
      "Epoch 9532/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 374.3089 - val_loss: 790.9007\n",
      "Epoch 9533/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 398.4020 - val_loss: 713.1527\n",
      "Epoch 9534/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 418.5409 - val_loss: 666.2477\n",
      "Epoch 9535/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 436.6613 - val_loss: 954.8334\n",
      "Epoch 9536/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 370.9135 - val_loss: 842.1099\n",
      "Epoch 9537/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 338.2552 - val_loss: 841.0545\n",
      "Epoch 9538/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 307.2569 - val_loss: 839.9950\n",
      "Epoch 9539/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 317.0760 - val_loss: 699.5729\n",
      "Epoch 9540/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.8886 - val_loss: 755.9899\n",
      "Epoch 9541/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 375.9806 - val_loss: 664.5464\n",
      "Epoch 9542/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.9749 - val_loss: 696.0858\n",
      "Epoch 9543/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 319.5966 - val_loss: 757.5247\n",
      "Epoch 9544/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 310.0356 - val_loss: 719.7986\n",
      "Epoch 9545/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.7600 - val_loss: 697.2203\n",
      "Epoch 9546/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 373.4681 - val_loss: 940.7741\n",
      "Epoch 9547/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 341.4742 - val_loss: 940.9742\n",
      "Epoch 9548/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 335.6365 - val_loss: 767.9456\n",
      "Epoch 9549/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 312.7389 - val_loss: 701.4182\n",
      "Epoch 9550/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 345.5787 - val_loss: 796.8219\n",
      "Epoch 9551/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.5210 - val_loss: 632.6698\n",
      "Epoch 9552/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 1538.8298 - val_loss: 1531.1181\n",
      "Epoch 9553/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 1865.7153 - val_loss: 1563.7008\n",
      "Epoch 9554/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1558.1511 - val_loss: 1325.0478\n",
      "Epoch 9555/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 1255.1057 - val_loss: 1277.7105\n",
      "Epoch 9556/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 1004.9949 - val_loss: 1312.7332\n",
      "Epoch 9557/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 760.6095 - val_loss: 797.2373\n",
      "Epoch 9558/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 625.7916 - val_loss: 922.2950\n",
      "Epoch 9559/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 541.9180 - val_loss: 1151.1769\n",
      "Epoch 9560/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 673.7246 - val_loss: 1686.2050\n",
      "Epoch 9561/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 777.6693 - val_loss: 1391.8869\n",
      "Epoch 9562/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 796.0204 - val_loss: 946.7559\n",
      "Epoch 9563/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 559.5166 - val_loss: 1263.8304\n",
      "Epoch 9564/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 762.4778 - val_loss: 1076.7661\n",
      "Epoch 9565/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 680.9415 - val_loss: 957.0167\n",
      "Epoch 9566/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 880.0055 - val_loss: 1316.3433\n",
      "Epoch 9567/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 629.7414 - val_loss: 1436.2468\n",
      "Epoch 9568/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 711.2648 - val_loss: 836.8299\n",
      "Epoch 9569/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 696.1808 - val_loss: 1497.5118\n",
      "Epoch 9570/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 752.0336 - val_loss: 813.9136\n",
      "Epoch 9571/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 683.9231 - val_loss: 757.0288\n",
      "Epoch 9572/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 512.8089 - val_loss: 1094.3450\n",
      "Epoch 9573/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 542.0907 - val_loss: 992.5465\n",
      "Epoch 9574/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 458.0160 - val_loss: 935.6627\n",
      "Epoch 9575/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 399.8498 - val_loss: 895.4450\n",
      "Epoch 9576/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 588.0426 - val_loss: 950.8916\n",
      "Epoch 9577/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 507.5779 - val_loss: 925.1695\n",
      "Epoch 9578/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 476.3281 - val_loss: 842.2500\n",
      "Epoch 9579/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 596.6170 - val_loss: 924.1759\n",
      "Epoch 9580/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 550.5093 - val_loss: 1175.2723\n",
      "Epoch 9581/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 510.2075 - val_loss: 825.5495\n",
      "Epoch 9582/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 655.3530 - val_loss: 1089.5587\n",
      "Epoch 9583/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 558.6131 - val_loss: 854.2421\n",
      "Epoch 9584/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 420.7274 - val_loss: 908.1261\n",
      "Epoch 9585/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 418.2197 - val_loss: 851.0929\n",
      "Epoch 9586/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 393.2707 - val_loss: 886.6963\n",
      "Epoch 9587/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 374.4607 - val_loss: 862.9348\n",
      "Epoch 9588/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 353.3703 - val_loss: 929.6904\n",
      "Epoch 9589/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 381.1452 - val_loss: 1322.0521\n",
      "Epoch 9590/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 444.4505 - val_loss: 1080.6029\n",
      "Epoch 9591/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 490.5349 - val_loss: 906.8866\n",
      "Epoch 9592/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 473.0566 - val_loss: 939.6027\n",
      "Epoch 9593/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 405.3959 - val_loss: 946.1252\n",
      "Epoch 9594/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 55us/step - loss: 355.3859 - val_loss: 758.0190\n",
      "Epoch 9595/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 363.2987 - val_loss: 776.2162\n",
      "Epoch 9596/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 371.4528 - val_loss: 742.0702\n",
      "Epoch 9597/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 551.2394 - val_loss: 761.2791\n",
      "Epoch 9598/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 577.9407 - val_loss: 783.5288\n",
      "Epoch 9599/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 560.4633 - val_loss: 813.1520\n",
      "Epoch 9600/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 511.9229 - val_loss: 958.7359\n",
      "Epoch 9601/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 475.5075 - val_loss: 794.7819\n",
      "Epoch 9602/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 417.0845 - val_loss: 894.4649\n",
      "Epoch 9603/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 385.1197 - val_loss: 921.1631\n",
      "Epoch 9604/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 363.4980 - val_loss: 854.0377\n",
      "Epoch 9605/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 352.2480 - val_loss: 861.7673\n",
      "Epoch 9606/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.0556 - val_loss: 1011.3562\n",
      "Epoch 9607/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 587.5954 - val_loss: 957.9063\n",
      "Epoch 9608/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 846.8635 - val_loss: 1148.2897\n",
      "Epoch 9609/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 653.8260 - val_loss: 863.8123\n",
      "Epoch 9610/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 458.1285 - val_loss: 870.9182\n",
      "Epoch 9611/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 377.5946 - val_loss: 898.2729\n",
      "Epoch 9612/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 343.5109 - val_loss: 853.8560\n",
      "Epoch 9613/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 385.3001 - val_loss: 840.1507\n",
      "Epoch 9614/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 405.0265 - val_loss: 1012.1642\n",
      "Epoch 9615/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 461.9597 - val_loss: 891.0084\n",
      "Epoch 9616/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 447.4837 - val_loss: 794.1227\n",
      "Epoch 9617/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 397.6913 - val_loss: 753.1819\n",
      "Epoch 9618/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 368.7735 - val_loss: 839.4755\n",
      "Epoch 9619/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 348.1947 - val_loss: 1424.5306\n",
      "Epoch 9620/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 546.8156 - val_loss: 817.7410\n",
      "Epoch 9621/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 595.9468 - val_loss: 909.1743\n",
      "Epoch 9622/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 408.1474 - val_loss: 914.9214\n",
      "Epoch 9623/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 429.6806 - val_loss: 952.1038\n",
      "Epoch 9624/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 435.7643 - val_loss: 825.7285\n",
      "Epoch 9625/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 418.7792 - val_loss: 859.6160\n",
      "Epoch 9626/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 381.4782 - val_loss: 794.5456\n",
      "Epoch 9627/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 359.1336 - val_loss: 883.5849\n",
      "Epoch 9628/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 318.3088 - val_loss: 995.4724\n",
      "Epoch 9629/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 324.7591 - val_loss: 1009.0169\n",
      "Epoch 9630/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 352.9141 - val_loss: 869.6379\n",
      "Epoch 9631/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 572.1683 - val_loss: 866.6641\n",
      "Epoch 9632/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 423.8021 - val_loss: 988.0915\n",
      "Epoch 9633/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 405.0156 - val_loss: 795.0742\n",
      "Epoch 9634/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 366.3281 - val_loss: 844.3306\n",
      "Epoch 9635/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.8427 - val_loss: 924.5840\n",
      "Epoch 9636/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 382.7448 - val_loss: 985.9228\n",
      "Epoch 9637/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 859.2848 - val_loss: 1117.4197\n",
      "Epoch 9638/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 909.6173 - val_loss: 891.6736\n",
      "Epoch 9639/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 660.6202 - val_loss: 865.4744\n",
      "Epoch 9640/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 496.6086 - val_loss: 961.6177\n",
      "Epoch 9641/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 429.5013 - val_loss: 805.5961\n",
      "Epoch 9642/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 397.7820 - val_loss: 778.3601\n",
      "Epoch 9643/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 358.1434 - val_loss: 856.6199\n",
      "Epoch 9644/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 375.8367 - val_loss: 772.5513\n",
      "Epoch 9645/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 383.1963 - val_loss: 694.0112\n",
      "Epoch 9646/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 355.6730 - val_loss: 866.5450\n",
      "Epoch 9647/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 315.0876 - val_loss: 870.7829\n",
      "Epoch 9648/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.1508 - val_loss: 884.0091\n",
      "Epoch 9649/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.7908 - val_loss: 732.1429\n",
      "Epoch 9650/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.7632 - val_loss: 722.7531\n",
      "Epoch 9651/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 333.9288 - val_loss: 895.6490\n",
      "Epoch 9652/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.3261 - val_loss: 858.6850\n",
      "Epoch 9653/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 330.9245 - val_loss: 810.3545\n",
      "Epoch 9654/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 305.4281 - val_loss: 1120.9891\n",
      "Epoch 9655/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 456.8138 - val_loss: 784.9325\n",
      "Epoch 9656/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 440.2621 - val_loss: 794.0636\n",
      "Epoch 9657/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.9516 - val_loss: 778.4303\n",
      "Epoch 9658/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 376.7928 - val_loss: 739.5707\n",
      "Epoch 9659/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 333.2870 - val_loss: 846.9143\n",
      "Epoch 9660/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 323.6114 - val_loss: 746.3199\n",
      "Epoch 9661/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.0926 - val_loss: 813.0613\n",
      "Epoch 9662/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 346.8185 - val_loss: 770.2726\n",
      "Epoch 9663/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 314.3401 - val_loss: 735.5262\n",
      "Epoch 9664/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 356.0521 - val_loss: 814.9010\n",
      "Epoch 9665/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 336.1535 - val_loss: 847.4833\n",
      "Epoch 9666/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.0416 - val_loss: 1187.4846\n",
      "Epoch 9667/10000\n",
      "630/630 [==============================] - ETA: 0s - loss: 455.601 - 0s 48us/step - loss: 418.4640 - val_loss: 896.7596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9668/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 385.6151 - val_loss: 787.7244\n",
      "Epoch 9669/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 404.5602 - val_loss: 709.5596\n",
      "Epoch 9670/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 404.4250 - val_loss: 824.2824\n",
      "Epoch 9671/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 375.0357 - val_loss: 732.1289\n",
      "Epoch 9672/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 343.2504 - val_loss: 828.9341\n",
      "Epoch 9673/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 362.3969 - val_loss: 766.8225\n",
      "Epoch 9674/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.8311 - val_loss: 728.3799\n",
      "Epoch 9675/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 396.7290 - val_loss: 751.5671\n",
      "Epoch 9676/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 417.5681 - val_loss: 1186.1094\n",
      "Epoch 9677/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 396.0338 - val_loss: 956.8176\n",
      "Epoch 9678/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 369.3761 - val_loss: 711.7704\n",
      "Epoch 9679/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 325.0691 - val_loss: 900.9544\n",
      "Epoch 9680/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 337.0681 - val_loss: 798.8595\n",
      "Epoch 9681/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 355.9816 - val_loss: 909.0182\n",
      "Epoch 9682/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 333.4778 - val_loss: 955.3825\n",
      "Epoch 9683/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 318.7186 - val_loss: 789.1663\n",
      "Epoch 9684/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 321.0794 - val_loss: 1102.4831\n",
      "Epoch 9685/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 336.8925 - val_loss: 842.9546\n",
      "Epoch 9686/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 343.8051 - val_loss: 862.2229\n",
      "Epoch 9687/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 442.6799 - val_loss: 638.0254\n",
      "Epoch 9688/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 533.1310 - val_loss: 862.2423\n",
      "Epoch 9689/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 463.1877 - val_loss: 802.1786\n",
      "Epoch 9690/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 430.0607 - val_loss: 936.8760\n",
      "Epoch 9691/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 386.7028 - val_loss: 811.2502\n",
      "Epoch 9692/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 365.8724 - val_loss: 729.4712\n",
      "Epoch 9693/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 351.6509 - val_loss: 820.5519\n",
      "Epoch 9694/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 355.8944 - val_loss: 846.5470\n",
      "Epoch 9695/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 459.0181 - val_loss: 762.5752\n",
      "Epoch 9696/10000\n",
      "630/630 [==============================] - 0s 83us/step - loss: 442.5997 - val_loss: 793.5693\n",
      "Epoch 9697/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 401.9909 - val_loss: 819.6503\n",
      "Epoch 9698/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 371.1800 - val_loss: 865.5667\n",
      "Epoch 9699/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 336.6231 - val_loss: 1282.4449\n",
      "Epoch 9700/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 1051.3374 - val_loss: 1481.0220\n",
      "Epoch 9701/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1387.5362 - val_loss: 1302.7781\n",
      "Epoch 9702/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 1216.5085 - val_loss: 1226.7079\n",
      "Epoch 9703/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1028.2072 - val_loss: 1196.3703\n",
      "Epoch 9704/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 917.1008 - val_loss: 1058.2066\n",
      "Epoch 9705/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 847.5530 - val_loss: 1168.7014\n",
      "Epoch 9706/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 837.2977 - val_loss: 1058.0975\n",
      "Epoch 9707/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 787.6632 - val_loss: 1029.4616\n",
      "Epoch 9708/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 716.3495 - val_loss: 976.4778\n",
      "Epoch 9709/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 693.7220 - val_loss: 1022.3842\n",
      "Epoch 9710/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 678.9813 - val_loss: 1022.9520\n",
      "Epoch 9711/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 626.9472 - val_loss: 953.1597\n",
      "Epoch 9712/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 606.4974 - val_loss: 1034.6494\n",
      "Epoch 9713/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 582.7791 - val_loss: 933.5370\n",
      "Epoch 9714/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 552.8071 - val_loss: 914.6291\n",
      "Epoch 9715/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 520.9260 - val_loss: 899.2144\n",
      "Epoch 9716/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 511.7505 - val_loss: 907.5714\n",
      "Epoch 9717/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 492.2589 - val_loss: 929.1735\n",
      "Epoch 9718/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 462.1543 - val_loss: 850.8629\n",
      "Epoch 9719/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 442.9987 - val_loss: 798.7733\n",
      "Epoch 9720/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 405.6240 - val_loss: 903.4077\n",
      "Epoch 9721/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 389.6916 - val_loss: 913.7035\n",
      "Epoch 9722/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 406.6593 - val_loss: 960.3363\n",
      "Epoch 9723/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 387.1279 - val_loss: 879.2643\n",
      "Epoch 9724/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 379.5367 - val_loss: 1335.8915\n",
      "Epoch 9725/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 478.2266 - val_loss: 899.2638\n",
      "Epoch 9726/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 380.3510 - val_loss: 844.7641\n",
      "Epoch 9727/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 353.7588 - val_loss: 840.9527\n",
      "Epoch 9728/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 510.3139 - val_loss: 936.4096\n",
      "Epoch 9729/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 552.0235 - val_loss: 1028.4033\n",
      "Epoch 9730/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 474.3442 - val_loss: 866.7099\n",
      "Epoch 9731/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 405.3498 - val_loss: 724.3223\n",
      "Epoch 9732/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 356.0090 - val_loss: 910.2493\n",
      "Epoch 9733/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 339.9245 - val_loss: 829.9829\n",
      "Epoch 9734/10000\n",
      "630/630 [==============================] - 0s 77us/step - loss: 341.7611 - val_loss: 869.7792\n",
      "Epoch 9735/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 332.5386 - val_loss: 885.0327\n",
      "Epoch 9736/10000\n",
      "630/630 [==============================] - 0s 81us/step - loss: 402.9764 - val_loss: 962.3470\n",
      "Epoch 9737/10000\n",
      "630/630 [==============================] - 0s 77us/step - loss: 339.3503 - val_loss: 869.3703\n",
      "Epoch 9738/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 331.2890 - val_loss: 964.7374\n",
      "Epoch 9739/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 695.5380 - val_loss: 932.3308\n",
      "Epoch 9740/10000\n",
      "630/630 [==============================] - 0s 75us/step - loss: 776.5338 - val_loss: 1042.2388\n",
      "Epoch 9741/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 59us/step - loss: 583.2055 - val_loss: 916.7485\n",
      "Epoch 9742/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 517.3285 - val_loss: 738.3800\n",
      "Epoch 9743/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 409.4823 - val_loss: 903.4354\n",
      "Epoch 9744/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 373.4082 - val_loss: 987.3288\n",
      "Epoch 9745/10000\n",
      "630/630 [==============================] - 0s 80us/step - loss: 319.5711 - val_loss: 860.1308\n",
      "Epoch 9746/10000\n",
      "630/630 [==============================] - 0s 91us/step - loss: 313.7707 - val_loss: 781.3147\n",
      "Epoch 9747/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 317.0159 - val_loss: 744.7636\n",
      "Epoch 9748/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 319.9325 - val_loss: 709.8873\n",
      "Epoch 9749/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 327.2174 - val_loss: 764.6335\n",
      "Epoch 9750/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 378.8523 - val_loss: 982.9609\n",
      "Epoch 9751/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 359.9622 - val_loss: 1223.0959\n",
      "Epoch 9752/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 426.9006 - val_loss: 686.0353\n",
      "Epoch 9753/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 350.8817 - val_loss: 751.6717\n",
      "Epoch 9754/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 372.5268 - val_loss: 1052.4700\n",
      "Epoch 9755/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 351.7473 - val_loss: 733.9647\n",
      "Epoch 9756/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 337.3469 - val_loss: 891.6784\n",
      "Epoch 9757/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 355.2576 - val_loss: 817.6729\n",
      "Epoch 9758/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 327.5353 - val_loss: 831.3073\n",
      "Epoch 9759/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 344.8802 - val_loss: 809.0127\n",
      "Epoch 9760/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 321.7095 - val_loss: 793.5395\n",
      "Epoch 9761/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 312.4784 - val_loss: 805.1048\n",
      "Epoch 9762/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 331.6131 - val_loss: 1039.7849\n",
      "Epoch 9763/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 359.4960 - val_loss: 834.2633\n",
      "Epoch 9764/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 364.2195 - val_loss: 817.7973\n",
      "Epoch 9765/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 347.3974 - val_loss: 798.8640\n",
      "Epoch 9766/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 349.4422 - val_loss: 856.0463\n",
      "Epoch 9767/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 348.6232 - val_loss: 927.0666\n",
      "Epoch 9768/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.4208 - val_loss: 846.0824\n",
      "Epoch 9769/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 718.8785 - val_loss: 914.8542\n",
      "Epoch 9770/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 1142.8442 - val_loss: 1158.8415\n",
      "Epoch 9771/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 935.8250 - val_loss: 793.5085\n",
      "Epoch 9772/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 772.2761 - val_loss: 1191.0758\n",
      "Epoch 9773/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 659.2806 - val_loss: 1050.4671\n",
      "Epoch 9774/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 558.8493 - val_loss: 740.4371\n",
      "Epoch 9775/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 495.4770 - val_loss: 829.2994\n",
      "Epoch 9776/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 430.5239 - val_loss: 812.3538\n",
      "Epoch 9777/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 397.7295 - val_loss: 819.5241\n",
      "Epoch 9778/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 377.4381 - val_loss: 813.4335\n",
      "Epoch 9779/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 352.4725 - val_loss: 799.3115\n",
      "Epoch 9780/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.7758 - val_loss: 857.5652\n",
      "Epoch 9781/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 298.7133 - val_loss: 944.2563\n",
      "Epoch 9782/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.7219 - val_loss: 961.9737\n",
      "Epoch 9783/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 342.5406 - val_loss: 902.7840\n",
      "Epoch 9784/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 334.8236 - val_loss: 729.2863\n",
      "Epoch 9785/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 327.1043 - val_loss: 1051.9824\n",
      "Epoch 9786/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 471.9478 - val_loss: 784.9947\n",
      "Epoch 9787/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 409.6346 - val_loss: 935.4856\n",
      "Epoch 9788/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 345.7657 - val_loss: 780.3025\n",
      "Epoch 9789/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.7954 - val_loss: 669.9541\n",
      "Epoch 9790/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 368.6028 - val_loss: 1034.0264\n",
      "Epoch 9791/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.6743 - val_loss: 893.8061\n",
      "Epoch 9792/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 343.9133 - val_loss: 935.4349\n",
      "Epoch 9793/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 345.1411 - val_loss: 736.2033\n",
      "Epoch 9794/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 436.5928 - val_loss: 1036.8896\n",
      "Epoch 9795/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 455.6438 - val_loss: 823.1481\n",
      "Epoch 9796/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 407.3883 - val_loss: 711.5337\n",
      "Epoch 9797/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 464.8319 - val_loss: 889.1793\n",
      "Epoch 9798/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 355.9984 - val_loss: 926.4252\n",
      "Epoch 9799/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 328.5412 - val_loss: 1260.6971\n",
      "Epoch 9800/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 590.4145 - val_loss: 646.7093\n",
      "Epoch 9801/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 460.1089 - val_loss: 884.3799\n",
      "Epoch 9802/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 402.9866 - val_loss: 849.0942\n",
      "Epoch 9803/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 337.2438 - val_loss: 912.6688\n",
      "Epoch 9804/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 341.6514 - val_loss: 793.5443\n",
      "Epoch 9805/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 325.0788 - val_loss: 841.8491\n",
      "Epoch 9806/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 398.7176 - val_loss: 996.0077\n",
      "Epoch 9807/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 369.2200 - val_loss: 822.0545\n",
      "Epoch 9808/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 395.0923 - val_loss: 732.3932\n",
      "Epoch 9809/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 329.3054 - val_loss: 768.9439\n",
      "Epoch 9810/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 319.6126 - val_loss: 757.9653\n",
      "Epoch 9811/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 328.5824 - val_loss: 811.2286\n",
      "Epoch 9812/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.9838 - val_loss: 762.9587\n",
      "Epoch 9813/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.3096 - val_loss: 786.3622\n",
      "Epoch 9814/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 314.3459 - val_loss: 786.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9815/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 310.6822 - val_loss: 875.3491\n",
      "Epoch 9816/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 293.2506 - val_loss: 777.1418\n",
      "Epoch 9817/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 279.5268 - val_loss: 798.8634\n",
      "Epoch 9818/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 279.9553 - val_loss: 750.8612\n",
      "Epoch 9819/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 305.0726 - val_loss: 817.4307\n",
      "Epoch 9820/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.1681 - val_loss: 751.4482\n",
      "Epoch 9821/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.6227 - val_loss: 714.2982\n",
      "Epoch 9822/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 324.9245 - val_loss: 868.6970\n",
      "Epoch 9823/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 312.8882 - val_loss: 756.8458\n",
      "Epoch 9824/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 316.3916 - val_loss: 857.7743\n",
      "Epoch 9825/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 328.8899 - val_loss: 968.7078\n",
      "Epoch 9826/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 421.3789 - val_loss: 808.8761\n",
      "Epoch 9827/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 440.6968 - val_loss: 710.9651\n",
      "Epoch 9828/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 376.3840 - val_loss: 769.6150\n",
      "Epoch 9829/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 353.1073 - val_loss: 869.0627\n",
      "Epoch 9830/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 376.2787 - val_loss: 925.0284\n",
      "Epoch 9831/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.9603 - val_loss: 926.7828\n",
      "Epoch 9832/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.9456 - val_loss: 747.7686\n",
      "Epoch 9833/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 351.6588 - val_loss: 761.9068\n",
      "Epoch 9834/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 332.9423 - val_loss: 750.1600\n",
      "Epoch 9835/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 289.0274 - val_loss: 926.7095\n",
      "Epoch 9836/10000\n",
      "630/630 [==============================] - 0s 65us/step - loss: 304.2774 - val_loss: 800.2140\n",
      "Epoch 9837/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 297.4718 - val_loss: 822.2557\n",
      "Epoch 9838/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 292.8921 - val_loss: 957.2740\n",
      "Epoch 9839/10000\n",
      "630/630 [==============================] - 0s 47us/step - loss: 349.4722 - val_loss: 808.1771\n",
      "Epoch 9840/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 330.6589 - val_loss: 818.3903\n",
      "Epoch 9841/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 326.4031 - val_loss: 863.7130\n",
      "Epoch 9842/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 321.8199 - val_loss: 849.1162\n",
      "Epoch 9843/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 318.8187 - val_loss: 778.3372\n",
      "Epoch 9844/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 378.1299 - val_loss: 697.6866\n",
      "Epoch 9845/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 373.0270 - val_loss: 726.5931\n",
      "Epoch 9846/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 355.4481 - val_loss: 863.1603\n",
      "Epoch 9847/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 337.4934 - val_loss: 992.6459\n",
      "Epoch 9848/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 312.0178 - val_loss: 997.2129\n",
      "Epoch 9849/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 397.7457 - val_loss: 776.7744\n",
      "Epoch 9850/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 379.0190 - val_loss: 997.2443\n",
      "Epoch 9851/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 338.0230 - val_loss: 898.9223\n",
      "Epoch 9852/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 379.9027 - val_loss: 853.5510\n",
      "Epoch 9853/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 616.3844 - val_loss: 1477.1798\n",
      "Epoch 9854/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 1158.5324 - val_loss: 1365.3937\n",
      "Epoch 9855/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 901.5711 - val_loss: 1225.6975\n",
      "Epoch 9856/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 739.9043 - val_loss: 1442.6042\n",
      "Epoch 9857/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 708.2013 - val_loss: 1338.0906\n",
      "Epoch 9858/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 908.6948 - val_loss: 964.5764\n",
      "Epoch 9859/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 586.0982 - val_loss: 1127.0895\n",
      "Epoch 9860/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 557.3688 - val_loss: 718.9242\n",
      "Epoch 9861/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 455.7185 - val_loss: 921.9300\n",
      "Epoch 9862/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 410.7680 - val_loss: 885.4154\n",
      "Epoch 9863/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 363.2406 - val_loss: 932.8384\n",
      "Epoch 9864/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 336.2229 - val_loss: 971.5662\n",
      "Epoch 9865/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 345.6364 - val_loss: 875.3518\n",
      "Epoch 9866/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 365.0950 - val_loss: 848.9552\n",
      "Epoch 9867/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.7323 - val_loss: 726.7910\n",
      "Epoch 9868/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 335.7951 - val_loss: 814.4691\n",
      "Epoch 9869/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 305.8427 - val_loss: 742.8941\n",
      "Epoch 9870/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 376.1576 - val_loss: 734.2193\n",
      "Epoch 9871/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 400.3068 - val_loss: 707.6603\n",
      "Epoch 9872/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 381.0051 - val_loss: 917.1115\n",
      "Epoch 9873/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 364.6480 - val_loss: 903.2938\n",
      "Epoch 9874/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 327.3708 - val_loss: 942.1838\n",
      "Epoch 9875/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 290.3572 - val_loss: 949.6418\n",
      "Epoch 9876/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 367.3138 - val_loss: 786.7773\n",
      "Epoch 9877/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 352.4757 - val_loss: 781.6446\n",
      "Epoch 9878/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 351.3557 - val_loss: 817.6273\n",
      "Epoch 9879/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 314.0945 - val_loss: 799.3333\n",
      "Epoch 9880/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 370.4249 - val_loss: 856.0836\n",
      "Epoch 9881/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 529.0396 - val_loss: 915.7824\n",
      "Epoch 9882/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 584.6904 - val_loss: 989.2223\n",
      "Epoch 9883/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 553.1648 - val_loss: 857.6556\n",
      "Epoch 9884/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 513.3540 - val_loss: 880.6639\n",
      "Epoch 9885/10000\n",
      "630/630 [==============================] - 0s 56us/step - loss: 463.4757 - val_loss: 912.9707\n",
      "Epoch 9886/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 441.6745 - val_loss: 848.8164\n",
      "Epoch 9887/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 423.7201 - val_loss: 935.5062\n",
      "Epoch 9888/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 51us/step - loss: 396.4429 - val_loss: 882.8817\n",
      "Epoch 9889/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 362.6777 - val_loss: 978.3989\n",
      "Epoch 9890/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 342.8509 - val_loss: 1100.9699\n",
      "Epoch 9891/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.9393 - val_loss: 1135.1287\n",
      "Epoch 9892/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 564.5573 - val_loss: 778.0309\n",
      "Epoch 9893/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 514.0299 - val_loss: 753.5161\n",
      "Epoch 9894/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 446.1260 - val_loss: 808.4888\n",
      "Epoch 9895/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 379.3728 - val_loss: 846.7577\n",
      "Epoch 9896/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 344.3518 - val_loss: 924.1643\n",
      "Epoch 9897/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 319.4967 - val_loss: 786.8521\n",
      "Epoch 9898/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 333.5268 - val_loss: 815.7177\n",
      "Epoch 9899/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 309.1902 - val_loss: 819.7215\n",
      "Epoch 9900/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 376.1691 - val_loss: 663.1859\n",
      "Epoch 9901/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 437.2631 - val_loss: 746.7602\n",
      "Epoch 9902/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 369.5617 - val_loss: 1164.5012\n",
      "Epoch 9903/10000\n",
      "630/630 [==============================] - 0s 68us/step - loss: 420.7618 - val_loss: 1325.9232\n",
      "Epoch 9904/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 682.1932 - val_loss: 720.7345\n",
      "Epoch 9905/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 547.7499 - val_loss: 930.1085\n",
      "Epoch 9906/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 456.5818 - val_loss: 988.3316\n",
      "Epoch 9907/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 384.3310 - val_loss: 814.7699\n",
      "Epoch 9908/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 335.6289 - val_loss: 757.7117\n",
      "Epoch 9909/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 339.4957 - val_loss: 927.6070\n",
      "Epoch 9910/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 323.7489 - val_loss: 925.7979\n",
      "Epoch 9911/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 325.8954 - val_loss: 1072.4251\n",
      "Epoch 9912/10000\n",
      "630/630 [==============================] - 0s 76us/step - loss: 327.7768 - val_loss: 978.8426\n",
      "Epoch 9913/10000\n",
      "630/630 [==============================] - 0s 57us/step - loss: 367.8415 - val_loss: 806.4577\n",
      "Epoch 9914/10000\n",
      "630/630 [==============================] - 0s 60us/step - loss: 344.5224 - val_loss: 822.2811\n",
      "Epoch 9915/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 369.6657 - val_loss: 758.4658\n",
      "Epoch 9916/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 365.1285 - val_loss: 1050.9622\n",
      "Epoch 9917/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 389.9329 - val_loss: 838.3115\n",
      "Epoch 9918/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 365.1251 - val_loss: 835.7575\n",
      "Epoch 9919/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 319.6923 - val_loss: 818.0324\n",
      "Epoch 9920/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 325.3667 - val_loss: 766.5116\n",
      "Epoch 9921/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 356.5349 - val_loss: 800.5439\n",
      "Epoch 9922/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 349.3651 - val_loss: 808.6127\n",
      "Epoch 9923/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.1337 - val_loss: 800.8499\n",
      "Epoch 9924/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 312.0366 - val_loss: 961.4455\n",
      "Epoch 9925/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 335.4500 - val_loss: 760.5197\n",
      "Epoch 9926/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 361.5147 - val_loss: 815.0201\n",
      "Epoch 9927/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 357.0884 - val_loss: 790.5494\n",
      "Epoch 9928/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 334.8198 - val_loss: 828.6447\n",
      "Epoch 9929/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 308.9094 - val_loss: 847.6483\n",
      "Epoch 9930/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 295.8589 - val_loss: 829.2033\n",
      "Epoch 9931/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 348.2552 - val_loss: 800.2473\n",
      "Epoch 9932/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 361.0093 - val_loss: 757.1722\n",
      "Epoch 9933/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 329.6634 - val_loss: 763.2002\n",
      "Epoch 9934/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 300.9593 - val_loss: 834.0560\n",
      "Epoch 9935/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 306.8419 - val_loss: 739.4192\n",
      "Epoch 9936/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 592.4035 - val_loss: 1226.8753\n",
      "Epoch 9937/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 733.4139 - val_loss: 1225.3748\n",
      "Epoch 9938/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 609.3079 - val_loss: 1257.9654\n",
      "Epoch 9939/10000\n",
      "630/630 [==============================] - 0s 61us/step - loss: 552.4647 - val_loss: 1184.5917\n",
      "Epoch 9940/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 515.8950 - val_loss: 1163.0021\n",
      "Epoch 9941/10000\n",
      "630/630 [==============================] - 0s 66us/step - loss: 497.3869 - val_loss: 1149.4721\n",
      "Epoch 9942/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 522.0039 - val_loss: 1065.8389\n",
      "Epoch 9943/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 537.6917 - val_loss: 1033.5674\n",
      "Epoch 9944/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 530.8650 - val_loss: 762.6706\n",
      "Epoch 9945/10000\n",
      "630/630 [==============================] - 0s 59us/step - loss: 391.9181 - val_loss: 1138.3721\n",
      "Epoch 9946/10000\n",
      "630/630 [==============================] - 0s 69us/step - loss: 407.0185 - val_loss: 777.1179\n",
      "Epoch 9947/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 355.9138 - val_loss: 785.9480\n",
      "Epoch 9948/10000\n",
      "630/630 [==============================] - 0s 71us/step - loss: 341.2992 - val_loss: 798.6319\n",
      "Epoch 9949/10000\n",
      "630/630 [==============================] - 0s 76us/step - loss: 358.6638 - val_loss: 777.5811\n",
      "Epoch 9950/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 345.9705 - val_loss: 795.9359\n",
      "Epoch 9951/10000\n",
      "630/630 [==============================] - 0s 70us/step - loss: 325.1162 - val_loss: 795.4913\n",
      "Epoch 9952/10000\n",
      "630/630 [==============================] - 0s 82us/step - loss: 321.3763 - val_loss: 881.2412\n",
      "Epoch 9953/10000\n",
      "630/630 [==============================] - 0s 174us/step - loss: 319.9571 - val_loss: 785.2883\n",
      "Epoch 9954/10000\n",
      "630/630 [==============================] - 0s 135us/step - loss: 324.6490 - val_loss: 801.0893\n",
      "Epoch 9955/10000\n",
      "630/630 [==============================] - 0s 133us/step - loss: 321.6495 - val_loss: 809.2367\n",
      "Epoch 9956/10000\n",
      "630/630 [==============================] - 0s 118us/step - loss: 372.1518 - val_loss: 803.1331\n",
      "Epoch 9957/10000\n",
      "630/630 [==============================] - 0s 75us/step - loss: 381.2424 - val_loss: 817.9149\n",
      "Epoch 9958/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 342.5608 - val_loss: 727.2544\n",
      "Epoch 9959/10000\n",
      "630/630 [==============================] - 0s 90us/step - loss: 350.5510 - val_loss: 689.4076\n",
      "Epoch 9960/10000\n",
      "630/630 [==============================] - 0s 78us/step - loss: 357.3472 - val_loss: 744.2338\n",
      "Epoch 9961/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 367.5188 - val_loss: 981.5333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9962/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 386.0467 - val_loss: 871.4839\n",
      "Epoch 9963/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 391.2216 - val_loss: 848.9104\n",
      "Epoch 9964/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 377.5875 - val_loss: 757.5765\n",
      "Epoch 9965/10000\n",
      "630/630 [==============================] - 0s 52us/step - loss: 326.7313 - val_loss: 873.8065\n",
      "Epoch 9966/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 315.4755 - val_loss: 1075.5068\n",
      "Epoch 9967/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 367.2619 - val_loss: 719.1326\n",
      "Epoch 9968/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 330.3705 - val_loss: 669.3884\n",
      "Epoch 9969/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 333.6178 - val_loss: 748.0310\n",
      "Epoch 9970/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 311.3287 - val_loss: 925.8353\n",
      "Epoch 9971/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 308.8078 - val_loss: 939.0350\n",
      "Epoch 9972/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 323.5563 - val_loss: 842.3408\n",
      "Epoch 9973/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 330.1056 - val_loss: 809.5727\n",
      "Epoch 9974/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 296.0495 - val_loss: 833.2339\n",
      "Epoch 9975/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 299.6518 - val_loss: 953.3731\n",
      "Epoch 9976/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 329.1735 - val_loss: 799.7577\n",
      "Epoch 9977/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 345.7204 - val_loss: 727.6313\n",
      "Epoch 9978/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.0143 - val_loss: 780.1863\n",
      "Epoch 9979/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 369.4692 - val_loss: 877.7890\n",
      "Epoch 9980/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 574.6864 - val_loss: 904.2206\n",
      "Epoch 9981/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 603.6045 - val_loss: 915.5471\n",
      "Epoch 9982/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 544.6959 - val_loss: 856.9390\n",
      "Epoch 9983/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 471.4183 - val_loss: 962.5550\n",
      "Epoch 9984/10000\n",
      "630/630 [==============================] - 0s 48us/step - loss: 424.9154 - val_loss: 927.6399\n",
      "Epoch 9985/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 388.6668 - val_loss: 939.2931\n",
      "Epoch 9986/10000\n",
      "630/630 [==============================] - 0s 50us/step - loss: 355.1956 - val_loss: 912.9339\n",
      "Epoch 9987/10000\n",
      "630/630 [==============================] - 0s 62us/step - loss: 318.3808 - val_loss: 932.8416\n",
      "Epoch 9988/10000\n",
      "630/630 [==============================] - 0s 89us/step - loss: 310.5274 - val_loss: 1122.7596\n",
      "Epoch 9989/10000\n",
      "630/630 [==============================] - 0s 63us/step - loss: 485.2703 - val_loss: 719.0970\n",
      "Epoch 9990/10000\n",
      "630/630 [==============================] - 0s 67us/step - loss: 432.2947 - val_loss: 729.2355\n",
      "Epoch 9991/10000\n",
      "630/630 [==============================] - 0s 64us/step - loss: 389.1803 - val_loss: 826.3828\n",
      "Epoch 9992/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 354.2585 - val_loss: 872.4547\n",
      "Epoch 9993/10000\n",
      "630/630 [==============================] - 0s 58us/step - loss: 350.3913 - val_loss: 1009.4200\n",
      "Epoch 9994/10000\n",
      "630/630 [==============================] - 0s 53us/step - loss: 349.2087 - val_loss: 918.1096\n",
      "Epoch 9995/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 340.8900 - val_loss: 775.8643\n",
      "Epoch 9996/10000\n",
      "630/630 [==============================] - 0s 54us/step - loss: 335.4651 - val_loss: 752.5756\n",
      "Epoch 9997/10000\n",
      "630/630 [==============================] - 0s 49us/step - loss: 344.2482 - val_loss: 756.9511\n",
      "Epoch 9998/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 314.7335 - val_loss: 780.6605\n",
      "Epoch 9999/10000\n",
      "630/630 [==============================] - 0s 51us/step - loss: 325.0367 - val_loss: 760.8411\n",
      "Epoch 10000/10000\n",
      "630/630 [==============================] - 0s 55us/step - loss: 322.4043 - val_loss: 723.5756\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_26 (InputLayer)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "LR (Dense)                   (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 200)               4200      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 26,561\n",
      "Trainable params: 26,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2827db64ef0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 51us/step\n",
      "593.719267927\n"
     ]
    }
   ],
   "source": [
    "history2 = LossHistory()\n",
    "#采用编码层的网络结构，从新构成一个新的model，此model的参数跟原来autoencode的训练的参数一样。\n",
    "out=Dense(200,activation='relu',activity_regularizer=regularizers.l1(0.01))(LR)\n",
    "out=Dense(100,activation='sigmoid',activity_regularizer=regularizers.l1(0.01))(out)\n",
    "out=Dense(20,activation='sigmoid',activity_regularizer=regularizers.l1(0.01))(out)\n",
    "out=Dense(1,activation='relu',activity_regularizer=regularizers.l1(0.01))(out)\n",
    "encoder=Model(inputs=input_img,outputs=out)\n",
    "encoder.compile(optimizer='adam',loss='mse')\n",
    "encoder.fit(X_train,y_train,epochs=10000,batch_size=100,validation_data=(X_test,y_test),shuffle=True,callbacks=[history2])\n",
    "#score=encoder.evaluate(X_test,y_test)\n",
    "#print(score)\n",
    "print(encoder.summary())\n",
    "history2.loss_plot('epoch')\n",
    "encoder.save('SAE-DNN.model')\n",
    "score=encoder.evaluate(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  32.22555542]\n",
      " [  38.35845566]\n",
      " [  45.40709686]\n",
      " [  50.43118286]\n",
      " [  50.53714752]\n",
      " [  53.5536232 ]\n",
      " [  51.11518478]\n",
      " [  52.40714264]\n",
      " [  60.7324028 ]\n",
      " [  62.04600143]\n",
      " [  61.29403687]\n",
      " [  61.12532425]\n",
      " [  53.70541   ]\n",
      " [  55.92053604]\n",
      " [  56.04697037]\n",
      " [  57.55313873]\n",
      " [  58.57022095]\n",
      " [  59.18490982]\n",
      " [  54.03082657]\n",
      " [  55.07949448]\n",
      " [  68.26917267]\n",
      " [  68.31056976]\n",
      " [  70.71308136]\n",
      " [  70.28076935]\n",
      " [  71.1314621 ]\n",
      " [  73.20974731]\n",
      " [  71.47983551]\n",
      " [  73.47168732]\n",
      " [  74.53856659]\n",
      " [  74.10269165]\n",
      " [  67.75262451]\n",
      " [  67.91387177]\n",
      " [  74.39043427]\n",
      " [  76.26861572]\n",
      " [  75.5817337 ]\n",
      " [  76.35897827]\n",
      " [  76.98412323]\n",
      " [  77.84152985]\n",
      " [  78.52856445]\n",
      " [  78.42034912]\n",
      " [  79.2738266 ]\n",
      " [  80.04985046]\n",
      " [  80.25201416]\n",
      " [  80.67403412]\n",
      " [  81.38587952]\n",
      " [  82.29178619]\n",
      " [  74.09727478]\n",
      " [  81.69068909]\n",
      " [  82.22266388]\n",
      " [  82.12815857]\n",
      " [  83.14366913]\n",
      " [  83.78153992]\n",
      " [  83.51831818]\n",
      " [  83.46974945]\n",
      " [  83.99106598]\n",
      " [  84.1677475 ]\n",
      " [  84.63144684]\n",
      " [  73.63130188]\n",
      " [  84.38613892]\n",
      " [  84.96038055]\n",
      " [  84.92088318]\n",
      " [  85.25919342]\n",
      " [  85.3261261 ]\n",
      " [  85.88549805]\n",
      " [  84.92430878]\n",
      " [  85.38253784]\n",
      " [  85.64109802]\n",
      " [  85.87699127]\n",
      " [  86.11180878]\n",
      " [  86.49856567]\n",
      " [  86.90201569]\n",
      " [  86.95806122]\n",
      " [  86.98351288]\n",
      " [  87.37950134]\n",
      " [  87.76332855]\n",
      " [  85.36504364]\n",
      " [  87.59838104]\n",
      " [  87.8180542 ]\n",
      " [  88.21291351]\n",
      " [  88.26544189]\n",
      " [  88.11070251]\n",
      " [  88.08133698]\n",
      " [  88.58100891]\n",
      " [  88.92435455]\n",
      " [  89.09561157]\n",
      " [  89.30831146]\n",
      " [  85.42552948]\n",
      " [  89.80368042]\n",
      " [  89.89151764]\n",
      " [  90.37021637]\n",
      " [  89.8348465 ]\n",
      " [  90.17661285]\n",
      " [  90.82161713]\n",
      " [  91.42263031]\n",
      " [  91.77778625]\n",
      " [  92.27851868]\n",
      " [  90.19631958]\n",
      " [  90.998703  ]\n",
      " [  91.15871429]\n",
      " [  91.70187378]\n",
      " [  91.77042389]\n",
      " [  92.50487518]\n",
      " [  93.01151276]\n",
      " [  93.27231598]\n",
      " [  93.79708099]\n",
      " [  95.00009918]\n",
      " [  95.99277496]\n",
      " [  90.32183838]\n",
      " [  95.4782486 ]\n",
      " [  95.25700378]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  90.01924133]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.13020325]\n",
      " [  97.55517578]\n",
      " [  97.6979599 ]\n",
      " [  97.78285217]\n",
      " [  97.46125793]\n",
      " [  97.72718048]\n",
      " [  97.13020325]\n",
      " [  98.01447296]\n",
      " [  97.81674957]\n",
      " [  98.2206192 ]\n",
      " [  98.50228882]\n",
      " [  99.04161072]\n",
      " [  99.04811859]\n",
      " [  99.34944916]\n",
      " [  99.20822906]\n",
      " [  99.53149414]\n",
      " [  99.46387482]\n",
      " [  97.7727356 ]\n",
      " [  99.83766937]\n",
      " [ 100.33623505]\n",
      " [ 100.6979599 ]\n",
      " [ 101.05834198]\n",
      " [ 100.98066711]\n",
      " [ 101.18855286]\n",
      " [ 101.50402832]\n",
      " [ 101.33833313]\n",
      " [ 101.45178223]\n",
      " [  97.92631531]\n",
      " [ 101.45558167]\n",
      " [ 101.72306824]\n",
      " [ 102.21948242]\n",
      " [ 102.11506653]\n",
      " [ 102.39836121]\n",
      " [ 102.79634094]\n",
      " [ 102.99146271]\n",
      " [ 103.34710693]\n",
      " [ 103.83992004]\n",
      " [ 104.09825134]\n",
      " [ 101.93862152]\n",
      " [ 104.46201324]\n",
      " [ 104.75413513]\n",
      " [ 104.67050171]\n",
      " [ 104.51921082]\n",
      " [ 104.87989807]\n",
      " [ 104.7232666 ]\n",
      " [ 105.08702087]\n",
      " [ 104.95171356]\n",
      " [ 105.47564697]\n",
      " [ 105.76544952]\n",
      " [ 103.68283081]\n",
      " [ 105.87094879]\n",
      " [ 105.87525177]\n",
      " [ 106.15434265]\n",
      " [ 106.12320709]\n",
      " [ 106.30250549]\n",
      " [ 106.77455139]\n",
      " [ 106.96815491]\n",
      " [ 107.01843262]\n",
      " [ 107.31748962]\n",
      " [ 107.38755035]\n",
      " [ 104.18849945]\n",
      " [ 107.49279785]\n",
      " [ 107.83538818]\n",
      " [ 108.01023865]\n",
      " [ 108.16377258]\n",
      " [ 108.28079987]\n",
      " [ 108.58751678]\n",
      " [ 108.91879272]\n",
      " [ 109.20545959]\n",
      " [ 109.22463989]\n",
      " [ 107.60506439]\n",
      " [ 108.14104462]\n",
      " [ 108.16527557]\n",
      " [ 108.37760162]\n",
      " [ 108.57930756]\n",
      " [ 108.57002258]\n",
      " [ 108.48558807]\n",
      " [ 108.67156982]\n",
      " [ 108.8518219 ]\n",
      " [ 108.8578949 ]\n",
      " [ 108.88778687]\n",
      " [ 107.94855499]\n",
      " [ 109.09324646]\n",
      " [ 108.98230743]\n",
      " [ 109.02433014]\n",
      " [ 109.33776093]\n",
      " [ 109.25230408]\n",
      " [ 109.15808105]\n",
      " [ 109.22867584]\n",
      " [ 109.39720154]\n",
      " [ 109.52813721]\n",
      " [ 109.36569214]\n",
      " [ 108.06820679]\n",
      " [ 109.59561157]\n",
      " [ 109.55601501]\n",
      " [ 109.55967712]\n",
      " [ 109.6290741 ]\n",
      " [ 109.56352997]\n",
      " [ 109.76145935]\n",
      " [ 109.82876587]\n",
      " [ 109.98873901]\n",
      " [ 110.04142761]\n",
      " [ 108.94052124]\n",
      " [ 109.48122406]\n",
      " [ 109.28645325]\n",
      " [ 110.44512177]\n",
      " [ 111.05696106]\n",
      " [ 113.21698761]\n",
      " [ 112.96878052]\n",
      " [ 114.02218628]\n",
      " [ 115.76778412]\n",
      " [ 122.88565826]\n",
      " [ 123.88023376]\n",
      " [ 109.11026001]\n",
      " [ 125.52164459]\n",
      " [ 125.57727051]\n",
      " [ 127.29743958]\n",
      " [ 128.32992554]\n",
      " [ 128.26693726]\n",
      " [ 130.45515442]\n",
      " [ 131.45236206]\n",
      " [ 131.58821106]\n",
      " [ 131.95732117]\n",
      " [ 109.22694397]\n",
      " [ 132.70941162]\n",
      " [ 133.56329346]\n",
      " [ 133.94839478]\n",
      " [ 134.74749756]\n",
      " [ 135.25964355]\n",
      " [ 135.86682129]\n",
      " [ 137.0541687 ]\n",
      " [ 137.92248535]\n",
      " [ 138.27770996]\n",
      " [ 139.05476379]\n",
      " [ 140.4251709 ]\n",
      " [ 140.03987122]\n",
      " [ 141.71359253]\n",
      " [ 143.41700745]\n",
      " [ 143.17205811]\n",
      " [ 144.88891602]\n",
      " [ 147.08163452]\n",
      " [ 151.58390808]\n",
      " [ 152.37071228]\n",
      " [ 153.0377655 ]\n",
      " [ 154.48590088]\n",
      " [ 140.29776001]\n",
      " [ 159.10966492]\n",
      " [ 161.30311584]\n",
      " [ 161.66424561]\n",
      " [ 164.39828491]\n",
      " [ 164.66133118]\n",
      " [ 165.18965149]\n",
      " [ 166.15875244]\n",
      " [ 166.46333313]\n",
      " [ 167.98876953]\n",
      " [ 167.94035339]\n",
      " [ 139.72874451]\n",
      " [ 168.18722534]\n",
      " [ 168.68835449]\n",
      " [ 170.84840393]\n",
      " [ 169.93913269]\n",
      " [ 171.20379639]\n",
      " [ 172.93721008]\n",
      " [ 179.46316528]\n",
      " [ 181.11151123]\n",
      " [ 181.85144043]\n",
      " [ 172.99319458]\n",
      " [ 177.71302795]\n",
      " [ 177.88699341]\n",
      " [ 179.36592102]\n",
      " [ 179.81845093]\n",
      " [ 181.42297363]\n",
      " [ 181.78848267]\n",
      " [ 181.77708435]\n",
      " [ 181.85284424]\n",
      " [ 181.85333252]\n",
      " [ 181.47642517]\n",
      " [ 177.11885071]\n",
      " [ 181.4683075 ]\n",
      " [ 180.24389648]\n",
      " [ 181.05921936]\n",
      " [ 180.76289368]\n",
      " [ 181.48860168]\n",
      " [ 180.94108582]\n",
      " [ 181.74940491]\n",
      " [ 181.30055237]\n",
      " [ 181.72067261]\n",
      " [ 181.77073669]\n",
      " [ 176.14001465]\n",
      " [ 181.58790588]\n",
      " [ 181.7389679 ]\n",
      " [ 181.8493042 ]\n",
      " [ 179.36437988]]\n"
     ]
    }
   ],
   "source": [
    "model=keras.models.load_model('SAE-DNN.model')\n",
    "pred=model.predict(X_test)\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
