{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(315, 10) (315, 10) (315, 10) (315,) (315,) (315,)\n",
      "(630, 10)\n",
      "(630,)\n",
      "(315, 10)\n",
      "(315,)\n",
      "(630, 10) (315, 10)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "import struct\n",
    "np.random.seed(2018)\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense,Input\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import regularizers\n",
    "import keras\n",
    "%matplotlib inline\n",
    "xfile1=\".\\\\data\\\\C1_feature_denoise.csv\"\n",
    "yfile1=\".\\\\data\\\\c1_wear_new.csv\"\n",
    "\n",
    "xfile2=\".\\\\data\\\\C4_feature_denoise.csv\"\n",
    "yfile2=\".\\\\data\\\\c4_wear_new.csv\"\n",
    "\n",
    "xfile3=\".\\\\data\\\\C6_feature_denoise.csv\"\n",
    "yfile3=\".\\\\data\\\\c6_wear_new.csv\"\n",
    "\n",
    "\n",
    "x1=pandas.read_csv(xfile1).values;\n",
    "x2=pandas.read_csv(xfile2).values;\n",
    "x3=pandas.read_csv(xfile3).values;\n",
    "y1=pandas.read_csv(yfile1).values[:,-1];\n",
    "y2=pandas.read_csv(yfile2).values[:,-1];\n",
    "y3=pandas.read_csv(yfile3).values[:,4];\n",
    "\n",
    "print(x1.shape,x2.shape,x3.shape,y1.shape,y2.shape,y3.shape);\n",
    "X_train=np.vstack((x1,x2))\n",
    "y_train=np.hstack((y1,y2))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "X_test=x3;\n",
    "y_test=y3;\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "X_train=X_train.astype('float32')/255-0.5 # minmax_normalized(归一化在（-0.5,0.5）)之间\n",
    "X_test=X_test.astype('float32')/255-0.5 # minmax_normalized\n",
    "X_train_len=X_train.shape[0]\n",
    "X_test_len=X_test.shape[0]\n",
    "\n",
    "X_train=X_train.reshape((X_train_len,-1))\n",
    "X_test=X_test.reshape((X_test_len,-1))\n",
    "\n",
    "print(X_train.shape,X_test.shape)\n",
    "\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch': [], 'epoch': []}\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        #创建一个图\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')#plt.plot(x,y)，这个将数据画成曲线\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)#设置网格形式\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')#给x，y轴加注释\n",
    "        plt.legend(loc=\"upper right\")#设置图例显示位置\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "630/630 [==============================] - 1s 977us/step - loss: 1532291200.0000\n",
      "Epoch 2/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1507913984.0000\n",
      "Epoch 3/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1480160768.0000\n",
      "Epoch 4/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1451186944.0000\n",
      "Epoch 5/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1421764864.0000\n",
      "Epoch 6/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1392262400.0000\n",
      "Epoch 7/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1362882816.0000\n",
      "Epoch 8/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1333749760.0000\n",
      "Epoch 9/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1304940032.0000\n",
      "Epoch 10/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1276503168.0000\n",
      "Epoch 11/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1248471040.0000\n",
      "Epoch 12/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1220863872.0000\n",
      "Epoch 13/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1193694336.0000\n",
      "Epoch 14/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1166970496.0000\n",
      "Epoch 15/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1140698880.0000\n",
      "Epoch 16/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 1114883584.0000\n",
      "Epoch 17/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1089528704.0000\n",
      "Epoch 18/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1064636800.0000\n",
      "Epoch 19/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1040210240.0000\n",
      "Epoch 20/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1016250560.0000\n",
      "Epoch 21/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 992758336.0000\n",
      "Epoch 22/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 969732992.0000\n",
      "Epoch 23/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 947173248.0000\n",
      "Epoch 24/3000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 925076672.0000\n",
      "Epoch 25/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 903439808.0000\n",
      "Epoch 26/3000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 882258880.0000\n",
      "Epoch 27/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 861528512.0000\n",
      "Epoch 28/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 841243328.0000\n",
      "Epoch 29/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 821397184.0000\n",
      "Epoch 30/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801982976.0000\n",
      "Epoch 31/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782994048.0000\n",
      "Epoch 32/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 764422720.0000\n",
      "Epoch 33/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 746261632.0000\n",
      "Epoch 34/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 728503104.0000\n",
      "Epoch 35/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 711139328.0000\n",
      "Epoch 36/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 694162688.0000\n",
      "Epoch 37/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 677565376.0000\n",
      "Epoch 38/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 661339712.0000\n",
      "Epoch 39/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 645477632.0000\n",
      "Epoch 40/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 629971584.0000\n",
      "Epoch 41/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 614813504.0000\n",
      "Epoch 42/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 599995328.0000\n",
      "Epoch 43/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 585509056.0000\n",
      "Epoch 44/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 571346688.0000\n",
      "Epoch 45/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 557500032.0000\n",
      "Epoch 46/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 543961408.0000\n",
      "Epoch 47/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 530722432.0000\n",
      "Epoch 48/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 517775808.0000\n",
      "Epoch 49/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 505113472.0000\n",
      "Epoch 50/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 492728480.0000\n",
      "Epoch 51/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 480613216.0000\n",
      "Epoch 52/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 468760864.0000\n",
      "Epoch 53/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 457164672.0000\n",
      "Epoch 54/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 445817952.0000\n",
      "Epoch 55/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 434714432.0000\n",
      "Epoch 56/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 423847808.0000\n",
      "Epoch 57/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 413212192.0000\n",
      "Epoch 58/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 402801472.0000\n",
      "Epoch 59/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 392610208.0000\n",
      "Epoch 60/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 382632832.0000\n",
      "Epoch 61/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 372864064.0000\n",
      "Epoch 62/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 363298752.0000\n",
      "Epoch 63/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 353932160.0000\n",
      "Epoch 64/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 344759488.0000\n",
      "Epoch 65/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 335776416.0000\n",
      "Epoch 66/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 326978592.0000\n",
      "Epoch 67/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 318361888.0000\n",
      "Epoch 68/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 309922368.0000\n",
      "Epoch 69/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 301656320.0000\n",
      "Epoch 70/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 293560032.0000\n",
      "Epoch 71/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 285630368.0000\n",
      "Epoch 72/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 277863808.0000\n",
      "Epoch 73/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 270257312.0000\n",
      "Epoch 74/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 262807872.0000\n",
      "Epoch 75/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 255512560.0000\n",
      "Epoch 76/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 248368656.0000\n",
      "Epoch 77/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 241373456.0000\n",
      "Epoch 78/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 234524464.0000\n",
      "Epoch 79/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 227819216.0000\n",
      "Epoch 80/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 221255424.0000\n",
      "Epoch 81/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 214830736.0000\n",
      "Epoch 82/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 208543152.0000\n",
      "Epoch 83/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 202390464.0000\n",
      "Epoch 84/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 196370736.0000\n",
      "Epoch 85/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 190481920.0000\n",
      "Epoch 86/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 184722176.0000\n",
      "Epoch 87/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 179089584.0000\n",
      "Epoch 88/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 173582352.0000\n",
      "Epoch 89/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 168198752.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 162937040.0000\n",
      "Epoch 91/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 157795568.0000\n",
      "Epoch 92/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 152772688.0000\n",
      "Epoch 93/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 147866816.0000\n",
      "Epoch 94/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 143076288.0000\n",
      "Epoch 95/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 138399536.0000\n",
      "Epoch 96/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 133835024.0000\n",
      "Epoch 97/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 129381208.0000\n",
      "Epoch 98/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 125036536.0000\n",
      "Epoch 99/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 120799544.0000\n",
      "Epoch 100/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 116668704.0000\n",
      "Epoch 101/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 112642504.0000\n",
      "Epoch 102/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 108719472.0000\n",
      "Epoch 103/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 104898192.0000\n",
      "Epoch 104/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 101177128.0000\n",
      "Epoch 105/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 97554872.0000\n",
      "Epoch 106/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 94029888.0000\n",
      "Epoch 107/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 90600784.0000\n",
      "Epoch 108/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 87266048.0000\n",
      "Epoch 109/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 84024232.0000\n",
      "Epoch 110/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 80873864.0000\n",
      "Epoch 111/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 77813480.0000\n",
      "Epoch 112/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 74841592.0000\n",
      "Epoch 113/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 71956752.0000\n",
      "Epoch 114/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 69157440.0000\n",
      "Epoch 115/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 66442216.0000\n",
      "Epoch 116/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 63809576.0000\n",
      "Epoch 117/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 61258032.0000\n",
      "Epoch 118/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 58786088.0000\n",
      "Epoch 119/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 56392280.0000\n",
      "Epoch 120/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 54075064.0000\n",
      "Epoch 121/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 51832980.0000\n",
      "Epoch 122/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 49664488.0000\n",
      "Epoch 123/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 47568116.0000\n",
      "Epoch 124/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 45542328.0000\n",
      "Epoch 125/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 43585640.0000\n",
      "Epoch 126/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 41696564.0000\n",
      "Epoch 127/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 39873564.0000\n",
      "Epoch 128/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 38115160.0000\n",
      "Epoch 129/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 36419848.0000\n",
      "Epoch 130/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 34786136.0000\n",
      "Epoch 131/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 33212542.0000\n",
      "Epoch 132/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 31697568.0000\n",
      "Epoch 133/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 30239758.0000\n",
      "Epoch 134/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 28837630.0000\n",
      "Epoch 135/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 27489728.0000\n",
      "Epoch 136/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 26194566.0000\n",
      "Epoch 137/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 24950754.0000\n",
      "Epoch 138/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 23756840.0000\n",
      "Epoch 139/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 22611418.0000\n",
      "Epoch 140/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 21513068.0000\n",
      "Epoch 141/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 20460408.0000\n",
      "Epoch 142/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 19452072.0000\n",
      "Epoch 143/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 18486704.0000\n",
      "Epoch 144/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 17562944.0000\n",
      "Epoch 145/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 16679484.0000\n",
      "Epoch 146/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 15835009.0000\n",
      "Epoch 147/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 15028244.0000\n",
      "Epoch 148/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 14257907.0000\n",
      "Epoch 149/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 13522786.0000\n",
      "Epoch 150/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 12821623.0000\n",
      "Epoch 151/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 12153234.0000\n",
      "Epoch 152/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 11516439.0000\n",
      "Epoch 153/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 10910078.0000\n",
      "Epoch 154/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 10333014.0000\n",
      "Epoch 155/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 9784162.0000\n",
      "Epoch 156/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 9262417.0000\n",
      "Epoch 157/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 8766733.0000\n",
      "Epoch 158/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 8296071.5000\n",
      "Epoch 159/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 7849423.5000\n",
      "Epoch 160/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 7425809.0000\n",
      "Epoch 161/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 7024276.5000\n",
      "Epoch 162/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 6643895.0000\n",
      "Epoch 163/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 6283750.0000\n",
      "Epoch 164/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 5942976.0000\n",
      "Epoch 165/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 5620718.5000\n",
      "Epoch 166/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 5316139.5000\n",
      "Epoch 167/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 5028453.5000\n",
      "Epoch 168/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 4756878.5000\n",
      "Epoch 169/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 4500664.0000\n",
      "Epoch 170/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 4259094.0000\n",
      "Epoch 171/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 4031457.0000\n",
      "Epoch 172/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 3817084.5000\n",
      "Epoch 173/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 3615327.2500\n",
      "Epoch 174/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 3425557.0000\n",
      "Epoch 175/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 3247171.0000\n",
      "Epoch 176/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 3079583.2500\n",
      "Epoch 177/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 2922243.2500\n",
      "Epoch 178/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 2774610.5000\n",
      "Epoch 179/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 2636180.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 2506451.5000\n",
      "Epoch 181/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 2384957.5000\n",
      "Epoch 182/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 2271248.0000\n",
      "Epoch 183/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 2164887.5000\n",
      "Epoch 184/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 2065465.2500\n",
      "Epoch 185/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1972590.6250\n",
      "Epoch 186/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1885885.3750\n",
      "Epoch 187/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1804992.2500\n",
      "Epoch 188/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1729570.1250\n",
      "Epoch 189/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1659297.3750\n",
      "Epoch 190/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1593860.3750\n",
      "Epoch 191/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1532968.5000\n",
      "Epoch 192/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1476346.5000\n",
      "Epoch 193/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1423725.2500\n",
      "Epoch 194/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1374855.0000\n",
      "Epoch 195/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1329502.2500\n",
      "Epoch 196/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1287440.1250\n",
      "Epoch 197/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1248454.7500\n",
      "Epoch 198/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1212348.8750\n",
      "Epoch 199/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1178931.5000\n",
      "Epoch 200/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1148023.0000\n",
      "Epoch 201/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1119456.1250\n",
      "Epoch 202/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1093072.2500\n",
      "Epoch 203/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1068722.0000\n",
      "Epoch 204/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 1046262.4375\n",
      "Epoch 205/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1025563.0625\n",
      "Epoch 206/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 1006500.2500\n",
      "Epoch 207/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 988956.8125\n",
      "Epoch 208/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 972824.0000\n",
      "Epoch 209/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 957998.3125\n",
      "Epoch 210/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 944386.3125\n",
      "Epoch 211/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 931895.9375\n",
      "Epoch 212/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 920444.2500\n",
      "Epoch 213/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 909953.3750\n",
      "Epoch 214/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 900350.3750\n",
      "Epoch 215/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 891565.8750\n",
      "Epoch 216/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 883537.5625\n",
      "Epoch 217/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 876206.1250\n",
      "Epoch 218/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 869515.7500\n",
      "Epoch 219/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 863416.1875\n",
      "Epoch 220/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 857860.3125\n",
      "Epoch 221/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 852802.3750\n",
      "Epoch 222/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 848203.1250\n",
      "Epoch 223/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 844024.3750\n",
      "Epoch 224/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 840230.6250\n",
      "Epoch 225/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 836790.5000\n",
      "Epoch 226/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 833672.1250\n",
      "Epoch 227/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 830849.1250\n",
      "Epoch 228/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 828296.1250\n",
      "Epoch 229/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 825989.4375\n",
      "Epoch 230/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 823906.5000\n",
      "Epoch 231/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 822027.7500\n",
      "Epoch 232/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 820335.5625\n",
      "Epoch 233/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 818812.5000\n",
      "Epoch 234/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 817442.7500\n",
      "Epoch 235/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 816212.6875\n",
      "Epoch 236/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 815109.0625\n",
      "Epoch 237/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 814119.7500\n",
      "Epoch 238/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 813234.3125\n",
      "Epoch 239/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 812442.3750\n",
      "Epoch 240/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 811735.3750\n",
      "Epoch 241/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 811104.3125\n",
      "Epoch 242/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 810542.3125\n",
      "Epoch 243/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 810042.0000\n",
      "Epoch 244/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 809597.3750\n",
      "Epoch 245/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 809202.7500\n",
      "Epoch 246/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 808852.9375\n",
      "Epoch 247/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 808543.2500\n",
      "Epoch 248/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 808269.4375\n",
      "Epoch 249/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 808027.6250\n",
      "Epoch 250/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 807814.5000\n",
      "Epoch 251/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 807626.9375\n",
      "Epoch 252/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 807462.0625\n",
      "Epoch 253/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 807317.2500\n",
      "Epoch 254/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 807190.3750\n",
      "Epoch 255/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 807079.4375\n",
      "Epoch 256/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806982.3750\n",
      "Epoch 257/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 806897.7500\n",
      "Epoch 258/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806824.0625\n",
      "Epoch 259/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806759.9375\n",
      "Epoch 260/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806704.3125\n",
      "Epoch 261/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806656.0000\n",
      "Epoch 262/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806614.2500\n",
      "Epoch 263/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806578.0000\n",
      "Epoch 264/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806546.6875\n",
      "Epoch 265/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806519.7500\n",
      "Epoch 266/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806496.2500\n",
      "Epoch 267/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806476.1250\n",
      "Epoch 268/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806458.7500\n",
      "Epoch 269/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806443.6250\n",
      "Epoch 270/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806430.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806419.1875\n",
      "Epoch 272/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806409.3125\n",
      "Epoch 273/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806400.7500\n",
      "Epoch 274/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806393.1250\n",
      "Epoch 275/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806386.3750\n",
      "Epoch 276/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806380.3750\n",
      "Epoch 277/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806374.9375\n",
      "Epoch 278/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806370.0625\n",
      "Epoch 279/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 806365.5000\n",
      "Epoch 280/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806361.3750\n",
      "Epoch 281/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806357.3125\n",
      "Epoch 282/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806353.6250\n",
      "Epoch 283/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806350.0000\n",
      "Epoch 284/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806346.5000\n",
      "Epoch 285/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806343.0625\n",
      "Epoch 286/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806339.6875\n",
      "Epoch 287/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806336.3750\n",
      "Epoch 288/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806333.0000\n",
      "Epoch 289/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806329.8125\n",
      "Epoch 290/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806326.4375\n",
      "Epoch 291/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806323.1250\n",
      "Epoch 292/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 806319.6875\n",
      "Epoch 293/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806316.3750\n",
      "Epoch 294/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806312.9375\n",
      "Epoch 295/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806309.5000\n",
      "Epoch 296/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806305.8750\n",
      "Epoch 297/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806302.4375\n",
      "Epoch 298/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806298.9375\n",
      "Epoch 299/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806295.5000\n",
      "Epoch 300/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806291.8125\n",
      "Epoch 301/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806288.2500\n",
      "Epoch 302/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806284.5625\n",
      "Epoch 303/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806280.9375\n",
      "Epoch 304/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806277.1875\n",
      "Epoch 305/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806273.5625\n",
      "Epoch 306/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806269.7500\n",
      "Epoch 307/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806266.0000\n",
      "Epoch 308/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806262.3750\n",
      "Epoch 309/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806258.4375\n",
      "Epoch 310/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806254.8125\n",
      "Epoch 311/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806251.0625\n",
      "Epoch 312/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806247.2500\n",
      "Epoch 313/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806243.5625\n",
      "Epoch 314/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806239.6250\n",
      "Epoch 315/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806235.8125\n",
      "Epoch 316/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806231.9375\n",
      "Epoch 317/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806228.1875\n",
      "Epoch 318/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806224.3750\n",
      "Epoch 319/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806220.5000\n",
      "Epoch 320/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806216.6875\n",
      "Epoch 321/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806212.9375\n",
      "Epoch 322/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806209.0625\n",
      "Epoch 323/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806205.3125\n",
      "Epoch 324/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806201.5000\n",
      "Epoch 325/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 806197.6250\n",
      "Epoch 326/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806193.8125\n",
      "Epoch 327/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806189.8750\n",
      "Epoch 328/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806186.0625\n",
      "Epoch 329/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 806182.1250\n",
      "Epoch 330/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806178.2500\n",
      "Epoch 331/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806174.4375\n",
      "Epoch 332/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806170.6250\n",
      "Epoch 333/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806166.6875\n",
      "Epoch 334/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806162.8125\n",
      "Epoch 335/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806158.9375\n",
      "Epoch 336/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806155.0625\n",
      "Epoch 337/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806151.2500\n",
      "Epoch 338/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806147.2500\n",
      "Epoch 339/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806143.4375\n",
      "Epoch 340/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806139.5000\n",
      "Epoch 341/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806135.6875\n",
      "Epoch 342/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806131.6875\n",
      "Epoch 343/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806127.8125\n",
      "Epoch 344/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806123.8125\n",
      "Epoch 345/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806119.9375\n",
      "Epoch 346/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806116.0000\n",
      "Epoch 347/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806112.0625\n",
      "Epoch 348/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806108.1250\n",
      "Epoch 349/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806104.1875\n",
      "Epoch 350/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806100.3125\n",
      "Epoch 351/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806096.3125\n",
      "Epoch 352/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806092.3750\n",
      "Epoch 353/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806088.3750\n",
      "Epoch 354/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806084.3750\n",
      "Epoch 355/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806080.3750\n",
      "Epoch 356/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806076.3750\n",
      "Epoch 357/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806072.4375\n",
      "Epoch 358/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806068.3750\n",
      "Epoch 359/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806064.4375\n",
      "Epoch 360/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806060.3750\n",
      "Epoch 361/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806056.3750\n",
      "Epoch 362/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806052.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 363/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806048.3750\n",
      "Epoch 364/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806044.2500\n",
      "Epoch 365/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806040.1875\n",
      "Epoch 366/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806036.1875\n",
      "Epoch 367/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806032.1250\n",
      "Epoch 368/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806028.0000\n",
      "Epoch 369/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806023.9375\n",
      "Epoch 370/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806019.8125\n",
      "Epoch 371/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806015.6875\n",
      "Epoch 372/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806011.6250\n",
      "Epoch 373/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 806007.5625\n",
      "Epoch 374/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 806003.5000\n",
      "Epoch 375/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805999.3125\n",
      "Epoch 376/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805995.2500\n",
      "Epoch 377/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 805991.1250\n",
      "Epoch 378/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805986.9375\n",
      "Epoch 379/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805982.8750\n",
      "Epoch 380/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805978.6875\n",
      "Epoch 381/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805974.4375\n",
      "Epoch 382/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805970.3125\n",
      "Epoch 383/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805966.2500\n",
      "Epoch 384/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805962.0000\n",
      "Epoch 385/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805957.9375\n",
      "Epoch 386/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805953.6250\n",
      "Epoch 387/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805949.5000\n",
      "Epoch 388/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 805945.3125\n",
      "Epoch 389/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805941.0625\n",
      "Epoch 390/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805936.8750\n",
      "Epoch 391/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805932.6875\n",
      "Epoch 392/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805928.4375\n",
      "Epoch 393/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805924.1875\n",
      "Epoch 394/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805919.9375\n",
      "Epoch 395/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805915.6250\n",
      "Epoch 396/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805911.5000\n",
      "Epoch 397/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805907.1875\n",
      "Epoch 398/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805903.0000\n",
      "Epoch 399/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805898.7500\n",
      "Epoch 400/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805894.3750\n",
      "Epoch 401/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805890.1875\n",
      "Epoch 402/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805885.8750\n",
      "Epoch 403/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805881.6250\n",
      "Epoch 404/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805877.2500\n",
      "Epoch 405/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805872.8125\n",
      "Epoch 406/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805868.6250\n",
      "Epoch 407/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805864.3125\n",
      "Epoch 408/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805860.0000\n",
      "Epoch 409/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805855.6875\n",
      "Epoch 410/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805851.3750\n",
      "Epoch 411/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805847.0000\n",
      "Epoch 412/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805842.6250\n",
      "Epoch 413/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805838.2500\n",
      "Epoch 414/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805833.8125\n",
      "Epoch 415/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805829.5000\n",
      "Epoch 416/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805825.1250\n",
      "Epoch 417/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805820.6250\n",
      "Epoch 418/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805816.3125\n",
      "Epoch 419/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805811.9375\n",
      "Epoch 420/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805807.5000\n",
      "Epoch 421/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805803.0625\n",
      "Epoch 422/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805798.6875\n",
      "Epoch 423/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805794.3125\n",
      "Epoch 424/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805789.8750\n",
      "Epoch 425/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805785.4375\n",
      "Epoch 426/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805781.0000\n",
      "Epoch 427/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805776.5000\n",
      "Epoch 428/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805772.1250\n",
      "Epoch 429/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805767.5625\n",
      "Epoch 430/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805763.1250\n",
      "Epoch 431/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805758.7500\n",
      "Epoch 432/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805754.1875\n",
      "Epoch 433/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805749.6875\n",
      "Epoch 434/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805745.1875\n",
      "Epoch 435/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805740.7500\n",
      "Epoch 436/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805736.2500\n",
      "Epoch 437/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805731.6875\n",
      "Epoch 438/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805727.1875\n",
      "Epoch 439/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805722.6250\n",
      "Epoch 440/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805718.1250\n",
      "Epoch 441/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805713.5000\n",
      "Epoch 442/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805709.0625\n",
      "Epoch 443/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805704.5000\n",
      "Epoch 444/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805699.8750\n",
      "Epoch 445/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805695.3750\n",
      "Epoch 446/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805690.8125\n",
      "Epoch 447/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805686.2500\n",
      "Epoch 448/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805681.6250\n",
      "Epoch 449/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805677.0625\n",
      "Epoch 450/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805672.5000\n",
      "Epoch 451/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805667.9375\n",
      "Epoch 452/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805663.3125\n",
      "Epoch 453/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805658.7500\n",
      "Epoch 454/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805654.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805649.3750\n",
      "Epoch 456/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805644.8125\n",
      "Epoch 457/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805640.1250\n",
      "Epoch 458/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805635.5000\n",
      "Epoch 459/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805630.8750\n",
      "Epoch 460/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805626.2500\n",
      "Epoch 461/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805621.5625\n",
      "Epoch 462/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805616.8750\n",
      "Epoch 463/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 805612.1875\n",
      "Epoch 464/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805607.4375\n",
      "Epoch 465/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 805602.8125\n",
      "Epoch 466/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805598.0625\n",
      "Epoch 467/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805593.4375\n",
      "Epoch 468/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805588.6875\n",
      "Epoch 469/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805583.9375\n",
      "Epoch 470/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805579.1875\n",
      "Epoch 471/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805574.5000\n",
      "Epoch 472/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805569.8125\n",
      "Epoch 473/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805565.0000\n",
      "Epoch 474/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805560.2500\n",
      "Epoch 475/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805555.5000\n",
      "Epoch 476/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805550.7500\n",
      "Epoch 477/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805546.0000\n",
      "Epoch 478/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805541.1875\n",
      "Epoch 479/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805536.4375\n",
      "Epoch 480/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805531.6250\n",
      "Epoch 481/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805526.8750\n",
      "Epoch 482/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805522.0625\n",
      "Epoch 483/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805517.3125\n",
      "Epoch 484/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805512.5000\n",
      "Epoch 485/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805507.6875\n",
      "Epoch 486/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805502.8750\n",
      "Epoch 487/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805498.0625\n",
      "Epoch 488/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805493.2500\n",
      "Epoch 489/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805488.3750\n",
      "Epoch 490/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 805483.5625\n",
      "Epoch 491/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805478.6875\n",
      "Epoch 492/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805473.8125\n",
      "Epoch 493/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805468.9375\n",
      "Epoch 494/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805464.0625\n",
      "Epoch 495/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805459.1875\n",
      "Epoch 496/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805454.3125\n",
      "Epoch 497/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805449.3125\n",
      "Epoch 498/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805444.5000\n",
      "Epoch 499/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805439.6875\n",
      "Epoch 500/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805434.6875\n",
      "Epoch 501/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805429.7500\n",
      "Epoch 502/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805424.8125\n",
      "Epoch 503/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805419.9375\n",
      "Epoch 504/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805415.0625\n",
      "Epoch 505/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805410.0000\n",
      "Epoch 506/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805405.0625\n",
      "Epoch 507/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805400.1250\n",
      "Epoch 508/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805395.1875\n",
      "Epoch 509/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 805390.2500\n",
      "Epoch 510/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805385.3125\n",
      "Epoch 511/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805380.3125\n",
      "Epoch 512/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805375.3750\n",
      "Epoch 513/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805370.3750\n",
      "Epoch 514/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805365.3125\n",
      "Epoch 515/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805360.2500\n",
      "Epoch 516/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805355.3125\n",
      "Epoch 517/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805350.3125\n",
      "Epoch 518/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805345.3125\n",
      "Epoch 519/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805340.2500\n",
      "Epoch 520/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805335.1875\n",
      "Epoch 521/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805330.2500\n",
      "Epoch 522/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805325.1875\n",
      "Epoch 523/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805320.1875\n",
      "Epoch 524/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805315.0625\n",
      "Epoch 525/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805310.0625\n",
      "Epoch 526/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805304.9375\n",
      "Epoch 527/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805299.7500\n",
      "Epoch 528/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805294.7500\n",
      "Epoch 529/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805289.7500\n",
      "Epoch 530/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805284.6875\n",
      "Epoch 531/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805279.5625\n",
      "Epoch 532/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805274.4375\n",
      "Epoch 533/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805269.3125\n",
      "Epoch 534/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805264.1875\n",
      "Epoch 535/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805259.1250\n",
      "Epoch 536/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805254.0000\n",
      "Epoch 537/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805248.8125\n",
      "Epoch 538/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805243.6250\n",
      "Epoch 539/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805238.5625\n",
      "Epoch 540/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805233.4375\n",
      "Epoch 541/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805228.2500\n",
      "Epoch 542/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805223.0625\n",
      "Epoch 543/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805217.8750\n",
      "Epoch 544/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805212.7500\n",
      "Epoch 545/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805207.5000\n",
      "Epoch 546/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805202.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805197.1250\n",
      "Epoch 548/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805191.8750\n",
      "Epoch 549/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805186.8125\n",
      "Epoch 550/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805181.5000\n",
      "Epoch 551/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805176.3750\n",
      "Epoch 552/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805171.0625\n",
      "Epoch 553/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805165.8125\n",
      "Epoch 554/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805160.5625\n",
      "Epoch 555/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805155.4375\n",
      "Epoch 556/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805150.0625\n",
      "Epoch 557/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805144.7500\n",
      "Epoch 558/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805139.5625\n",
      "Epoch 559/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805134.2500\n",
      "Epoch 560/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805128.9375\n",
      "Epoch 561/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805123.6875\n",
      "Epoch 562/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805118.3125\n",
      "Epoch 563/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805113.1250\n",
      "Epoch 564/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805107.8125\n",
      "Epoch 565/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805102.4375\n",
      "Epoch 566/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805097.1875\n",
      "Epoch 567/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805091.7500\n",
      "Epoch 568/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805086.5000\n",
      "Epoch 569/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805081.1250\n",
      "Epoch 570/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805075.7500\n",
      "Epoch 571/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805070.4375\n",
      "Epoch 572/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805065.2500\n",
      "Epoch 573/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805059.7500\n",
      "Epoch 574/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805054.4375\n",
      "Epoch 575/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805049.0000\n",
      "Epoch 576/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 805043.6250\n",
      "Epoch 577/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805038.1875\n",
      "Epoch 578/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805032.9375\n",
      "Epoch 579/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805027.4375\n",
      "Epoch 580/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805022.0625\n",
      "Epoch 581/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805016.6875\n",
      "Epoch 582/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 805011.3125\n",
      "Epoch 583/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805005.8125\n",
      "Epoch 584/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 805000.4375\n",
      "Epoch 585/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804995.0000\n",
      "Epoch 586/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804989.5000\n",
      "Epoch 587/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804984.1250\n",
      "Epoch 588/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804978.6875\n",
      "Epoch 589/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804973.1875\n",
      "Epoch 590/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804967.8125\n",
      "Epoch 591/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804962.2500\n",
      "Epoch 592/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804956.8125\n",
      "Epoch 593/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804951.3750\n",
      "Epoch 594/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804945.8750\n",
      "Epoch 595/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804940.3750\n",
      "Epoch 596/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804934.8750\n",
      "Epoch 597/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804929.4375\n",
      "Epoch 598/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804923.8750\n",
      "Epoch 599/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804918.4375\n",
      "Epoch 600/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804912.8750\n",
      "Epoch 601/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804907.3750\n",
      "Epoch 602/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804901.8750\n",
      "Epoch 603/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804896.2500\n",
      "Epoch 604/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804890.6875\n",
      "Epoch 605/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804885.1250\n",
      "Epoch 606/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804879.5625\n",
      "Epoch 607/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804874.0625\n",
      "Epoch 608/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804868.5000\n",
      "Epoch 609/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804862.8750\n",
      "Epoch 610/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804857.3750\n",
      "Epoch 611/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804851.7500\n",
      "Epoch 612/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804846.2500\n",
      "Epoch 613/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804840.5625\n",
      "Epoch 614/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804834.9375\n",
      "Epoch 615/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804829.3125\n",
      "Epoch 616/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804823.7500\n",
      "Epoch 617/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804818.0625\n",
      "Epoch 618/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804812.4375\n",
      "Epoch 619/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804806.8750\n",
      "Epoch 620/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804801.2500\n",
      "Epoch 621/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804795.5000\n",
      "Epoch 622/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804789.8750\n",
      "Epoch 623/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804784.3125\n",
      "Epoch 624/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804778.5625\n",
      "Epoch 625/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804772.8750\n",
      "Epoch 626/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804767.1875\n",
      "Epoch 627/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804761.6250\n",
      "Epoch 628/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804755.9375\n",
      "Epoch 629/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804750.2500\n",
      "Epoch 630/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804744.5625\n",
      "Epoch 631/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804738.7500\n",
      "Epoch 632/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804733.0625\n",
      "Epoch 633/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804727.4375\n",
      "Epoch 634/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804721.7500\n",
      "Epoch 635/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804715.9375\n",
      "Epoch 636/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804710.2500\n",
      "Epoch 637/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804704.4375\n",
      "Epoch 638/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804698.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 639/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804693.0000\n",
      "Epoch 640/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804687.1875\n",
      "Epoch 641/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804681.3750\n",
      "Epoch 642/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804675.6250\n",
      "Epoch 643/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 804669.8750\n",
      "Epoch 644/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804664.0625\n",
      "Epoch 645/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804658.3125\n",
      "Epoch 646/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804652.4375\n",
      "Epoch 647/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804646.6250\n",
      "Epoch 648/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804640.8750\n",
      "Epoch 649/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804635.0000\n",
      "Epoch 650/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804629.3125\n",
      "Epoch 651/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804623.3750\n",
      "Epoch 652/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804617.5625\n",
      "Epoch 653/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804611.6875\n",
      "Epoch 654/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804605.8125\n",
      "Epoch 655/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804600.0000\n",
      "Epoch 656/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804594.1250\n",
      "Epoch 657/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804588.2500\n",
      "Epoch 658/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804582.3750\n",
      "Epoch 659/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804576.5625\n",
      "Epoch 660/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804570.6250\n",
      "Epoch 661/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804564.8125\n",
      "Epoch 662/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804558.9375\n",
      "Epoch 663/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804552.9375\n",
      "Epoch 664/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804547.0625\n",
      "Epoch 665/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804541.1250\n",
      "Epoch 666/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804535.2500\n",
      "Epoch 667/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804529.3125\n",
      "Epoch 668/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804523.3125\n",
      "Epoch 669/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 804517.3750\n",
      "Epoch 670/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804511.3750\n",
      "Epoch 671/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804505.5000\n",
      "Epoch 672/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804499.5625\n",
      "Epoch 673/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804493.6250\n",
      "Epoch 674/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804487.6250\n",
      "Epoch 675/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 804481.6250\n",
      "Epoch 676/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804475.6250\n",
      "Epoch 677/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804469.6250\n",
      "Epoch 678/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804463.6875\n",
      "Epoch 679/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804457.8125\n",
      "Epoch 680/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804451.7500\n",
      "Epoch 681/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804445.6875\n",
      "Epoch 682/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804439.7500\n",
      "Epoch 683/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804433.6875\n",
      "Epoch 684/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804427.6250\n",
      "Epoch 685/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804421.6875\n",
      "Epoch 686/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804415.5625\n",
      "Epoch 687/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804409.5625\n",
      "Epoch 688/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804403.5625\n",
      "Epoch 689/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804397.5000\n",
      "Epoch 690/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804391.4375\n",
      "Epoch 691/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804385.3750\n",
      "Epoch 692/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804379.2500\n",
      "Epoch 693/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804373.2500\n",
      "Epoch 694/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804367.1250\n",
      "Epoch 695/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804361.0625\n",
      "Epoch 696/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804354.9375\n",
      "Epoch 697/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804348.8125\n",
      "Epoch 698/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804342.6875\n",
      "Epoch 699/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804336.5625\n",
      "Epoch 700/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804330.5000\n",
      "Epoch 701/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804324.3750\n",
      "Epoch 702/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804318.1875\n",
      "Epoch 703/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804312.1250\n",
      "Epoch 704/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804305.8750\n",
      "Epoch 705/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804299.7500\n",
      "Epoch 706/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804293.5000\n",
      "Epoch 707/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804287.5000\n",
      "Epoch 708/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804281.2500\n",
      "Epoch 709/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804275.0625\n",
      "Epoch 710/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804268.8750\n",
      "Epoch 711/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804262.7500\n",
      "Epoch 712/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804256.5000\n",
      "Epoch 713/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804250.1875\n",
      "Epoch 714/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804244.0625\n",
      "Epoch 715/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804237.8125\n",
      "Epoch 716/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804231.5625\n",
      "Epoch 717/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804225.3750\n",
      "Epoch 718/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804219.1875\n",
      "Epoch 719/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804212.9375\n",
      "Epoch 720/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804206.6875\n",
      "Epoch 721/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804200.4375\n",
      "Epoch 722/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804194.1250\n",
      "Epoch 723/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804187.9375\n",
      "Epoch 724/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804181.5625\n",
      "Epoch 725/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804175.4375\n",
      "Epoch 726/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804169.1250\n",
      "Epoch 727/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804162.8750\n",
      "Epoch 728/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804156.4375\n",
      "Epoch 729/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804150.1875\n",
      "Epoch 730/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804144.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 731/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804137.6250\n",
      "Epoch 732/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804131.2500\n",
      "Epoch 733/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804124.9375\n",
      "Epoch 734/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804118.6875\n",
      "Epoch 735/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804112.3125\n",
      "Epoch 736/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804105.9375\n",
      "Epoch 737/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 804099.5625\n",
      "Epoch 738/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804093.2500\n",
      "Epoch 739/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804086.8125\n",
      "Epoch 740/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804080.5625\n",
      "Epoch 741/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804074.1250\n",
      "Epoch 742/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804067.7500\n",
      "Epoch 743/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804061.4375\n",
      "Epoch 744/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804055.0000\n",
      "Epoch 745/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804048.5625\n",
      "Epoch 746/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804042.1875\n",
      "Epoch 747/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804035.8125\n",
      "Epoch 748/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804029.3125\n",
      "Epoch 749/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 804022.9375\n",
      "Epoch 750/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 804016.5625\n",
      "Epoch 751/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804010.0625\n",
      "Epoch 752/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 804003.6250\n",
      "Epoch 753/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803997.2500\n",
      "Epoch 754/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803990.8125\n",
      "Epoch 755/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803984.3125\n",
      "Epoch 756/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803977.8125\n",
      "Epoch 757/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803971.4375\n",
      "Epoch 758/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803964.8750\n",
      "Epoch 759/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803958.3750\n",
      "Epoch 760/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803952.0000\n",
      "Epoch 761/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803945.4375\n",
      "Epoch 762/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803938.8750\n",
      "Epoch 763/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803932.4375\n",
      "Epoch 764/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803925.8750\n",
      "Epoch 765/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803919.4375\n",
      "Epoch 766/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803912.8125\n",
      "Epoch 767/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803906.2500\n",
      "Epoch 768/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803899.8125\n",
      "Epoch 769/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803893.3750\n",
      "Epoch 770/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803886.7500\n",
      "Epoch 771/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803880.1875\n",
      "Epoch 772/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803873.6250\n",
      "Epoch 773/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803867.0000\n",
      "Epoch 774/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803860.4375\n",
      "Epoch 775/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803853.8750\n",
      "Epoch 776/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803847.3125\n",
      "Epoch 777/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803840.7500\n",
      "Epoch 778/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803834.1875\n",
      "Epoch 779/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803827.5625\n",
      "Epoch 780/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803820.8125\n",
      "Epoch 781/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803814.3125\n",
      "Epoch 782/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803807.8125\n",
      "Epoch 783/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803801.1250\n",
      "Epoch 784/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803794.4375\n",
      "Epoch 785/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803787.8750\n",
      "Epoch 786/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803781.1875\n",
      "Epoch 787/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803774.5625\n",
      "Epoch 788/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803767.8125\n",
      "Epoch 789/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803761.2500\n",
      "Epoch 790/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803754.5625\n",
      "Epoch 791/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803747.9375\n",
      "Epoch 792/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803741.1875\n",
      "Epoch 793/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803734.5625\n",
      "Epoch 794/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803727.8125\n",
      "Epoch 795/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803721.1875\n",
      "Epoch 796/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803714.4375\n",
      "Epoch 797/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803707.6875\n",
      "Epoch 798/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803701.0625\n",
      "Epoch 799/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803694.3750\n",
      "Epoch 800/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803687.5625\n",
      "Epoch 801/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803680.8750\n",
      "Epoch 802/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803674.1875\n",
      "Epoch 803/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803667.3125\n",
      "Epoch 804/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803660.6250\n",
      "Epoch 805/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803653.9375\n",
      "Epoch 806/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803647.1250\n",
      "Epoch 807/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803640.3750\n",
      "Epoch 808/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803633.5625\n",
      "Epoch 809/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803626.7500\n",
      "Epoch 810/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803619.8750\n",
      "Epoch 811/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803613.0625\n",
      "Epoch 812/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803606.3125\n",
      "Epoch 813/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803599.5000\n",
      "Epoch 814/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803592.6875\n",
      "Epoch 815/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803585.8750\n",
      "Epoch 816/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803579.1250\n",
      "Epoch 817/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803572.1875\n",
      "Epoch 818/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803565.4375\n",
      "Epoch 819/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803558.6875\n",
      "Epoch 820/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803551.7500\n",
      "Epoch 821/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803544.8750\n",
      "Epoch 822/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803538.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 823/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803531.1875\n",
      "Epoch 824/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803524.3125\n",
      "Epoch 825/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803517.4375\n",
      "Epoch 826/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803510.5000\n",
      "Epoch 827/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803503.6875\n",
      "Epoch 828/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803496.8125\n",
      "Epoch 829/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803489.8750\n",
      "Epoch 830/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803483.0000\n",
      "Epoch 831/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803476.1250\n",
      "Epoch 832/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803469.1875\n",
      "Epoch 833/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803462.2500\n",
      "Epoch 834/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803455.3750\n",
      "Epoch 835/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803448.4375\n",
      "Epoch 836/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803441.5000\n",
      "Epoch 837/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803434.5000\n",
      "Epoch 838/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803427.5625\n",
      "Epoch 839/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803420.5625\n",
      "Epoch 840/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803413.6875\n",
      "Epoch 841/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803406.7500\n",
      "Epoch 842/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803399.7500\n",
      "Epoch 843/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803392.6875\n",
      "Epoch 844/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803385.8125\n",
      "Epoch 845/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803378.7500\n",
      "Epoch 846/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803371.8125\n",
      "Epoch 847/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803364.8125\n",
      "Epoch 848/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803357.8750\n",
      "Epoch 849/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803350.8125\n",
      "Epoch 850/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803343.8125\n",
      "Epoch 851/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803336.7500\n",
      "Epoch 852/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803329.6875\n",
      "Epoch 853/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803322.6250\n",
      "Epoch 854/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803315.5000\n",
      "Epoch 855/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803308.5625\n",
      "Epoch 856/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803301.3750\n",
      "Epoch 857/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 803294.3125\n",
      "Epoch 858/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803287.2500\n",
      "Epoch 859/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803280.1875\n",
      "Epoch 860/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803273.0625\n",
      "Epoch 861/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803265.9375\n",
      "Epoch 862/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803258.8750\n",
      "Epoch 863/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803251.8125\n",
      "Epoch 864/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803244.6250\n",
      "Epoch 865/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803237.6250\n",
      "Epoch 866/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803230.3750\n",
      "Epoch 867/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803223.2500\n",
      "Epoch 868/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803216.1250\n",
      "Epoch 869/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803208.9375\n",
      "Epoch 870/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803201.8750\n",
      "Epoch 871/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803194.6875\n",
      "Epoch 872/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803187.6250\n",
      "Epoch 873/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803180.3125\n",
      "Epoch 874/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 803173.1250\n",
      "Epoch 875/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 803166.0000\n",
      "Epoch 876/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803158.7500\n",
      "Epoch 877/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 803151.6250\n",
      "Epoch 878/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803144.3750\n",
      "Epoch 879/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803137.1250\n",
      "Epoch 880/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 803129.9375\n",
      "Epoch 881/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803122.6250\n",
      "Epoch 882/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803115.5000\n",
      "Epoch 883/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803108.3125\n",
      "Epoch 884/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803101.0000\n",
      "Epoch 885/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803093.7500\n",
      "Epoch 886/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 803086.5000\n",
      "Epoch 887/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803079.2500\n",
      "Epoch 888/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803072.1250\n",
      "Epoch 889/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 803064.8125\n",
      "Epoch 890/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 803057.5625\n",
      "Epoch 891/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803050.2500\n",
      "Epoch 892/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 803043.0000\n",
      "Epoch 893/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 803035.7500\n",
      "Epoch 894/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803028.5000\n",
      "Epoch 895/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803021.1250\n",
      "Epoch 896/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 803013.8125\n",
      "Epoch 897/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 803006.5000\n",
      "Epoch 898/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802999.1875\n",
      "Epoch 899/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802991.8750\n",
      "Epoch 900/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802984.4375\n",
      "Epoch 901/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802977.1875\n",
      "Epoch 902/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802969.6875\n",
      "Epoch 903/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802962.4375\n",
      "Epoch 904/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802955.1250\n",
      "Epoch 905/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802947.6250\n",
      "Epoch 906/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802940.3125\n",
      "Epoch 907/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802933.0000\n",
      "Epoch 908/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802925.6250\n",
      "Epoch 909/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802918.1875\n",
      "Epoch 910/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802910.8750\n",
      "Epoch 911/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802903.4375\n",
      "Epoch 912/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802896.0000\n",
      "Epoch 913/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802888.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 914/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802881.2500\n",
      "Epoch 915/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802873.8125\n",
      "Epoch 916/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802866.4375\n",
      "Epoch 917/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802858.9375\n",
      "Epoch 918/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802851.5000\n",
      "Epoch 919/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802844.0000\n",
      "Epoch 920/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802836.5625\n",
      "Epoch 921/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802829.1875\n",
      "Epoch 922/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802821.7500\n",
      "Epoch 923/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802814.1875\n",
      "Epoch 924/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802806.7500\n",
      "Epoch 925/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802799.2500\n",
      "Epoch 926/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802791.7500\n",
      "Epoch 927/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802784.1875\n",
      "Epoch 928/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802776.7500\n",
      "Epoch 929/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802769.3125\n",
      "Epoch 930/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802761.7500\n",
      "Epoch 931/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802754.2500\n",
      "Epoch 932/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802746.6250\n",
      "Epoch 933/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802739.1875\n",
      "Epoch 934/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802731.6875\n",
      "Epoch 935/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802724.1250\n",
      "Epoch 936/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802716.5625\n",
      "Epoch 937/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802709.0000\n",
      "Epoch 938/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802701.4375\n",
      "Epoch 939/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802693.8750\n",
      "Epoch 940/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802686.2500\n",
      "Epoch 941/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802678.7500\n",
      "Epoch 942/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802671.1250\n",
      "Epoch 943/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802663.5000\n",
      "Epoch 944/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802655.8125\n",
      "Epoch 945/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802648.1875\n",
      "Epoch 946/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802640.6875\n",
      "Epoch 947/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802633.0000\n",
      "Epoch 948/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802625.4375\n",
      "Epoch 949/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802617.8125\n",
      "Epoch 950/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802610.1250\n",
      "Epoch 951/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802602.4375\n",
      "Epoch 952/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802594.8750\n",
      "Epoch 953/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802587.1250\n",
      "Epoch 954/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802579.5000\n",
      "Epoch 955/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802571.8125\n",
      "Epoch 956/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802564.1250\n",
      "Epoch 957/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802556.5000\n",
      "Epoch 958/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802548.8125\n",
      "Epoch 959/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802541.0625\n",
      "Epoch 960/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802533.3750\n",
      "Epoch 961/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802525.6875\n",
      "Epoch 962/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802517.9375\n",
      "Epoch 963/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802510.3125\n",
      "Epoch 964/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802502.5625\n",
      "Epoch 965/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802494.8125\n",
      "Epoch 966/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802487.0000\n",
      "Epoch 967/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802479.2500\n",
      "Epoch 968/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802471.6250\n",
      "Epoch 969/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802463.8125\n",
      "Epoch 970/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802456.0000\n",
      "Epoch 971/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802448.3125\n",
      "Epoch 972/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802440.5000\n",
      "Epoch 973/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802432.7500\n",
      "Epoch 974/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802424.8750\n",
      "Epoch 975/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802417.1875\n",
      "Epoch 976/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802409.4375\n",
      "Epoch 977/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802401.5000\n",
      "Epoch 978/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802393.7500\n",
      "Epoch 979/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 802385.9375\n",
      "Epoch 980/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802378.1250\n",
      "Epoch 981/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802370.1875\n",
      "Epoch 982/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802362.4375\n",
      "Epoch 983/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802354.6875\n",
      "Epoch 984/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802346.8750\n",
      "Epoch 985/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802339.0000\n",
      "Epoch 986/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802331.1250\n",
      "Epoch 987/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802323.1250\n",
      "Epoch 988/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802315.3750\n",
      "Epoch 989/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802307.5000\n",
      "Epoch 990/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802299.6250\n",
      "Epoch 991/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802291.8125\n",
      "Epoch 992/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802283.8125\n",
      "Epoch 993/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802276.0000\n",
      "Epoch 994/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802268.0625\n",
      "Epoch 995/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802260.1875\n",
      "Epoch 996/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802252.2500\n",
      "Epoch 997/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802244.3125\n",
      "Epoch 998/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802236.3750\n",
      "Epoch 999/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802228.4375\n",
      "Epoch 1000/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802220.5000\n",
      "Epoch 1001/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802212.6250\n",
      "Epoch 1002/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802204.6250\n",
      "Epoch 1003/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802196.5625\n",
      "Epoch 1004/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802188.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1005/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802180.5625\n",
      "Epoch 1006/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802172.6875\n",
      "Epoch 1007/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802164.6875\n",
      "Epoch 1008/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802156.6875\n",
      "Epoch 1009/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802148.6250\n",
      "Epoch 1010/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802140.6250\n",
      "Epoch 1011/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802132.5625\n",
      "Epoch 1012/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802124.5625\n",
      "Epoch 1013/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802116.5625\n",
      "Epoch 1014/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802108.5000\n",
      "Epoch 1015/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802100.4375\n",
      "Epoch 1016/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802092.5000\n",
      "Epoch 1017/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802084.4375\n",
      "Epoch 1018/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802076.3750\n",
      "Epoch 1019/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802068.2500\n",
      "Epoch 1020/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802060.2500\n",
      "Epoch 1021/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802052.1875\n",
      "Epoch 1022/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802044.0625\n",
      "Epoch 1023/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802036.0000\n",
      "Epoch 1024/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 802027.8750\n",
      "Epoch 1025/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802019.8750\n",
      "Epoch 1026/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802011.7500\n",
      "Epoch 1027/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 802003.5625\n",
      "Epoch 1028/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 801995.5000\n",
      "Epoch 1029/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801987.3750\n",
      "Epoch 1030/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801979.1875\n",
      "Epoch 1031/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801971.1250\n",
      "Epoch 1032/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801962.9375\n",
      "Epoch 1033/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801954.6250\n",
      "Epoch 1034/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801946.6250\n",
      "Epoch 1035/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801938.5000\n",
      "Epoch 1036/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801930.2500\n",
      "Epoch 1037/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801922.1250\n",
      "Epoch 1038/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801913.9375\n",
      "Epoch 1039/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801905.7500\n",
      "Epoch 1040/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801897.5000\n",
      "Epoch 1041/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 801889.3750\n",
      "Epoch 1042/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801881.0625\n",
      "Epoch 1043/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801872.8750\n",
      "Epoch 1044/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801864.6250\n",
      "Epoch 1045/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801856.3750\n",
      "Epoch 1046/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801848.1875\n",
      "Epoch 1047/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801839.9375\n",
      "Epoch 1048/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801831.7500\n",
      "Epoch 1049/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801823.5625\n",
      "Epoch 1050/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 801815.2500\n",
      "Epoch 1051/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801807.0000\n",
      "Epoch 1052/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801798.7500\n",
      "Epoch 1053/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801790.4375\n",
      "Epoch 1054/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801782.1875\n",
      "Epoch 1055/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801773.8750\n",
      "Epoch 1056/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801765.5625\n",
      "Epoch 1057/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801757.2500\n",
      "Epoch 1058/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801749.0000\n",
      "Epoch 1059/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801740.6250\n",
      "Epoch 1060/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801732.3750\n",
      "Epoch 1061/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801724.0625\n",
      "Epoch 1062/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801715.6875\n",
      "Epoch 1063/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801707.3125\n",
      "Epoch 1064/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801699.0625\n",
      "Epoch 1065/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801690.6875\n",
      "Epoch 1066/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801682.3750\n",
      "Epoch 1067/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801673.9375\n",
      "Epoch 1068/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801665.5625\n",
      "Epoch 1069/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801657.2500\n",
      "Epoch 1070/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801648.8750\n",
      "Epoch 1071/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801640.4375\n",
      "Epoch 1072/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801632.1250\n",
      "Epoch 1073/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801623.6875\n",
      "Epoch 1074/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801615.3125\n",
      "Epoch 1075/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801606.8750\n",
      "Epoch 1076/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801598.3750\n",
      "Epoch 1077/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801589.9375\n",
      "Epoch 1078/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801581.6250\n",
      "Epoch 1079/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801573.0625\n",
      "Epoch 1080/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801564.6250\n",
      "Epoch 1081/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801556.1250\n",
      "Epoch 1082/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801547.8125\n",
      "Epoch 1083/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801539.2500\n",
      "Epoch 1084/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801530.7500\n",
      "Epoch 1085/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801522.3125\n",
      "Epoch 1086/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801513.8125\n",
      "Epoch 1087/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801505.3750\n",
      "Epoch 1088/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801496.8750\n",
      "Epoch 1089/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801488.3750\n",
      "Epoch 1090/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801479.8750\n",
      "Epoch 1091/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801471.3750\n",
      "Epoch 1092/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801462.7500\n",
      "Epoch 1093/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801454.1875\n",
      "Epoch 1094/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801445.8125\n",
      "Epoch 1095/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801437.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1096/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801428.7500\n",
      "Epoch 1097/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801420.1875\n",
      "Epoch 1098/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801411.6250\n",
      "Epoch 1099/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801403.1250\n",
      "Epoch 1100/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801394.4375\n",
      "Epoch 1101/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801385.8750\n",
      "Epoch 1102/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801377.3125\n",
      "Epoch 1103/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801368.7500\n",
      "Epoch 1104/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801360.1250\n",
      "Epoch 1105/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801351.5000\n",
      "Epoch 1106/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801342.8750\n",
      "Epoch 1107/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801334.3750\n",
      "Epoch 1108/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801325.6875\n",
      "Epoch 1109/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801316.9375\n",
      "Epoch 1110/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801308.4375\n",
      "Epoch 1111/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801299.8125\n",
      "Epoch 1112/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801291.1250\n",
      "Epoch 1113/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801282.5625\n",
      "Epoch 1114/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801273.8750\n",
      "Epoch 1115/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801265.2500\n",
      "Epoch 1116/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801256.6250\n",
      "Epoch 1117/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801247.8750\n",
      "Epoch 1118/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801239.2500\n",
      "Epoch 1119/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801230.5625\n",
      "Epoch 1120/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801221.8750\n",
      "Epoch 1121/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801213.1875\n",
      "Epoch 1122/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801204.4375\n",
      "Epoch 1123/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801195.8125\n",
      "Epoch 1124/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801187.0625\n",
      "Epoch 1125/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801178.3125\n",
      "Epoch 1126/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801169.5625\n",
      "Epoch 1127/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801160.8125\n",
      "Epoch 1128/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801152.0625\n",
      "Epoch 1129/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 801143.3125\n",
      "Epoch 1130/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801134.4375\n",
      "Epoch 1131/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801125.6875\n",
      "Epoch 1132/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801116.9375\n",
      "Epoch 1133/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801108.2500\n",
      "Epoch 1134/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801099.3750\n",
      "Epoch 1135/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801090.6250\n",
      "Epoch 1136/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 801081.9375\n",
      "Epoch 1137/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801073.0625\n",
      "Epoch 1138/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801064.3125\n",
      "Epoch 1139/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801055.4375\n",
      "Epoch 1140/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801046.5625\n",
      "Epoch 1141/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801037.7500\n",
      "Epoch 1142/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801028.9375\n",
      "Epoch 1143/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801020.0625\n",
      "Epoch 1144/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 801011.1875\n",
      "Epoch 1145/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 801002.3750\n",
      "Epoch 1146/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 800993.4375\n",
      "Epoch 1147/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800984.5625\n",
      "Epoch 1148/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800975.7500\n",
      "Epoch 1149/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800966.8750\n",
      "Epoch 1150/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800957.8750\n",
      "Epoch 1151/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800949.0000\n",
      "Epoch 1152/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800940.1250\n",
      "Epoch 1153/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800931.2500\n",
      "Epoch 1154/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800922.3750\n",
      "Epoch 1155/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800913.3750\n",
      "Epoch 1156/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800904.5000\n",
      "Epoch 1157/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800895.4375\n",
      "Epoch 1158/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800886.6250\n",
      "Epoch 1159/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800877.5625\n",
      "Epoch 1160/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800868.8125\n",
      "Epoch 1161/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800859.8125\n",
      "Epoch 1162/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 800850.8125\n",
      "Epoch 1163/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800841.7500\n",
      "Epoch 1164/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800832.8125\n",
      "Epoch 1165/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800823.8750\n",
      "Epoch 1166/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800814.7500\n",
      "Epoch 1167/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800805.8125\n",
      "Epoch 1168/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800796.8750\n",
      "Epoch 1169/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800787.8750\n",
      "Epoch 1170/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800778.8125\n",
      "Epoch 1171/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800769.8125\n",
      "Epoch 1172/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800760.8125\n",
      "Epoch 1173/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 800751.7500\n",
      "Epoch 1174/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800742.7500\n",
      "Epoch 1175/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800733.7500\n",
      "Epoch 1176/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800724.6250\n",
      "Epoch 1177/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800715.6875\n",
      "Epoch 1178/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800706.5625\n",
      "Epoch 1179/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800697.5000\n",
      "Epoch 1180/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800688.3750\n",
      "Epoch 1181/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800679.2500\n",
      "Epoch 1182/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800670.1875\n",
      "Epoch 1183/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800661.0625\n",
      "Epoch 1184/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800652.0000\n",
      "Epoch 1185/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800642.8750\n",
      "Epoch 1186/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800633.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1187/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800624.7500\n",
      "Epoch 1188/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800615.5000\n",
      "Epoch 1189/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800606.4375\n",
      "Epoch 1190/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800597.2500\n",
      "Epoch 1191/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800588.1875\n",
      "Epoch 1192/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800578.9375\n",
      "Epoch 1193/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800569.8750\n",
      "Epoch 1194/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800560.6875\n",
      "Epoch 1195/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800551.5625\n",
      "Epoch 1196/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800542.3125\n",
      "Epoch 1197/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800533.1250\n",
      "Epoch 1198/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800523.8750\n",
      "Epoch 1199/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800514.7500\n",
      "Epoch 1200/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800505.5000\n",
      "Epoch 1201/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800496.3750\n",
      "Epoch 1202/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800487.0625\n",
      "Epoch 1203/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800477.8750\n",
      "Epoch 1204/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800468.6250\n",
      "Epoch 1205/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800459.4375\n",
      "Epoch 1206/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800450.1875\n",
      "Epoch 1207/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800441.0625\n",
      "Epoch 1208/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800431.6875\n",
      "Epoch 1209/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800422.3750\n",
      "Epoch 1210/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800413.1250\n",
      "Epoch 1211/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800403.9375\n",
      "Epoch 1212/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800394.5625\n",
      "Epoch 1213/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800385.3125\n",
      "Epoch 1214/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800376.0000\n",
      "Epoch 1215/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800366.7500\n",
      "Epoch 1216/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800357.3750\n",
      "Epoch 1217/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800348.0625\n",
      "Epoch 1218/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800338.6875\n",
      "Epoch 1219/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800329.4375\n",
      "Epoch 1220/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800320.1250\n",
      "Epoch 1221/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800310.8125\n",
      "Epoch 1222/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800301.4375\n",
      "Epoch 1223/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800292.0000\n",
      "Epoch 1224/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800282.6250\n",
      "Epoch 1225/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800273.2500\n",
      "Epoch 1226/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800263.9375\n",
      "Epoch 1227/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800254.4375\n",
      "Epoch 1228/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800245.0000\n",
      "Epoch 1229/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800235.6875\n",
      "Epoch 1230/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800226.3125\n",
      "Epoch 1231/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800216.9375\n",
      "Epoch 1232/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800207.5625\n",
      "Epoch 1233/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800198.0625\n",
      "Epoch 1234/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800188.6250\n",
      "Epoch 1235/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800179.1875\n",
      "Epoch 1236/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800169.8125\n",
      "Epoch 1237/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800160.3125\n",
      "Epoch 1238/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800150.8125\n",
      "Epoch 1239/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800141.3750\n",
      "Epoch 1240/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 800131.8125\n",
      "Epoch 1241/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 800122.3750\n",
      "Epoch 1242/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 800112.9375\n",
      "Epoch 1243/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800103.4375\n",
      "Epoch 1244/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800094.0625\n",
      "Epoch 1245/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 800084.5625\n",
      "Epoch 1246/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800075.0000\n",
      "Epoch 1247/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800065.5625\n",
      "Epoch 1248/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 800055.9375\n",
      "Epoch 1249/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 800046.4375\n",
      "Epoch 1250/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800037.0000\n",
      "Epoch 1251/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 800027.3750\n",
      "Epoch 1252/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 800017.8750\n",
      "Epoch 1253/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 800008.3125\n",
      "Epoch 1254/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799998.8125\n",
      "Epoch 1255/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799989.1875\n",
      "Epoch 1256/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799979.5625\n",
      "Epoch 1257/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799970.0000\n",
      "Epoch 1258/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799960.3750\n",
      "Epoch 1259/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799950.8750\n",
      "Epoch 1260/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799941.2500\n",
      "Epoch 1261/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799931.6250\n",
      "Epoch 1262/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799922.0625\n",
      "Epoch 1263/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799912.4375\n",
      "Epoch 1264/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799902.8125\n",
      "Epoch 1265/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799893.1875\n",
      "Epoch 1266/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799883.6250\n",
      "Epoch 1267/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799873.9375\n",
      "Epoch 1268/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799864.2500\n",
      "Epoch 1269/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799854.6250\n",
      "Epoch 1270/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799845.0000\n",
      "Epoch 1271/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799835.2500\n",
      "Epoch 1272/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799825.6875\n",
      "Epoch 1273/3000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 799815.9375\n",
      "Epoch 1274/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799806.2500\n",
      "Epoch 1275/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799796.5000\n",
      "Epoch 1276/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799786.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1277/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799777.1875\n",
      "Epoch 1278/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799767.3750\n",
      "Epoch 1279/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799757.6875\n",
      "Epoch 1280/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799747.9375\n",
      "Epoch 1281/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799738.2500\n",
      "Epoch 1282/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799728.5000\n",
      "Epoch 1283/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799718.7500\n",
      "Epoch 1284/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799708.9375\n",
      "Epoch 1285/3000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 799699.1250\n",
      "Epoch 1286/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 799689.3750\n",
      "Epoch 1287/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799679.6875\n",
      "Epoch 1288/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799669.9375\n",
      "Epoch 1289/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799660.1875\n",
      "Epoch 1290/3000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 799650.3125\n",
      "Epoch 1291/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799640.5625\n",
      "Epoch 1292/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799630.6875\n",
      "Epoch 1293/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799620.8750\n",
      "Epoch 1294/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799610.9375\n",
      "Epoch 1295/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799601.1875\n",
      "Epoch 1296/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799591.3125\n",
      "Epoch 1297/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799581.5000\n",
      "Epoch 1298/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799571.6250\n",
      "Epoch 1299/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799561.8125\n",
      "Epoch 1300/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799552.0000\n",
      "Epoch 1301/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799542.0625\n",
      "Epoch 1302/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799532.1875\n",
      "Epoch 1303/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799522.3125\n",
      "Epoch 1304/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799512.5625\n",
      "Epoch 1305/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799502.5625\n",
      "Epoch 1306/3000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 799492.6875\n",
      "Epoch 1307/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799482.7500\n",
      "Epoch 1308/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799472.9375\n",
      "Epoch 1309/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799462.9375\n",
      "Epoch 1310/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799453.0000\n",
      "Epoch 1311/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799443.1250\n",
      "Epoch 1312/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799433.1250\n",
      "Epoch 1313/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799423.2500\n",
      "Epoch 1314/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799413.1875\n",
      "Epoch 1315/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799403.3750\n",
      "Epoch 1316/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799393.3750\n",
      "Epoch 1317/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 799383.3750\n",
      "Epoch 1318/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 799373.3750\n",
      "Epoch 1319/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799363.3125\n",
      "Epoch 1320/3000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 799353.4375\n",
      "Epoch 1321/3000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 799343.3750\n",
      "Epoch 1322/3000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 799333.4375\n",
      "Epoch 1323/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 799323.3750\n",
      "Epoch 1324/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 799313.3125\n",
      "Epoch 1325/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799303.3750\n",
      "Epoch 1326/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799293.3750\n",
      "Epoch 1327/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799283.2500\n",
      "Epoch 1328/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799273.2500\n",
      "Epoch 1329/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799263.2500\n",
      "Epoch 1330/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799253.1875\n",
      "Epoch 1331/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799243.1250\n",
      "Epoch 1332/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799233.0000\n",
      "Epoch 1333/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799222.8750\n",
      "Epoch 1334/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799212.8125\n",
      "Epoch 1335/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799202.7500\n",
      "Epoch 1336/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 799192.7500\n",
      "Epoch 1337/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799182.5625\n",
      "Epoch 1338/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799172.5000\n",
      "Epoch 1339/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799162.3125\n",
      "Epoch 1340/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799152.1250\n",
      "Epoch 1341/3000\n",
      "630/630 [==============================] - 0s 27us/step - loss: 799142.0625\n",
      "Epoch 1342/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799131.8750\n",
      "Epoch 1343/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799121.7500\n",
      "Epoch 1344/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799111.6250\n",
      "Epoch 1345/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799101.5000\n",
      "Epoch 1346/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799091.3750\n",
      "Epoch 1347/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799081.1875\n",
      "Epoch 1348/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799070.9375\n",
      "Epoch 1349/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 799060.6875\n",
      "Epoch 1350/3000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 799050.5625\n",
      "Epoch 1351/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 799040.3750\n",
      "Epoch 1352/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 799030.1875\n",
      "Epoch 1353/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799019.9375\n",
      "Epoch 1354/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 799009.6875\n",
      "Epoch 1355/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798999.5000\n",
      "Epoch 1356/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798989.2500\n",
      "Epoch 1357/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798979.0000\n",
      "Epoch 1358/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798968.6875\n",
      "Epoch 1359/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798958.4375\n",
      "Epoch 1360/3000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 798948.1875\n",
      "Epoch 1361/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798937.9375\n",
      "Epoch 1362/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798927.6875\n",
      "Epoch 1363/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798917.3125\n",
      "Epoch 1364/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798907.0625\n",
      "Epoch 1365/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798896.8125\n",
      "Epoch 1366/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798886.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1367/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798876.1875\n",
      "Epoch 1368/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798865.8750\n",
      "Epoch 1369/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798855.5625\n",
      "Epoch 1370/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 798845.3750\n",
      "Epoch 1371/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798834.9375\n",
      "Epoch 1372/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798824.5625\n",
      "Epoch 1373/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798814.2500\n",
      "Epoch 1374/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798803.8125\n",
      "Epoch 1375/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798793.5000\n",
      "Epoch 1376/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798783.1250\n",
      "Epoch 1377/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798772.8125\n",
      "Epoch 1378/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798762.3125\n",
      "Epoch 1379/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798752.0000\n",
      "Epoch 1380/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798741.5625\n",
      "Epoch 1381/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798731.2500\n",
      "Epoch 1382/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798720.8125\n",
      "Epoch 1383/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798710.4375\n",
      "Epoch 1384/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798700.0000\n",
      "Epoch 1385/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798689.5000\n",
      "Epoch 1386/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 798679.1875\n",
      "Epoch 1387/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798668.7500\n",
      "Epoch 1388/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798658.3125\n",
      "Epoch 1389/3000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 798647.8125\n",
      "Epoch 1390/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 798637.3125\n",
      "Epoch 1391/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 798626.8125\n",
      "Epoch 1392/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 798616.3750\n",
      "Epoch 1393/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798605.8750\n",
      "Epoch 1394/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798595.3750\n",
      "Epoch 1395/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 798584.8750\n",
      "Epoch 1396/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798574.3750\n",
      "Epoch 1397/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798563.9375\n",
      "Epoch 1398/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798553.4375\n",
      "Epoch 1399/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798542.8125\n",
      "Epoch 1400/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798532.3750\n",
      "Epoch 1401/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798521.8125\n",
      "Epoch 1402/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798511.3125\n",
      "Epoch 1403/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798500.7500\n",
      "Epoch 1404/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798490.1250\n",
      "Epoch 1405/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798479.5000\n",
      "Epoch 1406/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798469.0000\n",
      "Epoch 1407/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 798458.5000\n",
      "Epoch 1408/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798447.8750\n",
      "Epoch 1409/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798437.1875\n",
      "Epoch 1410/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798426.5625\n",
      "Epoch 1411/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798416.0000\n",
      "Epoch 1412/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798405.4375\n",
      "Epoch 1413/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798394.7500\n",
      "Epoch 1414/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798384.1250\n",
      "Epoch 1415/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798373.5000\n",
      "Epoch 1416/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798362.8750\n",
      "Epoch 1417/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798352.1875\n",
      "Epoch 1418/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798341.5625\n",
      "Epoch 1419/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798330.8750\n",
      "Epoch 1420/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798320.2500\n",
      "Epoch 1421/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798309.5625\n",
      "Epoch 1422/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798298.8750\n",
      "Epoch 1423/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798288.1250\n",
      "Epoch 1424/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798277.5000\n",
      "Epoch 1425/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798266.7500\n",
      "Epoch 1426/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798256.0625\n",
      "Epoch 1427/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798245.3750\n",
      "Epoch 1428/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798234.6875\n",
      "Epoch 1429/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798223.8750\n",
      "Epoch 1430/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798213.1875\n",
      "Epoch 1431/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798202.3750\n",
      "Epoch 1432/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798191.6875\n",
      "Epoch 1433/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798180.8750\n",
      "Epoch 1434/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798170.1250\n",
      "Epoch 1435/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798159.3750\n",
      "Epoch 1436/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 798148.5000\n",
      "Epoch 1437/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798137.7500\n",
      "Epoch 1438/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798127.0000\n",
      "Epoch 1439/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798116.1250\n",
      "Epoch 1440/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798105.3750\n",
      "Epoch 1441/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798094.5625\n",
      "Epoch 1442/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798083.8125\n",
      "Epoch 1443/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798072.8750\n",
      "Epoch 1444/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798062.0625\n",
      "Epoch 1445/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798051.2500\n",
      "Epoch 1446/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798040.5000\n",
      "Epoch 1447/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798029.5000\n",
      "Epoch 1448/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 798018.6875\n",
      "Epoch 1449/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 798007.8750\n",
      "Epoch 1450/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797996.9375\n",
      "Epoch 1451/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797986.0625\n",
      "Epoch 1452/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797975.1875\n",
      "Epoch 1453/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797964.2500\n",
      "Epoch 1454/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797953.3125\n",
      "Epoch 1455/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797942.5000\n",
      "Epoch 1456/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797931.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1457/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797920.6250\n",
      "Epoch 1458/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797909.6875\n",
      "Epoch 1459/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797898.7500\n",
      "Epoch 1460/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797887.8125\n",
      "Epoch 1461/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797876.8125\n",
      "Epoch 1462/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797865.9375\n",
      "Epoch 1463/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797855.0000\n",
      "Epoch 1464/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797843.9375\n",
      "Epoch 1465/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797832.9375\n",
      "Epoch 1466/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 797822.0625\n",
      "Epoch 1467/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797811.0625\n",
      "Epoch 1468/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797800.1250\n",
      "Epoch 1469/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797789.0625\n",
      "Epoch 1470/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797778.0625\n",
      "Epoch 1471/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797767.0625\n",
      "Epoch 1472/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 797756.0000\n",
      "Epoch 1473/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797744.9375\n",
      "Epoch 1474/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797734.0000\n",
      "Epoch 1475/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797722.8750\n",
      "Epoch 1476/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797711.8750\n",
      "Epoch 1477/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797700.8125\n",
      "Epoch 1478/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797689.6875\n",
      "Epoch 1479/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797678.6875\n",
      "Epoch 1480/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797667.5625\n",
      "Epoch 1481/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797656.3750\n",
      "Epoch 1482/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797645.3125\n",
      "Epoch 1483/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797634.2500\n",
      "Epoch 1484/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 797623.0625\n",
      "Epoch 1485/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797612.0000\n",
      "Epoch 1486/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797600.7500\n",
      "Epoch 1487/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797589.7500\n",
      "Epoch 1488/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797578.5000\n",
      "Epoch 1489/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797567.5000\n",
      "Epoch 1490/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797556.1875\n",
      "Epoch 1491/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797545.1250\n",
      "Epoch 1492/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797533.9375\n",
      "Epoch 1493/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797522.7500\n",
      "Epoch 1494/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797511.5625\n",
      "Epoch 1495/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797500.3750\n",
      "Epoch 1496/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797489.1875\n",
      "Epoch 1497/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797478.0000\n",
      "Epoch 1498/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797466.7500\n",
      "Epoch 1499/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797455.5625\n",
      "Epoch 1500/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797444.3125\n",
      "Epoch 1501/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797433.0625\n",
      "Epoch 1502/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797421.8125\n",
      "Epoch 1503/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 797410.5625\n",
      "Epoch 1504/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797399.3125\n",
      "Epoch 1505/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797388.1250\n",
      "Epoch 1506/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797376.8125\n",
      "Epoch 1507/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797365.5625\n",
      "Epoch 1508/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797354.3125\n",
      "Epoch 1509/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797343.0000\n",
      "Epoch 1510/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797331.7500\n",
      "Epoch 1511/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797320.3750\n",
      "Epoch 1512/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797309.0625\n",
      "Epoch 1513/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797297.8125\n",
      "Epoch 1514/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797286.5000\n",
      "Epoch 1515/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797275.1875\n",
      "Epoch 1516/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 797263.8125\n",
      "Epoch 1517/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797252.4375\n",
      "Epoch 1518/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797241.0625\n",
      "Epoch 1519/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797229.7500\n",
      "Epoch 1520/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797218.3125\n",
      "Epoch 1521/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797207.0625\n",
      "Epoch 1522/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797195.6250\n",
      "Epoch 1523/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797184.1875\n",
      "Epoch 1524/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797172.8125\n",
      "Epoch 1525/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797161.4375\n",
      "Epoch 1526/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797149.9375\n",
      "Epoch 1527/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797138.6250\n",
      "Epoch 1528/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797127.1250\n",
      "Epoch 1529/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797115.7500\n",
      "Epoch 1530/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797104.3750\n",
      "Epoch 1531/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797092.8750\n",
      "Epoch 1532/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797081.5000\n",
      "Epoch 1533/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797070.0000\n",
      "Epoch 1534/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797058.5625\n",
      "Epoch 1535/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797047.0625\n",
      "Epoch 1536/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797035.6250\n",
      "Epoch 1537/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797024.0625\n",
      "Epoch 1538/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 797012.5000\n",
      "Epoch 1539/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 797001.0625\n",
      "Epoch 1540/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796989.5000\n",
      "Epoch 1541/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796978.0625\n",
      "Epoch 1542/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796966.5625\n",
      "Epoch 1543/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796955.0000\n",
      "Epoch 1544/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796943.5000\n",
      "Epoch 1545/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796932.0000\n",
      "Epoch 1546/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796920.4375\n",
      "Epoch 1547/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796909.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1548/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796897.3750\n",
      "Epoch 1549/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796885.7500\n",
      "Epoch 1550/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796874.1875\n",
      "Epoch 1551/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796862.6250\n",
      "Epoch 1552/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796851.0000\n",
      "Epoch 1553/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796839.4375\n",
      "Epoch 1554/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796827.8750\n",
      "Epoch 1555/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796816.2500\n",
      "Epoch 1556/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796804.6250\n",
      "Epoch 1557/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796793.0625\n",
      "Epoch 1558/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796781.3750\n",
      "Epoch 1559/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796769.7500\n",
      "Epoch 1560/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796758.0625\n",
      "Epoch 1561/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796746.4375\n",
      "Epoch 1562/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796734.7500\n",
      "Epoch 1563/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796723.1875\n",
      "Epoch 1564/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796711.4375\n",
      "Epoch 1565/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796699.7500\n",
      "Epoch 1566/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796688.0625\n",
      "Epoch 1567/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796676.4375\n",
      "Epoch 1568/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796664.6250\n",
      "Epoch 1569/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796652.9375\n",
      "Epoch 1570/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796641.1250\n",
      "Epoch 1571/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796629.3750\n",
      "Epoch 1572/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796617.6875\n",
      "Epoch 1573/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796606.0000\n",
      "Epoch 1574/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796594.1875\n",
      "Epoch 1575/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796582.5000\n",
      "Epoch 1576/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796570.7500\n",
      "Epoch 1577/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796559.0625\n",
      "Epoch 1578/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796547.1875\n",
      "Epoch 1579/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796535.4375\n",
      "Epoch 1580/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 796523.6875\n",
      "Epoch 1581/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796511.8750\n",
      "Epoch 1582/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796500.0625\n",
      "Epoch 1583/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796488.2500\n",
      "Epoch 1584/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796476.4375\n",
      "Epoch 1585/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796464.6250\n",
      "Epoch 1586/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 796452.8125\n",
      "Epoch 1587/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796440.8750\n",
      "Epoch 1588/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796429.0625\n",
      "Epoch 1589/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796417.2500\n",
      "Epoch 1590/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796405.3750\n",
      "Epoch 1591/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796393.4375\n",
      "Epoch 1592/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796381.5625\n",
      "Epoch 1593/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796369.6250\n",
      "Epoch 1594/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796357.8750\n",
      "Epoch 1595/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796345.8750\n",
      "Epoch 1596/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796333.9375\n",
      "Epoch 1597/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796322.0625\n",
      "Epoch 1598/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796310.1250\n",
      "Epoch 1599/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796298.2500\n",
      "Epoch 1600/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796286.3125\n",
      "Epoch 1601/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796274.3125\n",
      "Epoch 1602/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796262.3750\n",
      "Epoch 1603/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796250.3750\n",
      "Epoch 1604/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796238.4375\n",
      "Epoch 1605/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796226.5000\n",
      "Epoch 1606/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796214.5625\n",
      "Epoch 1607/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796202.5625\n",
      "Epoch 1608/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796190.5000\n",
      "Epoch 1609/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796178.4375\n",
      "Epoch 1610/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796166.3750\n",
      "Epoch 1611/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796154.4375\n",
      "Epoch 1612/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 796142.3750\n",
      "Epoch 1613/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796130.3750\n",
      "Epoch 1614/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796118.2500\n",
      "Epoch 1615/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796106.3125\n",
      "Epoch 1616/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796094.1875\n",
      "Epoch 1617/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796082.1875\n",
      "Epoch 1618/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796070.1875\n",
      "Epoch 1619/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796058.1250\n",
      "Epoch 1620/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 796046.0000\n",
      "Epoch 1621/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796033.9375\n",
      "Epoch 1622/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796021.8750\n",
      "Epoch 1623/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 796009.6875\n",
      "Epoch 1624/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 795997.6250\n",
      "Epoch 1625/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795985.5000\n",
      "Epoch 1626/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795973.3125\n",
      "Epoch 1627/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795961.2500\n",
      "Epoch 1628/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795949.0000\n",
      "Epoch 1629/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795936.9375\n",
      "Epoch 1630/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795924.7500\n",
      "Epoch 1631/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795912.6250\n",
      "Epoch 1632/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795900.4375\n",
      "Epoch 1633/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795888.1875\n",
      "Epoch 1634/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795876.0625\n",
      "Epoch 1635/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795863.8750\n",
      "Epoch 1636/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795851.6875\n",
      "Epoch 1637/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795839.5000\n",
      "Epoch 1638/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795827.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1639/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795815.1250\n",
      "Epoch 1640/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795802.8750\n",
      "Epoch 1641/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795790.6250\n",
      "Epoch 1642/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795778.3750\n",
      "Epoch 1643/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795766.0625\n",
      "Epoch 1644/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795753.8125\n",
      "Epoch 1645/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795741.6250\n",
      "Epoch 1646/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795729.3750\n",
      "Epoch 1647/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795717.0625\n",
      "Epoch 1648/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795704.6250\n",
      "Epoch 1649/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795692.4375\n",
      "Epoch 1650/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795680.1250\n",
      "Epoch 1651/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795667.8125\n",
      "Epoch 1652/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795655.5000\n",
      "Epoch 1653/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795643.1875\n",
      "Epoch 1654/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795630.8125\n",
      "Epoch 1655/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795618.5000\n",
      "Epoch 1656/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795606.1250\n",
      "Epoch 1657/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795593.8125\n",
      "Epoch 1658/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795581.3750\n",
      "Epoch 1659/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795569.1250\n",
      "Epoch 1660/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795556.6250\n",
      "Epoch 1661/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795544.3125\n",
      "Epoch 1662/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795531.8750\n",
      "Epoch 1663/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795519.5625\n",
      "Epoch 1664/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795507.0000\n",
      "Epoch 1665/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795494.6875\n",
      "Epoch 1666/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795482.2500\n",
      "Epoch 1667/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795469.8750\n",
      "Epoch 1668/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795457.4375\n",
      "Epoch 1669/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795444.8750\n",
      "Epoch 1670/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795432.5000\n",
      "Epoch 1671/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795420.0625\n",
      "Epoch 1672/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795407.6250\n",
      "Epoch 1673/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795395.0625\n",
      "Epoch 1674/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795382.6875\n",
      "Epoch 1675/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795370.1250\n",
      "Epoch 1676/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795357.6875\n",
      "Epoch 1677/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795345.1875\n",
      "Epoch 1678/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795332.6875\n",
      "Epoch 1679/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795320.1875\n",
      "Epoch 1680/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795307.6250\n",
      "Epoch 1681/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795295.0625\n",
      "Epoch 1682/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795282.5625\n",
      "Epoch 1683/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795270.0000\n",
      "Epoch 1684/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795257.4375\n",
      "Epoch 1685/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795244.8750\n",
      "Epoch 1686/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795232.3750\n",
      "Epoch 1687/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795219.7500\n",
      "Epoch 1688/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795207.2500\n",
      "Epoch 1689/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795194.5625\n",
      "Epoch 1690/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795181.9375\n",
      "Epoch 1691/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795169.3750\n",
      "Epoch 1692/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795156.6875\n",
      "Epoch 1693/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795144.1875\n",
      "Epoch 1694/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795131.5000\n",
      "Epoch 1695/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795118.7500\n",
      "Epoch 1696/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795106.0625\n",
      "Epoch 1697/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795093.5625\n",
      "Epoch 1698/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795080.8750\n",
      "Epoch 1699/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795068.1875\n",
      "Epoch 1700/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795055.5000\n",
      "Epoch 1701/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795042.8750\n",
      "Epoch 1702/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795030.3125\n",
      "Epoch 1703/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 795017.5000\n",
      "Epoch 1704/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 795004.8125\n",
      "Epoch 1705/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794992.0625\n",
      "Epoch 1706/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794979.4375\n",
      "Epoch 1707/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794966.6875\n",
      "Epoch 1708/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794953.8125\n",
      "Epoch 1709/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794941.1250\n",
      "Epoch 1710/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794928.3125\n",
      "Epoch 1711/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794915.6250\n",
      "Epoch 1712/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794902.8750\n",
      "Epoch 1713/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794890.1250\n",
      "Epoch 1714/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794877.3125\n",
      "Epoch 1715/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794864.5625\n",
      "Epoch 1716/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794851.8125\n",
      "Epoch 1717/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794839.0000\n",
      "Epoch 1718/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794826.1875\n",
      "Epoch 1719/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794813.3125\n",
      "Epoch 1720/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794800.5625\n",
      "Epoch 1721/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794787.6875\n",
      "Epoch 1722/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794774.8750\n",
      "Epoch 1723/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794762.0625\n",
      "Epoch 1724/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794749.1875\n",
      "Epoch 1725/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794736.3125\n",
      "Epoch 1726/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794723.3750\n",
      "Epoch 1727/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794710.6250\n",
      "Epoch 1728/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794697.6875\n",
      "Epoch 1729/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794684.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1730/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794671.9375\n",
      "Epoch 1731/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794659.0000\n",
      "Epoch 1732/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794646.0625\n",
      "Epoch 1733/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794633.1250\n",
      "Epoch 1734/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794620.1250\n",
      "Epoch 1735/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794607.1875\n",
      "Epoch 1736/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794594.3125\n",
      "Epoch 1737/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794581.2500\n",
      "Epoch 1738/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794568.3125\n",
      "Epoch 1739/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794555.4375\n",
      "Epoch 1740/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794542.4375\n",
      "Epoch 1741/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794529.4375\n",
      "Epoch 1742/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794516.3750\n",
      "Epoch 1743/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794503.4375\n",
      "Epoch 1744/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 794490.3750\n",
      "Epoch 1745/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794477.3125\n",
      "Epoch 1746/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794464.3750\n",
      "Epoch 1747/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794451.4375\n",
      "Epoch 1748/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794438.3750\n",
      "Epoch 1749/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 794425.1875\n",
      "Epoch 1750/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794412.2500\n",
      "Epoch 1751/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794399.1875\n",
      "Epoch 1752/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794386.2500\n",
      "Epoch 1753/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794373.1875\n",
      "Epoch 1754/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794359.9375\n",
      "Epoch 1755/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794346.8750\n",
      "Epoch 1756/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 794333.7500\n",
      "Epoch 1757/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794320.6250\n",
      "Epoch 1758/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794307.5625\n",
      "Epoch 1759/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794294.4375\n",
      "Epoch 1760/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794281.1875\n",
      "Epoch 1761/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794268.2500\n",
      "Epoch 1762/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794255.0000\n",
      "Epoch 1763/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794241.8750\n",
      "Epoch 1764/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794228.6250\n",
      "Epoch 1765/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794215.5625\n",
      "Epoch 1766/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794202.3750\n",
      "Epoch 1767/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794189.1250\n",
      "Epoch 1768/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794175.9375\n",
      "Epoch 1769/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794162.7500\n",
      "Epoch 1770/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794149.5000\n",
      "Epoch 1771/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794136.3750\n",
      "Epoch 1772/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794123.0625\n",
      "Epoch 1773/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794109.8750\n",
      "Epoch 1774/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794096.6875\n",
      "Epoch 1775/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794083.5000\n",
      "Epoch 1776/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794070.1875\n",
      "Epoch 1777/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794056.9375\n",
      "Epoch 1778/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794043.6250\n",
      "Epoch 1779/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794030.3125\n",
      "Epoch 1780/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 794017.0000\n",
      "Epoch 1781/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 794003.7500\n",
      "Epoch 1782/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793990.5000\n",
      "Epoch 1783/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793977.1875\n",
      "Epoch 1784/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793963.8750\n",
      "Epoch 1785/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793950.6250\n",
      "Epoch 1786/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793937.3125\n",
      "Epoch 1787/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793923.8750\n",
      "Epoch 1788/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793910.5000\n",
      "Epoch 1789/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793897.1875\n",
      "Epoch 1790/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793883.8125\n",
      "Epoch 1791/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793870.4375\n",
      "Epoch 1792/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793857.0625\n",
      "Epoch 1793/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793843.6875\n",
      "Epoch 1794/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793830.2500\n",
      "Epoch 1795/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793816.8125\n",
      "Epoch 1796/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793803.5000\n",
      "Epoch 1797/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793790.1250\n",
      "Epoch 1798/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793776.6875\n",
      "Epoch 1799/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793763.2500\n",
      "Epoch 1800/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793749.8125\n",
      "Epoch 1801/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793736.3125\n",
      "Epoch 1802/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793722.8750\n",
      "Epoch 1803/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793709.5000\n",
      "Epoch 1804/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793696.0000\n",
      "Epoch 1805/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793682.5625\n",
      "Epoch 1806/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 793669.0625\n",
      "Epoch 1807/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 793655.5625\n",
      "Epoch 1808/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793642.0625\n",
      "Epoch 1809/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 793628.5000\n",
      "Epoch 1810/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 793615.0625\n",
      "Epoch 1811/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793601.5000\n",
      "Epoch 1812/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793587.9375\n",
      "Epoch 1813/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793574.4375\n",
      "Epoch 1814/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793560.8750\n",
      "Epoch 1815/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793547.2500\n",
      "Epoch 1816/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793533.7500\n",
      "Epoch 1817/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 793520.2500\n",
      "Epoch 1818/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793506.6250\n",
      "Epoch 1819/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793493.0000\n",
      "Epoch 1820/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793479.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1821/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793465.7500\n",
      "Epoch 1822/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793452.1875\n",
      "Epoch 1823/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793438.5000\n",
      "Epoch 1824/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793424.8750\n",
      "Epoch 1825/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793411.2500\n",
      "Epoch 1826/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793397.6250\n",
      "Epoch 1827/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793384.0625\n",
      "Epoch 1828/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793370.2500\n",
      "Epoch 1829/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793356.6875\n",
      "Epoch 1830/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793342.9375\n",
      "Epoch 1831/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793329.3125\n",
      "Epoch 1832/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793315.6250\n",
      "Epoch 1833/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793301.8750\n",
      "Epoch 1834/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793288.1875\n",
      "Epoch 1835/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793274.5000\n",
      "Epoch 1836/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793260.7500\n",
      "Epoch 1837/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793247.0625\n",
      "Epoch 1838/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793233.3125\n",
      "Epoch 1839/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793219.5625\n",
      "Epoch 1840/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793205.7500\n",
      "Epoch 1841/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 793192.0625\n",
      "Epoch 1842/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793178.3125\n",
      "Epoch 1843/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793164.5000\n",
      "Epoch 1844/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793150.7500\n",
      "Epoch 1845/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793136.9375\n",
      "Epoch 1846/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793123.1875\n",
      "Epoch 1847/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793109.3750\n",
      "Epoch 1848/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 793095.5000\n",
      "Epoch 1849/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793081.7500\n",
      "Epoch 1850/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793067.9375\n",
      "Epoch 1851/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793054.0625\n",
      "Epoch 1852/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 793040.1250\n",
      "Epoch 1853/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793026.3750\n",
      "Epoch 1854/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 793012.4375\n",
      "Epoch 1855/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792998.6250\n",
      "Epoch 1856/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792984.7500\n",
      "Epoch 1857/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792970.8750\n",
      "Epoch 1858/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792956.9375\n",
      "Epoch 1859/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792943.0625\n",
      "Epoch 1860/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792929.1875\n",
      "Epoch 1861/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792915.1875\n",
      "Epoch 1862/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792901.3750\n",
      "Epoch 1863/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792887.4375\n",
      "Epoch 1864/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792873.4375\n",
      "Epoch 1865/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792859.6250\n",
      "Epoch 1866/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792845.5625\n",
      "Epoch 1867/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 792831.6875\n",
      "Epoch 1868/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792817.6250\n",
      "Epoch 1869/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792803.6250\n",
      "Epoch 1870/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792789.7500\n",
      "Epoch 1871/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792775.6250\n",
      "Epoch 1872/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792761.6875\n",
      "Epoch 1873/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792747.6875\n",
      "Epoch 1874/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792733.6250\n",
      "Epoch 1875/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792719.5625\n",
      "Epoch 1876/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792705.6250\n",
      "Epoch 1877/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 792691.5625\n",
      "Epoch 1878/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792677.5000\n",
      "Epoch 1879/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 792663.4375\n",
      "Epoch 1880/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 792649.3750\n",
      "Epoch 1881/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792635.2500\n",
      "Epoch 1882/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792621.1250\n",
      "Epoch 1883/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792607.0000\n",
      "Epoch 1884/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 792592.9375\n",
      "Epoch 1885/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 792578.8750\n",
      "Epoch 1886/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792564.8125\n",
      "Epoch 1887/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792550.5625\n",
      "Epoch 1888/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792536.5000\n",
      "Epoch 1889/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792522.3750\n",
      "Epoch 1890/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792508.1875\n",
      "Epoch 1891/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792494.0625\n",
      "Epoch 1892/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792479.8750\n",
      "Epoch 1893/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 792465.6250\n",
      "Epoch 1894/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792451.5625\n",
      "Epoch 1895/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792437.3750\n",
      "Epoch 1896/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792423.1875\n",
      "Epoch 1897/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792409.0000\n",
      "Epoch 1898/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792394.8125\n",
      "Epoch 1899/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792380.5625\n",
      "Epoch 1900/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792366.3125\n",
      "Epoch 1901/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792352.1250\n",
      "Epoch 1902/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792337.8750\n",
      "Epoch 1903/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792323.5625\n",
      "Epoch 1904/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792309.3750\n",
      "Epoch 1905/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792295.0625\n",
      "Epoch 1906/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792280.7500\n",
      "Epoch 1907/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792266.5000\n",
      "Epoch 1908/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792252.2500\n",
      "Epoch 1909/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792237.9375\n",
      "Epoch 1910/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792223.5000\n",
      "Epoch 1911/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792209.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1912/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792195.0000\n",
      "Epoch 1913/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792180.6250\n",
      "Epoch 1914/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792166.2500\n",
      "Epoch 1915/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792151.9375\n",
      "Epoch 1916/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792137.6250\n",
      "Epoch 1917/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792123.2500\n",
      "Epoch 1918/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792108.9375\n",
      "Epoch 1919/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792094.4375\n",
      "Epoch 1920/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792080.0625\n",
      "Epoch 1921/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792065.6250\n",
      "Epoch 1922/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792051.2500\n",
      "Epoch 1923/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792036.8125\n",
      "Epoch 1924/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 792022.4375\n",
      "Epoch 1925/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 792008.0625\n",
      "Epoch 1926/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791993.5625\n",
      "Epoch 1927/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791979.0625\n",
      "Epoch 1928/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791964.5625\n",
      "Epoch 1929/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791950.1875\n",
      "Epoch 1930/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791935.7500\n",
      "Epoch 1931/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791921.1875\n",
      "Epoch 1932/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791906.7500\n",
      "Epoch 1933/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791892.2500\n",
      "Epoch 1934/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791877.7500\n",
      "Epoch 1935/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791863.3125\n",
      "Epoch 1936/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791848.7500\n",
      "Epoch 1937/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791834.1875\n",
      "Epoch 1938/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791819.6875\n",
      "Epoch 1939/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791805.1250\n",
      "Epoch 1940/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791790.5625\n",
      "Epoch 1941/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791776.0625\n",
      "Epoch 1942/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791761.5000\n",
      "Epoch 1943/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791746.8125\n",
      "Epoch 1944/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791732.2500\n",
      "Epoch 1945/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791717.6250\n",
      "Epoch 1946/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791703.1250\n",
      "Epoch 1947/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791688.4375\n",
      "Epoch 1948/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791673.8125\n",
      "Epoch 1949/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791659.2500\n",
      "Epoch 1950/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 791644.6250\n",
      "Epoch 1951/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791630.0000\n",
      "Epoch 1952/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791615.3125\n",
      "Epoch 1953/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791600.6875\n",
      "Epoch 1954/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791585.9375\n",
      "Epoch 1955/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791571.3750\n",
      "Epoch 1956/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791556.6250\n",
      "Epoch 1957/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791541.9375\n",
      "Epoch 1958/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791527.2500\n",
      "Epoch 1959/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 791512.6250\n",
      "Epoch 1960/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791497.8125\n",
      "Epoch 1961/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791483.1250\n",
      "Epoch 1962/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791468.3750\n",
      "Epoch 1963/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791453.5625\n",
      "Epoch 1964/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791438.9375\n",
      "Epoch 1965/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791424.1250\n",
      "Epoch 1966/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791409.3125\n",
      "Epoch 1967/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791394.5625\n",
      "Epoch 1968/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791379.8125\n",
      "Epoch 1969/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791365.0000\n",
      "Epoch 1970/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791350.1875\n",
      "Epoch 1971/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791335.3750\n",
      "Epoch 1972/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791320.6250\n",
      "Epoch 1973/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791305.8125\n",
      "Epoch 1974/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791290.9375\n",
      "Epoch 1975/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791276.1250\n",
      "Epoch 1976/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791261.2500\n",
      "Epoch 1977/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791246.4375\n",
      "Epoch 1978/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791231.5000\n",
      "Epoch 1979/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791216.6875\n",
      "Epoch 1980/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791201.7500\n",
      "Epoch 1981/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791186.8750\n",
      "Epoch 1982/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791171.9375\n",
      "Epoch 1983/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791157.0625\n",
      "Epoch 1984/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791142.1875\n",
      "Epoch 1985/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791127.2500\n",
      "Epoch 1986/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791112.2500\n",
      "Epoch 1987/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791097.3750\n",
      "Epoch 1988/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791082.3125\n",
      "Epoch 1989/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 791067.4375\n",
      "Epoch 1990/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791052.5000\n",
      "Epoch 1991/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791037.4375\n",
      "Epoch 1992/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 791022.4375\n",
      "Epoch 1993/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 791007.5000\n",
      "Epoch 1994/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790992.5625\n",
      "Epoch 1995/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790977.5000\n",
      "Epoch 1996/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790962.5000\n",
      "Epoch 1997/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790947.4375\n",
      "Epoch 1998/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790932.3750\n",
      "Epoch 1999/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790917.3750\n",
      "Epoch 2000/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790902.4375\n",
      "Epoch 2001/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790887.2500\n",
      "Epoch 2002/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790872.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2003/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790857.2500\n",
      "Epoch 2004/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790842.1250\n",
      "Epoch 2005/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790826.9375\n",
      "Epoch 2006/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790811.8750\n",
      "Epoch 2007/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790796.7500\n",
      "Epoch 2008/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790781.7500\n",
      "Epoch 2009/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790766.6250\n",
      "Epoch 2010/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790751.4375\n",
      "Epoch 2011/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790736.3750\n",
      "Epoch 2012/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790721.1875\n",
      "Epoch 2013/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790706.0625\n",
      "Epoch 2014/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790690.8750\n",
      "Epoch 2015/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 790675.6875\n",
      "Epoch 2016/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790660.6250\n",
      "Epoch 2017/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790645.3750\n",
      "Epoch 2018/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790630.1875\n",
      "Epoch 2019/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790614.9375\n",
      "Epoch 2020/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790599.7500\n",
      "Epoch 2021/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790584.5000\n",
      "Epoch 2022/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790569.3125\n",
      "Epoch 2023/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790554.0000\n",
      "Epoch 2024/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790538.7500\n",
      "Epoch 2025/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790523.4375\n",
      "Epoch 2026/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790508.3125\n",
      "Epoch 2027/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790492.9375\n",
      "Epoch 2028/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790477.6875\n",
      "Epoch 2029/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790462.4375\n",
      "Epoch 2030/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790447.0625\n",
      "Epoch 2031/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790431.7500\n",
      "Epoch 2032/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790416.4375\n",
      "Epoch 2033/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790401.0625\n",
      "Epoch 2034/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790385.7500\n",
      "Epoch 2035/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790370.3750\n",
      "Epoch 2036/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 790355.0625\n",
      "Epoch 2037/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790339.7500\n",
      "Epoch 2038/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790324.2500\n",
      "Epoch 2039/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790308.9375\n",
      "Epoch 2040/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790293.5625\n",
      "Epoch 2041/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790278.2500\n",
      "Epoch 2042/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790262.7500\n",
      "Epoch 2043/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790247.3750\n",
      "Epoch 2044/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790231.8750\n",
      "Epoch 2045/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790216.5625\n",
      "Epoch 2046/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790201.0625\n",
      "Epoch 2047/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790185.6875\n",
      "Epoch 2048/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790170.1875\n",
      "Epoch 2049/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790154.7500\n",
      "Epoch 2050/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790139.2500\n",
      "Epoch 2051/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790123.7500\n",
      "Epoch 2052/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790108.2500\n",
      "Epoch 2053/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790092.7500\n",
      "Epoch 2054/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790077.2500\n",
      "Epoch 2055/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790061.8125\n",
      "Epoch 2056/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790046.3125\n",
      "Epoch 2057/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 790030.7500\n",
      "Epoch 2058/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 790015.2500\n",
      "Epoch 2059/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789999.6250\n",
      "Epoch 2060/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789984.1250\n",
      "Epoch 2061/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789968.5000\n",
      "Epoch 2062/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789953.0000\n",
      "Epoch 2063/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789937.4375\n",
      "Epoch 2064/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789921.8750\n",
      "Epoch 2065/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789906.2500\n",
      "Epoch 2066/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 789890.6250\n",
      "Epoch 2067/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789875.0625\n",
      "Epoch 2068/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789859.4375\n",
      "Epoch 2069/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789843.8125\n",
      "Epoch 2070/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789828.1875\n",
      "Epoch 2071/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789812.5625\n",
      "Epoch 2072/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789796.7500\n",
      "Epoch 2073/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789781.1250\n",
      "Epoch 2074/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789765.5625\n",
      "Epoch 2075/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 789749.8125\n",
      "Epoch 2076/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 789734.0625\n",
      "Epoch 2077/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789718.5000\n",
      "Epoch 2078/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789702.7500\n",
      "Epoch 2079/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789687.0625\n",
      "Epoch 2080/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789671.3125\n",
      "Epoch 2081/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789655.5000\n",
      "Epoch 2082/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789639.8125\n",
      "Epoch 2083/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789624.0625\n",
      "Epoch 2084/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789608.3750\n",
      "Epoch 2085/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 789592.5625\n",
      "Epoch 2086/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789576.7500\n",
      "Epoch 2087/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789561.0000\n",
      "Epoch 2088/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 789545.1875\n",
      "Epoch 2089/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789529.3750\n",
      "Epoch 2090/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789513.5625\n",
      "Epoch 2091/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789497.6250\n",
      "Epoch 2092/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789481.7500\n",
      "Epoch 2093/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789466.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2094/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789450.1875\n",
      "Epoch 2095/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789434.3125\n",
      "Epoch 2096/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789418.4375\n",
      "Epoch 2097/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789402.6250\n",
      "Epoch 2098/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789386.7500\n",
      "Epoch 2099/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 789370.8125\n",
      "Epoch 2100/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789354.9375\n",
      "Epoch 2101/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789339.0000\n",
      "Epoch 2102/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789323.1250\n",
      "Epoch 2103/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789307.1875\n",
      "Epoch 2104/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789291.2500\n",
      "Epoch 2105/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789275.2500\n",
      "Epoch 2106/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789259.3750\n",
      "Epoch 2107/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789243.4375\n",
      "Epoch 2108/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789227.4375\n",
      "Epoch 2109/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789211.4375\n",
      "Epoch 2110/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789195.5000\n",
      "Epoch 2111/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789179.5625\n",
      "Epoch 2112/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789163.5625\n",
      "Epoch 2113/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 789147.5000\n",
      "Epoch 2114/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789131.4375\n",
      "Epoch 2115/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789115.5000\n",
      "Epoch 2116/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789099.4375\n",
      "Epoch 2117/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789083.3125\n",
      "Epoch 2118/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789067.3125\n",
      "Epoch 2119/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 789051.2500\n",
      "Epoch 2120/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789035.1250\n",
      "Epoch 2121/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789019.0625\n",
      "Epoch 2122/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 789003.0000\n",
      "Epoch 2123/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788986.8750\n",
      "Epoch 2124/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788970.6875\n",
      "Epoch 2125/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788954.6875\n",
      "Epoch 2126/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788938.5000\n",
      "Epoch 2127/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788922.3750\n",
      "Epoch 2128/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788906.1875\n",
      "Epoch 2129/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788890.0625\n",
      "Epoch 2130/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788873.8750\n",
      "Epoch 2131/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 788857.7500\n",
      "Epoch 2132/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788841.5000\n",
      "Epoch 2133/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 788825.4375\n",
      "Epoch 2134/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788809.1875\n",
      "Epoch 2135/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788793.0000\n",
      "Epoch 2136/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788776.7500\n",
      "Epoch 2137/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788760.5625\n",
      "Epoch 2138/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788744.2500\n",
      "Epoch 2139/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788728.0625\n",
      "Epoch 2140/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 788711.8750\n",
      "Epoch 2141/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788695.6250\n",
      "Epoch 2142/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788679.3125\n",
      "Epoch 2143/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788663.1250\n",
      "Epoch 2144/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788646.8125\n",
      "Epoch 2145/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788630.4375\n",
      "Epoch 2146/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788614.1250\n",
      "Epoch 2147/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788597.9375\n",
      "Epoch 2148/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788581.5625\n",
      "Epoch 2149/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788565.3125\n",
      "Epoch 2150/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 788548.8125\n",
      "Epoch 2151/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788532.5000\n",
      "Epoch 2152/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788516.1250\n",
      "Epoch 2153/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 788499.8750\n",
      "Epoch 2154/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788483.5625\n",
      "Epoch 2155/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788467.1250\n",
      "Epoch 2156/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788450.7500\n",
      "Epoch 2157/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788434.3750\n",
      "Epoch 2158/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788417.9375\n",
      "Epoch 2159/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788401.4375\n",
      "Epoch 2160/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788385.0000\n",
      "Epoch 2161/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788368.6250\n",
      "Epoch 2162/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788352.2500\n",
      "Epoch 2163/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788335.6875\n",
      "Epoch 2164/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788319.2500\n",
      "Epoch 2165/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788302.8750\n",
      "Epoch 2166/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788286.3750\n",
      "Epoch 2167/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788269.8750\n",
      "Epoch 2168/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788253.3750\n",
      "Epoch 2169/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788236.9375\n",
      "Epoch 2170/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788220.4375\n",
      "Epoch 2171/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788203.9375\n",
      "Epoch 2172/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788187.4375\n",
      "Epoch 2173/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788170.8750\n",
      "Epoch 2174/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788154.1875\n",
      "Epoch 2175/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788137.7500\n",
      "Epoch 2176/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788121.0625\n",
      "Epoch 2177/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788104.4375\n",
      "Epoch 2178/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788087.9375\n",
      "Epoch 2179/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788071.3750\n",
      "Epoch 2180/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788054.8125\n",
      "Epoch 2181/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788038.1250\n",
      "Epoch 2182/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 788021.5625\n",
      "Epoch 2183/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 788004.8750\n",
      "Epoch 2184/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 787988.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2185/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 787971.5625\n",
      "Epoch 2186/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 787954.9375\n",
      "Epoch 2187/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 787938.3125\n",
      "Epoch 2188/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787921.5625\n",
      "Epoch 2189/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787905.0000\n",
      "Epoch 2190/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 787888.2500\n",
      "Epoch 2191/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787871.4375\n",
      "Epoch 2192/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787854.7500\n",
      "Epoch 2193/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 787838.0000\n",
      "Epoch 2194/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787821.3750\n",
      "Epoch 2195/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787804.5625\n",
      "Epoch 2196/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787787.8750\n",
      "Epoch 2197/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 787771.1875\n",
      "Epoch 2198/3000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 787754.3750\n",
      "Epoch 2199/3000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 787737.5625\n",
      "Epoch 2200/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787720.8750\n",
      "Epoch 2201/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 787704.0625\n",
      "Epoch 2202/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787687.2500\n",
      "Epoch 2203/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787670.3750\n",
      "Epoch 2204/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787653.6250\n",
      "Epoch 2205/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787636.8125\n",
      "Epoch 2206/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787620.0625\n",
      "Epoch 2207/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787603.1875\n",
      "Epoch 2208/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787586.3125\n",
      "Epoch 2209/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787569.4375\n",
      "Epoch 2210/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787552.6250\n",
      "Epoch 2211/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787535.6875\n",
      "Epoch 2212/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787518.8750\n",
      "Epoch 2213/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787501.9375\n",
      "Epoch 2214/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787485.0000\n",
      "Epoch 2215/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787468.0000\n",
      "Epoch 2216/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787451.1250\n",
      "Epoch 2217/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787434.2500\n",
      "Epoch 2218/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787417.2500\n",
      "Epoch 2219/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787400.3125\n",
      "Epoch 2220/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787383.3750\n",
      "Epoch 2221/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787366.3125\n",
      "Epoch 2222/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787349.2500\n",
      "Epoch 2223/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 787332.3125\n",
      "Epoch 2224/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787315.3125\n",
      "Epoch 2225/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 787298.3750\n",
      "Epoch 2226/3000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 787281.3750\n",
      "Epoch 2227/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787264.3125\n",
      "Epoch 2228/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787247.2500\n",
      "Epoch 2229/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787230.3125\n",
      "Epoch 2230/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787213.2500\n",
      "Epoch 2231/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787196.1250\n",
      "Epoch 2232/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787179.0625\n",
      "Epoch 2233/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787162.0000\n",
      "Epoch 2234/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787144.9375\n",
      "Epoch 2235/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787127.8750\n",
      "Epoch 2236/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787110.8125\n",
      "Epoch 2237/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787093.6250\n",
      "Epoch 2238/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787076.5625\n",
      "Epoch 2239/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787059.4375\n",
      "Epoch 2240/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 787042.2500\n",
      "Epoch 2241/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787025.1250\n",
      "Epoch 2242/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 787007.8750\n",
      "Epoch 2243/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786990.8125\n",
      "Epoch 2244/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786973.5000\n",
      "Epoch 2245/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786956.3125\n",
      "Epoch 2246/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786939.1875\n",
      "Epoch 2247/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 786921.9375\n",
      "Epoch 2248/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786904.7500\n",
      "Epoch 2249/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 786887.5000\n",
      "Epoch 2250/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786870.3125\n",
      "Epoch 2251/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 786853.1250\n",
      "Epoch 2252/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786835.8750\n",
      "Epoch 2253/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786818.6250\n",
      "Epoch 2254/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786801.3125\n",
      "Epoch 2255/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786784.0000\n",
      "Epoch 2256/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786766.6875\n",
      "Epoch 2257/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786749.3750\n",
      "Epoch 2258/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786732.1250\n",
      "Epoch 2259/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786714.7500\n",
      "Epoch 2260/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786697.3750\n",
      "Epoch 2261/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786680.1250\n",
      "Epoch 2262/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786662.6250\n",
      "Epoch 2263/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786645.3750\n",
      "Epoch 2264/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786628.0000\n",
      "Epoch 2265/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786610.6250\n",
      "Epoch 2266/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786593.3125\n",
      "Epoch 2267/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786575.8750\n",
      "Epoch 2268/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786558.5000\n",
      "Epoch 2269/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786541.0000\n",
      "Epoch 2270/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786523.6250\n",
      "Epoch 2271/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786506.2500\n",
      "Epoch 2272/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786488.7500\n",
      "Epoch 2273/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786471.4375\n",
      "Epoch 2274/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786453.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2275/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786436.4375\n",
      "Epoch 2276/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786418.8750\n",
      "Epoch 2277/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 786401.4375\n",
      "Epoch 2278/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786383.9375\n",
      "Epoch 2279/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786366.5000\n",
      "Epoch 2280/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786348.9375\n",
      "Epoch 2281/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786331.5000\n",
      "Epoch 2282/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786313.8750\n",
      "Epoch 2283/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786296.3125\n",
      "Epoch 2284/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786278.7500\n",
      "Epoch 2285/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786261.1875\n",
      "Epoch 2286/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786243.7500\n",
      "Epoch 2287/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786226.0625\n",
      "Epoch 2288/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786208.5000\n",
      "Epoch 2289/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786190.9375\n",
      "Epoch 2290/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786173.2500\n",
      "Epoch 2291/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786155.6875\n",
      "Epoch 2292/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786138.1250\n",
      "Epoch 2293/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786120.4375\n",
      "Epoch 2294/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786102.8125\n",
      "Epoch 2295/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 786085.1875\n",
      "Epoch 2296/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786067.5625\n",
      "Epoch 2297/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 786049.8750\n",
      "Epoch 2298/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786032.1250\n",
      "Epoch 2299/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 786014.5000\n",
      "Epoch 2300/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785996.7500\n",
      "Epoch 2301/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785979.0625\n",
      "Epoch 2302/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785961.3750\n",
      "Epoch 2303/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785943.6250\n",
      "Epoch 2304/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785925.8125\n",
      "Epoch 2305/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785908.1250\n",
      "Epoch 2306/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785890.3125\n",
      "Epoch 2307/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785872.6875\n",
      "Epoch 2308/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785854.8125\n",
      "Epoch 2309/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785837.0625\n",
      "Epoch 2310/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785819.3125\n",
      "Epoch 2311/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785801.4375\n",
      "Epoch 2312/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785783.6250\n",
      "Epoch 2313/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785765.8125\n",
      "Epoch 2314/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785748.0000\n",
      "Epoch 2315/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785730.1250\n",
      "Epoch 2316/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785712.3125\n",
      "Epoch 2317/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785694.4375\n",
      "Epoch 2318/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785676.6250\n",
      "Epoch 2319/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785658.6875\n",
      "Epoch 2320/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785640.7500\n",
      "Epoch 2321/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 785622.9375\n",
      "Epoch 2322/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785604.9375\n",
      "Epoch 2323/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785587.1250\n",
      "Epoch 2324/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785569.1875\n",
      "Epoch 2325/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785551.2500\n",
      "Epoch 2326/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785533.2500\n",
      "Epoch 2327/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785515.3750\n",
      "Epoch 2328/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785497.4375\n",
      "Epoch 2329/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785479.5000\n",
      "Epoch 2330/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785461.5625\n",
      "Epoch 2331/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785443.5000\n",
      "Epoch 2332/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785425.3750\n",
      "Epoch 2333/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785407.4375\n",
      "Epoch 2334/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785389.4375\n",
      "Epoch 2335/3000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 785371.3750\n",
      "Epoch 2336/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785353.3750\n",
      "Epoch 2337/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785335.3750\n",
      "Epoch 2338/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785317.2500\n",
      "Epoch 2339/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785299.1875\n",
      "Epoch 2340/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785281.0625\n",
      "Epoch 2341/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785263.1250\n",
      "Epoch 2342/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785245.0000\n",
      "Epoch 2343/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785226.8750\n",
      "Epoch 2344/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785208.8750\n",
      "Epoch 2345/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785190.7500\n",
      "Epoch 2346/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785172.5625\n",
      "Epoch 2347/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 785154.3125\n",
      "Epoch 2348/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785136.2500\n",
      "Epoch 2349/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785118.0625\n",
      "Epoch 2350/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785099.8750\n",
      "Epoch 2351/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 785081.6875\n",
      "Epoch 2352/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785063.6250\n",
      "Epoch 2353/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785045.2500\n",
      "Epoch 2354/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 785027.0625\n",
      "Epoch 2355/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 785008.9375\n",
      "Epoch 2356/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784990.6875\n",
      "Epoch 2357/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784972.4375\n",
      "Epoch 2358/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784954.2500\n",
      "Epoch 2359/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784935.9375\n",
      "Epoch 2360/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784917.6250\n",
      "Epoch 2361/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784899.3750\n",
      "Epoch 2362/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784881.0625\n",
      "Epoch 2363/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784862.7500\n",
      "Epoch 2364/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784844.5000\n",
      "Epoch 2365/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784826.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2366/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784807.7500\n",
      "Epoch 2367/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784789.5000\n",
      "Epoch 2368/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784771.1875\n",
      "Epoch 2369/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784752.8125\n",
      "Epoch 2370/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784734.3750\n",
      "Epoch 2371/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784716.1250\n",
      "Epoch 2372/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784697.6875\n",
      "Epoch 2373/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784679.3125\n",
      "Epoch 2374/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784660.9375\n",
      "Epoch 2375/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 784642.5625\n",
      "Epoch 2376/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784624.0625\n",
      "Epoch 2377/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784605.6250\n",
      "Epoch 2378/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 784587.2500\n",
      "Epoch 2379/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784568.8125\n",
      "Epoch 2380/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784550.3750\n",
      "Epoch 2381/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784531.8750\n",
      "Epoch 2382/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784513.4375\n",
      "Epoch 2383/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784494.9375\n",
      "Epoch 2384/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784476.4375\n",
      "Epoch 2385/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784457.9375\n",
      "Epoch 2386/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784439.3750\n",
      "Epoch 2387/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784420.7500\n",
      "Epoch 2388/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784402.3750\n",
      "Epoch 2389/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784383.7500\n",
      "Epoch 2390/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784365.2500\n",
      "Epoch 2391/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784346.6250\n",
      "Epoch 2392/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784328.1250\n",
      "Epoch 2393/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784309.6250\n",
      "Epoch 2394/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784290.9375\n",
      "Epoch 2395/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784272.3750\n",
      "Epoch 2396/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784253.8125\n",
      "Epoch 2397/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 784235.1250\n",
      "Epoch 2398/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784216.5625\n",
      "Epoch 2399/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784197.8125\n",
      "Epoch 2400/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784179.1250\n",
      "Epoch 2401/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784160.5000\n",
      "Epoch 2402/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784141.8125\n",
      "Epoch 2403/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784123.1875\n",
      "Epoch 2404/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784104.4375\n",
      "Epoch 2405/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 784085.6875\n",
      "Epoch 2406/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784067.0625\n",
      "Epoch 2407/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 784048.4375\n",
      "Epoch 2408/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784029.6875\n",
      "Epoch 2409/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 784010.9375\n",
      "Epoch 2410/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783992.1875\n",
      "Epoch 2411/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783973.5000\n",
      "Epoch 2412/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783954.6875\n",
      "Epoch 2413/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783935.8750\n",
      "Epoch 2414/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783917.0625\n",
      "Epoch 2415/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783898.3125\n",
      "Epoch 2416/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783879.5000\n",
      "Epoch 2417/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783860.6250\n",
      "Epoch 2418/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783841.8750\n",
      "Epoch 2419/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783823.0625\n",
      "Epoch 2420/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783804.2500\n",
      "Epoch 2421/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783785.3750\n",
      "Epoch 2422/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783766.3750\n",
      "Epoch 2423/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783747.6250\n",
      "Epoch 2424/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783728.6875\n",
      "Epoch 2425/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783709.8125\n",
      "Epoch 2426/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783690.8750\n",
      "Epoch 2427/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783671.9375\n",
      "Epoch 2428/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783652.9375\n",
      "Epoch 2429/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783634.1250\n",
      "Epoch 2430/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783615.1875\n",
      "Epoch 2431/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783596.2500\n",
      "Epoch 2432/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783577.3125\n",
      "Epoch 2433/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783558.3125\n",
      "Epoch 2434/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783539.3750\n",
      "Epoch 2435/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783520.2500\n",
      "Epoch 2436/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783501.3125\n",
      "Epoch 2437/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783482.2500\n",
      "Epoch 2438/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783463.2500\n",
      "Epoch 2439/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783444.2500\n",
      "Epoch 2440/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783425.2500\n",
      "Epoch 2441/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783406.1250\n",
      "Epoch 2442/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783387.0625\n",
      "Epoch 2443/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783367.9375\n",
      "Epoch 2444/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783348.8750\n",
      "Epoch 2445/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783329.8125\n",
      "Epoch 2446/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783310.7500\n",
      "Epoch 2447/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783291.6250\n",
      "Epoch 2448/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783272.5625\n",
      "Epoch 2449/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783253.3750\n",
      "Epoch 2450/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 783234.2500\n",
      "Epoch 2451/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783215.0625\n",
      "Epoch 2452/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783195.8125\n",
      "Epoch 2453/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783176.7500\n",
      "Epoch 2454/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783157.5000\n",
      "Epoch 2455/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 783138.3750\n",
      "Epoch 2456/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 783119.1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2457/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783100.0000\n",
      "Epoch 2458/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783080.7500\n",
      "Epoch 2459/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 783061.5625\n",
      "Epoch 2460/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783042.3125\n",
      "Epoch 2461/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 783023.0625\n",
      "Epoch 2462/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 783003.8750\n",
      "Epoch 2463/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782984.5625\n",
      "Epoch 2464/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 782965.3125\n",
      "Epoch 2465/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782946.0000\n",
      "Epoch 2466/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782926.6875\n",
      "Epoch 2467/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782907.3750\n",
      "Epoch 2468/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782888.1250\n",
      "Epoch 2469/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782868.7500\n",
      "Epoch 2470/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782849.3125\n",
      "Epoch 2471/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782830.0625\n",
      "Epoch 2472/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782810.6875\n",
      "Epoch 2473/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782791.2500\n",
      "Epoch 2474/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782771.9375\n",
      "Epoch 2475/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782752.5625\n",
      "Epoch 2476/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782733.1250\n",
      "Epoch 2477/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782713.7500\n",
      "Epoch 2478/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782694.2500\n",
      "Epoch 2479/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782674.8750\n",
      "Epoch 2480/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782655.4375\n",
      "Epoch 2481/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782635.9375\n",
      "Epoch 2482/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782616.4375\n",
      "Epoch 2483/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782597.0625\n",
      "Epoch 2484/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782577.5625\n",
      "Epoch 2485/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782558.0625\n",
      "Epoch 2486/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782538.5000\n",
      "Epoch 2487/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782519.0625\n",
      "Epoch 2488/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782499.5625\n",
      "Epoch 2489/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782480.0625\n",
      "Epoch 2490/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 782460.4375\n",
      "Epoch 2491/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782440.8750\n",
      "Epoch 2492/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782421.3125\n",
      "Epoch 2493/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782401.7500\n",
      "Epoch 2494/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782382.1875\n",
      "Epoch 2495/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782362.5625\n",
      "Epoch 2496/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782343.0000\n",
      "Epoch 2497/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782323.4375\n",
      "Epoch 2498/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782303.8125\n",
      "Epoch 2499/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782284.1250\n",
      "Epoch 2500/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782264.5000\n",
      "Epoch 2501/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782244.8750\n",
      "Epoch 2502/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782225.1875\n",
      "Epoch 2503/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782205.5625\n",
      "Epoch 2504/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782185.8750\n",
      "Epoch 2505/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 782166.0625\n",
      "Epoch 2506/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 782146.5000\n",
      "Epoch 2507/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782126.7500\n",
      "Epoch 2508/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 782107.0000\n",
      "Epoch 2509/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782087.2500\n",
      "Epoch 2510/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782067.5000\n",
      "Epoch 2511/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782047.8125\n",
      "Epoch 2512/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 782028.0625\n",
      "Epoch 2513/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 782008.3125\n",
      "Epoch 2514/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781988.5625\n",
      "Epoch 2515/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781968.6875\n",
      "Epoch 2516/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781948.9375\n",
      "Epoch 2517/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781929.1250\n",
      "Epoch 2518/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 781909.2500\n",
      "Epoch 2519/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781889.4375\n",
      "Epoch 2520/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781869.6250\n",
      "Epoch 2521/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781849.6875\n",
      "Epoch 2522/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781829.8750\n",
      "Epoch 2523/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781809.9375\n",
      "Epoch 2524/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781790.1250\n",
      "Epoch 2525/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781770.1250\n",
      "Epoch 2526/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781750.3125\n",
      "Epoch 2527/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781730.3125\n",
      "Epoch 2528/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781710.5000\n",
      "Epoch 2529/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781690.5000\n",
      "Epoch 2530/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 781670.5625\n",
      "Epoch 2531/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781650.6250\n",
      "Epoch 2532/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781630.5625\n",
      "Epoch 2533/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781610.6250\n",
      "Epoch 2534/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781590.6875\n",
      "Epoch 2535/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781570.6250\n",
      "Epoch 2536/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781550.6875\n",
      "Epoch 2537/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781530.6875\n",
      "Epoch 2538/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781510.6250\n",
      "Epoch 2539/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781490.6250\n",
      "Epoch 2540/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781470.5000\n",
      "Epoch 2541/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781450.5000\n",
      "Epoch 2542/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781430.3750\n",
      "Epoch 2543/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781410.4375\n",
      "Epoch 2544/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781390.2500\n",
      "Epoch 2545/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781370.1250\n",
      "Epoch 2546/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781350.0625\n",
      "Epoch 2547/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781329.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2548/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781309.7500\n",
      "Epoch 2549/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781289.6250\n",
      "Epoch 2550/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781269.3750\n",
      "Epoch 2551/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781249.3750\n",
      "Epoch 2552/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 781229.1875\n",
      "Epoch 2553/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 781208.9375\n",
      "Epoch 2554/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781188.6875\n",
      "Epoch 2555/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781168.5000\n",
      "Epoch 2556/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781148.2500\n",
      "Epoch 2557/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781128.1250\n",
      "Epoch 2558/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781107.8750\n",
      "Epoch 2559/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781087.6250\n",
      "Epoch 2560/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781067.3125\n",
      "Epoch 2561/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781047.1250\n",
      "Epoch 2562/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 781026.8750\n",
      "Epoch 2563/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 781006.5625\n",
      "Epoch 2564/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780986.2500\n",
      "Epoch 2565/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780965.8750\n",
      "Epoch 2566/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780945.5625\n",
      "Epoch 2567/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780925.3125\n",
      "Epoch 2568/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780905.0000\n",
      "Epoch 2569/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780884.6250\n",
      "Epoch 2570/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 780864.2500\n",
      "Epoch 2571/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780843.9375\n",
      "Epoch 2572/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780823.5000\n",
      "Epoch 2573/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780803.1875\n",
      "Epoch 2574/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 780782.7500\n",
      "Epoch 2575/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780762.3750\n",
      "Epoch 2576/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 780741.9375\n",
      "Epoch 2577/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780721.5625\n",
      "Epoch 2578/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780701.0625\n",
      "Epoch 2579/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780680.6250\n",
      "Epoch 2580/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780660.1875\n",
      "Epoch 2581/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780639.8125\n",
      "Epoch 2582/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780619.2500\n",
      "Epoch 2583/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780598.6875\n",
      "Epoch 2584/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780578.1875\n",
      "Epoch 2585/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780557.6875\n",
      "Epoch 2586/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780537.1250\n",
      "Epoch 2587/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780516.6875\n",
      "Epoch 2588/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780496.0625\n",
      "Epoch 2589/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780475.4375\n",
      "Epoch 2590/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780454.8750\n",
      "Epoch 2591/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780434.2500\n",
      "Epoch 2592/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780413.7500\n",
      "Epoch 2593/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780393.1250\n",
      "Epoch 2594/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780372.5000\n",
      "Epoch 2595/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780351.9375\n",
      "Epoch 2596/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780331.2500\n",
      "Epoch 2597/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780310.6875\n",
      "Epoch 2598/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780290.0000\n",
      "Epoch 2599/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780269.5000\n",
      "Epoch 2600/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780248.6875\n",
      "Epoch 2601/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780228.0000\n",
      "Epoch 2602/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780207.3125\n",
      "Epoch 2603/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780186.6250\n",
      "Epoch 2604/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780165.8750\n",
      "Epoch 2605/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780145.1875\n",
      "Epoch 2606/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780124.5000\n",
      "Epoch 2607/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 780103.6250\n",
      "Epoch 2608/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780082.8750\n",
      "Epoch 2609/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780062.1875\n",
      "Epoch 2610/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780041.3750\n",
      "Epoch 2611/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 780020.6250\n",
      "Epoch 2612/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779999.8125\n",
      "Epoch 2613/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779979.0000\n",
      "Epoch 2614/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779958.2500\n",
      "Epoch 2615/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779937.3750\n",
      "Epoch 2616/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779916.5625\n",
      "Epoch 2617/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779895.7500\n",
      "Epoch 2618/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779874.8750\n",
      "Epoch 2619/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779853.8750\n",
      "Epoch 2620/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779833.0625\n",
      "Epoch 2621/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779812.1875\n",
      "Epoch 2622/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779791.3125\n",
      "Epoch 2623/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779770.3750\n",
      "Epoch 2624/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779749.4375\n",
      "Epoch 2625/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779728.5625\n",
      "Epoch 2626/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779707.5625\n",
      "Epoch 2627/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779686.7500\n",
      "Epoch 2628/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779665.6250\n",
      "Epoch 2629/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779644.6250\n",
      "Epoch 2630/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779623.7500\n",
      "Epoch 2631/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779602.6875\n",
      "Epoch 2632/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779581.6875\n",
      "Epoch 2633/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779560.6875\n",
      "Epoch 2634/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779539.6250\n",
      "Epoch 2635/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779518.5625\n",
      "Epoch 2636/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779497.6250\n",
      "Epoch 2637/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779476.5000\n",
      "Epoch 2638/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779455.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2639/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779434.3125\n",
      "Epoch 2640/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779413.1875\n",
      "Epoch 2641/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779392.0000\n",
      "Epoch 2642/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779371.0625\n",
      "Epoch 2643/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779349.8750\n",
      "Epoch 2644/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779328.7500\n",
      "Epoch 2645/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779307.6250\n",
      "Epoch 2646/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779286.4375\n",
      "Epoch 2647/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779265.3125\n",
      "Epoch 2648/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779244.1250\n",
      "Epoch 2649/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779222.9375\n",
      "Epoch 2650/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779201.6250\n",
      "Epoch 2651/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779180.4375\n",
      "Epoch 2652/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779159.3125\n",
      "Epoch 2653/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779138.0625\n",
      "Epoch 2654/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 779116.8125\n",
      "Epoch 2655/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779095.5000\n",
      "Epoch 2656/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779074.2500\n",
      "Epoch 2657/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779053.0000\n",
      "Epoch 2658/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779031.7500\n",
      "Epoch 2659/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 779010.4375\n",
      "Epoch 2660/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778989.0000\n",
      "Epoch 2661/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778967.7500\n",
      "Epoch 2662/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778946.3750\n",
      "Epoch 2663/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778925.0000\n",
      "Epoch 2664/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 778903.6875\n",
      "Epoch 2665/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778882.3750\n",
      "Epoch 2666/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778861.0625\n",
      "Epoch 2667/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778839.6875\n",
      "Epoch 2668/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 778818.2500\n",
      "Epoch 2669/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778796.8125\n",
      "Epoch 2670/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778775.3750\n",
      "Epoch 2671/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778754.0000\n",
      "Epoch 2672/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 778732.5625\n",
      "Epoch 2673/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778711.0625\n",
      "Epoch 2674/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778689.6250\n",
      "Epoch 2675/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778668.1875\n",
      "Epoch 2676/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778646.6875\n",
      "Epoch 2677/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778625.2500\n",
      "Epoch 2678/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 778603.6875\n",
      "Epoch 2679/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778582.2500\n",
      "Epoch 2680/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778560.7500\n",
      "Epoch 2681/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778539.1250\n",
      "Epoch 2682/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778517.5625\n",
      "Epoch 2683/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778496.0625\n",
      "Epoch 2684/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778474.4375\n",
      "Epoch 2685/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778452.9375\n",
      "Epoch 2686/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778431.3125\n",
      "Epoch 2687/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778409.6875\n",
      "Epoch 2688/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778388.1250\n",
      "Epoch 2689/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778366.4375\n",
      "Epoch 2690/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778344.7500\n",
      "Epoch 2691/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778323.1875\n",
      "Epoch 2692/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778301.6250\n",
      "Epoch 2693/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778279.8750\n",
      "Epoch 2694/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778258.1250\n",
      "Epoch 2695/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 778236.5000\n",
      "Epoch 2696/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778214.8125\n",
      "Epoch 2697/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778193.1250\n",
      "Epoch 2698/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 778171.4375\n",
      "Epoch 2699/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778149.6250\n",
      "Epoch 2700/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778127.9375\n",
      "Epoch 2701/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778106.1875\n",
      "Epoch 2702/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778084.3125\n",
      "Epoch 2703/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 778062.5625\n",
      "Epoch 2704/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778040.8125\n",
      "Epoch 2705/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 778019.0625\n",
      "Epoch 2706/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777997.1875\n",
      "Epoch 2707/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777975.4375\n",
      "Epoch 2708/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777953.6250\n",
      "Epoch 2709/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777931.6875\n",
      "Epoch 2710/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777909.8750\n",
      "Epoch 2711/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777888.0625\n",
      "Epoch 2712/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 777866.1875\n",
      "Epoch 2713/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777844.1875\n",
      "Epoch 2714/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777822.4375\n",
      "Epoch 2715/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777800.4375\n",
      "Epoch 2716/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 777778.5625\n",
      "Epoch 2717/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777756.5625\n",
      "Epoch 2718/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 777734.6250\n",
      "Epoch 2719/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 777712.7500\n",
      "Epoch 2720/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777690.7500\n",
      "Epoch 2721/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777668.8125\n",
      "Epoch 2722/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777646.8125\n",
      "Epoch 2723/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777624.8750\n",
      "Epoch 2724/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777602.8125\n",
      "Epoch 2725/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777580.8125\n",
      "Epoch 2726/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777558.7500\n",
      "Epoch 2727/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777536.7500\n",
      "Epoch 2728/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777514.7500\n",
      "Epoch 2729/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 6us/step - loss: 777492.6250\n",
      "Epoch 2730/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 777470.5625\n",
      "Epoch 2731/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777448.5000\n",
      "Epoch 2732/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777426.4375\n",
      "Epoch 2733/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 777404.3125\n",
      "Epoch 2734/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777382.1875\n",
      "Epoch 2735/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777360.0625\n",
      "Epoch 2736/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 777337.8750\n",
      "Epoch 2737/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777315.8125\n",
      "Epoch 2738/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777293.6250\n",
      "Epoch 2739/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777271.3750\n",
      "Epoch 2740/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777249.2500\n",
      "Epoch 2741/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777227.0625\n",
      "Epoch 2742/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777204.8125\n",
      "Epoch 2743/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777182.6250\n",
      "Epoch 2744/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777160.3750\n",
      "Epoch 2745/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777138.1250\n",
      "Epoch 2746/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777115.8125\n",
      "Epoch 2747/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777093.6875\n",
      "Epoch 2748/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 777071.3750\n",
      "Epoch 2749/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777049.0625\n",
      "Epoch 2750/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777026.8125\n",
      "Epoch 2751/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 777004.5000\n",
      "Epoch 2752/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776982.2500\n",
      "Epoch 2753/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776959.8125\n",
      "Epoch 2754/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776937.5000\n",
      "Epoch 2755/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776915.1875\n",
      "Epoch 2756/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776892.8125\n",
      "Epoch 2757/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776870.4375\n",
      "Epoch 2758/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776848.1250\n",
      "Epoch 2759/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776825.7500\n",
      "Epoch 2760/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776803.3125\n",
      "Epoch 2761/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 776780.8750\n",
      "Epoch 2762/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 776758.4375\n",
      "Epoch 2763/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776736.0000\n",
      "Epoch 2764/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776713.6250\n",
      "Epoch 2765/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776691.0625\n",
      "Epoch 2766/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776668.6875\n",
      "Epoch 2767/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776646.1875\n",
      "Epoch 2768/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776623.6250\n",
      "Epoch 2769/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776601.1250\n",
      "Epoch 2770/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776578.6250\n",
      "Epoch 2771/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776556.1250\n",
      "Epoch 2772/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776533.5000\n",
      "Epoch 2773/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776511.0000\n",
      "Epoch 2774/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776488.5000\n",
      "Epoch 2775/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776466.0000\n",
      "Epoch 2776/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776443.3125\n",
      "Epoch 2777/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776420.7500\n",
      "Epoch 2778/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776398.1250\n",
      "Epoch 2779/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776375.5000\n",
      "Epoch 2780/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 776353.0000\n",
      "Epoch 2781/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776330.3750\n",
      "Epoch 2782/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776307.6250\n",
      "Epoch 2783/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 776284.8750\n",
      "Epoch 2784/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776262.1875\n",
      "Epoch 2785/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 776239.6250\n",
      "Epoch 2786/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776216.9375\n",
      "Epoch 2787/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776194.1875\n",
      "Epoch 2788/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776171.5000\n",
      "Epoch 2789/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776148.8125\n",
      "Epoch 2790/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776125.9375\n",
      "Epoch 2791/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776103.2500\n",
      "Epoch 2792/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776080.5000\n",
      "Epoch 2793/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776057.7500\n",
      "Epoch 2794/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 776035.0000\n",
      "Epoch 2795/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 776012.1875\n",
      "Epoch 2796/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775989.3750\n",
      "Epoch 2797/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775966.5625\n",
      "Epoch 2798/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775943.6875\n",
      "Epoch 2799/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775920.8125\n",
      "Epoch 2800/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775898.0000\n",
      "Epoch 2801/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775875.0625\n",
      "Epoch 2802/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775852.2500\n",
      "Epoch 2803/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775829.3750\n",
      "Epoch 2804/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775806.4375\n",
      "Epoch 2805/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 775783.4375\n",
      "Epoch 2806/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775760.6250\n",
      "Epoch 2807/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775737.6875\n",
      "Epoch 2808/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 775714.8125\n",
      "Epoch 2809/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775691.8125\n",
      "Epoch 2810/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775668.7500\n",
      "Epoch 2811/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775645.8750\n",
      "Epoch 2812/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775622.8750\n",
      "Epoch 2813/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775599.8750\n",
      "Epoch 2814/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775576.8125\n",
      "Epoch 2815/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775553.8750\n",
      "Epoch 2816/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775530.7500\n",
      "Epoch 2817/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775507.7500\n",
      "Epoch 2818/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775484.6875\n",
      "Epoch 2819/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775461.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2820/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775438.5625\n",
      "Epoch 2821/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775415.4375\n",
      "Epoch 2822/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775392.3750\n",
      "Epoch 2823/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775369.2500\n",
      "Epoch 2824/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 775346.1875\n",
      "Epoch 2825/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775323.0625\n",
      "Epoch 2826/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775300.0000\n",
      "Epoch 2827/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 775276.6875\n",
      "Epoch 2828/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775253.5625\n",
      "Epoch 2829/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775230.3750\n",
      "Epoch 2830/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 775207.2500\n",
      "Epoch 2831/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775184.0625\n",
      "Epoch 2832/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775160.7500\n",
      "Epoch 2833/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775137.6875\n",
      "Epoch 2834/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775114.4375\n",
      "Epoch 2835/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775091.1875\n",
      "Epoch 2836/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 775067.8750\n",
      "Epoch 2837/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 775044.5625\n",
      "Epoch 2838/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 775021.3125\n",
      "Epoch 2839/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774997.8750\n",
      "Epoch 2840/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774974.5625\n",
      "Epoch 2841/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774951.3125\n",
      "Epoch 2842/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774928.0625\n",
      "Epoch 2843/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774904.6875\n",
      "Epoch 2844/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774881.3750\n",
      "Epoch 2845/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774857.9375\n",
      "Epoch 2846/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774834.6250\n",
      "Epoch 2847/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774811.1875\n",
      "Epoch 2848/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774787.7500\n",
      "Epoch 2849/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774764.3750\n",
      "Epoch 2850/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774740.8750\n",
      "Epoch 2851/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 774717.5000\n",
      "Epoch 2852/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774694.0625\n",
      "Epoch 2853/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774670.5625\n",
      "Epoch 2854/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774647.1875\n",
      "Epoch 2855/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774623.6875\n",
      "Epoch 2856/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774600.1875\n",
      "Epoch 2857/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774576.7500\n",
      "Epoch 2858/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774553.2500\n",
      "Epoch 2859/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 774529.6250\n",
      "Epoch 2860/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774506.1250\n",
      "Epoch 2861/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774482.5625\n",
      "Epoch 2862/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774459.0625\n",
      "Epoch 2863/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774435.5000\n",
      "Epoch 2864/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774411.8750\n",
      "Epoch 2865/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774388.2500\n",
      "Epoch 2866/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774364.7500\n",
      "Epoch 2867/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774341.1250\n",
      "Epoch 2868/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774317.5000\n",
      "Epoch 2869/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774293.8125\n",
      "Epoch 2870/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774270.1875\n",
      "Epoch 2871/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774246.5625\n",
      "Epoch 2872/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774222.8125\n",
      "Epoch 2873/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 774199.1875\n",
      "Epoch 2874/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774175.4375\n",
      "Epoch 2875/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774151.7500\n",
      "Epoch 2876/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 774128.0000\n",
      "Epoch 2877/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774104.3750\n",
      "Epoch 2878/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774080.6250\n",
      "Epoch 2879/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 774056.8750\n",
      "Epoch 2880/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 774033.0625\n",
      "Epoch 2881/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 774009.3125\n",
      "Epoch 2882/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 773985.4375\n",
      "Epoch 2883/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773961.6875\n",
      "Epoch 2884/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773937.8750\n",
      "Epoch 2885/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773914.0000\n",
      "Epoch 2886/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773890.1875\n",
      "Epoch 2887/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773866.3750\n",
      "Epoch 2888/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773842.5000\n",
      "Epoch 2889/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773818.6250\n",
      "Epoch 2890/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773794.7500\n",
      "Epoch 2891/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773770.8125\n",
      "Epoch 2892/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773746.9375\n",
      "Epoch 2893/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773723.0000\n",
      "Epoch 2894/3000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 773699.0625\n",
      "Epoch 2895/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 773675.1875\n",
      "Epoch 2896/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773651.1875\n",
      "Epoch 2897/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773627.1875\n",
      "Epoch 2898/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773603.3125\n",
      "Epoch 2899/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773579.2500\n",
      "Epoch 2900/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773555.2500\n",
      "Epoch 2901/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773531.3125\n",
      "Epoch 2902/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773507.1875\n",
      "Epoch 2903/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 773483.1250\n",
      "Epoch 2904/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773459.0625\n",
      "Epoch 2905/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 773435.0000\n",
      "Epoch 2906/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773411.0000\n",
      "Epoch 2907/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773386.9375\n",
      "Epoch 2908/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773362.8125\n",
      "Epoch 2909/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773338.7500\n",
      "Epoch 2910/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 6us/step - loss: 773314.5000\n",
      "Epoch 2911/3000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 773290.4375\n",
      "Epoch 2912/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773266.3125\n",
      "Epoch 2913/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773242.1250\n",
      "Epoch 2914/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773218.0000\n",
      "Epoch 2915/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773193.8125\n",
      "Epoch 2916/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773169.6250\n",
      "Epoch 2917/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773145.5625\n",
      "Epoch 2918/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 773121.3125\n",
      "Epoch 2919/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773097.0625\n",
      "Epoch 2920/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 773072.8750\n",
      "Epoch 2921/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773048.6250\n",
      "Epoch 2922/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773024.3750\n",
      "Epoch 2923/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 773000.0000\n",
      "Epoch 2924/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772975.7500\n",
      "Epoch 2925/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772951.5625\n",
      "Epoch 2926/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772927.3125\n",
      "Epoch 2927/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772902.9375\n",
      "Epoch 2928/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 772878.6875\n",
      "Epoch 2929/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772854.3125\n",
      "Epoch 2930/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772829.8750\n",
      "Epoch 2931/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772805.6250\n",
      "Epoch 2932/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772781.1875\n",
      "Epoch 2933/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772756.8125\n",
      "Epoch 2934/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772732.4375\n",
      "Epoch 2935/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 772708.0000\n",
      "Epoch 2936/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772683.5625\n",
      "Epoch 2937/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772659.1250\n",
      "Epoch 2938/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772634.7500\n",
      "Epoch 2939/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772610.2500\n",
      "Epoch 2940/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772585.9375\n",
      "Epoch 2941/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772561.3750\n",
      "Epoch 2942/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772536.8750\n",
      "Epoch 2943/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772512.3750\n",
      "Epoch 2944/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772487.8125\n",
      "Epoch 2945/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772463.3125\n",
      "Epoch 2946/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772438.8125\n",
      "Epoch 2947/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772414.3125\n",
      "Epoch 2948/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772389.7500\n",
      "Epoch 2949/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772365.1250\n",
      "Epoch 2950/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772340.5625\n",
      "Epoch 2951/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772316.0000\n",
      "Epoch 2952/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772291.3750\n",
      "Epoch 2953/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772266.8125\n",
      "Epoch 2954/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772242.1250\n",
      "Epoch 2955/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772217.4375\n",
      "Epoch 2956/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772192.8125\n",
      "Epoch 2957/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 772168.0625\n",
      "Epoch 2958/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 772143.4375\n",
      "Epoch 2959/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 772118.7500\n",
      "Epoch 2960/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772094.1250\n",
      "Epoch 2961/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 772069.4375\n",
      "Epoch 2962/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 772044.6875\n",
      "Epoch 2963/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 772020.0000\n",
      "Epoch 2964/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771995.1250\n",
      "Epoch 2965/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 771970.4375\n",
      "Epoch 2966/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771945.6875\n",
      "Epoch 2967/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771920.8750\n",
      "Epoch 2968/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771896.1250\n",
      "Epoch 2969/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771871.3125\n",
      "Epoch 2970/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 771846.5000\n",
      "Epoch 2971/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771821.7500\n",
      "Epoch 2972/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 771796.8125\n",
      "Epoch 2973/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771772.0000\n",
      "Epoch 2974/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771747.0625\n",
      "Epoch 2975/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771722.2500\n",
      "Epoch 2976/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 771697.3125\n",
      "Epoch 2977/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771672.4375\n",
      "Epoch 2978/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 771647.5000\n",
      "Epoch 2979/3000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 771622.5625\n",
      "Epoch 2980/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771597.7500\n",
      "Epoch 2981/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771572.6875\n",
      "Epoch 2982/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771547.8125\n",
      "Epoch 2983/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771522.8750\n",
      "Epoch 2984/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771497.7500\n",
      "Epoch 2985/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771472.8750\n",
      "Epoch 2986/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771447.8125\n",
      "Epoch 2987/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771422.8750\n",
      "Epoch 2988/3000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 771397.8750\n",
      "Epoch 2989/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771372.7500\n",
      "Epoch 2990/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771347.7500\n",
      "Epoch 2991/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771322.6875\n",
      "Epoch 2992/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771297.6875\n",
      "Epoch 2993/3000\n",
      "630/630 [==============================] - 0s 3us/step - loss: 771272.5000\n",
      "Epoch 2994/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771247.4375\n",
      "Epoch 2995/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771222.3750\n",
      "Epoch 2996/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771197.2500\n",
      "Epoch 2997/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771172.1250\n",
      "Epoch 2998/3000\n",
      "630/630 [==============================] - 0s 5us/step - loss: 771146.8750\n",
      "Epoch 2999/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771121.6875\n",
      "Epoch 3000/3000\n",
      "630/630 [==============================] - 0s 6us/step - loss: 771096.5000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2826d617978>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1 = LossHistory()\n",
    "input_img=Input(shape=(10,))\n",
    "# 编码层\n",
    "#encoded=Dense(128,activation='relu',name='encoded_hidden1',activity_regularizer=regularizers.l1(0.01))(input_img)\n",
    "#encoded=Dense(64,activation='sigmoid',name='encoded_hidden2',activity_regularizer=regularizers.l1(0.01))(encoded)\n",
    "#encoded=Dense(32,activation='sigmoid',name='encoded_hidden3',activity_regularizer=regularizers.l1(0.01))(encoded)\n",
    "#encoder_output=Dense(16,activation='relu',name='encoded_hidden4',activity_regularizer=regularizers.l1(0.01))(encoded)\n",
    "LR=Dense(20,name='LR',activity_regularizer=regularizers.l1(0.01))(input_img)\n",
    "\n",
    "# 解码层\n",
    "decoded=Dense(10,name='decoded_hidden2')(LR)\n",
    "#decoded=Dense(32,activation='sigmoid',name='decoded_hidden3',activity_regularizer=regularizers.l1(0.01))(decoded)\n",
    "#decoded=Dense(64,activation='sigmoid',name='decoded_hidden4',activity_regularizer=regularizers.l1(0.01))(decoded)\n",
    "#decoded=Dense(128,activation='sigmoid',name='decoded_hidden5',activity_regularizer=regularizers.l1(0.01))(decoded)\n",
    "#decoded=Dense(10,activation='sigmoid',name='decoded_output')(decoded)\n",
    "\n",
    "# 构建自编码模型\n",
    "autoencoder=Model(inputs=input_img,outputs=decoded)\n",
    "\n",
    "# complile autoencoder 设置自编码的优化参数\n",
    "autoencoder.compile(optimizer='adam',loss='mse')\n",
    "# train\n",
    "hist=autoencoder.fit(X_train,X_train,epochs=3000,batch_size=1000,shuffle=True,callbacks=[history1])\n",
    "history1.loss_plot('epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 630 samples, validate on 315 samples\n",
      "Epoch 1/10000\n",
      "630/630 [==============================] - 1s 2ms/step - loss: 15822.9873 - val_loss: 20442.5566\n",
      "Epoch 2/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 17819.3477 - val_loss: 19852.1289\n",
      "Epoch 3/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 16033.2002 - val_loss: 19790.5527\n",
      "Epoch 4/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15803.9561 - val_loss: 19917.8223\n",
      "Epoch 5/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16151.9209 - val_loss: 19707.2246\n",
      "Epoch 6/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15442.9971 - val_loss: 19515.0742\n",
      "Epoch 7/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14837.7891 - val_loss: 19490.3613\n",
      "Epoch 8/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14815.3164 - val_loss: 19477.8281\n",
      "Epoch 9/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14800.6318 - val_loss: 19390.9316\n",
      "Epoch 10/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14488.1768 - val_loss: 19332.7871\n",
      "Epoch 11/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14285.8975 - val_loss: 19329.0586\n",
      "Epoch 12/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14310.4629 - val_loss: 19322.4531\n",
      "Epoch 13/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14294.1045 - val_loss: 19318.1992\n",
      "Epoch 14/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14303.2002 - val_loss: 19283.6641\n",
      "Epoch 15/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14230.7461 - val_loss: 19210.8125\n",
      "Epoch 16/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14028.5811 - val_loss: 19155.8379\n",
      "Epoch 17/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13787.4902 - val_loss: 19168.1562\n",
      "Epoch 18/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13767.3564 - val_loss: 19180.1367\n",
      "Epoch 19/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13761.3135 - val_loss: 19129.8613\n",
      "Epoch 20/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13636.8418 - val_loss: 19125.0312\n",
      "Epoch 21/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13690.1953 - val_loss: 19082.8867\n",
      "Epoch 22/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13621.8545 - val_loss: 19007.1309\n",
      "Epoch 23/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13423.2773 - val_loss: 19051.4316\n",
      "Epoch 24/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13519.5078 - val_loss: 19042.4199\n",
      "Epoch 25/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13444.2754 - val_loss: 19009.3359\n",
      "Epoch 26/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13254.3867 - val_loss: 19066.2324\n",
      "Epoch 27/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13382.4180 - val_loss: 19078.0137\n",
      "Epoch 28/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13467.7783 - val_loss: 19012.1973\n",
      "Epoch 29/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13352.8242 - val_loss: 18945.8535\n",
      "Epoch 30/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13244.5215 - val_loss: 18941.1230\n",
      "Epoch 31/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13244.9688 - val_loss: 18987.1211\n",
      "Epoch 32/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13295.3545 - val_loss: 18999.8340\n",
      "Epoch 33/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13219.1484 - val_loss: 18993.9805\n",
      "Epoch 34/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13157.5303 - val_loss: 19001.2129\n",
      "Epoch 35/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13256.6318 - val_loss: 18991.1328\n",
      "Epoch 36/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13295.4062 - val_loss: 18913.3770\n",
      "Epoch 37/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13095.4033 - val_loss: 18922.9590\n",
      "Epoch 38/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13156.4854 - val_loss: 18952.7617\n",
      "Epoch 39/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13204.6807 - val_loss: 18962.2930\n",
      "Epoch 40/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13112.0791 - val_loss: 18982.4961\n",
      "Epoch 41/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13155.5879 - val_loss: 18939.8164\n",
      "Epoch 42/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13098.7090 - val_loss: 18909.7559\n",
      "Epoch 43/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13095.7900 - val_loss: 18908.0254\n",
      "Epoch 44/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13069.5430 - val_loss: 18897.8672\n",
      "Epoch 45/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12988.7461 - val_loss: 18934.3945\n",
      "Epoch 46/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13108.5117 - val_loss: 18906.6992\n",
      "Epoch 47/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13001.8760 - val_loss: 18939.1914\n",
      "Epoch 48/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13074.5635 - val_loss: 18934.8828\n",
      "Epoch 49/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13061.8848 - val_loss: 18914.3203\n",
      "Epoch 50/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13043.1045 - val_loss: 18901.6953\n",
      "Epoch 51/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13047.7793 - val_loss: 18895.6465\n",
      "Epoch 52/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13040.7793 - val_loss: 18873.9102\n",
      "Epoch 53/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12966.4727 - val_loss: 18898.2344\n",
      "Epoch 54/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12996.8076 - val_loss: 18906.0391\n",
      "Epoch 55/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12975.7852 - val_loss: 18910.2578\n",
      "Epoch 56/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12998.5605 - val_loss: 18896.7031\n",
      "Epoch 57/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12989.5547 - val_loss: 18884.4609\n",
      "Epoch 58/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12992.0283 - val_loss: 18862.5977\n",
      "Epoch 59/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12950.6504 - val_loss: 18886.7188\n",
      "Epoch 60/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13024.3125 - val_loss: 18881.3496\n",
      "Epoch 61/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12940.5088 - val_loss: 18906.1270\n",
      "Epoch 62/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12976.0615 - val_loss: 18884.0586\n",
      "Epoch 63/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.9541 - val_loss: 18876.8711\n",
      "Epoch 64/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12931.4150 - val_loss: 18878.2617\n",
      "Epoch 65/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.7432 - val_loss: 18871.2637\n",
      "Epoch 66/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13023.6348 - val_loss: 18870.2285\n",
      "Epoch 67/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12985.9541 - val_loss: 18883.9980\n",
      "Epoch 68/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12946.3955 - val_loss: 18910.7207\n",
      "Epoch 69/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12967.6377 - val_loss: 18882.7148\n",
      "Epoch 70/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12945.7949 - val_loss: 18869.6035\n",
      "Epoch 71/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12944.5088 - val_loss: 18877.1250\n",
      "Epoch 72/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13006.2695 - val_loss: 18866.9277\n",
      "Epoch 73/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12960.0957 - val_loss: 18863.9902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12919.4404 - val_loss: 18873.7773\n",
      "Epoch 75/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12924.5410 - val_loss: 18874.8223\n",
      "Epoch 76/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12949.5781 - val_loss: 18875.7441\n",
      "Epoch 77/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12925.4316 - val_loss: 18889.2207\n",
      "Epoch 78/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12978.9014 - val_loss: 18862.9121\n",
      "Epoch 79/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12915.3057 - val_loss: 18858.3672\n",
      "Epoch 80/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12941.5322 - val_loss: 18830.5215\n",
      "Epoch 81/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12852.9473 - val_loss: 18870.7578\n",
      "Epoch 82/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12945.0781 - val_loss: 18872.5215\n",
      "Epoch 83/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12950.8926 - val_loss: 18863.0703\n",
      "Epoch 84/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12891.4336 - val_loss: 18896.9219\n",
      "Epoch 85/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12995.1885 - val_loss: 18884.7363\n",
      "Epoch 86/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12965.8672 - val_loss: 18824.4824\n",
      "Epoch 87/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12795.4561 - val_loss: 18878.5625\n",
      "Epoch 88/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.7275 - val_loss: 18855.3652\n",
      "Epoch 89/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12955.3887 - val_loss: 18846.5918\n",
      "Epoch 90/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12895.8350 - val_loss: 18881.2207\n",
      "Epoch 91/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12998.0088 - val_loss: 18882.0898\n",
      "Epoch 92/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12969.0781 - val_loss: 18883.9258\n",
      "Epoch 93/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12955.8311 - val_loss: 18869.8008\n",
      "Epoch 94/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12923.1162 - val_loss: 18830.1367\n",
      "Epoch 95/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12821.6104 - val_loss: 18884.9668\n",
      "Epoch 96/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13032.1113 - val_loss: 18848.6582\n",
      "Epoch 97/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12906.3057 - val_loss: 18869.0312\n",
      "Epoch 98/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12960.1387 - val_loss: 18888.7383\n",
      "Epoch 99/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13018.4512 - val_loss: 18887.0312\n",
      "Epoch 100/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13012.7295 - val_loss: 18839.1230\n",
      "Epoch 101/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.2559 - val_loss: 18854.9277\n",
      "Epoch 102/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12918.1201 - val_loss: 18875.2383\n",
      "Epoch 103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12971.0859 - val_loss: 18847.5957\n",
      "Epoch 104/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12869.5645 - val_loss: 18851.3301\n",
      "Epoch 105/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12897.8457 - val_loss: 18854.9727\n",
      "Epoch 106/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12910.1230 - val_loss: 18841.2402\n",
      "Epoch 107/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12876.0332 - val_loss: 18848.4395\n",
      "Epoch 108/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12889.4502 - val_loss: 18831.6367\n",
      "Epoch 109/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12843.1377 - val_loss: 18844.2871\n",
      "Epoch 110/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.3076 - val_loss: 18845.1855\n",
      "Epoch 111/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12875.5664 - val_loss: 18843.7285\n",
      "Epoch 112/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12873.4248 - val_loss: 18873.3887\n",
      "Epoch 113/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12964.9043 - val_loss: 18848.7754\n",
      "Epoch 114/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12896.0869 - val_loss: 18840.7910\n",
      "Epoch 115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12895.3145 - val_loss: 18853.7188\n",
      "Epoch 116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12935.7256 - val_loss: 18837.2871\n",
      "Epoch 117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.2061 - val_loss: 18902.8105\n",
      "Epoch 118/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13041.6318 - val_loss: 18818.1992\n",
      "Epoch 119/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12793.1475 - val_loss: 18861.8926\n",
      "Epoch 120/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12945.1523 - val_loss: 18843.8320\n",
      "Epoch 121/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12886.6172 - val_loss: 18846.0254\n",
      "Epoch 122/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12883.4834 - val_loss: 18856.4141\n",
      "Epoch 123/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12919.4502 - val_loss: 18824.7930\n",
      "Epoch 124/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.2734 - val_loss: 18849.8125\n",
      "Epoch 125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12896.0195 - val_loss: 18814.1738\n",
      "Epoch 126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.5547 - val_loss: 18835.2969\n",
      "Epoch 127/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12864.0264 - val_loss: 18845.9902\n",
      "Epoch 128/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12897.9590 - val_loss: 18852.4062\n",
      "Epoch 129/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12902.5938 - val_loss: 18844.5703\n",
      "Epoch 130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.3311 - val_loss: 18852.1934\n",
      "Epoch 131/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12878.9473 - val_loss: 18842.7969\n",
      "Epoch 132/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12881.4785 - val_loss: 18834.4023\n",
      "Epoch 133/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12870.8711 - val_loss: 18814.2695\n",
      "Epoch 134/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12806.4541 - val_loss: 18835.5469\n",
      "Epoch 135/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12864.7588 - val_loss: 18830.9688\n",
      "Epoch 136/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12836.0830 - val_loss: 18836.2422\n",
      "Epoch 137/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12871.9121 - val_loss: 18840.5293\n",
      "Epoch 138/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12892.2881 - val_loss: 18837.0000\n",
      "Epoch 139/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12866.1436 - val_loss: 18816.3848\n",
      "Epoch 140/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.4902 - val_loss: 18840.4492\n",
      "Epoch 141/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.1113 - val_loss: 18809.9062\n",
      "Epoch 142/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12777.9023 - val_loss: 18827.7168\n",
      "Epoch 143/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.2725 - val_loss: 18815.7520\n",
      "Epoch 144/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.6279 - val_loss: 18790.7578\n",
      "Epoch 145/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12731.2568 - val_loss: 18823.5352\n",
      "Epoch 146/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.4287 - val_loss: 18803.5098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.1221 - val_loss: 18821.1465\n",
      "Epoch 148/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.5078 - val_loss: 18828.4395\n",
      "Epoch 149/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12814.5771 - val_loss: 18811.1895\n",
      "Epoch 150/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12762.7822 - val_loss: 18811.3105\n",
      "Epoch 151/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12788.1270 - val_loss: 18823.7598\n",
      "Epoch 152/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12833.4082 - val_loss: 18802.5820\n",
      "Epoch 153/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12769.2441 - val_loss: 18833.4863\n",
      "Epoch 154/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.0537 - val_loss: 18809.3242\n",
      "Epoch 155/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12783.9121 - val_loss: 18809.6016\n",
      "Epoch 156/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.5205 - val_loss: 18817.8047\n",
      "Epoch 157/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12799.3096 - val_loss: 18843.6914\n",
      "Epoch 158/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12864.9551 - val_loss: 18813.2012\n",
      "Epoch 159/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12790.4307 - val_loss: 18840.1504\n",
      "Epoch 160/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12889.2070 - val_loss: 18827.1445\n",
      "Epoch 161/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.7334 - val_loss: 18842.5234\n",
      "Epoch 162/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12903.8037 - val_loss: 18807.6094\n",
      "Epoch 163/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.3711 - val_loss: 18823.3672\n",
      "Epoch 164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12812.4990 - val_loss: 18794.3301\n",
      "Epoch 165/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.4453 - val_loss: 18811.8027\n",
      "Epoch 166/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.1992 - val_loss: 18792.1836\n",
      "Epoch 167/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12719.5752 - val_loss: 18813.5293\n",
      "Epoch 168/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12772.0166 - val_loss: 18807.7051\n",
      "Epoch 169/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12794.2686 - val_loss: 18838.3184\n",
      "Epoch 170/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12900.5947 - val_loss: 18822.2227\n",
      "Epoch 171/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12849.0635 - val_loss: 18789.8574\n",
      "Epoch 172/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12735.7568 - val_loss: 18892.3555\n",
      "Epoch 173/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13014.6279 - val_loss: 18807.7773\n",
      "Epoch 174/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.8066 - val_loss: 18852.9336\n",
      "Epoch 175/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12911.8711 - val_loss: 18854.5723\n",
      "Epoch 176/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12922.5576 - val_loss: 18804.4863\n",
      "Epoch 177/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.6543 - val_loss: 18842.4453\n",
      "Epoch 178/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12890.2949 - val_loss: 18804.4297\n",
      "Epoch 179/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.4590 - val_loss: 18829.5781\n",
      "Epoch 180/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.1709 - val_loss: 18835.7969\n",
      "Epoch 181/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12875.3525 - val_loss: 18789.8477\n",
      "Epoch 182/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.1797 - val_loss: 18819.2969\n",
      "Epoch 183/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12813.6475 - val_loss: 18805.2207\n",
      "Epoch 184/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.7568 - val_loss: 18818.5586\n",
      "Epoch 185/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12824.3799 - val_loss: 18829.3711\n",
      "Epoch 186/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12843.0088 - val_loss: 18813.3984\n",
      "Epoch 187/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12788.5928 - val_loss: 18801.9668\n",
      "Epoch 188/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.4170 - val_loss: 18789.2090\n",
      "Epoch 189/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.7822 - val_loss: 18824.3750\n",
      "Epoch 190/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12832.2324 - val_loss: 18815.0840\n",
      "Epoch 191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12804.0068 - val_loss: 18820.0820\n",
      "Epoch 192/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12830.3643 - val_loss: 18822.2910\n",
      "Epoch 193/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12839.8164 - val_loss: 18829.3086\n",
      "Epoch 194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.0127 - val_loss: 18801.7266\n",
      "Epoch 195/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12783.1924 - val_loss: 18846.1445\n",
      "Epoch 196/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12899.5488 - val_loss: 18805.2754\n",
      "Epoch 197/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12771.4209 - val_loss: 18808.9512\n",
      "Epoch 198/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.4023 - val_loss: 18836.0156\n",
      "Epoch 199/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12894.1504 - val_loss: 18837.1562\n",
      "Epoch 200/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12910.1982 - val_loss: 18834.0176\n",
      "Epoch 201/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12894.4365 - val_loss: 18832.2031\n",
      "Epoch 202/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.1104 - val_loss: 18825.7324\n",
      "Epoch 203/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12839.1289 - val_loss: 18834.3828\n",
      "Epoch 204/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.8076 - val_loss: 18835.1895\n",
      "Epoch 205/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12871.5137 - val_loss: 18797.2285\n",
      "Epoch 206/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.3955 - val_loss: 18806.0312\n",
      "Epoch 207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12806.2666 - val_loss: 18804.9727\n",
      "Epoch 208/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12802.3896 - val_loss: 18815.9941\n",
      "Epoch 209/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12827.7314 - val_loss: 18807.5625\n",
      "Epoch 210/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.9189 - val_loss: 18855.4043\n",
      "Epoch 211/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12916.9297 - val_loss: 18804.0059\n",
      "Epoch 212/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.6475 - val_loss: 18803.7500\n",
      "Epoch 213/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12806.7236 - val_loss: 18858.5176\n",
      "Epoch 214/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12960.1055 - val_loss: 18800.5234\n",
      "Epoch 215/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12794.3223 - val_loss: 18795.6777\n",
      "Epoch 216/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12775.0410 - val_loss: 18847.1191\n",
      "Epoch 217/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12900.3203 - val_loss: 18810.2500\n",
      "Epoch 218/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12813.2285 - val_loss: 18847.4590\n",
      "Epoch 219/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12933.2324 - val_loss: 18828.7715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12873.5088 - val_loss: 18800.3691\n",
      "Epoch 221/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.0166 - val_loss: 18858.2324\n",
      "Epoch 222/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12942.3486 - val_loss: 18791.2832\n",
      "Epoch 223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12766.8926 - val_loss: 18777.1797\n",
      "Epoch 224/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.6758 - val_loss: 18862.2363\n",
      "Epoch 225/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12967.2891 - val_loss: 18799.3477\n",
      "Epoch 226/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.2930 - val_loss: 18817.3535\n",
      "Epoch 227/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.7686 - val_loss: 18860.2441\n",
      "Epoch 228/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12949.6084 - val_loss: 18798.5332\n",
      "Epoch 229/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.8906 - val_loss: 18797.9316\n",
      "Epoch 230/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.6055 - val_loss: 18788.3750\n",
      "Epoch 231/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.4473 - val_loss: 18769.7090\n",
      "Epoch 232/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12705.4736 - val_loss: 18820.2559\n",
      "Epoch 233/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.2617 - val_loss: 18795.7695\n",
      "Epoch 234/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12783.6777 - val_loss: 18839.2520\n",
      "Epoch 235/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12920.0742 - val_loss: 18832.1777\n",
      "Epoch 236/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12903.7881 - val_loss: 18814.9160\n",
      "Epoch 237/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12838.6445 - val_loss: 18811.5020\n",
      "Epoch 238/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12820.1191 - val_loss: 18804.4570\n",
      "Epoch 239/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.2871 - val_loss: 18779.0684\n",
      "Epoch 240/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.7324 - val_loss: 18846.5449\n",
      "Epoch 241/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12892.1162 - val_loss: 18782.4395\n",
      "Epoch 242/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12752.3086 - val_loss: 18820.5957\n",
      "Epoch 243/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12880.0469 - val_loss: 18829.1016\n",
      "Epoch 244/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.7812 - val_loss: 18831.0156\n",
      "Epoch 245/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12898.2461 - val_loss: 18801.3008\n",
      "Epoch 246/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.6533 - val_loss: 18809.2266\n",
      "Epoch 247/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12765.8496 - val_loss: 18792.9453\n",
      "Epoch 248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12751.5469 - val_loss: 18843.4512\n",
      "Epoch 249/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12922.7305 - val_loss: 18812.6914\n",
      "Epoch 250/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12857.1875 - val_loss: 18791.4121\n",
      "Epoch 251/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12815.9570 - val_loss: 18823.8301\n",
      "Epoch 252/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12904.0547 - val_loss: 18808.8691\n",
      "Epoch 253/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12838.3154 - val_loss: 18821.3867\n",
      "Epoch 254/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12854.4404 - val_loss: 18821.8320\n",
      "Epoch 255/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12831.3193 - val_loss: 18833.5781\n",
      "Epoch 256/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12862.8740 - val_loss: 18798.7480\n",
      "Epoch 257/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.2041 - val_loss: 18794.9551\n",
      "Epoch 258/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.1562 - val_loss: 18783.2891\n",
      "Epoch 259/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12768.4258 - val_loss: 18814.4570\n",
      "Epoch 260/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12866.8555 - val_loss: 18792.9727\n",
      "Epoch 261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12799.6318 - val_loss: 18775.5762\n",
      "Epoch 262/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.1045 - val_loss: 18796.5508\n",
      "Epoch 263/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12746.6934 - val_loss: 18778.9785\n",
      "Epoch 264/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12715.0254 - val_loss: 18846.1738\n",
      "Epoch 265/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12923.0176 - val_loss: 18806.8105\n",
      "Epoch 266/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12830.4443 - val_loss: 18784.0273\n",
      "Epoch 267/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12769.7236 - val_loss: 18813.7949\n",
      "Epoch 268/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.3984 - val_loss: 18787.2734\n",
      "Epoch 269/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12776.9785 - val_loss: 18780.7910\n",
      "Epoch 270/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12747.2090 - val_loss: 18781.5527\n",
      "Epoch 271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.5576 - val_loss: 18779.5215\n",
      "Epoch 272/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12705.2979 - val_loss: 18767.4414\n",
      "Epoch 273/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12699.8799 - val_loss: 18814.7656\n",
      "Epoch 274/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12833.9326 - val_loss: 18777.8145\n",
      "Epoch 275/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12748.4385 - val_loss: 18765.6152\n",
      "Epoch 276/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.3574 - val_loss: 18801.1816\n",
      "Epoch 277/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12803.8604 - val_loss: 18755.5137\n",
      "Epoch 278/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12674.8613 - val_loss: 18771.5918\n",
      "Epoch 279/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12705.8018 - val_loss: 18825.0430\n",
      "Epoch 280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12824.5410 - val_loss: 18788.4785\n",
      "Epoch 281/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12771.3184 - val_loss: 18814.3926\n",
      "Epoch 282/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12862.5068 - val_loss: 18800.7188\n",
      "Epoch 283/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12829.8828 - val_loss: 18788.6309\n",
      "Epoch 284/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12796.3037 - val_loss: 18813.1602\n",
      "Epoch 285/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12861.1680 - val_loss: 18818.6953\n",
      "Epoch 286/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12846.5986 - val_loss: 18790.2852\n",
      "Epoch 287/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.9922 - val_loss: 18819.5117\n",
      "Epoch 288/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12825.9961 - val_loss: 18785.7891\n",
      "Epoch 289/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12773.4727 - val_loss: 18786.3613\n",
      "Epoch 290/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12795.5674 - val_loss: 18786.5840\n",
      "Epoch 291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.9629 - val_loss: 18779.4141\n",
      "Epoch 292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.9766 - val_loss: 18760.3965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12674.9072 - val_loss: 18812.5176\n",
      "Epoch 294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.9424 - val_loss: 18777.0703\n",
      "Epoch 295/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.2217 - val_loss: 18793.1270\n",
      "Epoch 296/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12802.8740 - val_loss: 18787.3926\n",
      "Epoch 297/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12796.2422 - val_loss: 18802.1055\n",
      "Epoch 298/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12821.6748 - val_loss: 18754.1777\n",
      "Epoch 299/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12673.1953 - val_loss: 18800.0586\n",
      "Epoch 300/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.6270 - val_loss: 18793.5391\n",
      "Epoch 301/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.4600 - val_loss: 18780.1250\n",
      "Epoch 302/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12742.2070 - val_loss: 18805.3965\n",
      "Epoch 303/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.7461 - val_loss: 18778.4160\n",
      "Epoch 304/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12738.5488 - val_loss: 18815.2148\n",
      "Epoch 305/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12854.9951 - val_loss: 18796.5352\n",
      "Epoch 306/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12814.2979 - val_loss: 18784.0684\n",
      "Epoch 307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12772.2383 - val_loss: 18750.7090\n",
      "Epoch 308/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.4736 - val_loss: 18841.8027\n",
      "Epoch 309/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.4893 - val_loss: 18800.4805\n",
      "Epoch 310/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12817.8750 - val_loss: 18865.1289\n",
      "Epoch 311/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13017.0703 - val_loss: 18886.0527\n",
      "Epoch 312/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13087.1602 - val_loss: 18893.8594\n",
      "Epoch 313/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13103.5381 - val_loss: 18859.0176\n",
      "Epoch 314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12984.4688 - val_loss: 18847.1953\n",
      "Epoch 315/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12949.5225 - val_loss: 18821.8379\n",
      "Epoch 316/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12872.2979 - val_loss: 18782.7344\n",
      "Epoch 317/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.1279 - val_loss: 18802.7324\n",
      "Epoch 318/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12801.0947 - val_loss: 18763.1934\n",
      "Epoch 319/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.5244 - val_loss: 18800.3438\n",
      "Epoch 320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12826.2832 - val_loss: 18809.8145\n",
      "Epoch 321/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.7461 - val_loss: 18808.9219\n",
      "Epoch 322/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12863.1611 - val_loss: 18828.8652\n",
      "Epoch 323/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12885.6719 - val_loss: 18805.5859\n",
      "Epoch 324/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12814.6670 - val_loss: 18831.2324\n",
      "Epoch 325/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12897.7900 - val_loss: 18821.6172\n",
      "Epoch 326/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12867.6934 - val_loss: 18778.3770\n",
      "Epoch 327/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12751.0400 - val_loss: 18825.1484\n",
      "Epoch 328/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.5654 - val_loss: 18773.7188\n",
      "Epoch 329/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12746.9365 - val_loss: 18814.7793\n",
      "Epoch 330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.8789 - val_loss: 18811.5566\n",
      "Epoch 331/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12873.4814 - val_loss: 18795.9707\n",
      "Epoch 332/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.1680 - val_loss: 18788.9180\n",
      "Epoch 333/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12783.1836 - val_loss: 18794.4648\n",
      "Epoch 334/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.1084 - val_loss: 18798.6543\n",
      "Epoch 335/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12793.3896 - val_loss: 18813.1543\n",
      "Epoch 336/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12851.6436 - val_loss: 18808.1758\n",
      "Epoch 337/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12847.4365 - val_loss: 18813.4648\n",
      "Epoch 338/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12878.5479 - val_loss: 18785.3438\n",
      "Epoch 339/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12782.0557 - val_loss: 18772.2891\n",
      "Epoch 340/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12734.1904 - val_loss: 18836.3633\n",
      "Epoch 341/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.0518 - val_loss: 18780.4297\n",
      "Epoch 342/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12761.9395 - val_loss: 18843.1602\n",
      "Epoch 343/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12971.9170 - val_loss: 18839.5547\n",
      "Epoch 344/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12965.8330 - val_loss: 18820.5996\n",
      "Epoch 345/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12897.4863 - val_loss: 18793.8750\n",
      "Epoch 346/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12800.8711 - val_loss: 18777.6074\n",
      "Epoch 347/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12727.6953 - val_loss: 18863.5801\n",
      "Epoch 348/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12928.5947 - val_loss: 18819.7363\n",
      "Epoch 349/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12898.5098 - val_loss: 18913.4492\n",
      "Epoch 350/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13202.1895 - val_loss: 18925.5938\n",
      "Epoch 351/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13258.6533 - val_loss: 18907.0957\n",
      "Epoch 352/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13201.2119 - val_loss: 18864.5371\n",
      "Epoch 353/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13052.2549 - val_loss: 18830.1504\n",
      "Epoch 354/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12913.1230 - val_loss: 18766.8730\n",
      "Epoch 355/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.6152 - val_loss: 18859.7695\n",
      "Epoch 356/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12977.1768 - val_loss: 18840.6953\n",
      "Epoch 357/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12943.0068 - val_loss: 18835.0957\n",
      "Epoch 358/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12926.9619 - val_loss: 18823.0098\n",
      "Epoch 359/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12898.6357 - val_loss: 18814.8379\n",
      "Epoch 360/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12875.7852 - val_loss: 18832.8164\n",
      "Epoch 361/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12922.9648 - val_loss: 18834.0488\n",
      "Epoch 362/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12929.4141 - val_loss: 18818.2227\n",
      "Epoch 363/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12881.7930 - val_loss: 18783.8574\n",
      "Epoch 364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12769.6631 - val_loss: 18804.9316\n",
      "Epoch 365/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 11us/step - loss: 12812.8574 - val_loss: 18746.6914\n",
      "Epoch 366/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12656.0742 - val_loss: 18775.7637\n",
      "Epoch 367/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12752.6934 - val_loss: 18781.0645\n",
      "Epoch 368/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12782.7090 - val_loss: 18781.4277\n",
      "Epoch 369/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12780.0869 - val_loss: 18768.8633\n",
      "Epoch 370/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12721.1865 - val_loss: 18754.1211\n",
      "Epoch 371/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12665.1357 - val_loss: 18822.4277\n",
      "Epoch 372/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12830.4502 - val_loss: 18794.0508\n",
      "Epoch 373/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12810.8320 - val_loss: 18853.4980\n",
      "Epoch 374/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13003.2197 - val_loss: 18853.7148\n",
      "Epoch 375/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13015.2480 - val_loss: 18815.7695\n",
      "Epoch 376/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12904.1904 - val_loss: 18783.8711\n",
      "Epoch 377/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.5176 - val_loss: 18851.7852\n",
      "Epoch 378/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12940.4531 - val_loss: 18786.0879\n",
      "Epoch 379/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.7812 - val_loss: 18861.6230\n",
      "Epoch 380/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13002.2227 - val_loss: 18882.7773\n",
      "Epoch 381/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13075.1260 - val_loss: 18892.9648\n",
      "Epoch 382/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13110.9062 - val_loss: 18856.3047\n",
      "Epoch 383/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13000.8213 - val_loss: 18833.7715\n",
      "Epoch 384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12923.4033 - val_loss: 18811.4980\n",
      "Epoch 385/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12868.7227 - val_loss: 18822.0000\n",
      "Epoch 386/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12911.9404 - val_loss: 18819.7227\n",
      "Epoch 387/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12885.4756 - val_loss: 18773.0469\n",
      "Epoch 388/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.9512 - val_loss: 18760.3809\n",
      "Epoch 389/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12702.1865 - val_loss: 18833.4648\n",
      "Epoch 390/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12899.6406 - val_loss: 18779.6504\n",
      "Epoch 391/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.1270 - val_loss: 18831.2012\n",
      "Epoch 392/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12959.5381 - val_loss: 18832.9453\n",
      "Epoch 393/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12967.0039 - val_loss: 18814.4355\n",
      "Epoch 394/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12887.1240 - val_loss: 18787.6387\n",
      "Epoch 395/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12775.0449 - val_loss: 18786.6230\n",
      "Epoch 396/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.3281 - val_loss: 18766.9512\n",
      "Epoch 397/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.4648 - val_loss: 18755.1953\n",
      "Epoch 398/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12691.4336 - val_loss: 18763.8867\n",
      "Epoch 399/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12743.3770 - val_loss: 18780.4551\n",
      "Epoch 400/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12809.7783 - val_loss: 18789.4531\n",
      "Epoch 401/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12825.2178 - val_loss: 18782.6328\n",
      "Epoch 402/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12786.5371 - val_loss: 18737.5859\n",
      "Epoch 403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12644.7207 - val_loss: 18850.7246\n",
      "Epoch 404/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12917.6826 - val_loss: 18811.1953\n",
      "Epoch 405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12872.7803 - val_loss: 18903.3926\n",
      "Epoch 406/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13182.8643 - val_loss: 18947.8301\n",
      "Epoch 407/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13321.1865 - val_loss: 18937.2109\n",
      "Epoch 408/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13271.5615 - val_loss: 18904.8945\n",
      "Epoch 409/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13156.2979 - val_loss: 18869.7891\n",
      "Epoch 410/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13044.4834 - val_loss: 18868.6836\n",
      "Epoch 411/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13041.5439 - val_loss: 18859.0645\n",
      "Epoch 412/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12996.9326 - val_loss: 18830.5918\n",
      "Epoch 413/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12921.0869 - val_loss: 18773.9141\n",
      "Epoch 414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12766.4668 - val_loss: 18854.5293\n",
      "Epoch 415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12991.0283 - val_loss: 18762.3184\n",
      "Epoch 416/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.1309 - val_loss: 18785.4570\n",
      "Epoch 417/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12809.7803 - val_loss: 18811.6855\n",
      "Epoch 418/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.8145 - val_loss: 18798.9375\n",
      "Epoch 419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12837.0107 - val_loss: 18805.5312\n",
      "Epoch 420/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12842.3389 - val_loss: 18800.4980\n",
      "Epoch 421/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12823.9180 - val_loss: 18788.3496\n",
      "Epoch 422/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12796.7949 - val_loss: 18787.9336\n",
      "Epoch 423/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12788.7656 - val_loss: 18789.3438\n",
      "Epoch 424/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.6895 - val_loss: 18759.0859\n",
      "Epoch 425/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12697.0801 - val_loss: 18724.2500\n",
      "Epoch 426/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12606.4502 - val_loss: 18813.5742\n",
      "Epoch 427/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.3096 - val_loss: 18770.7969\n",
      "Epoch 428/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12762.7441 - val_loss: 18809.5195\n",
      "Epoch 429/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12885.3008 - val_loss: 18800.2305\n",
      "Epoch 430/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.9268 - val_loss: 18779.2070\n",
      "Epoch 431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12803.1230 - val_loss: 18793.3965\n",
      "Epoch 432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12825.1924 - val_loss: 18810.1387\n",
      "Epoch 433/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12844.0605 - val_loss: 18793.8320\n",
      "Epoch 434/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12790.5537 - val_loss: 18790.1582\n",
      "Epoch 435/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.3438 - val_loss: 18769.8926\n",
      "Epoch 436/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.9023 - val_loss: 18756.8203\n",
      "Epoch 437/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12678.0264 - val_loss: 18744.1230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 438/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12671.2861 - val_loss: 18812.4316\n",
      "Epoch 439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12867.8086 - val_loss: 18756.8906\n",
      "Epoch 440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12729.3721 - val_loss: 18776.8164\n",
      "Epoch 441/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.5166 - val_loss: 18764.6191\n",
      "Epoch 442/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.9512 - val_loss: 18787.9395\n",
      "Epoch 443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.2539 - val_loss: 18745.5840\n",
      "Epoch 444/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12645.6260 - val_loss: 18823.9551\n",
      "Epoch 445/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12887.3711 - val_loss: 18813.9941\n",
      "Epoch 446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.3643 - val_loss: 18788.7734\n",
      "Epoch 447/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12783.0078 - val_loss: 18760.6836\n",
      "Epoch 448/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12729.2832 - val_loss: 18748.3496\n",
      "Epoch 449/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.4258 - val_loss: 18735.0820\n",
      "Epoch 450/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12637.5527 - val_loss: 18775.6230\n",
      "Epoch 451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12762.7627 - val_loss: 18802.4238\n",
      "Epoch 452/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12815.2510 - val_loss: 18752.8672\n",
      "Epoch 453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12694.4707 - val_loss: 18766.1543\n",
      "Epoch 454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12738.5371 - val_loss: 18786.0605\n",
      "Epoch 455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12802.1836 - val_loss: 18781.7520\n",
      "Epoch 456/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12770.0625 - val_loss: 18756.1367\n",
      "Epoch 457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.8350 - val_loss: 18766.5801\n",
      "Epoch 458/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12688.4717 - val_loss: 18751.9492\n",
      "Epoch 459/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12698.6309 - val_loss: 18800.8809\n",
      "Epoch 460/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12872.1797 - val_loss: 18814.6523\n",
      "Epoch 461/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12906.5029 - val_loss: 18773.3789\n",
      "Epoch 462/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12780.6553 - val_loss: 18746.7578\n",
      "Epoch 463/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12684.4248 - val_loss: 18802.1797\n",
      "Epoch 464/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.4961 - val_loss: 18768.1836\n",
      "Epoch 465/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.5615 - val_loss: 18804.9316\n",
      "Epoch 466/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.6807 - val_loss: 18801.9785\n",
      "Epoch 467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.7715 - val_loss: 18800.0117\n",
      "Epoch 468/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12833.1416 - val_loss: 18802.8809\n",
      "Epoch 469/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12847.2607 - val_loss: 18767.8242\n",
      "Epoch 470/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.9365 - val_loss: 18775.6738\n",
      "Epoch 471/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12753.0459 - val_loss: 18752.5293\n",
      "Epoch 472/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12694.5693 - val_loss: 18771.8867\n",
      "Epoch 473/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.9453 - val_loss: 18788.6895\n",
      "Epoch 474/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12789.5459 - val_loss: 18796.5020\n",
      "Epoch 475/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12817.3750 - val_loss: 18775.6328\n",
      "Epoch 476/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12762.5518 - val_loss: 18749.7812\n",
      "Epoch 477/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12687.7373 - val_loss: 18759.0527\n",
      "Epoch 478/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.0645 - val_loss: 18765.7227\n",
      "Epoch 479/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.7832 - val_loss: 18803.5039\n",
      "Epoch 480/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12856.0303 - val_loss: 18777.9258\n",
      "Epoch 481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12779.9160 - val_loss: 18761.3711\n",
      "Epoch 482/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.1230 - val_loss: 18782.1270\n",
      "Epoch 483/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.6797 - val_loss: 18756.7246\n",
      "Epoch 484/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.2461 - val_loss: 18761.2715\n",
      "Epoch 485/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12712.8330 - val_loss: 18790.8008\n",
      "Epoch 486/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.5244 - val_loss: 18745.2969\n",
      "Epoch 487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12667.0869 - val_loss: 18746.8711\n",
      "Epoch 488/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.5098 - val_loss: 18790.5488\n",
      "Epoch 489/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.8701 - val_loss: 18760.7344\n",
      "Epoch 490/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12717.3877 - val_loss: 18779.8965\n",
      "Epoch 491/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12778.3135 - val_loss: 18780.8145\n",
      "Epoch 492/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12775.7393 - val_loss: 18764.2383\n",
      "Epoch 493/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12712.8486 - val_loss: 18747.0312\n",
      "Epoch 494/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.5732 - val_loss: 18756.2324\n",
      "Epoch 495/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.6240 - val_loss: 18738.6094\n",
      "Epoch 496/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12657.6211 - val_loss: 18765.6777\n",
      "Epoch 497/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.1895 - val_loss: 18741.6348\n",
      "Epoch 498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12683.0635 - val_loss: 18743.9473\n",
      "Epoch 499/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12671.6846 - val_loss: 18781.4746\n",
      "Epoch 500/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12750.2080 - val_loss: 18742.7480\n",
      "Epoch 501/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12660.1689 - val_loss: 18775.5527\n",
      "Epoch 502/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.5459 - val_loss: 18790.2441\n",
      "Epoch 503/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 12820.8486 - val_loss: 18776.3965\n",
      "Epoch 504/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12755.8096 - val_loss: 18781.4414\n",
      "Epoch 505/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.6719 - val_loss: 18766.3164\n",
      "Epoch 506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12723.7402 - val_loss: 18749.0078\n",
      "Epoch 507/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.6621 - val_loss: 18718.3457\n",
      "Epoch 508/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12583.9541 - val_loss: 18734.6973\n",
      "Epoch 509/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12656.8965 - val_loss: 18798.0156\n",
      "Epoch 510/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12820.0518 - val_loss: 18759.2500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 511/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 12741.2617 - val_loss: 18805.6504\n",
      "Epoch 512/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12884.4736 - val_loss: 18822.6992\n",
      "Epoch 513/10000\n",
      "630/630 [==============================] - 0s 21us/step - loss: 12934.3760 - val_loss: 18824.9375\n",
      "Epoch 514/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12934.1338 - val_loss: 18813.4512\n",
      "Epoch 515/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12876.3730 - val_loss: 18801.4004\n",
      "Epoch 516/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12821.0029 - val_loss: 18785.2051\n",
      "Epoch 517/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12774.5000 - val_loss: 18783.0605\n",
      "Epoch 518/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12784.7041 - val_loss: 18764.2246\n",
      "Epoch 519/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.4512 - val_loss: 18741.4707\n",
      "Epoch 520/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12666.9238 - val_loss: 18821.0957\n",
      "Epoch 521/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12887.8975 - val_loss: 18768.7734\n",
      "Epoch 522/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12787.0449 - val_loss: 18821.2285\n",
      "Epoch 523/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12947.8740 - val_loss: 18820.5273\n",
      "Epoch 524/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12946.4346 - val_loss: 18790.1484\n",
      "Epoch 525/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12831.2031 - val_loss: 18808.6621\n",
      "Epoch 526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12844.3701 - val_loss: 18794.0898\n",
      "Epoch 527/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12796.1240 - val_loss: 18769.6562\n",
      "Epoch 528/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12721.3350 - val_loss: 18807.8125\n",
      "Epoch 529/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12808.4990 - val_loss: 18775.9395\n",
      "Epoch 530/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12773.8447 - val_loss: 18825.7500\n",
      "Epoch 531/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12950.1855 - val_loss: 18858.7246\n",
      "Epoch 532/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13054.7588 - val_loss: 18850.5215\n",
      "Epoch 533/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13034.2432 - val_loss: 18820.8535\n",
      "Epoch 534/10000\n",
      "630/630 [==============================] - 0s 25us/step - loss: 12939.5654 - val_loss: 18789.5996\n",
      "Epoch 535/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 12841.0703 - val_loss: 18748.3398\n",
      "Epoch 536/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12707.0127 - val_loss: 18798.7090\n",
      "Epoch 537/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 12817.9521 - val_loss: 18762.0547\n",
      "Epoch 538/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12709.6719 - val_loss: 18796.1719\n",
      "Epoch 539/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12811.8008 - val_loss: 18815.6406\n",
      "Epoch 540/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12877.8574 - val_loss: 18776.6133\n",
      "Epoch 541/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12751.7148 - val_loss: 18761.7148\n",
      "Epoch 542/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12726.4580 - val_loss: 18765.9629\n",
      "Epoch 543/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12748.8584 - val_loss: 18763.5410\n",
      "Epoch 544/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12762.6641 - val_loss: 18772.1367\n",
      "Epoch 545/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12759.9619 - val_loss: 18764.4648\n",
      "Epoch 546/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12732.0957 - val_loss: 18755.0938\n",
      "Epoch 547/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 12672.9043 - val_loss: 18731.2852\n",
      "Epoch 548/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12609.8203 - val_loss: 18756.0605\n",
      "Epoch 549/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 12718.5820 - val_loss: 18777.9453\n",
      "Epoch 550/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12800.7070 - val_loss: 18746.4727\n",
      "Epoch 551/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12704.3271 - val_loss: 18759.7227\n",
      "Epoch 552/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12715.6719 - val_loss: 18753.8164\n",
      "Epoch 553/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12685.1367 - val_loss: 18805.0039\n",
      "Epoch 554/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12809.5762 - val_loss: 18760.5410\n",
      "Epoch 555/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12716.6152 - val_loss: 18796.4336\n",
      "Epoch 556/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12836.8789 - val_loss: 18783.5762\n",
      "Epoch 557/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12824.5811 - val_loss: 18775.3066\n",
      "Epoch 558/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12798.3633 - val_loss: 18778.4141\n",
      "Epoch 559/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12787.4648 - val_loss: 18749.5840\n",
      "Epoch 560/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12682.9570 - val_loss: 18754.7051\n",
      "Epoch 561/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12689.8926 - val_loss: 18755.0781\n",
      "Epoch 562/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.4033 - val_loss: 18743.1699\n",
      "Epoch 563/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12644.0273 - val_loss: 18744.2871\n",
      "Epoch 564/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12645.1787 - val_loss: 18720.9453\n",
      "Epoch 565/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12609.3770 - val_loss: 18735.2090\n",
      "Epoch 566/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12667.6328 - val_loss: 18746.3652\n",
      "Epoch 567/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12699.8672 - val_loss: 18749.8262\n",
      "Epoch 568/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12710.0400 - val_loss: 18760.9922\n",
      "Epoch 569/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12732.9834 - val_loss: 18745.3359\n",
      "Epoch 570/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12643.6982 - val_loss: 18734.7402\n",
      "Epoch 571/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12623.7568 - val_loss: 18771.5352\n",
      "Epoch 572/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.7188 - val_loss: 18765.0742\n",
      "Epoch 573/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12745.8623 - val_loss: 18747.1484\n",
      "Epoch 574/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12691.2666 - val_loss: 18721.5664\n",
      "Epoch 575/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12608.4385 - val_loss: 18795.6895\n",
      "Epoch 576/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12814.5840 - val_loss: 18753.5957\n",
      "Epoch 577/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.7100 - val_loss: 18807.1973\n",
      "Epoch 578/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12886.4990 - val_loss: 18809.6309\n",
      "Epoch 579/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12889.3906 - val_loss: 18788.3145\n",
      "Epoch 580/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12816.0137 - val_loss: 18767.7188\n",
      "Epoch 581/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12734.1152 - val_loss: 18760.9238\n",
      "Epoch 582/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12699.9287 - val_loss: 18771.2148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 583/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.6006 - val_loss: 18737.3086\n",
      "Epoch 584/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.1670 - val_loss: 18741.6172\n",
      "Epoch 585/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12693.8711 - val_loss: 18727.6152\n",
      "Epoch 586/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12649.0127 - val_loss: 18730.7832\n",
      "Epoch 587/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12649.8848 - val_loss: 18736.6602\n",
      "Epoch 588/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12660.1553 - val_loss: 18725.7637\n",
      "Epoch 589/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12627.0078 - val_loss: 18753.7051\n",
      "Epoch 590/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12692.0479 - val_loss: 18743.1367\n",
      "Epoch 591/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12646.9463 - val_loss: 18748.4180\n",
      "Epoch 592/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.2910 - val_loss: 18721.4512\n",
      "Epoch 593/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12594.7695 - val_loss: 18710.7246\n",
      "Epoch 594/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.5654 - val_loss: 18727.6504\n",
      "Epoch 595/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.7480 - val_loss: 18735.2148\n",
      "Epoch 596/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12665.3662 - val_loss: 18723.6621\n",
      "Epoch 597/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12620.9580 - val_loss: 18737.4863\n",
      "Epoch 598/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12632.0117 - val_loss: 18739.2129\n",
      "Epoch 599/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12638.0547 - val_loss: 18758.6816\n",
      "Epoch 600/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12706.0205 - val_loss: 18784.2207\n",
      "Epoch 601/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12782.3564 - val_loss: 18764.9688\n",
      "Epoch 602/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.7646 - val_loss: 18760.4082\n",
      "Epoch 603/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.8545 - val_loss: 18755.5449\n",
      "Epoch 604/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.1475 - val_loss: 18788.5430\n",
      "Epoch 605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.9023 - val_loss: 18751.6855\n",
      "Epoch 606/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.6543 - val_loss: 18774.9648\n",
      "Epoch 607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12764.0684 - val_loss: 18789.7539\n",
      "Epoch 608/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12828.5703 - val_loss: 18806.9922\n",
      "Epoch 609/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.9756 - val_loss: 18747.8945\n",
      "Epoch 610/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12679.1484 - val_loss: 18780.3438\n",
      "Epoch 611/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.1611 - val_loss: 18790.4707\n",
      "Epoch 612/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12831.5381 - val_loss: 18759.7578\n",
      "Epoch 613/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12745.9951 - val_loss: 18762.7637\n",
      "Epoch 614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12740.1572 - val_loss: 18736.4492\n",
      "Epoch 615/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.3398 - val_loss: 18768.2734\n",
      "Epoch 616/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12719.4580 - val_loss: 18740.7109\n",
      "Epoch 617/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12654.2119 - val_loss: 18769.5527\n",
      "Epoch 618/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12775.8701 - val_loss: 18788.7891\n",
      "Epoch 619/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12833.2363 - val_loss: 18762.9668\n",
      "Epoch 620/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.2002 - val_loss: 18773.1094\n",
      "Epoch 621/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.9609 - val_loss: 18738.0820\n",
      "Epoch 622/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.9717 - val_loss: 18749.1172\n",
      "Epoch 623/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.3086 - val_loss: 18739.4219\n",
      "Epoch 624/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12686.1904 - val_loss: 18740.4414\n",
      "Epoch 625/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.9688 - val_loss: 18732.4141\n",
      "Epoch 626/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.0537 - val_loss: 18746.1230\n",
      "Epoch 627/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12652.2979 - val_loss: 18720.7715\n",
      "Epoch 628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12612.7852 - val_loss: 18760.9492\n",
      "Epoch 629/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.1055 - val_loss: 18765.9121\n",
      "Epoch 630/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12756.1006 - val_loss: 18757.4648\n",
      "Epoch 631/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12710.1104 - val_loss: 18763.2402\n",
      "Epoch 632/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.7568 - val_loss: 18738.7793\n",
      "Epoch 633/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12638.9346 - val_loss: 18763.1641\n",
      "Epoch 634/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.9941 - val_loss: 18739.8301\n",
      "Epoch 635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12693.0088 - val_loss: 18754.7148\n",
      "Epoch 636/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12739.1982 - val_loss: 18735.9277\n",
      "Epoch 637/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.7568 - val_loss: 18723.8730\n",
      "Epoch 638/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12609.9434 - val_loss: 18801.8105\n",
      "Epoch 639/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12809.3574 - val_loss: 18787.3730\n",
      "Epoch 640/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12815.6348 - val_loss: 18847.3281\n",
      "Epoch 641/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13016.1230 - val_loss: 18843.4863\n",
      "Epoch 642/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13012.2617 - val_loss: 18815.2969\n",
      "Epoch 643/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12933.1338 - val_loss: 18826.9453\n",
      "Epoch 644/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12926.1543 - val_loss: 18790.8047\n",
      "Epoch 645/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12808.4248 - val_loss: 18770.5605\n",
      "Epoch 646/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12738.3076 - val_loss: 18787.3691\n",
      "Epoch 647/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12802.9248 - val_loss: 18774.7930\n",
      "Epoch 648/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12756.5752 - val_loss: 18718.3965\n",
      "Epoch 649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12622.6230 - val_loss: 18765.6641\n",
      "Epoch 650/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12768.0186 - val_loss: 18763.6582\n",
      "Epoch 651/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12761.0645 - val_loss: 18736.2480\n",
      "Epoch 652/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12664.1816 - val_loss: 18745.7930\n",
      "Epoch 653/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12691.2178 - val_loss: 18792.8887\n",
      "Epoch 654/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12775.4434 - val_loss: 18743.6660\n",
      "Epoch 655/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "630/630 [==============================] - 0s 9us/step - loss: 12660.9482 - val_loss: 18766.2344\n",
      "Epoch 656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.1367 - val_loss: 18791.9297\n",
      "Epoch 657/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12857.9551 - val_loss: 18780.6426\n",
      "Epoch 658/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12810.3438 - val_loss: 18753.3418\n",
      "Epoch 659/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12712.5830 - val_loss: 18772.7285\n",
      "Epoch 660/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.6191 - val_loss: 18791.8750\n",
      "Epoch 661/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12814.9980 - val_loss: 18774.9141\n",
      "Epoch 662/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12762.9336 - val_loss: 18747.2910\n",
      "Epoch 663/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12687.3662 - val_loss: 18718.0039\n",
      "Epoch 664/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12605.2705 - val_loss: 18739.6875\n",
      "Epoch 665/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.8877 - val_loss: 18735.3691\n",
      "Epoch 666/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.9043 - val_loss: 18758.2246\n",
      "Epoch 667/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.3809 - val_loss: 18746.7441\n",
      "Epoch 668/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12691.2627 - val_loss: 18729.7500\n",
      "Epoch 669/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12623.4473 - val_loss: 18783.3809\n",
      "Epoch 670/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12766.9453 - val_loss: 18734.6328\n",
      "Epoch 671/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.8320 - val_loss: 18781.6699\n",
      "Epoch 672/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12817.5557 - val_loss: 18781.5215\n",
      "Epoch 673/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12807.5469 - val_loss: 18770.3203\n",
      "Epoch 674/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12742.3027 - val_loss: 18778.8730\n",
      "Epoch 675/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12768.3398 - val_loss: 18735.3438\n",
      "Epoch 676/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12655.5879 - val_loss: 18763.2031\n",
      "Epoch 677/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.4873 - val_loss: 18760.6133\n",
      "Epoch 678/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.3037 - val_loss: 18737.4727\n",
      "Epoch 679/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12661.4053 - val_loss: 18776.0625\n",
      "Epoch 680/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.7559 - val_loss: 18733.7305\n",
      "Epoch 681/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12655.8301 - val_loss: 18778.7148\n",
      "Epoch 682/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12788.4023 - val_loss: 18778.1777\n",
      "Epoch 683/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.3945 - val_loss: 18756.5527\n",
      "Epoch 684/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.0264 - val_loss: 18721.1504\n",
      "Epoch 685/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12625.9463 - val_loss: 18742.4395\n",
      "Epoch 686/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12675.6514 - val_loss: 18757.1738\n",
      "Epoch 687/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12700.0195 - val_loss: 18779.8477\n",
      "Epoch 688/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12764.5811 - val_loss: 18737.1152\n",
      "Epoch 689/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12658.4248 - val_loss: 18729.8242\n",
      "Epoch 690/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.5645 - val_loss: 18738.6172\n",
      "Epoch 691/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12679.0381 - val_loss: 18737.4531\n",
      "Epoch 692/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12643.1670 - val_loss: 18767.9727\n",
      "Epoch 693/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.7881 - val_loss: 18815.7266\n",
      "Epoch 694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12890.2295 - val_loss: 18787.0898\n",
      "Epoch 695/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12798.8496 - val_loss: 18786.1270\n",
      "Epoch 696/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12772.9736 - val_loss: 18759.8105\n",
      "Epoch 697/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12749.5547 - val_loss: 18815.1816\n",
      "Epoch 698/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12934.0752 - val_loss: 18824.7227\n",
      "Epoch 699/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12958.9688 - val_loss: 18803.1387\n",
      "Epoch 700/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12848.9512 - val_loss: 18769.7715\n",
      "Epoch 701/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12741.3564 - val_loss: 18766.1289\n",
      "Epoch 702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.0303 - val_loss: 18794.8066\n",
      "Epoch 703/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12836.9424 - val_loss: 18807.0762\n",
      "Epoch 704/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12896.2031 - val_loss: 18786.1562\n",
      "Epoch 705/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12824.8047 - val_loss: 18765.0137\n",
      "Epoch 706/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12734.3467 - val_loss: 18752.5410\n",
      "Epoch 707/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12688.0801 - val_loss: 18742.3691\n",
      "Epoch 708/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12677.7754 - val_loss: 18795.1582\n",
      "Epoch 709/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12853.7285 - val_loss: 18810.2637\n",
      "Epoch 710/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12901.4531 - val_loss: 18768.5879\n",
      "Epoch 711/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.3906 - val_loss: 18739.5098\n",
      "Epoch 712/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12651.5176 - val_loss: 18757.2305\n",
      "Epoch 713/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12704.1631 - val_loss: 18778.8340\n",
      "Epoch 714/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.0322 - val_loss: 18746.5605\n",
      "Epoch 715/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12689.6787 - val_loss: 18741.3887\n",
      "Epoch 716/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12692.9580 - val_loss: 18737.3184\n",
      "Epoch 717/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12672.9736 - val_loss: 18836.5625\n",
      "Epoch 718/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12937.1680 - val_loss: 18789.5293\n",
      "Epoch 719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12845.4912 - val_loss: 18857.1230\n",
      "Epoch 720/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13062.9629 - val_loss: 18895.5664\n",
      "Epoch 721/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13183.1338 - val_loss: 18910.5645\n",
      "Epoch 722/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13222.6650 - val_loss: 18907.2754\n",
      "Epoch 723/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13207.0049 - val_loss: 18893.6602\n",
      "Epoch 724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13146.4961 - val_loss: 18854.3965\n",
      "Epoch 725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13022.0166 - val_loss: 18810.9590\n",
      "Epoch 726/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12888.2148 - val_loss: 18811.5117\n",
      "Epoch 727/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12888.4395 - val_loss: 18836.5508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 728/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12963.5566 - val_loss: 18804.7031\n",
      "Epoch 729/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12852.5020 - val_loss: 18763.8516\n",
      "Epoch 730/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12749.4492 - val_loss: 18757.6855\n",
      "Epoch 731/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12745.3906 - val_loss: 18756.3008\n",
      "Epoch 732/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.9766 - val_loss: 18857.1348\n",
      "Epoch 733/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13020.5703 - val_loss: 18800.3652\n",
      "Epoch 734/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12882.7969 - val_loss: 18880.1152\n",
      "Epoch 735/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13127.3057 - val_loss: 18892.6426\n",
      "Epoch 736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13164.2822 - val_loss: 18862.6680\n",
      "Epoch 737/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13073.7705 - val_loss: 18849.2734\n",
      "Epoch 738/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13006.8105 - val_loss: 18846.7422\n",
      "Epoch 739/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12995.4062 - val_loss: 18805.0117\n",
      "Epoch 740/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12855.7236 - val_loss: 18768.9883\n",
      "Epoch 741/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12744.4775 - val_loss: 18804.7207\n",
      "Epoch 742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12860.1250 - val_loss: 18823.4297\n",
      "Epoch 743/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12941.8389 - val_loss: 18812.6504\n",
      "Epoch 744/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12911.9502 - val_loss: 18793.9961\n",
      "Epoch 745/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.7441 - val_loss: 18781.3555\n",
      "Epoch 746/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12801.7998 - val_loss: 18744.2656\n",
      "Epoch 747/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12709.3516 - val_loss: 18810.0625\n",
      "Epoch 748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12909.0859 - val_loss: 18828.5332\n",
      "Epoch 749/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12966.9219 - val_loss: 18843.2051\n",
      "Epoch 750/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12980.5361 - val_loss: 18843.0176\n",
      "Epoch 751/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12973.3574 - val_loss: 18777.6816\n",
      "Epoch 752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12753.6787 - val_loss: 18784.0352\n",
      "Epoch 753/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12781.6924 - val_loss: 18797.1641\n",
      "Epoch 754/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12847.4219 - val_loss: 18812.3105\n",
      "Epoch 755/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12904.5908 - val_loss: 18792.9316\n",
      "Epoch 756/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12863.2549 - val_loss: 18774.0508\n",
      "Epoch 757/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.7725 - val_loss: 18774.6211\n",
      "Epoch 758/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12766.1963 - val_loss: 18771.2754\n",
      "Epoch 759/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.2441 - val_loss: 18766.1797\n",
      "Epoch 760/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12744.8145 - val_loss: 18774.7578\n",
      "Epoch 761/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12779.6611 - val_loss: 18753.3223\n",
      "Epoch 762/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12725.0244 - val_loss: 18732.6680\n",
      "Epoch 763/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12654.0420 - val_loss: 18726.9746\n",
      "Epoch 764/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.5439 - val_loss: 18723.9707\n",
      "Epoch 765/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.1367 - val_loss: 18754.4102\n",
      "Epoch 766/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12716.9307 - val_loss: 18768.4688\n",
      "Epoch 767/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12743.6826 - val_loss: 18746.9102\n",
      "Epoch 768/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12665.8965 - val_loss: 18766.2773\n",
      "Epoch 769/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12763.0156 - val_loss: 18753.0488\n",
      "Epoch 770/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12716.2178 - val_loss: 18775.5117\n",
      "Epoch 771/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.0674 - val_loss: 18784.5918\n",
      "Epoch 772/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12807.9238 - val_loss: 18813.8848\n",
      "Epoch 773/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12900.0273 - val_loss: 18804.1289\n",
      "Epoch 774/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.0488 - val_loss: 18818.5469\n",
      "Epoch 775/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12915.0420 - val_loss: 18806.0781\n",
      "Epoch 776/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12851.3271 - val_loss: 18768.8496\n",
      "Epoch 777/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12758.0049 - val_loss: 18797.9316\n",
      "Epoch 778/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12849.8496 - val_loss: 18822.4941\n",
      "Epoch 779/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12916.6455 - val_loss: 18797.9883\n",
      "Epoch 780/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.5020 - val_loss: 18788.9824\n",
      "Epoch 781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12810.3418 - val_loss: 18745.5996\n",
      "Epoch 782/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.3145 - val_loss: 18760.6055\n",
      "Epoch 783/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12758.5703 - val_loss: 18783.4629\n",
      "Epoch 784/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12796.9658 - val_loss: 18824.2891\n",
      "Epoch 785/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12903.3926 - val_loss: 18761.1230\n",
      "Epoch 786/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.0547 - val_loss: 18820.5117\n",
      "Epoch 787/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12948.4033 - val_loss: 18864.1309\n",
      "Epoch 788/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13089.1328 - val_loss: 18857.1777\n",
      "Epoch 789/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13048.9482 - val_loss: 18823.0254\n",
      "Epoch 790/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12914.9326 - val_loss: 18806.3672\n",
      "Epoch 791/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12846.5693 - val_loss: 18726.1582\n",
      "Epoch 792/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12614.8359 - val_loss: 18767.5430\n",
      "Epoch 793/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.4150 - val_loss: 18770.2715\n",
      "Epoch 794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.1924 - val_loss: 18780.4336\n",
      "Epoch 795/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12811.7695 - val_loss: 18766.2656\n",
      "Epoch 796/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12776.4336 - val_loss: 18781.1816\n",
      "Epoch 797/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12804.2266 - val_loss: 18771.8594\n",
      "Epoch 798/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12770.1748 - val_loss: 18744.9512\n",
      "Epoch 799/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12688.9268 - val_loss: 18764.4707\n",
      "Epoch 800/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12744.8555 - val_loss: 18812.0918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 801/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12880.5420 - val_loss: 18826.4414\n",
      "Epoch 802/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12931.1396 - val_loss: 18789.4414\n",
      "Epoch 803/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12803.6270 - val_loss: 18746.5957\n",
      "Epoch 804/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12681.6396 - val_loss: 18767.7363\n",
      "Epoch 805/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12759.8291 - val_loss: 18746.0430\n",
      "Epoch 806/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.6143 - val_loss: 18741.9902\n",
      "Epoch 807/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12698.1680 - val_loss: 18748.7461\n",
      "Epoch 808/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.2676 - val_loss: 18861.1895\n",
      "Epoch 809/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12997.9316 - val_loss: 18851.0547\n",
      "Epoch 810/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13036.8994 - val_loss: 18978.7129\n",
      "Epoch 811/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13441.3955 - val_loss: 19024.9844\n",
      "Epoch 812/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13579.5498 - val_loss: 19019.8926\n",
      "Epoch 813/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13552.2441 - val_loss: 18997.7266\n",
      "Epoch 814/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13490.7451 - val_loss: 18989.4688\n",
      "Epoch 815/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13479.0850 - val_loss: 18986.8789\n",
      "Epoch 816/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13453.4980 - val_loss: 18921.7754\n",
      "Epoch 817/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13254.8096 - val_loss: 18939.4297\n",
      "Epoch 818/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13285.0439 - val_loss: 18953.0156\n",
      "Epoch 819/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13329.3438 - val_loss: 18925.5781\n",
      "Epoch 820/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13245.2568 - val_loss: 18894.5508\n",
      "Epoch 821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13147.4062 - val_loss: 18865.9805\n",
      "Epoch 822/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13045.3203 - val_loss: 18835.7910\n",
      "Epoch 823/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12952.6982 - val_loss: 18797.0957\n",
      "Epoch 824/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12835.3896 - val_loss: 18806.9512\n",
      "Epoch 825/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12899.3457 - val_loss: 18816.8359\n",
      "Epoch 826/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12935.7266 - val_loss: 18821.1270\n",
      "Epoch 827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12950.5791 - val_loss: 18823.9980\n",
      "Epoch 828/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12954.3096 - val_loss: 18803.7031\n",
      "Epoch 829/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12891.7383 - val_loss: 18786.8867\n",
      "Epoch 830/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12831.1562 - val_loss: 18765.9590\n",
      "Epoch 831/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12775.9688 - val_loss: 18787.1758\n",
      "Epoch 832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12813.2354 - val_loss: 18788.8926\n",
      "Epoch 833/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12794.7529 - val_loss: 18811.2422\n",
      "Epoch 834/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12868.5771 - val_loss: 18813.0508\n",
      "Epoch 835/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12893.7119 - val_loss: 18779.8906\n",
      "Epoch 836/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12784.3770 - val_loss: 18744.4102\n",
      "Epoch 837/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12670.4375 - val_loss: 18887.4980\n",
      "Epoch 838/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13088.4209 - val_loss: 18843.7930\n",
      "Epoch 839/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13023.5693 - val_loss: 18986.9004\n",
      "Epoch 840/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13473.8711 - val_loss: 19057.9219\n",
      "Epoch 841/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13693.7598 - val_loss: 19054.9434\n",
      "Epoch 842/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13685.2871 - val_loss: 19009.9531\n",
      "Epoch 843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13539.9775 - val_loss: 18994.1895\n",
      "Epoch 844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13476.5840 - val_loss: 18972.0664\n",
      "Epoch 845/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13425.5752 - val_loss: 18946.8164\n",
      "Epoch 846/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13343.8975 - val_loss: 18888.2500\n",
      "Epoch 847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13152.3027 - val_loss: 18899.2383\n",
      "Epoch 848/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13139.0459 - val_loss: 18889.6270\n",
      "Epoch 849/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13118.0176 - val_loss: 18838.0684\n",
      "Epoch 850/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12975.3662 - val_loss: 18807.7793\n",
      "Epoch 851/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12870.6152 - val_loss: 18794.1074\n",
      "Epoch 852/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12826.1328 - val_loss: 18828.6406\n",
      "Epoch 853/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12923.9141 - val_loss: 18834.6680\n",
      "Epoch 854/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12973.3145 - val_loss: 18808.8477\n",
      "Epoch 855/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12898.7354 - val_loss: 18765.4629\n",
      "Epoch 856/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12776.0547 - val_loss: 18794.6465\n",
      "Epoch 857/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.7695 - val_loss: 18767.0020\n",
      "Epoch 858/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.6182 - val_loss: 18770.9160\n",
      "Epoch 859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12790.8740 - val_loss: 18769.7441\n",
      "Epoch 860/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12787.7305 - val_loss: 18760.6484\n",
      "Epoch 861/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12750.8721 - val_loss: 18761.6719\n",
      "Epoch 862/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12707.4092 - val_loss: 18725.9766\n",
      "Epoch 863/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12614.5547 - val_loss: 18766.5996\n",
      "Epoch 864/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12750.9600 - val_loss: 18788.9531\n",
      "Epoch 865/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12825.3145 - val_loss: 18767.3926\n",
      "Epoch 866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12761.6426 - val_loss: 18719.5195\n",
      "Epoch 867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12611.7725 - val_loss: 18757.6328\n",
      "Epoch 868/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.0088 - val_loss: 18749.1621\n",
      "Epoch 869/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.1299 - val_loss: 18747.6113\n",
      "Epoch 870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.0449 - val_loss: 18766.1816\n",
      "Epoch 871/10000\n",
      "630/630 [==============================] - 0s 22us/step - loss: 12765.0664 - val_loss: 18705.1406\n",
      "Epoch 872/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12585.1934 - val_loss: 18737.5293\n",
      "Epoch 873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.8672 - val_loss: 18736.5684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 874/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12643.2402 - val_loss: 18751.1387\n",
      "Epoch 875/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12698.1328 - val_loss: 18778.6367\n",
      "Epoch 876/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.3633 - val_loss: 18744.6074\n",
      "Epoch 877/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12679.6396 - val_loss: 18746.1211\n",
      "Epoch 878/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12675.5098 - val_loss: 18770.7402\n",
      "Epoch 879/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12751.0674 - val_loss: 18729.7148\n",
      "Epoch 880/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12666.0967 - val_loss: 18767.0078\n",
      "Epoch 881/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12778.7764 - val_loss: 18766.1738\n",
      "Epoch 882/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12760.2139 - val_loss: 18759.8926\n",
      "Epoch 883/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.3213 - val_loss: 18752.4238\n",
      "Epoch 884/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.8271 - val_loss: 18743.5371\n",
      "Epoch 885/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.2764 - val_loss: 18767.0918\n",
      "Epoch 886/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.4736 - val_loss: 18777.3086\n",
      "Epoch 887/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12783.5234 - val_loss: 18777.2520\n",
      "Epoch 888/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12768.4219 - val_loss: 18730.4551\n",
      "Epoch 889/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12636.5430 - val_loss: 18735.4629\n",
      "Epoch 890/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12643.1182 - val_loss: 18821.8789\n",
      "Epoch 891/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12902.1748 - val_loss: 18794.5859\n",
      "Epoch 892/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12870.3574 - val_loss: 18905.1484\n",
      "Epoch 893/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13204.1299 - val_loss: 18972.9180\n",
      "Epoch 894/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13412.8643 - val_loss: 18965.3516\n",
      "Epoch 895/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13388.8604 - val_loss: 18921.7539\n",
      "Epoch 896/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13262.1729 - val_loss: 18888.2207\n",
      "Epoch 897/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13172.4473 - val_loss: 18882.0137\n",
      "Epoch 898/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13146.7842 - val_loss: 18860.9883\n",
      "Epoch 899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13053.9912 - val_loss: 18898.2324\n",
      "Epoch 900/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13143.4590 - val_loss: 18823.8438\n",
      "Epoch 901/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12925.4980 - val_loss: 18804.8867\n",
      "Epoch 902/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.4619 - val_loss: 18799.9961\n",
      "Epoch 903/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12854.7773 - val_loss: 18772.2070\n",
      "Epoch 904/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.3906 - val_loss: 18777.5820\n",
      "Epoch 905/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.1270 - val_loss: 18777.7598\n",
      "Epoch 906/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.0117 - val_loss: 18811.3242\n",
      "Epoch 907/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12902.4893 - val_loss: 18803.4102\n",
      "Epoch 908/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12896.1523 - val_loss: 18776.5391\n",
      "Epoch 909/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12807.2568 - val_loss: 18749.4590\n",
      "Epoch 910/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.3086 - val_loss: 18751.2891\n",
      "Epoch 911/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12707.8057 - val_loss: 18743.3867\n",
      "Epoch 912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12683.1768 - val_loss: 18870.0137\n",
      "Epoch 913/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13016.5273 - val_loss: 18870.5059\n",
      "Epoch 914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13097.4365 - val_loss: 19051.4609\n",
      "Epoch 915/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13660.7461 - val_loss: 19157.4043\n",
      "Epoch 916/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13994.6416 - val_loss: 19192.5430\n",
      "Epoch 917/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14105.4619 - val_loss: 19200.6660\n",
      "Epoch 918/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14134.8965 - val_loss: 19196.7930\n",
      "Epoch 919/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14118.4072 - val_loss: 19169.2383\n",
      "Epoch 920/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14036.5000 - val_loss: 19142.3848\n",
      "Epoch 921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13953.1328 - val_loss: 19066.3145\n",
      "Epoch 922/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13719.0879 - val_loss: 18993.6914\n",
      "Epoch 923/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13468.1240 - val_loss: 18988.2227\n",
      "Epoch 924/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13432.4268 - val_loss: 18950.8613\n",
      "Epoch 925/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13332.1768 - val_loss: 18965.5723\n",
      "Epoch 926/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13364.5186 - val_loss: 18974.5547\n",
      "Epoch 927/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13391.9561 - val_loss: 18892.9727\n",
      "Epoch 928/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13143.5557 - val_loss: 18851.0117\n",
      "Epoch 929/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13017.4248 - val_loss: 18855.9805\n",
      "Epoch 930/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13056.6904 - val_loss: 18865.4023\n",
      "Epoch 931/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13076.9990 - val_loss: 18844.9082\n",
      "Epoch 932/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13025.3242 - val_loss: 18828.6016\n",
      "Epoch 933/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12975.0811 - val_loss: 18790.0391\n",
      "Epoch 934/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12841.7520 - val_loss: 18783.0938\n",
      "Epoch 935/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12810.2090 - val_loss: 18755.3223\n",
      "Epoch 936/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12712.3926 - val_loss: 18750.7305\n",
      "Epoch 937/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.2256 - val_loss: 18791.5879\n",
      "Epoch 938/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.4248 - val_loss: 18779.7637\n",
      "Epoch 939/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12812.4746 - val_loss: 18768.0176\n",
      "Epoch 940/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12757.8496 - val_loss: 18768.9922\n",
      "Epoch 941/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12756.3643 - val_loss: 18728.3320\n",
      "Epoch 942/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12630.3809 - val_loss: 18727.2676\n",
      "Epoch 943/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.7715 - val_loss: 18758.5566\n",
      "Epoch 944/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12739.8545 - val_loss: 18755.2441\n",
      "Epoch 945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12706.9492 - val_loss: 18722.2012\n",
      "Epoch 946/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12612.5303 - val_loss: 18728.5566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 947/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12615.6885 - val_loss: 18753.3652\n",
      "Epoch 948/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12714.0566 - val_loss: 18810.0508\n",
      "Epoch 949/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.6123 - val_loss: 18815.7773\n",
      "Epoch 950/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12925.8535 - val_loss: 18796.8125\n",
      "Epoch 951/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.9619 - val_loss: 18733.5254\n",
      "Epoch 952/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12680.5508 - val_loss: 18737.3105\n",
      "Epoch 953/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12661.5127 - val_loss: 18877.3398\n",
      "Epoch 954/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13030.7471 - val_loss: 18875.6250\n",
      "Epoch 955/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13093.4199 - val_loss: 19043.7070\n",
      "Epoch 956/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13620.5098 - val_loss: 19114.4785\n",
      "Epoch 957/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13860.6846 - val_loss: 19161.8418\n",
      "Epoch 958/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14010.4844 - val_loss: 19170.0391\n",
      "Epoch 959/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14042.6230 - val_loss: 19150.4004\n",
      "Epoch 960/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13979.5723 - val_loss: 19117.3984\n",
      "Epoch 961/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13873.9590 - val_loss: 19093.7715\n",
      "Epoch 962/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13792.0186 - val_loss: 19075.3809\n",
      "Epoch 963/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13738.7256 - val_loss: 19033.2051\n",
      "Epoch 964/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13596.7910 - val_loss: 18979.6426\n",
      "Epoch 965/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13413.8115 - val_loss: 18930.8926\n",
      "Epoch 966/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13274.3125 - val_loss: 18925.9219\n",
      "Epoch 967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13261.3477 - val_loss: 18901.2402\n",
      "Epoch 968/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13178.1709 - val_loss: 18835.9590\n",
      "Epoch 969/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12967.9385 - val_loss: 18815.6914\n",
      "Epoch 970/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12889.4092 - val_loss: 18817.5312\n",
      "Epoch 971/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12882.4385 - val_loss: 18854.3613\n",
      "Epoch 972/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13012.3984 - val_loss: 18864.1152\n",
      "Epoch 973/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13056.5869 - val_loss: 18852.1152\n",
      "Epoch 974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13031.1865 - val_loss: 18848.9727\n",
      "Epoch 975/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13026.1855 - val_loss: 18844.5098\n",
      "Epoch 976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13013.3936 - val_loss: 18792.0508\n",
      "Epoch 977/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12855.5928 - val_loss: 18801.1934\n",
      "Epoch 978/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12880.3418 - val_loss: 18816.7969\n",
      "Epoch 979/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12931.3408 - val_loss: 18787.9512\n",
      "Epoch 980/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12841.9980 - val_loss: 18778.5234\n",
      "Epoch 981/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12787.5117 - val_loss: 18765.8867\n",
      "Epoch 982/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.7588 - val_loss: 18812.2559\n",
      "Epoch 983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12896.5723 - val_loss: 18812.4570\n",
      "Epoch 984/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12883.8232 - val_loss: 18802.6465\n",
      "Epoch 985/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12849.6152 - val_loss: 18752.4863\n",
      "Epoch 986/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.0146 - val_loss: 18761.6230\n",
      "Epoch 987/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12758.2285 - val_loss: 18777.3809\n",
      "Epoch 988/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12810.4492 - val_loss: 18756.3691\n",
      "Epoch 989/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.3408 - val_loss: 18733.0215\n",
      "Epoch 990/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.2734 - val_loss: 18739.3887\n",
      "Epoch 991/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12676.2646 - val_loss: 18773.5000\n",
      "Epoch 992/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12772.3994 - val_loss: 18777.5957\n",
      "Epoch 993/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12783.7305 - val_loss: 18757.6016\n",
      "Epoch 994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.1006 - val_loss: 18713.9238\n",
      "Epoch 995/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.9629 - val_loss: 18736.8906\n",
      "Epoch 996/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12656.3467 - val_loss: 18771.8965\n",
      "Epoch 997/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.7676 - val_loss: 18763.8027\n",
      "Epoch 998/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12761.0000 - val_loss: 18766.5000\n",
      "Epoch 999/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.7656 - val_loss: 18804.0996\n",
      "Epoch 1000/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12893.8721 - val_loss: 18785.3613\n",
      "Epoch 1001/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12821.9043 - val_loss: 18758.9336\n",
      "Epoch 1002/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.9912 - val_loss: 18780.8438\n",
      "Epoch 1003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.9111 - val_loss: 18753.3105\n",
      "Epoch 1004/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12705.0518 - val_loss: 18808.7832\n",
      "Epoch 1005/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12891.3262 - val_loss: 18818.2422\n",
      "Epoch 1006/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12922.6621 - val_loss: 18780.9570\n",
      "Epoch 1007/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12825.0879 - val_loss: 18753.3789\n",
      "Epoch 1008/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12736.3398 - val_loss: 18734.7676\n",
      "Epoch 1009/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12684.1953 - val_loss: 18760.7188\n",
      "Epoch 1010/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12750.0410 - val_loss: 18803.0098\n",
      "Epoch 1011/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12856.3203 - val_loss: 18781.6055\n",
      "Epoch 1012/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12800.1152 - val_loss: 18771.9160\n",
      "Epoch 1013/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.3027 - val_loss: 18763.7949\n",
      "Epoch 1014/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.7373 - val_loss: 18752.3379\n",
      "Epoch 1015/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.1318 - val_loss: 18717.4062\n",
      "Epoch 1016/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12623.4219 - val_loss: 18718.1230\n",
      "Epoch 1017/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12620.9033 - val_loss: 18727.2617\n",
      "Epoch 1018/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.2910 - val_loss: 18765.9102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1019/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.7598 - val_loss: 18748.5371\n",
      "Epoch 1020/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12719.4121 - val_loss: 18728.7148\n",
      "Epoch 1021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.3574 - val_loss: 18767.5742\n",
      "Epoch 1022/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12743.8848 - val_loss: 18741.0527\n",
      "Epoch 1023/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12663.9189 - val_loss: 18787.2168\n",
      "Epoch 1024/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12810.9443 - val_loss: 18792.7773\n",
      "Epoch 1025/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12859.4092 - val_loss: 18777.8398\n",
      "Epoch 1026/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12818.3613 - val_loss: 18751.7246\n",
      "Epoch 1027/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12723.1943 - val_loss: 18766.3184\n",
      "Epoch 1028/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12745.9141 - val_loss: 18776.2773\n",
      "Epoch 1029/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12764.1846 - val_loss: 18738.4883\n",
      "Epoch 1030/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12676.0586 - val_loss: 18746.3047\n",
      "Epoch 1031/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12714.0674 - val_loss: 18728.5996\n",
      "Epoch 1032/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.2627 - val_loss: 18724.8125\n",
      "Epoch 1033/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12626.7773 - val_loss: 18720.3574\n",
      "Epoch 1034/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12611.7979 - val_loss: 18718.9902\n",
      "Epoch 1035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.8701 - val_loss: 18717.3340\n",
      "Epoch 1036/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12613.3506 - val_loss: 18710.3535\n",
      "Epoch 1037/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.6895 - val_loss: 18729.9863\n",
      "Epoch 1038/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.2188 - val_loss: 18741.2090\n",
      "Epoch 1039/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.8408 - val_loss: 18730.9082\n",
      "Epoch 1040/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.7510 - val_loss: 18714.5684\n",
      "Epoch 1041/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12588.2109 - val_loss: 18740.7832\n",
      "Epoch 1042/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12654.3682 - val_loss: 18759.9922\n",
      "Epoch 1043/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12749.1084 - val_loss: 18823.9375\n",
      "Epoch 1044/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.1055 - val_loss: 18867.2637\n",
      "Epoch 1045/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13092.6650 - val_loss: 18875.8242\n",
      "Epoch 1046/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13117.1816 - val_loss: 18843.0273\n",
      "Epoch 1047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13020.9746 - val_loss: 18804.4590\n",
      "Epoch 1048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12903.7461 - val_loss: 18799.8906\n",
      "Epoch 1049/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.8330 - val_loss: 18793.8574\n",
      "Epoch 1050/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12851.9639 - val_loss: 18778.1738\n",
      "Epoch 1051/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12794.2383 - val_loss: 18757.3887\n",
      "Epoch 1052/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.0361 - val_loss: 18744.0176\n",
      "Epoch 1053/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12667.1826 - val_loss: 18818.4941\n",
      "Epoch 1054/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12878.2627 - val_loss: 18811.6758\n",
      "Epoch 1055/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12915.1016 - val_loss: 18927.0430\n",
      "Epoch 1056/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13279.6074 - val_loss: 18974.7871\n",
      "Epoch 1057/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13435.4678 - val_loss: 18968.1855\n",
      "Epoch 1058/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13426.2002 - val_loss: 18955.9551\n",
      "Epoch 1059/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13383.6787 - val_loss: 18928.8711\n",
      "Epoch 1060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13283.9941 - val_loss: 18885.5469\n",
      "Epoch 1061/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13146.1289 - val_loss: 18816.5508\n",
      "Epoch 1062/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12933.8008 - val_loss: 18845.0820\n",
      "Epoch 1063/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13000.8984 - val_loss: 18783.7773\n",
      "Epoch 1064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12812.4463 - val_loss: 18894.6875\n",
      "Epoch 1065/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13153.3623 - val_loss: 18933.2070\n",
      "Epoch 1066/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13260.9199 - val_loss: 18954.2402\n",
      "Epoch 1067/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13318.4141 - val_loss: 18950.1035\n",
      "Epoch 1068/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13306.6680 - val_loss: 18910.9238\n",
      "Epoch 1069/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13187.4277 - val_loss: 18820.2773\n",
      "Epoch 1070/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12927.0371 - val_loss: 18760.3770\n",
      "Epoch 1071/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.5664 - val_loss: 18857.4258\n",
      "Epoch 1072/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13031.6543 - val_loss: 18814.2480\n",
      "Epoch 1073/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12928.6797 - val_loss: 18890.7812\n",
      "Epoch 1074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13169.4121 - val_loss: 18942.7422\n",
      "Epoch 1075/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13332.8350 - val_loss: 18951.5645\n",
      "Epoch 1076/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13358.9072 - val_loss: 18942.9512\n",
      "Epoch 1077/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13330.0801 - val_loss: 18899.7402\n",
      "Epoch 1078/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13193.2402 - val_loss: 18891.0488\n",
      "Epoch 1079/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13143.1299 - val_loss: 18860.8320\n",
      "Epoch 1080/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13055.4873 - val_loss: 18849.9238\n",
      "Epoch 1081/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13020.8164 - val_loss: 18879.0000\n",
      "Epoch 1082/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13085.8594 - val_loss: 18806.2559\n",
      "Epoch 1083/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12869.6475 - val_loss: 18796.1953\n",
      "Epoch 1084/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12859.8359 - val_loss: 18795.2969\n",
      "Epoch 1085/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12880.6826 - val_loss: 18799.7676\n",
      "Epoch 1086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12897.3525 - val_loss: 18765.2285\n",
      "Epoch 1087/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12776.6260 - val_loss: 18733.6348\n",
      "Epoch 1088/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12669.2441 - val_loss: 18775.1230\n",
      "Epoch 1089/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.9229 - val_loss: 18761.7793\n",
      "Epoch 1090/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12767.6396 - val_loss: 18821.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1091/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12964.2090 - val_loss: 18869.9980\n",
      "Epoch 1092/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13098.4551 - val_loss: 18861.2129\n",
      "Epoch 1093/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13063.7080 - val_loss: 18847.5273\n",
      "Epoch 1094/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13011.4580 - val_loss: 18865.0527\n",
      "Epoch 1095/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13063.4346 - val_loss: 18855.2148\n",
      "Epoch 1096/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13037.5635 - val_loss: 18841.9375\n",
      "Epoch 1097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12987.9316 - val_loss: 18818.9961\n",
      "Epoch 1098/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12925.0205 - val_loss: 18766.8555\n",
      "Epoch 1099/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.0928 - val_loss: 18778.2090\n",
      "Epoch 1100/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12813.8369 - val_loss: 18799.8633\n",
      "Epoch 1101/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.2812 - val_loss: 18816.6602\n",
      "Epoch 1102/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12912.4160 - val_loss: 18761.0664\n",
      "Epoch 1103/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12734.7051 - val_loss: 18713.9922\n",
      "Epoch 1104/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12595.2119 - val_loss: 18742.6348\n",
      "Epoch 1105/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12678.5020 - val_loss: 18752.3633\n",
      "Epoch 1106/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12731.3760 - val_loss: 18753.5410\n",
      "Epoch 1107/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12735.1816 - val_loss: 18752.8027\n",
      "Epoch 1108/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12726.7666 - val_loss: 18749.2891\n",
      "Epoch 1109/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12712.1006 - val_loss: 18744.8203\n",
      "Epoch 1110/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12693.9414 - val_loss: 18755.6465\n",
      "Epoch 1111/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12720.5273 - val_loss: 18751.7305\n",
      "Epoch 1112/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12718.6279 - val_loss: 18747.0293\n",
      "Epoch 1113/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12702.8447 - val_loss: 18712.6973\n",
      "Epoch 1114/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.3613 - val_loss: 18723.2070\n",
      "Epoch 1115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.1709 - val_loss: 18761.8379\n",
      "Epoch 1116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12758.8154 - val_loss: 18807.3125\n",
      "Epoch 1117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12896.3057 - val_loss: 18790.8848\n",
      "Epoch 1118/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12854.8525 - val_loss: 18760.3613\n",
      "Epoch 1119/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12759.0820 - val_loss: 18749.6719\n",
      "Epoch 1120/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.4414 - val_loss: 18762.6289\n",
      "Epoch 1121/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.3164 - val_loss: 18751.1758\n",
      "Epoch 1122/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.7588 - val_loss: 18751.1250\n",
      "Epoch 1123/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.3721 - val_loss: 18740.1328\n",
      "Epoch 1124/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.4385 - val_loss: 18717.5098\n",
      "Epoch 1125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12605.3184 - val_loss: 18800.8574\n",
      "Epoch 1126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.3076 - val_loss: 18815.5703\n",
      "Epoch 1127/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12933.1221 - val_loss: 18901.6504\n",
      "Epoch 1128/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13205.6152 - val_loss: 18937.0762\n",
      "Epoch 1129/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13328.2588 - val_loss: 18957.6230\n",
      "Epoch 1130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13390.5869 - val_loss: 18951.9805\n",
      "Epoch 1131/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13360.2617 - val_loss: 18913.6465\n",
      "Epoch 1132/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13235.6504 - val_loss: 18871.6016\n",
      "Epoch 1133/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13103.1191 - val_loss: 18844.8594\n",
      "Epoch 1134/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13034.2773 - val_loss: 18814.3730\n",
      "Epoch 1135/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12921.3564 - val_loss: 18818.3828\n",
      "Epoch 1136/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12905.1787 - val_loss: 18805.4961\n",
      "Epoch 1137/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12861.4844 - val_loss: 18879.8672\n",
      "Epoch 1138/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13073.0312 - val_loss: 18924.3145\n",
      "Epoch 1139/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13255.6074 - val_loss: 19143.4258\n",
      "Epoch 1140/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13955.1260 - val_loss: 19257.9609\n",
      "Epoch 1141/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14311.9961 - val_loss: 19287.3828\n",
      "Epoch 1142/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14407.1787 - val_loss: 19286.2520\n",
      "Epoch 1143/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14414.9541 - val_loss: 19257.7852\n",
      "Epoch 1144/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14330.1299 - val_loss: 19221.5898\n",
      "Epoch 1145/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14217.1494 - val_loss: 19150.8516\n",
      "Epoch 1146/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13986.8896 - val_loss: 19121.6719\n",
      "Epoch 1147/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13884.0713 - val_loss: 19083.9688\n",
      "Epoch 1148/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13768.4355 - val_loss: 19059.1777\n",
      "Epoch 1149/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13680.9326 - val_loss: 19015.3223\n",
      "Epoch 1150/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13525.1748 - val_loss: 19010.1035\n",
      "Epoch 1151/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13493.3115 - val_loss: 18959.5898\n",
      "Epoch 1152/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13352.4590 - val_loss: 19001.7598\n",
      "Epoch 1153/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13478.5342 - val_loss: 18838.4688\n",
      "Epoch 1154/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12966.6787 - val_loss: 18834.2129\n",
      "Epoch 1155/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12972.3457 - val_loss: 18869.5859\n",
      "Epoch 1156/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13098.3086 - val_loss: 18915.3965\n",
      "Epoch 1157/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13238.5537 - val_loss: 18940.2129\n",
      "Epoch 1158/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13328.4756 - val_loss: 18937.6348\n",
      "Epoch 1159/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13320.2061 - val_loss: 18932.6562\n",
      "Epoch 1160/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13302.8926 - val_loss: 18874.3887\n",
      "Epoch 1161/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13129.4023 - val_loss: 18803.1562\n",
      "Epoch 1162/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.7627 - val_loss: 18779.0547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1163/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12826.4316 - val_loss: 18763.0488\n",
      "Epoch 1164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12761.6016 - val_loss: 18879.4668\n",
      "Epoch 1165/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13074.6006 - val_loss: 18833.4043\n",
      "Epoch 1166/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12966.0615 - val_loss: 18935.0605\n",
      "Epoch 1167/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13279.8525 - val_loss: 19003.1309\n",
      "Epoch 1168/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13496.7432 - val_loss: 19016.1836\n",
      "Epoch 1169/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13537.8555 - val_loss: 18946.6113\n",
      "Epoch 1170/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13321.2432 - val_loss: 18939.2559\n",
      "Epoch 1171/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13305.7344 - val_loss: 18923.2734\n",
      "Epoch 1172/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13246.9629 - val_loss: 18919.2754\n",
      "Epoch 1173/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13232.6240 - val_loss: 18902.2324\n",
      "Epoch 1174/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13176.1611 - val_loss: 18828.2695\n",
      "Epoch 1175/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12946.2549 - val_loss: 18798.1562\n",
      "Epoch 1176/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.0566 - val_loss: 18807.3340\n",
      "Epoch 1177/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12901.3047 - val_loss: 18849.3691\n",
      "Epoch 1178/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13023.1641 - val_loss: 18790.3008\n",
      "Epoch 1179/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12859.2051 - val_loss: 18791.6074\n",
      "Epoch 1180/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12859.2490 - val_loss: 18787.3594\n",
      "Epoch 1181/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12844.7744 - val_loss: 18773.5410\n",
      "Epoch 1182/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12792.7510 - val_loss: 18791.7871\n",
      "Epoch 1183/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.6113 - val_loss: 18762.9160\n",
      "Epoch 1184/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.7725 - val_loss: 18822.4219\n",
      "Epoch 1185/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12958.8301 - val_loss: 18860.0371\n",
      "Epoch 1186/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13072.8779 - val_loss: 18854.7207\n",
      "Epoch 1187/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13053.9961 - val_loss: 18845.9629\n",
      "Epoch 1188/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13013.7324 - val_loss: 18818.9980\n",
      "Epoch 1189/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12919.4414 - val_loss: 18797.9766\n",
      "Epoch 1190/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12844.8008 - val_loss: 18769.0254\n",
      "Epoch 1191/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12762.2529 - val_loss: 18804.9609\n",
      "Epoch 1192/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12877.5674 - val_loss: 18736.7793\n",
      "Epoch 1193/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12693.1338 - val_loss: 18809.7441\n",
      "Epoch 1194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12920.7588 - val_loss: 18849.7598\n",
      "Epoch 1195/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13046.4199 - val_loss: 18857.3809\n",
      "Epoch 1196/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13072.8164 - val_loss: 18839.9023\n",
      "Epoch 1197/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13018.7529 - val_loss: 18812.9375\n",
      "Epoch 1198/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12929.0186 - val_loss: 18786.4141\n",
      "Epoch 1199/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12843.1758 - val_loss: 18805.1992\n",
      "Epoch 1200/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.7334 - val_loss: 18806.8770\n",
      "Epoch 1201/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12885.8027 - val_loss: 18792.0312\n",
      "Epoch 1202/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12844.6602 - val_loss: 18794.8242\n",
      "Epoch 1203/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12851.3779 - val_loss: 18795.6289\n",
      "Epoch 1204/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.2822 - val_loss: 18781.1934\n",
      "Epoch 1205/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12790.2871 - val_loss: 18744.9180\n",
      "Epoch 1206/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12677.4951 - val_loss: 18755.2695\n",
      "Epoch 1207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.5850 - val_loss: 18788.8184\n",
      "Epoch 1208/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12854.1689 - val_loss: 18792.2852\n",
      "Epoch 1209/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12868.3574 - val_loss: 18757.6895\n",
      "Epoch 1210/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12760.8037 - val_loss: 18764.4141\n",
      "Epoch 1211/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12773.3574 - val_loss: 18769.5508\n",
      "Epoch 1212/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12787.9160 - val_loss: 18758.4922\n",
      "Epoch 1213/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.9805 - val_loss: 18713.0703\n",
      "Epoch 1214/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12618.5830 - val_loss: 18719.7168\n",
      "Epoch 1215/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12601.6602 - val_loss: 18751.9961\n",
      "Epoch 1216/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.9121 - val_loss: 18786.1133\n",
      "Epoch 1217/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12806.2432 - val_loss: 18750.3906\n",
      "Epoch 1218/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12702.2305 - val_loss: 18770.1445\n",
      "Epoch 1219/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.1484 - val_loss: 18783.6973\n",
      "Epoch 1220/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12837.3477 - val_loss: 18781.5586\n",
      "Epoch 1221/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12843.3398 - val_loss: 18774.3652\n",
      "Epoch 1222/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12812.2695 - val_loss: 18721.7734\n",
      "Epoch 1223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.5244 - val_loss: 18761.0605\n",
      "Epoch 1224/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12732.2910 - val_loss: 18768.7324\n",
      "Epoch 1225/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12769.5322 - val_loss: 18848.0293\n",
      "Epoch 1226/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13016.3916 - val_loss: 18872.1367\n",
      "Epoch 1227/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13102.8760 - val_loss: 18854.6641\n",
      "Epoch 1228/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13051.1846 - val_loss: 18844.9336\n",
      "Epoch 1229/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13009.6191 - val_loss: 18814.9805\n",
      "Epoch 1230/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12918.5107 - val_loss: 18802.7578\n",
      "Epoch 1231/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12873.2432 - val_loss: 18739.9121\n",
      "Epoch 1232/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.4512 - val_loss: 18747.4336\n",
      "Epoch 1233/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.6523 - val_loss: 18865.4863\n",
      "Epoch 1234/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13061.0312 - val_loss: 18832.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1235/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12988.2822 - val_loss: 18909.5137\n",
      "Epoch 1236/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13231.0234 - val_loss: 18936.3965\n",
      "Epoch 1237/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13314.0596 - val_loss: 18950.6660\n",
      "Epoch 1238/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13368.6230 - val_loss: 18941.8672\n",
      "Epoch 1239/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13336.1445 - val_loss: 18891.4805\n",
      "Epoch 1240/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13174.6455 - val_loss: 18880.2227\n",
      "Epoch 1241/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13117.3496 - val_loss: 18874.2812\n",
      "Epoch 1242/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13102.8594 - val_loss: 18876.1875\n",
      "Epoch 1243/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13106.6201 - val_loss: 18853.3164\n",
      "Epoch 1244/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13030.3320 - val_loss: 18804.2910\n",
      "Epoch 1245/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12867.1094 - val_loss: 18751.0801\n",
      "Epoch 1246/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.1660 - val_loss: 18785.0488\n",
      "Epoch 1247/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12824.8857 - val_loss: 18852.3438\n",
      "Epoch 1248/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13046.7061 - val_loss: 18854.4941\n",
      "Epoch 1249/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13058.9062 - val_loss: 18959.8984\n",
      "Epoch 1250/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13388.1279 - val_loss: 19011.2441\n",
      "Epoch 1251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13545.6318 - val_loss: 18997.5547\n",
      "Epoch 1252/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13505.8555 - val_loss: 18979.3184\n",
      "Epoch 1253/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13450.4248 - val_loss: 18947.0488\n",
      "Epoch 1254/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13346.8760 - val_loss: 18896.9316\n",
      "Epoch 1255/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13201.1572 - val_loss: 18858.8848\n",
      "Epoch 1256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13077.4980 - val_loss: 18849.7051\n",
      "Epoch 1257/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13021.2373 - val_loss: 18863.9883\n",
      "Epoch 1258/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13057.1963 - val_loss: 18890.0156\n",
      "Epoch 1259/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13132.5430 - val_loss: 18821.2422\n",
      "Epoch 1260/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12918.6084 - val_loss: 18837.7031\n",
      "Epoch 1261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12974.6768 - val_loss: 18855.2207\n",
      "Epoch 1262/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13062.5693 - val_loss: 18860.9082\n",
      "Epoch 1263/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13075.7812 - val_loss: 18831.8281\n",
      "Epoch 1264/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12991.3730 - val_loss: 18785.4414\n",
      "Epoch 1265/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12856.6523 - val_loss: 18792.2188\n",
      "Epoch 1266/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12859.8906 - val_loss: 18743.9531\n",
      "Epoch 1267/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.7881 - val_loss: 18742.3750\n",
      "Epoch 1268/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12693.8076 - val_loss: 18751.2500\n",
      "Epoch 1269/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.6484 - val_loss: 18766.4688\n",
      "Epoch 1270/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.8789 - val_loss: 18777.2461\n",
      "Epoch 1271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12772.8164 - val_loss: 18739.1504\n",
      "Epoch 1272/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12697.7266 - val_loss: 18761.6348\n",
      "Epoch 1273/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12776.0361 - val_loss: 18765.7051\n",
      "Epoch 1274/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12791.9082 - val_loss: 18762.9004\n",
      "Epoch 1275/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.8301 - val_loss: 18754.3770\n",
      "Epoch 1276/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.7549 - val_loss: 18722.0371\n",
      "Epoch 1277/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12630.7959 - val_loss: 18730.2480\n",
      "Epoch 1278/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.0215 - val_loss: 18723.6074\n",
      "Epoch 1279/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12626.4111 - val_loss: 18731.7637\n",
      "Epoch 1280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12648.9502 - val_loss: 18748.5938\n",
      "Epoch 1281/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12707.1855 - val_loss: 18722.8418\n",
      "Epoch 1282/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12643.2344 - val_loss: 18731.2168\n",
      "Epoch 1283/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12667.1553 - val_loss: 18701.5215\n",
      "Epoch 1284/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12579.3701 - val_loss: 18701.0488\n",
      "Epoch 1285/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12581.8359 - val_loss: 18722.0957\n",
      "Epoch 1286/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.4404 - val_loss: 18724.4375\n",
      "Epoch 1287/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12632.5391 - val_loss: 18716.6543\n",
      "Epoch 1288/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.6592 - val_loss: 18691.5234\n",
      "Epoch 1289/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.2266 - val_loss: 18732.1895\n",
      "Epoch 1290/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12647.5244 - val_loss: 18746.7891\n",
      "Epoch 1291/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12713.6865 - val_loss: 18771.7324\n",
      "Epoch 1292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12796.4629 - val_loss: 18760.1738\n",
      "Epoch 1293/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12770.6230 - val_loss: 18742.5059\n",
      "Epoch 1294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.6895 - val_loss: 18718.1582\n",
      "Epoch 1295/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.8477 - val_loss: 18721.5918\n",
      "Epoch 1296/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12604.2354 - val_loss: 18711.8398\n",
      "Epoch 1297/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12584.4072 - val_loss: 18728.5234\n",
      "Epoch 1298/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.1465 - val_loss: 18762.8477\n",
      "Epoch 1299/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12753.1895 - val_loss: 18750.9648\n",
      "Epoch 1300/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12736.4531 - val_loss: 18845.1152\n",
      "Epoch 1301/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13029.7930 - val_loss: 18858.0410\n",
      "Epoch 1302/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13076.7822 - val_loss: 18844.9277\n",
      "Epoch 1303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13034.8291 - val_loss: 18809.6836\n",
      "Epoch 1304/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12918.3115 - val_loss: 18759.5469\n",
      "Epoch 1305/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.7822 - val_loss: 18773.7559\n",
      "Epoch 1306/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.4990 - val_loss: 18807.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12886.1465 - val_loss: 18782.7988\n",
      "Epoch 1308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12806.2070 - val_loss: 18726.1816\n",
      "Epoch 1309/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.2246 - val_loss: 18715.5020\n",
      "Epoch 1310/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12611.2148 - val_loss: 18750.5625\n",
      "Epoch 1311/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.3643 - val_loss: 18739.5703\n",
      "Epoch 1312/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12703.1631 - val_loss: 18731.8242\n",
      "Epoch 1313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.3848 - val_loss: 18755.6328\n",
      "Epoch 1314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12761.6250 - val_loss: 18733.8633\n",
      "Epoch 1315/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.7246 - val_loss: 18728.3027\n",
      "Epoch 1316/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12639.1553 - val_loss: 18731.4258\n",
      "Epoch 1317/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12639.0566 - val_loss: 18785.2266\n",
      "Epoch 1318/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12799.4541 - val_loss: 18807.4531\n",
      "Epoch 1319/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12916.1240 - val_loss: 18949.4961\n",
      "Epoch 1320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13358.4727 - val_loss: 19033.1484\n",
      "Epoch 1321/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13623.0381 - val_loss: 19047.3691\n",
      "Epoch 1322/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13660.5762 - val_loss: 19046.1426\n",
      "Epoch 1323/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13656.5010 - val_loss: 19026.1074\n",
      "Epoch 1324/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13603.2314 - val_loss: 18985.6426\n",
      "Epoch 1325/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13475.2539 - val_loss: 18954.7754\n",
      "Epoch 1326/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13378.6006 - val_loss: 18928.3848\n",
      "Epoch 1327/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13298.0000 - val_loss: 18907.5664\n",
      "Epoch 1328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13220.2402 - val_loss: 18914.5078\n",
      "Epoch 1329/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13223.0264 - val_loss: 18934.5742\n",
      "Epoch 1330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13282.9492 - val_loss: 18903.9785\n",
      "Epoch 1331/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13184.6484 - val_loss: 18892.0977\n",
      "Epoch 1332/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13159.2578 - val_loss: 18861.7559\n",
      "Epoch 1333/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13069.6826 - val_loss: 18831.7422\n",
      "Epoch 1334/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12971.1045 - val_loss: 18796.6445\n",
      "Epoch 1335/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.7959 - val_loss: 18772.1113\n",
      "Epoch 1336/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12773.8311 - val_loss: 18744.5723\n",
      "Epoch 1337/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12717.4600 - val_loss: 18749.1113\n",
      "Epoch 1338/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.7441 - val_loss: 18843.6699\n",
      "Epoch 1339/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13021.1768 - val_loss: 18894.3633\n",
      "Epoch 1340/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13181.2256 - val_loss: 19067.9102\n",
      "Epoch 1341/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13723.9404 - val_loss: 19172.0352\n",
      "Epoch 1342/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14052.9258 - val_loss: 19201.0293\n",
      "Epoch 1343/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14142.3115 - val_loss: 19151.6035\n",
      "Epoch 1344/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13989.2822 - val_loss: 19075.6250\n",
      "Epoch 1345/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13753.7617 - val_loss: 19005.2852\n",
      "Epoch 1346/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13528.5791 - val_loss: 18981.4180\n",
      "Epoch 1347/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13458.9473 - val_loss: 18973.3105\n",
      "Epoch 1348/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13432.1582 - val_loss: 18975.7363\n",
      "Epoch 1349/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13415.0957 - val_loss: 18932.9980\n",
      "Epoch 1350/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13273.9072 - val_loss: 19003.8867\n",
      "Epoch 1351/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13507.2412 - val_loss: 18842.1172\n",
      "Epoch 1352/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12993.0840 - val_loss: 18968.4863\n",
      "Epoch 1353/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13387.8457 - val_loss: 19073.3984\n",
      "Epoch 1354/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13746.1670 - val_loss: 19138.6504\n",
      "Epoch 1355/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13951.9600 - val_loss: 19119.3145\n",
      "Epoch 1356/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13892.5068 - val_loss: 19063.8438\n",
      "Epoch 1357/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13711.4023 - val_loss: 19033.4121\n",
      "Epoch 1358/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13613.5146 - val_loss: 18979.1523\n",
      "Epoch 1359/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13427.4443 - val_loss: 18911.1816\n",
      "Epoch 1360/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13205.4707 - val_loss: 18885.1953\n",
      "Epoch 1361/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13136.5225 - val_loss: 18892.1621\n",
      "Epoch 1362/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13162.9941 - val_loss: 18878.6855\n",
      "Epoch 1363/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13093.3418 - val_loss: 18931.3457\n",
      "Epoch 1364/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13275.5850 - val_loss: 18926.4395\n",
      "Epoch 1365/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13254.4766 - val_loss: 18893.3789\n",
      "Epoch 1366/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13151.5596 - val_loss: 18858.9082\n",
      "Epoch 1367/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13050.0049 - val_loss: 18864.0547\n",
      "Epoch 1368/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13092.2119 - val_loss: 18774.8555\n",
      "Epoch 1369/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12807.1973 - val_loss: 18816.9219\n",
      "Epoch 1370/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12947.4170 - val_loss: 18866.9082\n",
      "Epoch 1371/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13088.1729 - val_loss: 18857.1855\n",
      "Epoch 1372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13052.6670 - val_loss: 18829.3926\n",
      "Epoch 1373/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12959.7188 - val_loss: 18793.4609\n",
      "Epoch 1374/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12844.6064 - val_loss: 18786.3535\n",
      "Epoch 1375/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12812.4072 - val_loss: 18733.6953\n",
      "Epoch 1376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12664.3467 - val_loss: 18755.7402\n",
      "Epoch 1377/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.3613 - val_loss: 18773.8105\n",
      "Epoch 1378/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12801.9961 - val_loss: 18733.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1379/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12691.3936 - val_loss: 18713.0742\n",
      "Epoch 1380/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12632.8936 - val_loss: 18738.8691\n",
      "Epoch 1381/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12705.2520 - val_loss: 18717.1270\n",
      "Epoch 1382/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12615.1689 - val_loss: 18705.5176\n",
      "Epoch 1383/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12570.7949 - val_loss: 18718.1699\n",
      "Epoch 1384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.4971 - val_loss: 18716.6152\n",
      "Epoch 1385/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12600.8057 - val_loss: 18688.5020\n",
      "Epoch 1386/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12516.8906 - val_loss: 18676.6543\n",
      "Epoch 1387/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12497.5605 - val_loss: 18732.4902\n",
      "Epoch 1388/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.3750 - val_loss: 18757.4629\n",
      "Epoch 1389/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12749.4375 - val_loss: 18753.5156\n",
      "Epoch 1390/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12744.9121 - val_loss: 18724.7305\n",
      "Epoch 1391/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12655.3828 - val_loss: 18700.7500\n",
      "Epoch 1392/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.5303 - val_loss: 19045.1191\n",
      "Epoch 1393/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13612.5137 - val_loss: 19112.8594\n",
      "Epoch 1394/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13855.0283 - val_loss: 19552.7383\n",
      "Epoch 1395/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15234.0186 - val_loss: 19886.6895\n",
      "Epoch 1396/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 16276.5166 - val_loss: 20102.1465\n",
      "Epoch 1397/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16948.3867 - val_loss: 20207.8887\n",
      "Epoch 1398/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 17277.9004 - val_loss: 20243.1387\n",
      "Epoch 1399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 17384.2969 - val_loss: 20246.7598\n",
      "Epoch 1400/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 17393.8867 - val_loss: 20203.6289\n",
      "Epoch 1401/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 17246.4414 - val_loss: 20150.4336\n",
      "Epoch 1402/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 17099.3828 - val_loss: 20091.2168\n",
      "Epoch 1403/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 16918.7871 - val_loss: 19991.3906\n",
      "Epoch 1404/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16614.1113 - val_loss: 19864.9062\n",
      "Epoch 1405/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16223.2461 - val_loss: 19797.9297\n",
      "Epoch 1406/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16013.3936 - val_loss: 19781.3535\n",
      "Epoch 1407/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15958.1367 - val_loss: 19807.0156\n",
      "Epoch 1408/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16027.0547 - val_loss: 19775.4922\n",
      "Epoch 1409/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15928.6523 - val_loss: 19701.3086\n",
      "Epoch 1410/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15672.3057 - val_loss: 19657.2324\n",
      "Epoch 1411/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 15547.4492 - val_loss: 19607.9688\n",
      "Epoch 1412/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15395.7656 - val_loss: 19556.9551\n",
      "Epoch 1413/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15237.8574 - val_loss: 19483.1895\n",
      "Epoch 1414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15004.4082 - val_loss: 19445.3438\n",
      "Epoch 1415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14886.2510 - val_loss: 19390.4160\n",
      "Epoch 1416/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14717.0859 - val_loss: 19352.4316\n",
      "Epoch 1417/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14594.4746 - val_loss: 19319.9453\n",
      "Epoch 1418/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14487.4346 - val_loss: 19266.4023\n",
      "Epoch 1419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14316.4834 - val_loss: 19211.0742\n",
      "Epoch 1420/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14149.3125 - val_loss: 19160.3672\n",
      "Epoch 1421/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14018.9189 - val_loss: 19087.3301\n",
      "Epoch 1422/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13793.8662 - val_loss: 19019.6523\n",
      "Epoch 1423/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13592.5742 - val_loss: 19009.2148\n",
      "Epoch 1424/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13552.8438 - val_loss: 19001.7148\n",
      "Epoch 1425/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13530.8682 - val_loss: 18992.8164\n",
      "Epoch 1426/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13492.9561 - val_loss: 18976.0137\n",
      "Epoch 1427/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13411.6934 - val_loss: 18950.8711\n",
      "Epoch 1428/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13324.1357 - val_loss: 18947.2441\n",
      "Epoch 1429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13301.1172 - val_loss: 18923.3398\n",
      "Epoch 1430/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13248.8740 - val_loss: 18905.4492\n",
      "Epoch 1431/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13196.0430 - val_loss: 18876.2891\n",
      "Epoch 1432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13097.0771 - val_loss: 18767.1699\n",
      "Epoch 1433/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.6660 - val_loss: 18711.8926\n",
      "Epoch 1434/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12622.4971 - val_loss: 18754.6406\n",
      "Epoch 1435/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12752.6445 - val_loss: 18795.9766\n",
      "Epoch 1436/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.3926 - val_loss: 18779.9863\n",
      "Epoch 1437/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12838.9043 - val_loss: 18787.0039\n",
      "Epoch 1438/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12860.7520 - val_loss: 18785.7441\n",
      "Epoch 1439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.2930 - val_loss: 18787.8711\n",
      "Epoch 1440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12819.5889 - val_loss: 18771.3340\n",
      "Epoch 1441/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12767.1416 - val_loss: 18774.0137\n",
      "Epoch 1442/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12785.4580 - val_loss: 18771.5059\n",
      "Epoch 1443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.6289 - val_loss: 18748.4277\n",
      "Epoch 1444/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12707.3682 - val_loss: 18728.7793\n",
      "Epoch 1445/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12623.9873 - val_loss: 18707.5195\n",
      "Epoch 1446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12597.6816 - val_loss: 18697.6836\n",
      "Epoch 1447/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12575.9307 - val_loss: 18699.1328\n",
      "Epoch 1448/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.5527 - val_loss: 18712.7070\n",
      "Epoch 1449/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.9580 - val_loss: 18736.3789\n",
      "Epoch 1450/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.4502 - val_loss: 18720.9082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12646.7148 - val_loss: 18706.5312\n",
      "Epoch 1452/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.1846 - val_loss: 18722.6367\n",
      "Epoch 1453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.6963 - val_loss: 18765.2344\n",
      "Epoch 1454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.4746 - val_loss: 18764.2344\n",
      "Epoch 1455/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.1279 - val_loss: 18770.9199\n",
      "Epoch 1456/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.6768 - val_loss: 18766.8418\n",
      "Epoch 1457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.8730 - val_loss: 18765.1816\n",
      "Epoch 1458/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12744.0928 - val_loss: 18733.6543\n",
      "Epoch 1459/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12680.9746 - val_loss: 18744.0703\n",
      "Epoch 1460/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12708.3584 - val_loss: 18688.4062\n",
      "Epoch 1461/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.1416 - val_loss: 18714.9629\n",
      "Epoch 1462/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12630.3262 - val_loss: 18772.4102\n",
      "Epoch 1463/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12807.7334 - val_loss: 18790.1035\n",
      "Epoch 1464/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12835.1924 - val_loss: 18765.4160\n",
      "Epoch 1465/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.4629 - val_loss: 18768.7559\n",
      "Epoch 1466/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12751.8857 - val_loss: 18742.7363\n",
      "Epoch 1467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12689.4316 - val_loss: 18775.6133\n",
      "Epoch 1468/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12780.9014 - val_loss: 18729.5820\n",
      "Epoch 1469/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.3105 - val_loss: 18768.5352\n",
      "Epoch 1470/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.4355 - val_loss: 18769.5957\n",
      "Epoch 1471/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12805.4912 - val_loss: 18751.8574\n",
      "Epoch 1472/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.0293 - val_loss: 18725.7949\n",
      "Epoch 1473/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.0234 - val_loss: 18833.3516\n",
      "Epoch 1474/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12958.8105 - val_loss: 18894.6680\n",
      "Epoch 1475/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13183.3271 - val_loss: 19100.4746\n",
      "Epoch 1476/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13828.0508 - val_loss: 19236.5156\n",
      "Epoch 1477/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14253.2217 - val_loss: 19312.3770\n",
      "Epoch 1478/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14488.9795 - val_loss: 19329.8242\n",
      "Epoch 1479/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14545.5566 - val_loss: 19289.4199\n",
      "Epoch 1480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14417.0352 - val_loss: 19239.2871\n",
      "Epoch 1481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14258.2354 - val_loss: 19224.1836\n",
      "Epoch 1482/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14210.3174 - val_loss: 19203.0840\n",
      "Epoch 1483/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14129.4736 - val_loss: 19161.2891\n",
      "Epoch 1484/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13996.6836 - val_loss: 19159.3848\n",
      "Epoch 1485/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13997.7314 - val_loss: 19154.9629\n",
      "Epoch 1486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13983.3369 - val_loss: 19129.2539\n",
      "Epoch 1487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13889.9912 - val_loss: 19062.5039\n",
      "Epoch 1488/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13674.6758 - val_loss: 18988.6152\n",
      "Epoch 1489/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13457.8301 - val_loss: 18942.0801\n",
      "Epoch 1490/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13320.3965 - val_loss: 18904.4863\n",
      "Epoch 1491/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13219.1484 - val_loss: 18884.9824\n",
      "Epoch 1492/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13162.5625 - val_loss: 18845.7129\n",
      "Epoch 1493/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13040.4141 - val_loss: 18821.7402\n",
      "Epoch 1494/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12961.9854 - val_loss: 18836.4043\n",
      "Epoch 1495/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12989.6367 - val_loss: 18875.4863\n",
      "Epoch 1496/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13099.5469 - val_loss: 18791.0703\n",
      "Epoch 1497/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12856.4092 - val_loss: 18821.7852\n",
      "Epoch 1498/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12961.6836 - val_loss: 18853.8340\n",
      "Epoch 1499/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13068.0938 - val_loss: 18850.8379\n",
      "Epoch 1500/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13051.5703 - val_loss: 18853.1230\n",
      "Epoch 1501/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13039.1680 - val_loss: 18828.8828\n",
      "Epoch 1502/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12956.5889 - val_loss: 18814.5664\n",
      "Epoch 1503/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12914.7480 - val_loss: 18815.0430\n",
      "Epoch 1504/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12919.3623 - val_loss: 18838.8613\n",
      "Epoch 1505/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12989.3984 - val_loss: 18838.9492\n",
      "Epoch 1506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13014.8906 - val_loss: 18796.8574\n",
      "Epoch 1507/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12888.7412 - val_loss: 18752.1406\n",
      "Epoch 1508/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.0059 - val_loss: 18748.0371\n",
      "Epoch 1509/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12718.2178 - val_loss: 18917.4082\n",
      "Epoch 1510/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13227.1924 - val_loss: 18876.1270\n",
      "Epoch 1511/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13127.4268 - val_loss: 19036.1289\n",
      "Epoch 1512/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13626.4414 - val_loss: 19108.2168\n",
      "Epoch 1513/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13853.6504 - val_loss: 19151.8652\n",
      "Epoch 1514/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13993.4111 - val_loss: 19149.2676\n",
      "Epoch 1515/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13990.6807 - val_loss: 19115.7402\n",
      "Epoch 1516/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13888.9434 - val_loss: 19057.0508\n",
      "Epoch 1517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13706.5576 - val_loss: 19016.4668\n",
      "Epoch 1518/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13572.3516 - val_loss: 18989.7930\n",
      "Epoch 1519/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13468.3350 - val_loss: 19012.3926\n",
      "Epoch 1520/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13529.4473 - val_loss: 19018.2969\n",
      "Epoch 1521/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13550.8848 - val_loss: 19010.5430\n",
      "Epoch 1522/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13521.9102 - val_loss: 18988.7051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1523/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13435.4023 - val_loss: 18980.8828\n",
      "Epoch 1524/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13410.1025 - val_loss: 18931.4941\n",
      "Epoch 1525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13255.8955 - val_loss: 18906.5645\n",
      "Epoch 1526/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13177.9951 - val_loss: 18895.0039\n",
      "Epoch 1527/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13161.8125 - val_loss: 18893.9902\n",
      "Epoch 1528/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13185.9688 - val_loss: 18870.3770\n",
      "Epoch 1529/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13116.6514 - val_loss: 18884.2598\n",
      "Epoch 1530/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13160.9678 - val_loss: 18846.8359\n",
      "Epoch 1531/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13046.7461 - val_loss: 18799.2812\n",
      "Epoch 1532/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12893.2500 - val_loss: 18759.0195\n",
      "Epoch 1533/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12764.1211 - val_loss: 18730.9023\n",
      "Epoch 1534/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12657.4463 - val_loss: 18727.6055\n",
      "Epoch 1535/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12637.9434 - val_loss: 18968.9609\n",
      "Epoch 1536/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13347.6641 - val_loss: 18954.8477\n",
      "Epoch 1537/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13375.1514 - val_loss: 19212.9785\n",
      "Epoch 1538/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14180.4219 - val_loss: 19375.6309\n",
      "Epoch 1539/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14690.5518 - val_loss: 19454.0508\n",
      "Epoch 1540/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14938.2969 - val_loss: 19486.9238\n",
      "Epoch 1541/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15042.8027 - val_loss: 19483.8359\n",
      "Epoch 1542/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15030.2754 - val_loss: 19437.7930\n",
      "Epoch 1543/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14884.3184 - val_loss: 19386.4570\n",
      "Epoch 1544/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14724.5566 - val_loss: 19405.1543\n",
      "Epoch 1545/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14785.3545 - val_loss: 19427.6328\n",
      "Epoch 1546/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14859.8779 - val_loss: 19404.7480\n",
      "Epoch 1547/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14792.3145 - val_loss: 19343.8438\n",
      "Epoch 1548/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14601.6338 - val_loss: 19271.4551\n",
      "Epoch 1549/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14371.2842 - val_loss: 19233.8652\n",
      "Epoch 1550/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14246.0547 - val_loss: 19163.9629\n",
      "Epoch 1551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14028.1074 - val_loss: 19155.2012\n",
      "Epoch 1552/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13953.2949 - val_loss: 19118.0234\n",
      "Epoch 1553/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13831.7061 - val_loss: 19064.9648\n",
      "Epoch 1554/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13671.6094 - val_loss: 19035.3711\n",
      "Epoch 1555/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13583.5713 - val_loss: 19023.4062\n",
      "Epoch 1556/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13567.9727 - val_loss: 19004.4531\n",
      "Epoch 1557/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13505.8809 - val_loss: 18942.9746\n",
      "Epoch 1558/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13316.5244 - val_loss: 18903.6602\n",
      "Epoch 1559/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13194.6689 - val_loss: 18938.6055\n",
      "Epoch 1560/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13301.7041 - val_loss: 18860.7891\n",
      "Epoch 1561/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13055.1416 - val_loss: 18874.1895\n",
      "Epoch 1562/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13101.3477 - val_loss: 18850.9824\n",
      "Epoch 1563/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13030.8828 - val_loss: 18821.2676\n",
      "Epoch 1564/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12957.2881 - val_loss: 18850.4766\n",
      "Epoch 1565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13052.1943 - val_loss: 18863.5859\n",
      "Epoch 1566/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13089.2822 - val_loss: 18857.2930\n",
      "Epoch 1567/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13071.0889 - val_loss: 18872.1641\n",
      "Epoch 1568/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13111.7578 - val_loss: 18792.5508\n",
      "Epoch 1569/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12872.8330 - val_loss: 18839.5547\n",
      "Epoch 1570/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12998.6533 - val_loss: 18877.4023\n",
      "Epoch 1571/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13110.0488 - val_loss: 18874.1523\n",
      "Epoch 1572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13080.2910 - val_loss: 18840.3203\n",
      "Epoch 1573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12971.1299 - val_loss: 18821.4648\n",
      "Epoch 1574/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12934.2002 - val_loss: 18802.4512\n",
      "Epoch 1575/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.6514 - val_loss: 18761.2754\n",
      "Epoch 1576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.8828 - val_loss: 18766.2480\n",
      "Epoch 1577/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.3555 - val_loss: 18778.9609\n",
      "Epoch 1578/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12827.7227 - val_loss: 18774.5430\n",
      "Epoch 1579/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12820.9502 - val_loss: 18798.9336\n",
      "Epoch 1580/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12895.7949 - val_loss: 18739.2148\n",
      "Epoch 1581/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12714.2061 - val_loss: 18742.6914\n",
      "Epoch 1582/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12714.8330 - val_loss: 18748.9023\n",
      "Epoch 1583/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.6123 - val_loss: 18751.4688\n",
      "Epoch 1584/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12717.1963 - val_loss: 18752.9844\n",
      "Epoch 1585/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12726.1377 - val_loss: 18778.5000\n",
      "Epoch 1586/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.7373 - val_loss: 18767.4316\n",
      "Epoch 1587/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.6523 - val_loss: 18839.4082\n",
      "Epoch 1588/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13013.8242 - val_loss: 18874.8516\n",
      "Epoch 1589/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13125.6016 - val_loss: 18869.7383\n",
      "Epoch 1590/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13106.3506 - val_loss: 18835.8906\n",
      "Epoch 1591/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13000.3779 - val_loss: 18837.0820\n",
      "Epoch 1592/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13006.6328 - val_loss: 18839.2344\n",
      "Epoch 1593/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13022.1729 - val_loss: 18846.2617\n",
      "Epoch 1594/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13015.9160 - val_loss: 18830.2109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1595/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12958.5996 - val_loss: 18786.6816\n",
      "Epoch 1596/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12829.7764 - val_loss: 18773.4258\n",
      "Epoch 1597/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.3057 - val_loss: 18843.0977\n",
      "Epoch 1598/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12987.8291 - val_loss: 18840.5195\n",
      "Epoch 1599/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13020.7627 - val_loss: 18969.7734\n",
      "Epoch 1600/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13421.5273 - val_loss: 19033.0859\n",
      "Epoch 1601/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13622.6064 - val_loss: 19033.9961\n",
      "Epoch 1602/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13626.1182 - val_loss: 18986.1367\n",
      "Epoch 1603/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13477.5254 - val_loss: 18936.4805\n",
      "Epoch 1604/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13317.9873 - val_loss: 18943.5898\n",
      "Epoch 1605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13346.1729 - val_loss: 18964.1562\n",
      "Epoch 1606/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13406.7383 - val_loss: 18924.7617\n",
      "Epoch 1607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13287.2930 - val_loss: 18878.2949\n",
      "Epoch 1608/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13140.7412 - val_loss: 18847.2559\n",
      "Epoch 1609/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13036.8242 - val_loss: 18844.7051\n",
      "Epoch 1610/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.0488 - val_loss: 18822.7598\n",
      "Epoch 1611/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12936.5049 - val_loss: 18808.6934\n",
      "Epoch 1612/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12900.8896 - val_loss: 18835.6445\n",
      "Epoch 1613/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12984.2051 - val_loss: 18862.3887\n",
      "Epoch 1614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13060.8975 - val_loss: 18827.5000\n",
      "Epoch 1615/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12949.7158 - val_loss: 18778.7129\n",
      "Epoch 1616/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12804.1738 - val_loss: 18763.9375\n",
      "Epoch 1617/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12772.3828 - val_loss: 18805.1074\n",
      "Epoch 1618/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12915.7422 - val_loss: 18799.8789\n",
      "Epoch 1619/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12896.7783 - val_loss: 18806.3418\n",
      "Epoch 1620/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12920.4082 - val_loss: 18798.3418\n",
      "Epoch 1621/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12890.6367 - val_loss: 18767.3320\n",
      "Epoch 1622/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12797.0508 - val_loss: 18752.0605\n",
      "Epoch 1623/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.6182 - val_loss: 18754.7598\n",
      "Epoch 1624/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.0312 - val_loss: 18775.0605\n",
      "Epoch 1625/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12802.0146 - val_loss: 18765.4336\n",
      "Epoch 1626/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.3594 - val_loss: 18762.1797\n",
      "Epoch 1627/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12752.5820 - val_loss: 18763.4023\n",
      "Epoch 1628/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12751.3164 - val_loss: 18735.8984\n",
      "Epoch 1629/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12665.7969 - val_loss: 18730.3984\n",
      "Epoch 1630/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.9775 - val_loss: 18753.7539\n",
      "Epoch 1631/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12747.4697 - val_loss: 18748.9980\n",
      "Epoch 1632/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12737.3867 - val_loss: 18765.1895\n",
      "Epoch 1633/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12792.4424 - val_loss: 18780.5059\n",
      "Epoch 1634/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12836.8477 - val_loss: 18797.6465\n",
      "Epoch 1635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.3311 - val_loss: 18797.8789\n",
      "Epoch 1636/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12881.7090 - val_loss: 18715.6230\n",
      "Epoch 1637/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.3496 - val_loss: 18764.4414\n",
      "Epoch 1638/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12787.6709 - val_loss: 18800.8730\n",
      "Epoch 1639/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12888.4551 - val_loss: 18783.1699\n",
      "Epoch 1640/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12815.8271 - val_loss: 18788.8711\n",
      "Epoch 1641/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12818.4180 - val_loss: 18756.0566\n",
      "Epoch 1642/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.6777 - val_loss: 18717.3125\n",
      "Epoch 1643/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.7334 - val_loss: 18742.1992\n",
      "Epoch 1644/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12682.8965 - val_loss: 18708.9141\n",
      "Epoch 1645/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.8867 - val_loss: 18753.0312\n",
      "Epoch 1646/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12745.5352 - val_loss: 18764.8066\n",
      "Epoch 1647/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.3213 - val_loss: 18746.0469\n",
      "Epoch 1648/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12731.7354 - val_loss: 18740.2422\n",
      "Epoch 1649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12712.9600 - val_loss: 18789.2656\n",
      "Epoch 1650/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.0234 - val_loss: 18743.5703\n",
      "Epoch 1651/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12699.1182 - val_loss: 18702.5703\n",
      "Epoch 1652/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.4795 - val_loss: 18742.7676\n",
      "Epoch 1653/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12686.3955 - val_loss: 18770.7734\n",
      "Epoch 1654/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.7598 - val_loss: 18749.5000\n",
      "Epoch 1655/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.3896 - val_loss: 18695.1172\n",
      "Epoch 1656/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.2539 - val_loss: 18714.7305\n",
      "Epoch 1657/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12632.7734 - val_loss: 18741.5820\n",
      "Epoch 1658/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12713.3809 - val_loss: 18728.0273\n",
      "Epoch 1659/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.9863 - val_loss: 18732.7109\n",
      "Epoch 1660/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12668.1377 - val_loss: 18732.3535\n",
      "Epoch 1661/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.3438 - val_loss: 18744.6621\n",
      "Epoch 1662/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.3555 - val_loss: 18718.7617\n",
      "Epoch 1663/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.7568 - val_loss: 18718.7305\n",
      "Epoch 1664/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12613.2920 - val_loss: 18709.6660\n",
      "Epoch 1665/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.5371 - val_loss: 18729.8789\n",
      "Epoch 1666/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12672.4307 - val_loss: 18724.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1667/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12664.9473 - val_loss: 18777.8730\n",
      "Epoch 1668/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12832.6807 - val_loss: 18819.8965\n",
      "Epoch 1669/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12953.3545 - val_loss: 18965.4297\n",
      "Epoch 1670/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13409.0811 - val_loss: 19057.1621\n",
      "Epoch 1671/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13695.8516 - val_loss: 19091.3555\n",
      "Epoch 1672/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13809.6572 - val_loss: 19088.0762\n",
      "Epoch 1673/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13799.5625 - val_loss: 19079.5801\n",
      "Epoch 1674/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13769.9434 - val_loss: 19050.1621\n",
      "Epoch 1675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13668.5977 - val_loss: 19039.9043\n",
      "Epoch 1676/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13624.2539 - val_loss: 19038.8281\n",
      "Epoch 1677/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13614.1201 - val_loss: 19010.6309\n",
      "Epoch 1678/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13513.7666 - val_loss: 18980.8711\n",
      "Epoch 1679/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13413.3945 - val_loss: 18965.5723\n",
      "Epoch 1680/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13372.9990 - val_loss: 18961.2129\n",
      "Epoch 1681/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13372.3994 - val_loss: 18942.6895\n",
      "Epoch 1682/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13315.1211 - val_loss: 18922.4336\n",
      "Epoch 1683/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13249.3955 - val_loss: 18900.7520\n",
      "Epoch 1684/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13182.2031 - val_loss: 18861.7441\n",
      "Epoch 1685/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13083.7480 - val_loss: 18844.1133\n",
      "Epoch 1686/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13037.5898 - val_loss: 18867.9277\n",
      "Epoch 1687/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13106.8799 - val_loss: 18846.7539\n",
      "Epoch 1688/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13049.9980 - val_loss: 18805.8047\n",
      "Epoch 1689/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12919.9980 - val_loss: 18782.5059\n",
      "Epoch 1690/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12827.4697 - val_loss: 18832.5312\n",
      "Epoch 1691/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12950.5723 - val_loss: 18785.9551\n",
      "Epoch 1692/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12835.5986 - val_loss: 18827.3242\n",
      "Epoch 1693/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12981.7490 - val_loss: 18874.0059\n",
      "Epoch 1694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13121.4678 - val_loss: 18870.5527\n",
      "Epoch 1695/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13116.9561 - val_loss: 18864.2383\n",
      "Epoch 1696/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13099.1738 - val_loss: 18848.1914\n",
      "Epoch 1697/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13034.5947 - val_loss: 18871.7812\n",
      "Epoch 1698/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13092.3867 - val_loss: 18853.7539\n",
      "Epoch 1699/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13036.4229 - val_loss: 18820.7598\n",
      "Epoch 1700/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12943.3145 - val_loss: 18829.1387\n",
      "Epoch 1701/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.8887 - val_loss: 18833.3887\n",
      "Epoch 1702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12978.1113 - val_loss: 18823.7637\n",
      "Epoch 1703/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12961.7100 - val_loss: 18786.5918\n",
      "Epoch 1704/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12866.6162 - val_loss: 18763.1465\n",
      "Epoch 1705/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12794.5479 - val_loss: 18756.2207\n",
      "Epoch 1706/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.1230 - val_loss: 18720.2637\n",
      "Epoch 1707/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12627.4053 - val_loss: 18731.9629\n",
      "Epoch 1708/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.3389 - val_loss: 18722.7715\n",
      "Epoch 1709/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12626.4297 - val_loss: 18765.5449\n",
      "Epoch 1710/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.2256 - val_loss: 18749.1211\n",
      "Epoch 1711/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.2373 - val_loss: 18831.6367\n",
      "Epoch 1712/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12996.8047 - val_loss: 18869.2637\n",
      "Epoch 1713/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13119.6543 - val_loss: 18841.8379\n",
      "Epoch 1714/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13039.3301 - val_loss: 18847.8965\n",
      "Epoch 1715/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13048.5693 - val_loss: 18857.6953\n",
      "Epoch 1716/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13077.2236 - val_loss: 18818.4199\n",
      "Epoch 1717/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12955.5889 - val_loss: 18759.0586\n",
      "Epoch 1718/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12749.6016 - val_loss: 18784.7012\n",
      "Epoch 1719/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12819.9453 - val_loss: 18809.0176\n",
      "Epoch 1720/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12902.8564 - val_loss: 18827.0195\n",
      "Epoch 1721/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12957.8291 - val_loss: 18746.3789\n",
      "Epoch 1722/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12702.8223 - val_loss: 18755.2617\n",
      "Epoch 1723/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.5830 - val_loss: 18752.6641\n",
      "Epoch 1724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.0957 - val_loss: 18747.0273\n",
      "Epoch 1725/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12732.4883 - val_loss: 18710.5059\n",
      "Epoch 1726/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.6416 - val_loss: 18707.4512\n",
      "Epoch 1727/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.8828 - val_loss: 18886.9199\n",
      "Epoch 1728/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13166.6934 - val_loss: 18972.4336\n",
      "Epoch 1729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13431.9268 - val_loss: 19261.2773\n",
      "Epoch 1730/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14332.2090 - val_loss: 19437.5391\n",
      "Epoch 1731/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14882.4756 - val_loss: 19514.0762\n",
      "Epoch 1732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15120.7705 - val_loss: 19539.2539\n",
      "Epoch 1733/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15200.5410 - val_loss: 19542.8613\n",
      "Epoch 1734/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15215.8926 - val_loss: 19528.8965\n",
      "Epoch 1735/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15172.3916 - val_loss: 19545.9082\n",
      "Epoch 1736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15231.3975 - val_loss: 19491.6250\n",
      "Epoch 1737/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15057.0869 - val_loss: 19441.6172\n",
      "Epoch 1738/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14894.5615 - val_loss: 19397.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1739/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14753.4404 - val_loss: 19344.2441\n",
      "Epoch 1740/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14593.3711 - val_loss: 19265.8555\n",
      "Epoch 1741/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14335.5605 - val_loss: 19214.3457\n",
      "Epoch 1742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14163.2930 - val_loss: 19183.5000\n",
      "Epoch 1743/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14067.7520 - val_loss: 19153.2383\n",
      "Epoch 1744/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13968.8926 - val_loss: 19177.0215\n",
      "Epoch 1745/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14043.5693 - val_loss: 19166.4531\n",
      "Epoch 1746/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14015.3477 - val_loss: 19141.0469\n",
      "Epoch 1747/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13942.8594 - val_loss: 19105.8340\n",
      "Epoch 1748/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13828.2197 - val_loss: 19056.9395\n",
      "Epoch 1749/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13674.7012 - val_loss: 19006.9043\n",
      "Epoch 1750/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13523.5254 - val_loss: 18961.3320\n",
      "Epoch 1751/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13403.2822 - val_loss: 18966.9512\n",
      "Epoch 1752/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13421.5430 - val_loss: 18980.6055\n",
      "Epoch 1753/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13463.5205 - val_loss: 18955.5840\n",
      "Epoch 1754/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13382.7412 - val_loss: 18934.4160\n",
      "Epoch 1755/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13320.8545 - val_loss: 18899.1562\n",
      "Epoch 1756/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13213.3125 - val_loss: 18872.2168\n",
      "Epoch 1757/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13110.9668 - val_loss: 18855.1914\n",
      "Epoch 1758/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13032.2793 - val_loss: 18829.1973\n",
      "Epoch 1759/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12954.2715 - val_loss: 18797.6504\n",
      "Epoch 1760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.3936 - val_loss: 18827.8574\n",
      "Epoch 1761/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12946.5400 - val_loss: 18780.0664\n",
      "Epoch 1762/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12838.8779 - val_loss: 18835.0742\n",
      "Epoch 1763/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13007.6582 - val_loss: 18880.5977\n",
      "Epoch 1764/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13151.8301 - val_loss: 18880.6172\n",
      "Epoch 1765/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13150.6904 - val_loss: 18883.8320\n",
      "Epoch 1766/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13163.6572 - val_loss: 18883.4844\n",
      "Epoch 1767/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13164.0771 - val_loss: 18855.3027\n",
      "Epoch 1768/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13077.0938 - val_loss: 18816.5938\n",
      "Epoch 1769/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12953.4473 - val_loss: 18791.1152\n",
      "Epoch 1770/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12845.7285 - val_loss: 18794.6641\n",
      "Epoch 1771/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12851.7715 - val_loss: 18797.8223\n",
      "Epoch 1772/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12866.1602 - val_loss: 18800.3340\n",
      "Epoch 1773/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.7461 - val_loss: 18769.1465\n",
      "Epoch 1774/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12778.4736 - val_loss: 18746.1445\n",
      "Epoch 1775/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12700.7988 - val_loss: 18741.5430\n",
      "Epoch 1776/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.1807 - val_loss: 18764.8633\n",
      "Epoch 1777/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12788.8516 - val_loss: 18768.6758\n",
      "Epoch 1778/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12806.2041 - val_loss: 18770.1016\n",
      "Epoch 1779/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12807.8936 - val_loss: 18741.9043\n",
      "Epoch 1780/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.2686 - val_loss: 18707.4766\n",
      "Epoch 1781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12602.8311 - val_loss: 18753.3750\n",
      "Epoch 1782/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12718.7666 - val_loss: 18822.4668\n",
      "Epoch 1783/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12962.9199 - val_loss: 18967.2129\n",
      "Epoch 1784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13417.4326 - val_loss: 19025.9688\n",
      "Epoch 1785/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13600.5195 - val_loss: 19015.0039\n",
      "Epoch 1786/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13567.3115 - val_loss: 18998.1816\n",
      "Epoch 1787/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13520.3945 - val_loss: 18972.8223\n",
      "Epoch 1788/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13441.6768 - val_loss: 18979.3242\n",
      "Epoch 1789/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13465.7422 - val_loss: 19000.1680\n",
      "Epoch 1790/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13504.7686 - val_loss: 18994.0137\n",
      "Epoch 1791/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13477.4834 - val_loss: 18989.3867\n",
      "Epoch 1792/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13457.0234 - val_loss: 18971.8418\n",
      "Epoch 1793/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13402.7939 - val_loss: 18933.2109\n",
      "Epoch 1794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13284.7480 - val_loss: 18926.6738\n",
      "Epoch 1795/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13266.2842 - val_loss: 18913.4629\n",
      "Epoch 1796/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13227.8506 - val_loss: 18866.6621\n",
      "Epoch 1797/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13109.5615 - val_loss: 18821.5781\n",
      "Epoch 1798/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12975.3613 - val_loss: 18808.5586\n",
      "Epoch 1799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12927.3896 - val_loss: 18754.4375\n",
      "Epoch 1800/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12758.2578 - val_loss: 18763.3809\n",
      "Epoch 1801/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12769.4229 - val_loss: 19069.7305\n",
      "Epoch 1802/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13695.7539 - val_loss: 18943.0449\n",
      "Epoch 1803/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13337.7256 - val_loss: 19233.9883\n",
      "Epoch 1804/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 14256.4062 - val_loss: 19440.9102\n",
      "Epoch 1805/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14901.1455 - val_loss: 19563.1172\n",
      "Epoch 1806/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15281.6865 - val_loss: 19628.0508\n",
      "Epoch 1807/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15475.1777 - val_loss: 19645.2031\n",
      "Epoch 1808/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15529.3945 - val_loss: 19615.1211\n",
      "Epoch 1809/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15438.2441 - val_loss: 19577.0566\n",
      "Epoch 1810/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15320.5088 - val_loss: 19558.4102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1811/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15265.2041 - val_loss: 19571.6367\n",
      "Epoch 1812/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15310.1064 - val_loss: 19537.6387\n",
      "Epoch 1813/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15203.9922 - val_loss: 19462.5527\n",
      "Epoch 1814/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14970.1807 - val_loss: 19378.5859\n",
      "Epoch 1815/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14704.0664 - val_loss: 19291.4434\n",
      "Epoch 1816/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14432.1523 - val_loss: 19244.4863\n",
      "Epoch 1817/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14258.1377 - val_loss: 19210.9863\n",
      "Epoch 1818/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14153.7012 - val_loss: 19166.6035\n",
      "Epoch 1819/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14014.8555 - val_loss: 19121.5117\n",
      "Epoch 1820/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13872.6846 - val_loss: 19120.6270\n",
      "Epoch 1821/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13869.4062 - val_loss: 19120.4316\n",
      "Epoch 1822/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13870.8232 - val_loss: 19097.7891\n",
      "Epoch 1823/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13803.2803 - val_loss: 19045.5566\n",
      "Epoch 1824/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13643.5352 - val_loss: 18986.1895\n",
      "Epoch 1825/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13456.9131 - val_loss: 18943.2812\n",
      "Epoch 1826/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13319.1904 - val_loss: 18910.2051\n",
      "Epoch 1827/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13235.6826 - val_loss: 18911.0938\n",
      "Epoch 1828/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13242.4766 - val_loss: 18894.9102\n",
      "Epoch 1829/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13195.3018 - val_loss: 18867.8496\n",
      "Epoch 1830/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13111.1719 - val_loss: 18855.5039\n",
      "Epoch 1831/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13076.7061 - val_loss: 18837.4102\n",
      "Epoch 1832/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13016.6045 - val_loss: 18796.7402\n",
      "Epoch 1833/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12888.5615 - val_loss: 18786.7578\n",
      "Epoch 1834/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12836.4111 - val_loss: 18758.7832\n",
      "Epoch 1835/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.0557 - val_loss: 18771.0156\n",
      "Epoch 1836/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12779.7002 - val_loss: 18800.7656\n",
      "Epoch 1837/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12872.0742 - val_loss: 18808.1191\n",
      "Epoch 1838/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12900.1738 - val_loss: 18798.1016\n",
      "Epoch 1839/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.3477 - val_loss: 18759.5801\n",
      "Epoch 1840/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12779.0137 - val_loss: 18735.5332\n",
      "Epoch 1841/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12703.7959 - val_loss: 18746.3516\n",
      "Epoch 1842/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12723.5215 - val_loss: 18754.7520\n",
      "Epoch 1843/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12740.8965 - val_loss: 18763.2227\n",
      "Epoch 1844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12766.0391 - val_loss: 18752.6230\n",
      "Epoch 1845/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.4062 - val_loss: 18720.0840\n",
      "Epoch 1846/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12627.6084 - val_loss: 18741.9512\n",
      "Epoch 1847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.0752 - val_loss: 18738.8848\n",
      "Epoch 1848/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12704.0703 - val_loss: 18753.3047\n",
      "Epoch 1849/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12754.4736 - val_loss: 18751.2402\n",
      "Epoch 1850/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12739.4492 - val_loss: 18749.7617\n",
      "Epoch 1851/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12706.1914 - val_loss: 18751.8887\n",
      "Epoch 1852/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12717.3223 - val_loss: 18734.1465\n",
      "Epoch 1853/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12672.3086 - val_loss: 18728.3223\n",
      "Epoch 1854/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12667.8086 - val_loss: 18722.6719\n",
      "Epoch 1855/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12657.9580 - val_loss: 18711.9043\n",
      "Epoch 1856/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.9238 - val_loss: 18713.5098\n",
      "Epoch 1857/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.6104 - val_loss: 18703.4844\n",
      "Epoch 1858/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.9775 - val_loss: 18726.9727\n",
      "Epoch 1859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.4062 - val_loss: 18726.7598\n",
      "Epoch 1860/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.5996 - val_loss: 18715.6973\n",
      "Epoch 1861/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.7764 - val_loss: 18692.8828\n",
      "Epoch 1862/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.7334 - val_loss: 18704.5078\n",
      "Epoch 1863/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12577.1338 - val_loss: 18706.6328\n",
      "Epoch 1864/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12600.2891 - val_loss: 18711.4902\n",
      "Epoch 1865/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12618.5869 - val_loss: 18708.8887\n",
      "Epoch 1866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.4043 - val_loss: 18699.0156\n",
      "Epoch 1867/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12581.4531 - val_loss: 18705.2344\n",
      "Epoch 1868/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.1670 - val_loss: 18707.0254\n",
      "Epoch 1869/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12604.7432 - val_loss: 18741.9355\n",
      "Epoch 1870/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12717.5625 - val_loss: 18780.8145\n",
      "Epoch 1871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.3184 - val_loss: 18784.1328\n",
      "Epoch 1872/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.7588 - val_loss: 18745.9551\n",
      "Epoch 1873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12699.4531 - val_loss: 18728.6172\n",
      "Epoch 1874/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.5967 - val_loss: 18732.3809\n",
      "Epoch 1875/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12664.6543 - val_loss: 18795.6660\n",
      "Epoch 1876/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12871.8184 - val_loss: 18777.7500\n",
      "Epoch 1877/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12825.6592 - val_loss: 18892.8301\n",
      "Epoch 1878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13183.0840 - val_loss: 18972.6406\n",
      "Epoch 1879/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13435.6143 - val_loss: 19025.9102\n",
      "Epoch 1880/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13604.2080 - val_loss: 19043.6562\n",
      "Epoch 1881/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13657.8281 - val_loss: 19011.1035\n",
      "Epoch 1882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13562.4531 - val_loss: 18980.9746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1883/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13468.3936 - val_loss: 18957.8027\n",
      "Epoch 1884/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13392.6377 - val_loss: 18925.5176\n",
      "Epoch 1885/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13286.7432 - val_loss: 18913.8867\n",
      "Epoch 1886/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13252.3066 - val_loss: 18910.9355\n",
      "Epoch 1887/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13238.7363 - val_loss: 18880.7266\n",
      "Epoch 1888/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13121.1904 - val_loss: 18878.8301\n",
      "Epoch 1889/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13125.5293 - val_loss: 18848.6562\n",
      "Epoch 1890/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13032.3730 - val_loss: 18791.2656\n",
      "Epoch 1891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.5664 - val_loss: 18777.5156\n",
      "Epoch 1892/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12798.4111 - val_loss: 18781.8848\n",
      "Epoch 1893/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12814.0215 - val_loss: 18772.8691\n",
      "Epoch 1894/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.6064 - val_loss: 18748.5449\n",
      "Epoch 1895/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.1758 - val_loss: 18877.8203\n",
      "Epoch 1896/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13141.8125 - val_loss: 18972.0723\n",
      "Epoch 1897/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13434.5234 - val_loss: 19224.8262\n",
      "Epoch 1898/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14222.9531 - val_loss: 19378.7578\n",
      "Epoch 1899/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14701.4600 - val_loss: 19451.5488\n",
      "Epoch 1900/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14926.9854 - val_loss: 19490.4453\n",
      "Epoch 1901/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15055.6240 - val_loss: 19505.1445\n",
      "Epoch 1902/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15104.3506 - val_loss: 19523.6172\n",
      "Epoch 1903/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15164.1309 - val_loss: 19539.1289\n",
      "Epoch 1904/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15214.5010 - val_loss: 19533.9180\n",
      "Epoch 1905/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15190.8252 - val_loss: 19525.8672\n",
      "Epoch 1906/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15165.0752 - val_loss: 19495.1152\n",
      "Epoch 1907/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15064.9219 - val_loss: 19414.5508\n",
      "Epoch 1908/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14819.0645 - val_loss: 19400.7070\n",
      "Epoch 1909/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14778.0010 - val_loss: 19372.5000\n",
      "Epoch 1910/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14691.6426 - val_loss: 19362.3926\n",
      "Epoch 1911/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14654.6309 - val_loss: 19295.4961\n",
      "Epoch 1912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14446.2197 - val_loss: 19178.5469\n",
      "Epoch 1913/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14080.3066 - val_loss: 19092.1797\n",
      "Epoch 1914/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13811.4824 - val_loss: 19052.7246\n",
      "Epoch 1915/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13675.5420 - val_loss: 19074.4336\n",
      "Epoch 1916/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13712.9629 - val_loss: 19069.1777\n",
      "Epoch 1917/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13701.7979 - val_loss: 19043.8125\n",
      "Epoch 1918/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13641.3252 - val_loss: 19017.8105\n",
      "Epoch 1919/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13557.5020 - val_loss: 18987.5312\n",
      "Epoch 1920/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13459.9424 - val_loss: 18994.9121\n",
      "Epoch 1921/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13477.2559 - val_loss: 18962.6914\n",
      "Epoch 1922/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13378.7227 - val_loss: 18928.1602\n",
      "Epoch 1923/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13276.1240 - val_loss: 18894.0820\n",
      "Epoch 1924/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13171.9902 - val_loss: 18883.6094\n",
      "Epoch 1925/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13131.0039 - val_loss: 18851.1719\n",
      "Epoch 1926/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13026.7910 - val_loss: 18788.8281\n",
      "Epoch 1927/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12859.5117 - val_loss: 18786.6992\n",
      "Epoch 1928/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12866.5498 - val_loss: 18789.0137\n",
      "Epoch 1929/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.2744 - val_loss: 18770.6895\n",
      "Epoch 1930/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12810.0273 - val_loss: 18762.6406\n",
      "Epoch 1931/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.0723 - val_loss: 18781.7617\n",
      "Epoch 1932/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12845.9639 - val_loss: 18809.4668\n",
      "Epoch 1933/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12937.0156 - val_loss: 18799.6152\n",
      "Epoch 1934/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12905.7197 - val_loss: 18767.5312\n",
      "Epoch 1935/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12798.5879 - val_loss: 18739.5645\n",
      "Epoch 1936/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12715.4785 - val_loss: 18733.1582\n",
      "Epoch 1937/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12684.4365 - val_loss: 18751.6426\n",
      "Epoch 1938/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.2324 - val_loss: 18770.8262\n",
      "Epoch 1939/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.7393 - val_loss: 18765.6895\n",
      "Epoch 1940/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12761.0352 - val_loss: 18755.9512\n",
      "Epoch 1941/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12734.8867 - val_loss: 18728.7305\n",
      "Epoch 1942/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.4697 - val_loss: 18719.7812\n",
      "Epoch 1943/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12608.8174 - val_loss: 18706.6152\n",
      "Epoch 1944/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12612.5059 - val_loss: 18768.3965\n",
      "Epoch 1945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.9238 - val_loss: 18782.2676\n",
      "Epoch 1946/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12842.0156 - val_loss: 18772.8203\n",
      "Epoch 1947/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12812.2812 - val_loss: 18747.3164\n",
      "Epoch 1948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12738.1729 - val_loss: 18747.6406\n",
      "Epoch 1949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12742.1221 - val_loss: 18760.9277\n",
      "Epoch 1950/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12783.6230 - val_loss: 18743.9160\n",
      "Epoch 1951/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.3018 - val_loss: 18686.9902\n",
      "Epoch 1952/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12552.0088 - val_loss: 18673.9141\n",
      "Epoch 1953/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12489.8828 - val_loss: 18809.3516\n",
      "Epoch 1954/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12888.5127 - val_loss: 18931.4902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1955/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13305.9395 - val_loss: 19143.3652\n",
      "Epoch 1956/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13967.1729 - val_loss: 19258.9316\n",
      "Epoch 1957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14327.0332 - val_loss: 19306.7227\n",
      "Epoch 1958/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14478.9932 - val_loss: 19321.1191\n",
      "Epoch 1959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14514.0801 - val_loss: 19307.2793\n",
      "Epoch 1960/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14466.2227 - val_loss: 19288.4648\n",
      "Epoch 1961/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14425.1484 - val_loss: 19268.7246\n",
      "Epoch 1962/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14364.2041 - val_loss: 19233.2637\n",
      "Epoch 1963/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14258.3877 - val_loss: 19211.5000\n",
      "Epoch 1964/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14161.1221 - val_loss: 19189.0078\n",
      "Epoch 1965/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14088.6719 - val_loss: 19176.8672\n",
      "Epoch 1966/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14046.8750 - val_loss: 19166.2559\n",
      "Epoch 1967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14010.1553 - val_loss: 19136.3516\n",
      "Epoch 1968/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13918.0117 - val_loss: 19083.6484\n",
      "Epoch 1969/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13760.0010 - val_loss: 19046.6699\n",
      "Epoch 1970/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13644.3535 - val_loss: 19009.1621\n",
      "Epoch 1971/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13528.5703 - val_loss: 18952.3984\n",
      "Epoch 1972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13376.3262 - val_loss: 18917.9043\n",
      "Epoch 1973/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13270.0088 - val_loss: 18899.9336\n",
      "Epoch 1974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13215.6211 - val_loss: 18905.8594\n",
      "Epoch 1975/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13234.5186 - val_loss: 18899.3555\n",
      "Epoch 1976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13213.8408 - val_loss: 18897.1367\n",
      "Epoch 1977/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13185.7373 - val_loss: 18899.9004\n",
      "Epoch 1978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13181.6709 - val_loss: 18876.7891\n",
      "Epoch 1979/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13111.1816 - val_loss: 18845.3730\n",
      "Epoch 1980/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13017.1484 - val_loss: 18789.4336\n",
      "Epoch 1981/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.8828 - val_loss: 18797.1094\n",
      "Epoch 1982/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12864.5176 - val_loss: 18765.4102\n",
      "Epoch 1983/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12794.1748 - val_loss: 18786.1387\n",
      "Epoch 1984/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12862.4834 - val_loss: 18826.5000\n",
      "Epoch 1985/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12984.2344 - val_loss: 18823.5020\n",
      "Epoch 1986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.9883 - val_loss: 18797.6250\n",
      "Epoch 1987/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12894.1660 - val_loss: 18805.9141\n",
      "Epoch 1988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12931.1992 - val_loss: 18805.4453\n",
      "Epoch 1989/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12928.8604 - val_loss: 18784.1738\n",
      "Epoch 1990/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12836.1465 - val_loss: 18778.3398\n",
      "Epoch 1991/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12802.3643 - val_loss: 18802.2344\n",
      "Epoch 1992/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12873.2051 - val_loss: 18775.4180\n",
      "Epoch 1993/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12791.9746 - val_loss: 18743.4746\n",
      "Epoch 1994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.5303 - val_loss: 18741.2246\n",
      "Epoch 1995/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12699.3545 - val_loss: 18774.2012\n",
      "Epoch 1996/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12821.0830 - val_loss: 18761.5312\n",
      "Epoch 1997/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12785.3916 - val_loss: 18720.9141\n",
      "Epoch 1998/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.3223 - val_loss: 18713.3379\n",
      "Epoch 1999/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12630.3594 - val_loss: 18729.0410\n",
      "Epoch 2000/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12665.6572 - val_loss: 18825.3105\n",
      "Epoch 2001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12939.5098 - val_loss: 18841.1172\n",
      "Epoch 2002/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13024.9463 - val_loss: 18989.5625\n",
      "Epoch 2003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13493.9111 - val_loss: 19088.6836\n",
      "Epoch 2004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13803.6084 - val_loss: 19147.3730\n",
      "Epoch 2005/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13985.7559 - val_loss: 19162.3359\n",
      "Epoch 2006/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14032.9180 - val_loss: 19149.0293\n",
      "Epoch 2007/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13994.7627 - val_loss: 19121.4902\n",
      "Epoch 2008/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13905.7568 - val_loss: 19115.4668\n",
      "Epoch 2009/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13887.5830 - val_loss: 19107.5566\n",
      "Epoch 2010/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13862.2803 - val_loss: 19087.6953\n",
      "Epoch 2011/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13771.3682 - val_loss: 19051.0059\n",
      "Epoch 2012/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13655.4053 - val_loss: 19012.7383\n",
      "Epoch 2013/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13523.5078 - val_loss: 18973.5840\n",
      "Epoch 2014/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13399.6660 - val_loss: 18941.6934\n",
      "Epoch 2015/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13319.2061 - val_loss: 18935.3730\n",
      "Epoch 2016/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13299.3496 - val_loss: 18937.0215\n",
      "Epoch 2017/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13298.3008 - val_loss: 18923.1309\n",
      "Epoch 2018/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13255.0127 - val_loss: 18898.1875\n",
      "Epoch 2019/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13201.7510 - val_loss: 18909.1641\n",
      "Epoch 2020/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13242.5918 - val_loss: 18889.0566\n",
      "Epoch 2021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13187.5107 - val_loss: 18847.5957\n",
      "Epoch 2022/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13052.5068 - val_loss: 18789.5000\n",
      "Epoch 2023/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12867.5879 - val_loss: 18752.4180\n",
      "Epoch 2024/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12750.4863 - val_loss: 18744.1992\n",
      "Epoch 2025/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12699.0938 - val_loss: 18755.3164\n",
      "Epoch 2026/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.3994 - val_loss: 18738.0898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2027/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12680.4453 - val_loss: 18746.1602\n",
      "Epoch 2028/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12705.7246 - val_loss: 18758.4219\n",
      "Epoch 2029/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12764.7480 - val_loss: 18781.8652\n",
      "Epoch 2030/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12843.6504 - val_loss: 18797.1738\n",
      "Epoch 2031/10000\n",
      "630/630 [==============================] - 0s 12us/step - loss: 12889.1797 - val_loss: 18789.5625\n",
      "Epoch 2032/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.6523 - val_loss: 18769.3770\n",
      "Epoch 2033/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12811.6328 - val_loss: 18743.3633\n",
      "Epoch 2034/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.0117 - val_loss: 18699.2832\n",
      "Epoch 2035/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.9814 - val_loss: 18849.2520\n",
      "Epoch 2036/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13032.9834 - val_loss: 18929.9277\n",
      "Epoch 2037/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13304.3311 - val_loss: 19190.0664\n",
      "Epoch 2038/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14115.9150 - val_loss: 19348.4629\n",
      "Epoch 2039/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14608.9932 - val_loss: 19437.9180\n",
      "Epoch 2040/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14888.3711 - val_loss: 19485.0918\n",
      "Epoch 2041/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15040.7969 - val_loss: 19508.9648\n",
      "Epoch 2042/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15117.0898 - val_loss: 19507.5957\n",
      "Epoch 2043/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15112.2383 - val_loss: 19492.5684\n",
      "Epoch 2044/10000\n",
      "630/630 [==============================] - 0s 12us/step - loss: 15051.9014 - val_loss: 19449.9043\n",
      "Epoch 2045/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14913.8535 - val_loss: 19380.5039\n",
      "Epoch 2046/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14714.0986 - val_loss: 19329.3418\n",
      "Epoch 2047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14555.3809 - val_loss: 19263.2305\n",
      "Epoch 2048/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14347.8770 - val_loss: 19220.1777\n",
      "Epoch 2049/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14182.9658 - val_loss: 19174.6660\n",
      "Epoch 2050/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14045.0010 - val_loss: 19130.8125\n",
      "Epoch 2051/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13906.5225 - val_loss: 19118.9062\n",
      "Epoch 2052/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13866.8906 - val_loss: 19106.9336\n",
      "Epoch 2053/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13830.8613 - val_loss: 19093.6621\n",
      "Epoch 2054/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13793.2666 - val_loss: 19095.3086\n",
      "Epoch 2055/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13799.0264 - val_loss: 19089.4102\n",
      "Epoch 2056/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13774.6777 - val_loss: 19072.6152\n",
      "Epoch 2057/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13729.0996 - val_loss: 19035.2578\n",
      "Epoch 2058/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13637.9277 - val_loss: 19018.2637\n",
      "Epoch 2059/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13582.0430 - val_loss: 18967.8418\n",
      "Epoch 2060/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13426.0049 - val_loss: 18908.9297\n",
      "Epoch 2061/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13244.4326 - val_loss: 18897.2676\n",
      "Epoch 2062/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13207.3252 - val_loss: 18879.0820\n",
      "Epoch 2063/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13139.6543 - val_loss: 18921.4629\n",
      "Epoch 2064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13247.4375 - val_loss: 18911.5957\n",
      "Epoch 2065/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13216.7129 - val_loss: 18854.4453\n",
      "Epoch 2066/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13048.7666 - val_loss: 18812.2500\n",
      "Epoch 2067/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12909.9941 - val_loss: 18800.6777\n",
      "Epoch 2068/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.9229 - val_loss: 18794.4980\n",
      "Epoch 2069/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12872.2373 - val_loss: 18749.2090\n",
      "Epoch 2070/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12745.2451 - val_loss: 18711.6426\n",
      "Epoch 2071/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12630.7695 - val_loss: 19038.8066\n",
      "Epoch 2072/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13648.6807 - val_loss: 19050.3828\n",
      "Epoch 2073/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13679.0791 - val_loss: 19424.1504\n",
      "Epoch 2074/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14846.1719 - val_loss: 19687.2617\n",
      "Epoch 2075/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 15665.2930 - val_loss: 19836.8105\n",
      "Epoch 2076/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 16131.7432 - val_loss: 19912.9688\n",
      "Epoch 2077/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16371.8701 - val_loss: 19970.0449\n",
      "Epoch 2078/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16551.4492 - val_loss: 19978.4062\n",
      "Epoch 2079/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 16579.7949 - val_loss: 20012.4766\n",
      "Epoch 2080/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16688.4961 - val_loss: 20004.1660\n",
      "Epoch 2081/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16662.7832 - val_loss: 19948.1211\n",
      "Epoch 2082/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16488.0938 - val_loss: 19869.2324\n",
      "Epoch 2083/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16243.9355 - val_loss: 19764.0371\n",
      "Epoch 2084/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15914.9561 - val_loss: 19692.2012\n",
      "Epoch 2085/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15686.5049 - val_loss: 19621.6621\n",
      "Epoch 2086/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 15465.4727 - val_loss: 19617.7832\n",
      "Epoch 2087/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15450.9277 - val_loss: 19565.5566\n",
      "Epoch 2088/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15290.0537 - val_loss: 19508.0605\n",
      "Epoch 2089/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15097.8838 - val_loss: 19447.9707\n",
      "Epoch 2090/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14895.5049 - val_loss: 19375.7070\n",
      "Epoch 2091/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14673.6826 - val_loss: 19345.6699\n",
      "Epoch 2092/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14577.0781 - val_loss: 19318.5547\n",
      "Epoch 2093/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14476.7480 - val_loss: 19211.6055\n",
      "Epoch 2094/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14161.5645 - val_loss: 19206.0898\n",
      "Epoch 2095/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14143.9102 - val_loss: 19225.1133\n",
      "Epoch 2096/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14200.6055 - val_loss: 19196.7012\n",
      "Epoch 2097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14112.2754 - val_loss: 19160.5195\n",
      "Epoch 2098/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13991.3457 - val_loss: 19104.6270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2099/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13819.0801 - val_loss: 19061.2812\n",
      "Epoch 2100/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13688.4727 - val_loss: 19054.5273\n",
      "Epoch 2101/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13702.1787 - val_loss: 19076.8828\n",
      "Epoch 2102/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13770.4346 - val_loss: 19041.6680\n",
      "Epoch 2103/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13659.9756 - val_loss: 19007.6973\n",
      "Epoch 2104/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13552.4531 - val_loss: 19002.6367\n",
      "Epoch 2105/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13534.6045 - val_loss: 18934.5625\n",
      "Epoch 2106/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13323.8105 - val_loss: 18898.3516\n",
      "Epoch 2107/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13204.7715 - val_loss: 18870.5879\n",
      "Epoch 2108/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13097.6348 - val_loss: 18874.3457\n",
      "Epoch 2109/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13103.6025 - val_loss: 18850.9941\n",
      "Epoch 2110/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13033.7422 - val_loss: 18827.2422\n",
      "Epoch 2111/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12961.6436 - val_loss: 18787.8770\n",
      "Epoch 2112/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12837.2334 - val_loss: 18758.4258\n",
      "Epoch 2113/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.6719 - val_loss: 18730.7363\n",
      "Epoch 2114/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12648.8857 - val_loss: 18722.1133\n",
      "Epoch 2115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.0967 - val_loss: 18768.1367\n",
      "Epoch 2116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12810.3125 - val_loss: 18784.3379\n",
      "Epoch 2117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12859.8301 - val_loss: 18772.4375\n",
      "Epoch 2118/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12819.7949 - val_loss: 18760.3105\n",
      "Epoch 2119/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12776.2266 - val_loss: 18760.4199\n",
      "Epoch 2120/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.2969 - val_loss: 18741.1641\n",
      "Epoch 2121/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.2139 - val_loss: 18814.2637\n",
      "Epoch 2122/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12943.1699 - val_loss: 18753.9473\n",
      "Epoch 2123/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.0459 - val_loss: 18846.8164\n",
      "Epoch 2124/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13046.6689 - val_loss: 18900.3125\n",
      "Epoch 2125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13208.9326 - val_loss: 18916.2266\n",
      "Epoch 2126/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13244.9502 - val_loss: 18895.9609\n",
      "Epoch 2127/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13173.2744 - val_loss: 18867.4766\n",
      "Epoch 2128/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13086.0664 - val_loss: 18861.1172\n",
      "Epoch 2129/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13067.9248 - val_loss: 18841.6035\n",
      "Epoch 2130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13010.4346 - val_loss: 18837.6855\n",
      "Epoch 2131/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.1787 - val_loss: 18832.3184\n",
      "Epoch 2132/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12996.7041 - val_loss: 18826.9355\n",
      "Epoch 2133/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12980.8779 - val_loss: 18817.1055\n",
      "Epoch 2134/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12951.0244 - val_loss: 18812.5703\n",
      "Epoch 2135/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12929.0645 - val_loss: 18800.4297\n",
      "Epoch 2136/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12888.5186 - val_loss: 18791.3145\n",
      "Epoch 2137/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.0820 - val_loss: 18783.0215\n",
      "Epoch 2138/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12820.0674 - val_loss: 18779.0332\n",
      "Epoch 2139/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12808.1670 - val_loss: 18758.6797\n",
      "Epoch 2140/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.2109 - val_loss: 18739.5625\n",
      "Epoch 2141/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12704.0312 - val_loss: 18737.1816\n",
      "Epoch 2142/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12697.1484 - val_loss: 18709.5820\n",
      "Epoch 2143/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12606.6191 - val_loss: 18840.3711\n",
      "Epoch 2144/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12994.2148 - val_loss: 18955.6719\n",
      "Epoch 2145/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13368.1514 - val_loss: 19204.8066\n",
      "Epoch 2146/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14138.6846 - val_loss: 19374.9648\n",
      "Epoch 2147/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14663.4307 - val_loss: 19455.8066\n",
      "Epoch 2148/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14916.8818 - val_loss: 19497.4180\n",
      "Epoch 2149/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15050.2256 - val_loss: 19483.2148\n",
      "Epoch 2150/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15012.4248 - val_loss: 19458.7793\n",
      "Epoch 2151/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14950.1455 - val_loss: 19474.1953\n",
      "Epoch 2152/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15006.1758 - val_loss: 19474.8496\n",
      "Epoch 2153/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15013.9404 - val_loss: 19402.9238\n",
      "Epoch 2154/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14788.8623 - val_loss: 19339.2109\n",
      "Epoch 2155/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14585.2617 - val_loss: 19281.6367\n",
      "Epoch 2156/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14401.7197 - val_loss: 19225.5957\n",
      "Epoch 2157/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14228.1914 - val_loss: 19196.0938\n",
      "Epoch 2158/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14137.7842 - val_loss: 19137.3711\n",
      "Epoch 2159/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13935.2588 - val_loss: 19095.2676\n",
      "Epoch 2160/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13796.4521 - val_loss: 19069.7852\n",
      "Epoch 2161/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13717.8936 - val_loss: 19049.6895\n",
      "Epoch 2162/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13651.9697 - val_loss: 19063.3574\n",
      "Epoch 2163/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13696.3486 - val_loss: 19075.7109\n",
      "Epoch 2164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13734.8193 - val_loss: 19074.1172\n",
      "Epoch 2165/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13732.7295 - val_loss: 19016.1055\n",
      "Epoch 2166/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13553.1064 - val_loss: 18996.9883\n",
      "Epoch 2167/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13490.7158 - val_loss: 18983.4492\n",
      "Epoch 2168/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13442.6592 - val_loss: 18936.0996\n",
      "Epoch 2169/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13319.6416 - val_loss: 18924.1348\n",
      "Epoch 2170/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13292.9941 - val_loss: 18897.7090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2171/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13215.4658 - val_loss: 18878.0938\n",
      "Epoch 2172/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13151.3770 - val_loss: 18897.2656\n",
      "Epoch 2173/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13207.6660 - val_loss: 18871.0391\n",
      "Epoch 2174/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13122.4160 - val_loss: 18820.4258\n",
      "Epoch 2175/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12966.0615 - val_loss: 18779.4258\n",
      "Epoch 2176/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12825.6123 - val_loss: 18777.7559\n",
      "Epoch 2177/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12811.0576 - val_loss: 18785.0527\n",
      "Epoch 2178/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12833.2627 - val_loss: 18782.5293\n",
      "Epoch 2179/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12820.0410 - val_loss: 18982.8242\n",
      "Epoch 2180/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13417.4580 - val_loss: 18963.7949\n",
      "Epoch 2181/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13410.8145 - val_loss: 19254.2754\n",
      "Epoch 2182/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14317.1172 - val_loss: 19444.0664\n",
      "Epoch 2183/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14914.6885 - val_loss: 19574.1543\n",
      "Epoch 2184/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15321.6553 - val_loss: 19644.3750\n",
      "Epoch 2185/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15536.8555 - val_loss: 19705.5488\n",
      "Epoch 2186/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15727.5840 - val_loss: 19690.0371\n",
      "Epoch 2187/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15679.9268 - val_loss: 19647.1270\n",
      "Epoch 2188/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15548.5088 - val_loss: 19627.1582\n",
      "Epoch 2189/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15488.4150 - val_loss: 19583.0117\n",
      "Epoch 2190/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15345.1250 - val_loss: 19503.1035\n",
      "Epoch 2191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15094.2646 - val_loss: 19472.5488\n",
      "Epoch 2192/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14996.7939 - val_loss: 19404.0879\n",
      "Epoch 2193/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14789.5801 - val_loss: 19348.1250\n",
      "Epoch 2194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14610.6572 - val_loss: 19342.6641\n",
      "Epoch 2195/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14597.6826 - val_loss: 19304.7285\n",
      "Epoch 2196/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14484.6055 - val_loss: 19216.3379\n",
      "Epoch 2197/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14208.8389 - val_loss: 19140.3477\n",
      "Epoch 2198/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13971.1436 - val_loss: 19083.0527\n",
      "Epoch 2199/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13760.4980 - val_loss: 19104.2285\n",
      "Epoch 2200/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13821.0820 - val_loss: 19114.7148\n",
      "Epoch 2201/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13854.8594 - val_loss: 19069.0996\n",
      "Epoch 2202/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13715.8770 - val_loss: 19006.7539\n",
      "Epoch 2203/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13521.1201 - val_loss: 18967.4590\n",
      "Epoch 2204/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13397.9414 - val_loss: 19002.3867\n",
      "Epoch 2205/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13509.9375 - val_loss: 19010.7344\n",
      "Epoch 2206/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13531.5068 - val_loss: 18978.9199\n",
      "Epoch 2207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13432.9629 - val_loss: 18944.1055\n",
      "Epoch 2208/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13324.6250 - val_loss: 18881.7891\n",
      "Epoch 2209/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13132.7939 - val_loss: 18883.0176\n",
      "Epoch 2210/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13166.4834 - val_loss: 18877.5781\n",
      "Epoch 2211/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13149.4346 - val_loss: 18830.9141\n",
      "Epoch 2212/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13003.2939 - val_loss: 18795.6973\n",
      "Epoch 2213/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12891.5303 - val_loss: 18799.5156\n",
      "Epoch 2214/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.8584 - val_loss: 18779.8457\n",
      "Epoch 2215/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12825.2822 - val_loss: 18759.3340\n",
      "Epoch 2216/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12778.8096 - val_loss: 18746.2480\n",
      "Epoch 2217/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12718.6270 - val_loss: 18728.5566\n",
      "Epoch 2218/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12656.3750 - val_loss: 18782.5059\n",
      "Epoch 2219/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12820.6396 - val_loss: 18810.1113\n",
      "Epoch 2220/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12909.9580 - val_loss: 18822.5996\n",
      "Epoch 2221/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12945.9209 - val_loss: 18805.3340\n",
      "Epoch 2222/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12904.9248 - val_loss: 18773.2832\n",
      "Epoch 2223/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12820.3799 - val_loss: 18746.6641\n",
      "Epoch 2224/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12742.2090 - val_loss: 18748.4043\n",
      "Epoch 2225/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.1846 - val_loss: 18757.8105\n",
      "Epoch 2226/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12762.8506 - val_loss: 18781.8301\n",
      "Epoch 2227/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12822.5049 - val_loss: 18773.8750\n",
      "Epoch 2228/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.6543 - val_loss: 18772.7031\n",
      "Epoch 2229/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.5371 - val_loss: 18829.8027\n",
      "Epoch 2230/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12964.4736 - val_loss: 18843.5312\n",
      "Epoch 2231/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13036.6260 - val_loss: 19049.4590\n",
      "Epoch 2232/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13680.5029 - val_loss: 19186.3086\n",
      "Epoch 2233/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14109.8545 - val_loss: 19249.2969\n",
      "Epoch 2234/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14309.7314 - val_loss: 19258.8730\n",
      "Epoch 2235/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14339.5801 - val_loss: 19266.9512\n",
      "Epoch 2236/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14359.4629 - val_loss: 19249.8555\n",
      "Epoch 2237/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14303.9150 - val_loss: 19222.7754\n",
      "Epoch 2238/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14225.8076 - val_loss: 19219.5820\n",
      "Epoch 2239/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14216.0059 - val_loss: 19197.2969\n",
      "Epoch 2240/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14143.1123 - val_loss: 19174.8672\n",
      "Epoch 2241/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14073.7041 - val_loss: 19109.3203\n",
      "Epoch 2242/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13873.0439 - val_loss: 19031.7344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2243/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13633.2246 - val_loss: 19018.5371\n",
      "Epoch 2244/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13569.9961 - val_loss: 19047.8242\n",
      "Epoch 2245/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13643.9170 - val_loss: 19037.3438\n",
      "Epoch 2246/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13619.7627 - val_loss: 19028.2070\n",
      "Epoch 2247/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13584.4502 - val_loss: 18992.3242\n",
      "Epoch 2248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13478.4932 - val_loss: 18970.5781\n",
      "Epoch 2249/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13409.2510 - val_loss: 18963.3438\n",
      "Epoch 2250/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13390.9375 - val_loss: 18953.7910\n",
      "Epoch 2251/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13338.6719 - val_loss: 18903.0605\n",
      "Epoch 2252/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13192.8252 - val_loss: 18900.3516\n",
      "Epoch 2253/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13184.0117 - val_loss: 18887.0996\n",
      "Epoch 2254/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13165.9150 - val_loss: 18866.7285\n",
      "Epoch 2255/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13115.6357 - val_loss: 18849.3516\n",
      "Epoch 2256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13057.1631 - val_loss: 18828.6191\n",
      "Epoch 2257/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12991.2246 - val_loss: 18790.8418\n",
      "Epoch 2258/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12877.3896 - val_loss: 18787.0488\n",
      "Epoch 2259/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12868.5850 - val_loss: 18765.5801\n",
      "Epoch 2260/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.2139 - val_loss: 18747.7656\n",
      "Epoch 2261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12714.3545 - val_loss: 18763.5723\n",
      "Epoch 2262/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12758.5420 - val_loss: 18878.0762\n",
      "Epoch 2263/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13120.8271 - val_loss: 18866.1406\n",
      "Epoch 2264/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13103.9707 - val_loss: 19018.8770\n",
      "Epoch 2265/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13586.8135 - val_loss: 19111.3457\n",
      "Epoch 2266/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13877.3740 - val_loss: 19166.4238\n",
      "Epoch 2267/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14049.1875 - val_loss: 19185.9883\n",
      "Epoch 2268/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14106.0938 - val_loss: 19190.2227\n",
      "Epoch 2269/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14120.3682 - val_loss: 19163.7676\n",
      "Epoch 2270/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14040.0244 - val_loss: 19118.9082\n",
      "Epoch 2271/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13904.7178 - val_loss: 19095.3633\n",
      "Epoch 2272/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13830.5332 - val_loss: 19046.6309\n",
      "Epoch 2273/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13675.8984 - val_loss: 18988.9414\n",
      "Epoch 2274/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13480.9502 - val_loss: 18964.5137\n",
      "Epoch 2275/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13384.4043 - val_loss: 18934.2715\n",
      "Epoch 2276/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13291.9473 - val_loss: 18956.9805\n",
      "Epoch 2277/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13367.3691 - val_loss: 18990.6992\n",
      "Epoch 2278/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13473.6484 - val_loss: 18972.3965\n",
      "Epoch 2279/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13416.9102 - val_loss: 18889.9551\n",
      "Epoch 2280/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13160.6387 - val_loss: 18806.2246\n",
      "Epoch 2281/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12894.1973 - val_loss: 18805.1914\n",
      "Epoch 2282/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12913.6533 - val_loss: 18812.7734\n",
      "Epoch 2283/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12940.2275 - val_loss: 18834.2285\n",
      "Epoch 2284/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13009.9590 - val_loss: 18818.9961\n",
      "Epoch 2285/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12974.4004 - val_loss: 18781.1484\n",
      "Epoch 2286/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12846.8301 - val_loss: 18873.9590\n",
      "Epoch 2287/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13137.6582 - val_loss: 18877.5137\n",
      "Epoch 2288/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13126.9014 - val_loss: 19033.3535\n",
      "Epoch 2289/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13613.1943 - val_loss: 19101.2578\n",
      "Epoch 2290/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13844.6709 - val_loss: 19099.6660\n",
      "Epoch 2291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13838.3115 - val_loss: 19101.6426\n",
      "Epoch 2292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13843.6455 - val_loss: 19111.4844\n",
      "Epoch 2293/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13878.3018 - val_loss: 19099.4336\n",
      "Epoch 2294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13825.4062 - val_loss: 19092.3203\n",
      "Epoch 2295/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13789.0986 - val_loss: 19030.8848\n",
      "Epoch 2296/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13598.9385 - val_loss: 18976.3379\n",
      "Epoch 2297/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13429.0947 - val_loss: 18974.6152\n",
      "Epoch 2298/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13419.9795 - val_loss: 19007.6094\n",
      "Epoch 2299/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13521.4775 - val_loss: 19005.8848\n",
      "Epoch 2300/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13518.3525 - val_loss: 18977.2539\n",
      "Epoch 2301/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13450.8271 - val_loss: 18927.8242\n",
      "Epoch 2302/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13305.0166 - val_loss: 18927.8496\n",
      "Epoch 2303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13294.8232 - val_loss: 18860.3125\n",
      "Epoch 2304/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13102.4395 - val_loss: 18792.8477\n",
      "Epoch 2305/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.7627 - val_loss: 18785.6270\n",
      "Epoch 2306/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12829.5098 - val_loss: 18792.1230\n",
      "Epoch 2307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12845.7803 - val_loss: 18793.3418\n",
      "Epoch 2308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12853.6963 - val_loss: 18833.0781\n",
      "Epoch 2309/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12982.7148 - val_loss: 18786.2227\n",
      "Epoch 2310/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12854.9971 - val_loss: 18802.6543\n",
      "Epoch 2311/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12908.6406 - val_loss: 18825.7656\n",
      "Epoch 2312/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12984.0459 - val_loss: 18808.6348\n",
      "Epoch 2313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12932.4365 - val_loss: 18779.1035\n",
      "Epoch 2314/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12845.5029 - val_loss: 18775.9863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2315/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12838.2529 - val_loss: 18738.1172\n",
      "Epoch 2316/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12707.6572 - val_loss: 18741.0039\n",
      "Epoch 2317/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12700.8066 - val_loss: 18775.7871\n",
      "Epoch 2318/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12797.4424 - val_loss: 18801.3262\n",
      "Epoch 2319/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12871.7725 - val_loss: 18812.4277\n",
      "Epoch 2320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12912.0771 - val_loss: 18773.8418\n",
      "Epoch 2321/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12793.6270 - val_loss: 18714.5703\n",
      "Epoch 2322/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.1494 - val_loss: 18726.9004\n",
      "Epoch 2323/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12672.5781 - val_loss: 18754.7539\n",
      "Epoch 2324/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.3760 - val_loss: 18780.1230\n",
      "Epoch 2325/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12838.1152 - val_loss: 18765.8398\n",
      "Epoch 2326/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12795.7695 - val_loss: 18768.1797\n",
      "Epoch 2327/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12804.2090 - val_loss: 18781.6191\n",
      "Epoch 2328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12852.4053 - val_loss: 18808.8848\n",
      "Epoch 2329/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12927.2637 - val_loss: 18793.7988\n",
      "Epoch 2330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.6123 - val_loss: 18765.6465\n",
      "Epoch 2331/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12773.8105 - val_loss: 18740.4219\n",
      "Epoch 2332/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.7793 - val_loss: 18751.3477\n",
      "Epoch 2333/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12717.7490 - val_loss: 18743.9492\n",
      "Epoch 2334/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12698.3652 - val_loss: 18719.4492\n",
      "Epoch 2335/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12639.6416 - val_loss: 18674.9570\n",
      "Epoch 2336/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12518.5254 - val_loss: 18703.6816\n",
      "Epoch 2337/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12611.9580 - val_loss: 18700.1094\n",
      "Epoch 2338/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12602.5840 - val_loss: 18663.9746\n",
      "Epoch 2339/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12481.4805 - val_loss: 18693.2676\n",
      "Epoch 2340/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12559.0156 - val_loss: 18701.5977\n",
      "Epoch 2341/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12568.7197 - val_loss: 18684.3320\n",
      "Epoch 2342/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12515.7744 - val_loss: 18676.8809\n",
      "Epoch 2343/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12486.2773 - val_loss: 18686.3379\n",
      "Epoch 2344/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12525.2520 - val_loss: 18694.2695\n",
      "Epoch 2345/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12568.5439 - val_loss: 18686.1758\n",
      "Epoch 2346/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12553.1689 - val_loss: 18677.0254\n",
      "Epoch 2347/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12526.2891 - val_loss: 18685.0566\n",
      "Epoch 2348/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12538.9219 - val_loss: 18698.4492\n",
      "Epoch 2349/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12573.9600 - val_loss: 18697.1797\n",
      "Epoch 2350/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.8662 - val_loss: 18745.4023\n",
      "Epoch 2351/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.1875 - val_loss: 18754.6309\n",
      "Epoch 2352/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12760.3057 - val_loss: 18745.7715\n",
      "Epoch 2353/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12726.3770 - val_loss: 18729.6504\n",
      "Epoch 2354/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12664.5977 - val_loss: 18742.0254\n",
      "Epoch 2355/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12691.3125 - val_loss: 18731.4531\n",
      "Epoch 2356/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.0586 - val_loss: 18710.2871\n",
      "Epoch 2357/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12600.4297 - val_loss: 18725.9258\n",
      "Epoch 2358/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.9805 - val_loss: 18729.0410\n",
      "Epoch 2359/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12672.5576 - val_loss: 18721.2031\n",
      "Epoch 2360/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12656.4482 - val_loss: 18701.6035\n",
      "Epoch 2361/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12597.1787 - val_loss: 18685.6562\n",
      "Epoch 2362/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12549.7217 - val_loss: 18722.1758\n",
      "Epoch 2363/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12657.3574 - val_loss: 18749.7383\n",
      "Epoch 2364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.3955 - val_loss: 18733.9844\n",
      "Epoch 2365/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12673.0938 - val_loss: 18727.2871\n",
      "Epoch 2366/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12645.4365 - val_loss: 18752.2422\n",
      "Epoch 2367/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.0127 - val_loss: 18784.2344\n",
      "Epoch 2368/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.1895 - val_loss: 18735.9082\n",
      "Epoch 2369/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.0928 - val_loss: 18729.7656\n",
      "Epoch 2370/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.7246 - val_loss: 18733.4219\n",
      "Epoch 2371/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12695.1074 - val_loss: 18758.6992\n",
      "Epoch 2372/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.3125 - val_loss: 18774.6152\n",
      "Epoch 2373/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12813.2881 - val_loss: 18774.8652\n",
      "Epoch 2374/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12799.5537 - val_loss: 18744.3242\n",
      "Epoch 2375/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12697.6357 - val_loss: 18713.9590\n",
      "Epoch 2376/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12606.8818 - val_loss: 18707.0039\n",
      "Epoch 2377/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12586.9658 - val_loss: 18722.3086\n",
      "Epoch 2378/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12651.2891 - val_loss: 18709.4785\n",
      "Epoch 2379/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.0996 - val_loss: 18699.5352\n",
      "Epoch 2380/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.1826 - val_loss: 18750.3418\n",
      "Epoch 2381/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12750.7246 - val_loss: 18810.1426\n",
      "Epoch 2382/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12935.5547 - val_loss: 18834.5957\n",
      "Epoch 2383/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13007.3926 - val_loss: 18830.7656\n",
      "Epoch 2384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12997.5205 - val_loss: 18807.9160\n",
      "Epoch 2385/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12932.0713 - val_loss: 18750.4316\n",
      "Epoch 2386/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12740.8076 - val_loss: 18752.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2387/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12734.0615 - val_loss: 18813.0977\n",
      "Epoch 2388/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12911.7070 - val_loss: 18806.2031\n",
      "Epoch 2389/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12896.0293 - val_loss: 18774.1406\n",
      "Epoch 2390/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12799.5869 - val_loss: 18748.9062\n",
      "Epoch 2391/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12716.6240 - val_loss: 18734.5996\n",
      "Epoch 2392/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.5449 - val_loss: 18778.1191\n",
      "Epoch 2393/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12835.7500 - val_loss: 18780.4883\n",
      "Epoch 2394/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12845.3662 - val_loss: 18729.3438\n",
      "Epoch 2395/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12688.1270 - val_loss: 18702.0527\n",
      "Epoch 2396/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12607.3105 - val_loss: 18745.4082\n",
      "Epoch 2397/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12732.3984 - val_loss: 18768.2441\n",
      "Epoch 2398/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.9385 - val_loss: 18747.4551\n",
      "Epoch 2399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.9277 - val_loss: 18733.8848\n",
      "Epoch 2400/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.3193 - val_loss: 18742.5918\n",
      "Epoch 2401/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12696.1592 - val_loss: 18730.5605\n",
      "Epoch 2402/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12668.2021 - val_loss: 18699.8750\n",
      "Epoch 2403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.6123 - val_loss: 18668.4570\n",
      "Epoch 2404/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12483.3887 - val_loss: 18698.6055\n",
      "Epoch 2405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.3574 - val_loss: 18734.1367\n",
      "Epoch 2406/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12697.4824 - val_loss: 18782.0273\n",
      "Epoch 2407/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.4297 - val_loss: 18794.4766\n",
      "Epoch 2408/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12887.4678 - val_loss: 18784.8320\n",
      "Epoch 2409/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12853.1377 - val_loss: 18763.5625\n",
      "Epoch 2410/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12777.3857 - val_loss: 18730.0566\n",
      "Epoch 2411/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.2275 - val_loss: 18747.6992\n",
      "Epoch 2412/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12720.8467 - val_loss: 18788.4727\n",
      "Epoch 2413/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.8281 - val_loss: 18744.0801\n",
      "Epoch 2414/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12709.2041 - val_loss: 18787.1348\n",
      "Epoch 2415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.4736 - val_loss: 18821.9980\n",
      "Epoch 2416/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12974.7588 - val_loss: 18819.6562\n",
      "Epoch 2417/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12967.3857 - val_loss: 18798.2246\n",
      "Epoch 2418/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12899.9229 - val_loss: 18784.0918\n",
      "Epoch 2419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.7656 - val_loss: 18786.7656\n",
      "Epoch 2420/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12832.1689 - val_loss: 18773.4805\n",
      "Epoch 2421/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12793.8564 - val_loss: 18766.3711\n",
      "Epoch 2422/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12775.4150 - val_loss: 18749.7266\n",
      "Epoch 2423/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12729.6553 - val_loss: 18723.8867\n",
      "Epoch 2424/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.8711 - val_loss: 18757.6426\n",
      "Epoch 2425/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.9014 - val_loss: 18748.9609\n",
      "Epoch 2426/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12750.3486 - val_loss: 18734.1348\n",
      "Epoch 2427/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.6641 - val_loss: 18736.6191\n",
      "Epoch 2428/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12685.6592 - val_loss: 18709.3027\n",
      "Epoch 2429/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12602.6865 - val_loss: 18685.3613\n",
      "Epoch 2430/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.0117 - val_loss: 18710.2227\n",
      "Epoch 2431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12630.3594 - val_loss: 18731.5801\n",
      "Epoch 2432/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12691.1221 - val_loss: 18731.2773\n",
      "Epoch 2433/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12686.3154 - val_loss: 18737.2090\n",
      "Epoch 2434/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.5869 - val_loss: 18742.4707\n",
      "Epoch 2435/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12696.8096 - val_loss: 18753.4766\n",
      "Epoch 2436/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12729.3730 - val_loss: 18750.0352\n",
      "Epoch 2437/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12723.9170 - val_loss: 18748.3828\n",
      "Epoch 2438/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.1592 - val_loss: 18721.8789\n",
      "Epoch 2439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12649.0176 - val_loss: 18695.9609\n",
      "Epoch 2440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12573.7891 - val_loss: 18681.3398\n",
      "Epoch 2441/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.2988 - val_loss: 18699.1914\n",
      "Epoch 2442/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.8340 - val_loss: 18875.5215\n",
      "Epoch 2443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13164.2568 - val_loss: 18979.0527\n",
      "Epoch 2444/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13462.2031 - val_loss: 19289.8730\n",
      "Epoch 2445/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14427.1846 - val_loss: 19511.4590\n",
      "Epoch 2446/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15117.7861 - val_loss: 19627.4062\n",
      "Epoch 2447/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15479.6377 - val_loss: 19679.2715\n",
      "Epoch 2448/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15645.9482 - val_loss: 19739.2168\n",
      "Epoch 2449/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15835.9854 - val_loss: 19758.6777\n",
      "Epoch 2450/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15898.2139 - val_loss: 19738.5137\n",
      "Epoch 2451/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15834.2061 - val_loss: 19707.3379\n",
      "Epoch 2452/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15732.2266 - val_loss: 19622.3398\n",
      "Epoch 2453/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15468.2217 - val_loss: 19552.4941\n",
      "Epoch 2454/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15250.1777 - val_loss: 19503.7266\n",
      "Epoch 2455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15096.8545 - val_loss: 19415.2363\n",
      "Epoch 2456/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14824.8672 - val_loss: 19363.4102\n",
      "Epoch 2457/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14663.2686 - val_loss: 19346.5547\n",
      "Epoch 2458/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14608.2949 - val_loss: 19358.9277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2459/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14620.0859 - val_loss: 19357.6328\n",
      "Epoch 2460/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14617.0020 - val_loss: 19349.4727\n",
      "Epoch 2461/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14592.6006 - val_loss: 19305.0371\n",
      "Epoch 2462/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14454.7334 - val_loss: 19265.8770\n",
      "Epoch 2463/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14327.7402 - val_loss: 19219.4629\n",
      "Epoch 2464/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14183.2959 - val_loss: 19150.0000\n",
      "Epoch 2465/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13973.6201 - val_loss: 19118.6660\n",
      "Epoch 2466/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13875.3662 - val_loss: 19091.3477\n",
      "Epoch 2467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13788.5391 - val_loss: 19052.3418\n",
      "Epoch 2468/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13663.2852 - val_loss: 19029.7637\n",
      "Epoch 2469/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13598.9082 - val_loss: 19016.7188\n",
      "Epoch 2470/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13582.3252 - val_loss: 19007.9160\n",
      "Epoch 2471/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13555.9434 - val_loss: 18982.6133\n",
      "Epoch 2472/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13475.7539 - val_loss: 18966.2324\n",
      "Epoch 2473/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13422.8506 - val_loss: 18943.5820\n",
      "Epoch 2474/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13351.6201 - val_loss: 18902.9941\n",
      "Epoch 2475/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13228.8828 - val_loss: 18913.3477\n",
      "Epoch 2476/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13254.8115 - val_loss: 18919.7871\n",
      "Epoch 2477/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13253.1328 - val_loss: 18910.6113\n",
      "Epoch 2478/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13224.7080 - val_loss: 18867.9004\n",
      "Epoch 2479/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13089.5244 - val_loss: 18822.6816\n",
      "Epoch 2480/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12943.3525 - val_loss: 18770.5430\n",
      "Epoch 2481/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.5791 - val_loss: 18777.0527\n",
      "Epoch 2482/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12812.7773 - val_loss: 18753.4551\n",
      "Epoch 2483/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.8838 - val_loss: 18741.5840\n",
      "Epoch 2484/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.6045 - val_loss: 18729.0566\n",
      "Epoch 2485/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12684.5664 - val_loss: 18713.7109\n",
      "Epoch 2486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12633.7285 - val_loss: 18963.5898\n",
      "Epoch 2487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13426.0029 - val_loss: 19030.3379\n",
      "Epoch 2488/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13620.9014 - val_loss: 19346.9688\n",
      "Epoch 2489/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14608.7979 - val_loss: 19556.8809\n",
      "Epoch 2490/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15263.7627 - val_loss: 19702.2656\n",
      "Epoch 2491/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15718.6611 - val_loss: 19773.1289\n",
      "Epoch 2492/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15937.4854 - val_loss: 19811.9570\n",
      "Epoch 2493/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16061.9805 - val_loss: 19855.6348\n",
      "Epoch 2494/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16199.4072 - val_loss: 19849.7637\n",
      "Epoch 2495/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16179.3652 - val_loss: 19811.5645\n",
      "Epoch 2496/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16061.1494 - val_loss: 19758.6895\n",
      "Epoch 2497/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15893.7539 - val_loss: 19731.8047\n",
      "Epoch 2498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15810.6582 - val_loss: 19697.2754\n",
      "Epoch 2499/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15703.7627 - val_loss: 19691.0820\n",
      "Epoch 2500/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15687.9482 - val_loss: 19665.2539\n",
      "Epoch 2501/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15605.1357 - val_loss: 19606.0117\n",
      "Epoch 2502/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15420.7949 - val_loss: 19507.1172\n",
      "Epoch 2503/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15097.6416 - val_loss: 19433.0781\n",
      "Epoch 2504/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14848.5020 - val_loss: 19378.4805\n",
      "Epoch 2505/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14682.6680 - val_loss: 19328.7676\n",
      "Epoch 2506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14528.4463 - val_loss: 19297.9199\n",
      "Epoch 2507/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14432.6572 - val_loss: 19252.0723\n",
      "Epoch 2508/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14289.6191 - val_loss: 19214.9707\n",
      "Epoch 2509/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14175.8877 - val_loss: 19182.7305\n",
      "Epoch 2510/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14075.0010 - val_loss: 19134.7383\n",
      "Epoch 2511/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13923.9082 - val_loss: 19067.0918\n",
      "Epoch 2512/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13708.8281 - val_loss: 19001.3320\n",
      "Epoch 2513/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13505.2754 - val_loss: 18992.4395\n",
      "Epoch 2514/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13497.8613 - val_loss: 19037.4668\n",
      "Epoch 2515/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13651.6104 - val_loss: 19062.6328\n",
      "Epoch 2516/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13727.0830 - val_loss: 19029.3184\n",
      "Epoch 2517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13624.2275 - val_loss: 18979.4727\n",
      "Epoch 2518/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13471.2061 - val_loss: 18990.2891\n",
      "Epoch 2519/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13498.1025 - val_loss: 18986.8906\n",
      "Epoch 2520/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13478.8291 - val_loss: 18957.7891\n",
      "Epoch 2521/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13367.1729 - val_loss: 18933.8711\n",
      "Epoch 2522/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13296.6387 - val_loss: 18903.0195\n",
      "Epoch 2523/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13200.2373 - val_loss: 18864.4160\n",
      "Epoch 2524/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13072.5000 - val_loss: 18834.5605\n",
      "Epoch 2525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12988.5400 - val_loss: 18794.0527\n",
      "Epoch 2526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12866.5801 - val_loss: 18759.6621\n",
      "Epoch 2527/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.2832 - val_loss: 18738.9434\n",
      "Epoch 2528/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12712.6719 - val_loss: 18758.5859\n",
      "Epoch 2529/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12780.4893 - val_loss: 18880.3398\n",
      "Epoch 2530/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13151.1533 - val_loss: 18834.7285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2531/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13014.7119 - val_loss: 18922.9082\n",
      "Epoch 2532/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13268.8779 - val_loss: 19001.2344\n",
      "Epoch 2533/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13516.1387 - val_loss: 19027.2695\n",
      "Epoch 2534/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13592.7617 - val_loss: 19038.6641\n",
      "Epoch 2535/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13630.8340 - val_loss: 19023.4746\n",
      "Epoch 2536/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13593.1064 - val_loss: 19010.5840\n",
      "Epoch 2537/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13562.8076 - val_loss: 18977.3809\n",
      "Epoch 2538/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13457.1572 - val_loss: 18958.0234\n",
      "Epoch 2539/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13376.4609 - val_loss: 18924.3477\n",
      "Epoch 2540/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13267.5400 - val_loss: 18886.5840\n",
      "Epoch 2541/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13149.9248 - val_loss: 18833.7656\n",
      "Epoch 2542/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12981.1230 - val_loss: 18810.9688\n",
      "Epoch 2543/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12914.6826 - val_loss: 18804.0293\n",
      "Epoch 2544/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12890.2588 - val_loss: 18792.4355\n",
      "Epoch 2545/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.1621 - val_loss: 18786.2461\n",
      "Epoch 2546/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.9502 - val_loss: 18818.1348\n",
      "Epoch 2547/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12961.3311 - val_loss: 18743.6309\n",
      "Epoch 2548/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.4951 - val_loss: 18796.4043\n",
      "Epoch 2549/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12898.0195 - val_loss: 18874.5605\n",
      "Epoch 2550/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13136.1729 - val_loss: 18902.7578\n",
      "Epoch 2551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13224.6123 - val_loss: 18888.8555\n",
      "Epoch 2552/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13187.9014 - val_loss: 18863.9941\n",
      "Epoch 2553/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13109.9121 - val_loss: 18820.8730\n",
      "Epoch 2554/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12971.3154 - val_loss: 18811.6973\n",
      "Epoch 2555/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12941.1797 - val_loss: 18760.5293\n",
      "Epoch 2556/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12785.0879 - val_loss: 18739.8496\n",
      "Epoch 2557/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12695.3203 - val_loss: 18745.1895\n",
      "Epoch 2558/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.4980 - val_loss: 18745.8848\n",
      "Epoch 2559/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12708.3105 - val_loss: 18821.1895\n",
      "Epoch 2560/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12928.3887 - val_loss: 18813.4980\n",
      "Epoch 2561/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12941.6084 - val_loss: 18957.4766\n",
      "Epoch 2562/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13398.6982 - val_loss: 19051.4746\n",
      "Epoch 2563/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13693.2080 - val_loss: 19092.7539\n",
      "Epoch 2564/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13820.2773 - val_loss: 19090.6758\n",
      "Epoch 2565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13813.6299 - val_loss: 19106.2480\n",
      "Epoch 2566/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13861.1719 - val_loss: 19143.0273\n",
      "Epoch 2567/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13979.6650 - val_loss: 19148.8711\n",
      "Epoch 2568/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13996.7695 - val_loss: 19121.5801\n",
      "Epoch 2569/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13906.3037 - val_loss: 19058.6191\n",
      "Epoch 2570/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13713.1914 - val_loss: 18985.9375\n",
      "Epoch 2571/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13489.8145 - val_loss: 18938.1992\n",
      "Epoch 2572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13338.3740 - val_loss: 18951.6797\n",
      "Epoch 2573/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13378.4443 - val_loss: 18948.9590\n",
      "Epoch 2574/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13343.5664 - val_loss: 18951.3672\n",
      "Epoch 2575/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13351.0195 - val_loss: 18930.8418\n",
      "Epoch 2576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13285.0537 - val_loss: 18919.3027\n",
      "Epoch 2577/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13251.7393 - val_loss: 18876.9668\n",
      "Epoch 2578/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13122.1582 - val_loss: 18831.0215\n",
      "Epoch 2579/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12976.8965 - val_loss: 18788.2305\n",
      "Epoch 2580/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12842.1270 - val_loss: 18814.9922\n",
      "Epoch 2581/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12924.8076 - val_loss: 18817.2305\n",
      "Epoch 2582/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12935.3291 - val_loss: 18794.1641\n",
      "Epoch 2583/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12891.0449 - val_loss: 18779.8340\n",
      "Epoch 2584/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12846.2324 - val_loss: 18754.2324\n",
      "Epoch 2585/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12766.2061 - val_loss: 18811.7480\n",
      "Epoch 2586/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12951.7490 - val_loss: 18847.2676\n",
      "Epoch 2587/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13053.9062 - val_loss: 19031.4883\n",
      "Epoch 2588/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13621.9014 - val_loss: 19122.1348\n",
      "Epoch 2589/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13910.0957 - val_loss: 19164.4219\n",
      "Epoch 2590/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14041.9824 - val_loss: 19166.0859\n",
      "Epoch 2591/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14046.9727 - val_loss: 19129.8340\n",
      "Epoch 2592/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13937.7275 - val_loss: 19104.4473\n",
      "Epoch 2593/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13856.1338 - val_loss: 19099.7148\n",
      "Epoch 2594/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13844.6240 - val_loss: 19100.1465\n",
      "Epoch 2595/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13845.6787 - val_loss: 19100.7383\n",
      "Epoch 2596/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13848.6758 - val_loss: 19109.0039\n",
      "Epoch 2597/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13841.4336 - val_loss: 19063.5938\n",
      "Epoch 2598/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13699.9395 - val_loss: 19019.7617\n",
      "Epoch 2599/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13563.5771 - val_loss: 18987.5234\n",
      "Epoch 2600/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13461.6777 - val_loss: 18967.3438\n",
      "Epoch 2601/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13401.3281 - val_loss: 18952.4043\n",
      "Epoch 2602/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13356.1865 - val_loss: 18935.4199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2603/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13302.3359 - val_loss: 18885.0410\n",
      "Epoch 2604/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13143.8633 - val_loss: 18849.7910\n",
      "Epoch 2605/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13056.8066 - val_loss: 18832.6484\n",
      "Epoch 2606/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13012.2734 - val_loss: 18795.2617\n",
      "Epoch 2607/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12892.4160 - val_loss: 18798.1387\n",
      "Epoch 2608/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12902.3760 - val_loss: 18796.1621\n",
      "Epoch 2609/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12895.1230 - val_loss: 18762.2520\n",
      "Epoch 2610/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.4219 - val_loss: 18777.4395\n",
      "Epoch 2611/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12826.6367 - val_loss: 18839.1543\n",
      "Epoch 2612/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13028.8740 - val_loss: 18994.1836\n",
      "Epoch 2613/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13513.0752 - val_loss: 19091.8184\n",
      "Epoch 2614/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13816.5273 - val_loss: 19109.0293\n",
      "Epoch 2615/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13868.0918 - val_loss: 19108.9199\n",
      "Epoch 2616/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13869.7686 - val_loss: 19106.3574\n",
      "Epoch 2617/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13861.6279 - val_loss: 19098.3828\n",
      "Epoch 2618/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13838.4727 - val_loss: 19101.0566\n",
      "Epoch 2619/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13818.0566 - val_loss: 19127.6484\n",
      "Epoch 2620/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13901.0762 - val_loss: 19113.7988\n",
      "Epoch 2621/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13859.9297 - val_loss: 19070.8398\n",
      "Epoch 2622/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13725.4111 - val_loss: 19002.8887\n",
      "Epoch 2623/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13511.1250 - val_loss: 18998.1816\n",
      "Epoch 2624/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13495.1074 - val_loss: 19004.0820\n",
      "Epoch 2625/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13529.5840 - val_loss: 18985.0449\n",
      "Epoch 2626/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13484.5820 - val_loss: 18932.5586\n",
      "Epoch 2627/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13319.7051 - val_loss: 18872.1660\n",
      "Epoch 2628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13129.2061 - val_loss: 18787.2168\n",
      "Epoch 2629/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12862.0664 - val_loss: 18796.6387\n",
      "Epoch 2630/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12879.8506 - val_loss: 18851.3203\n",
      "Epoch 2631/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13039.5586 - val_loss: 18870.8789\n",
      "Epoch 2632/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13100.1172 - val_loss: 18928.5332\n",
      "Epoch 2633/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13272.8418 - val_loss: 18839.1836\n",
      "Epoch 2634/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13027.6992 - val_loss: 19018.5898\n",
      "Epoch 2635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13586.8359 - val_loss: 19157.6211\n",
      "Epoch 2636/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14023.1006 - val_loss: 19208.9785\n",
      "Epoch 2637/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14184.2617 - val_loss: 19210.7637\n",
      "Epoch 2638/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14188.2822 - val_loss: 19183.1914\n",
      "Epoch 2639/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14101.7480 - val_loss: 19185.9062\n",
      "Epoch 2640/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14111.2881 - val_loss: 19184.5859\n",
      "Epoch 2641/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14107.4033 - val_loss: 19139.5879\n",
      "Epoch 2642/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13965.9658 - val_loss: 19087.8027\n",
      "Epoch 2643/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13806.8076 - val_loss: 19064.4512\n",
      "Epoch 2644/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13730.8701 - val_loss: 19008.7617\n",
      "Epoch 2645/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13562.6240 - val_loss: 19026.0898\n",
      "Epoch 2646/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13614.1191 - val_loss: 19013.5938\n",
      "Epoch 2647/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13548.9541 - val_loss: 18989.3105\n",
      "Epoch 2648/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13470.3428 - val_loss: 18952.9941\n",
      "Epoch 2649/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13357.4873 - val_loss: 18940.3770\n",
      "Epoch 2650/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13316.6543 - val_loss: 18900.8848\n",
      "Epoch 2651/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13196.0283 - val_loss: 18879.7461\n",
      "Epoch 2652/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13125.7471 - val_loss: 18899.9297\n",
      "Epoch 2653/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13193.9150 - val_loss: 18892.3809\n",
      "Epoch 2654/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13169.9258 - val_loss: 18862.0918\n",
      "Epoch 2655/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13075.1904 - val_loss: 18856.7500\n",
      "Epoch 2656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13055.7432 - val_loss: 18830.8242\n",
      "Epoch 2657/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.7334 - val_loss: 18812.8672\n",
      "Epoch 2658/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12946.9082 - val_loss: 18809.6523\n",
      "Epoch 2659/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12939.1768 - val_loss: 18755.4395\n",
      "Epoch 2660/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.5020 - val_loss: 18780.1270\n",
      "Epoch 2661/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12853.9268 - val_loss: 18749.7109\n",
      "Epoch 2662/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12749.0576 - val_loss: 18816.5156\n",
      "Epoch 2663/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12957.5596 - val_loss: 18853.6113\n",
      "Epoch 2664/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13076.8252 - val_loss: 18882.8750\n",
      "Epoch 2665/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13167.1787 - val_loss: 18865.5312\n",
      "Epoch 2666/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13114.5713 - val_loss: 18841.0273\n",
      "Epoch 2667/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13015.2500 - val_loss: 18818.0430\n",
      "Epoch 2668/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12931.8037 - val_loss: 18800.9805\n",
      "Epoch 2669/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12882.4590 - val_loss: 18814.6211\n",
      "Epoch 2670/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12928.0459 - val_loss: 18832.6328\n",
      "Epoch 2671/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12984.9004 - val_loss: 18823.1465\n",
      "Epoch 2672/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12953.3037 - val_loss: 18785.1543\n",
      "Epoch 2673/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12833.1211 - val_loss: 18712.8008\n",
      "Epoch 2674/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12627.8135 - val_loss: 18717.3359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.4297 - val_loss: 18871.5664\n",
      "Epoch 2676/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13128.9961 - val_loss: 18921.9316\n",
      "Epoch 2677/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13288.4512 - val_loss: 19095.2695\n",
      "Epoch 2678/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13829.2764 - val_loss: 19204.3477\n",
      "Epoch 2679/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14168.7959 - val_loss: 19247.0840\n",
      "Epoch 2680/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14302.2324 - val_loss: 19283.4219\n",
      "Epoch 2681/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14413.9131 - val_loss: 19303.0234\n",
      "Epoch 2682/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14475.1523 - val_loss: 19267.0527\n",
      "Epoch 2683/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14364.9697 - val_loss: 19251.7949\n",
      "Epoch 2684/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14316.8145 - val_loss: 19285.7148\n",
      "Epoch 2685/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14426.6680 - val_loss: 19275.1973\n",
      "Epoch 2686/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14394.3633 - val_loss: 19237.1621\n",
      "Epoch 2687/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14272.8027 - val_loss: 19153.2734\n",
      "Epoch 2688/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14009.7871 - val_loss: 19077.5488\n",
      "Epoch 2689/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13770.2510 - val_loss: 19001.1973\n",
      "Epoch 2690/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13533.6406 - val_loss: 18969.2930\n",
      "Epoch 2691/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13423.6924 - val_loss: 19008.0840\n",
      "Epoch 2692/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13531.3779 - val_loss: 19045.6934\n",
      "Epoch 2693/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13649.1738 - val_loss: 19084.0859\n",
      "Epoch 2694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13767.5820 - val_loss: 19075.1309\n",
      "Epoch 2695/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13737.9756 - val_loss: 19041.5117\n",
      "Epoch 2696/10000\n",
      "630/630 [==============================] - 0s 22us/step - loss: 13632.3623 - val_loss: 19024.1465\n",
      "Epoch 2697/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13577.0898 - val_loss: 18998.2363\n",
      "Epoch 2698/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13498.9307 - val_loss: 18969.6602\n",
      "Epoch 2699/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13409.8291 - val_loss: 18926.4980\n",
      "Epoch 2700/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13276.4990 - val_loss: 18886.5605\n",
      "Epoch 2701/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13155.8594 - val_loss: 18876.7148\n",
      "Epoch 2702/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13131.5117 - val_loss: 18863.2559\n",
      "Epoch 2703/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 13098.3525 - val_loss: 18862.2402\n",
      "Epoch 2704/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13101.5293 - val_loss: 18858.4492\n",
      "Epoch 2705/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13092.9531 - val_loss: 18853.8457\n",
      "Epoch 2706/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 13080.2061 - val_loss: 18829.7695\n",
      "Epoch 2707/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13002.8223 - val_loss: 18790.3789\n",
      "Epoch 2708/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12860.1309 - val_loss: 18793.8457\n",
      "Epoch 2709/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12856.7627 - val_loss: 18787.1191\n",
      "Epoch 2710/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12838.5049 - val_loss: 18750.0273\n",
      "Epoch 2711/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12724.3936 - val_loss: 18745.8809\n",
      "Epoch 2712/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12713.5889 - val_loss: 18738.9805\n",
      "Epoch 2713/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.0000 - val_loss: 18725.6387\n",
      "Epoch 2714/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12649.4033 - val_loss: 18848.8887\n",
      "Epoch 2715/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13042.0225 - val_loss: 18857.9082\n",
      "Epoch 2716/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13087.6797 - val_loss: 19063.0430\n",
      "Epoch 2717/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13727.5791 - val_loss: 19206.9844\n",
      "Epoch 2718/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14177.2119 - val_loss: 19270.4531\n",
      "Epoch 2719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14377.3984 - val_loss: 19256.6523\n",
      "Epoch 2720/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14334.8936 - val_loss: 19263.8730\n",
      "Epoch 2721/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14353.9746 - val_loss: 19252.0957\n",
      "Epoch 2722/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 14314.7480 - val_loss: 19204.6211\n",
      "Epoch 2723/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 14167.6748 - val_loss: 19156.3633\n",
      "Epoch 2724/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14019.9492 - val_loss: 19118.2441\n",
      "Epoch 2725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13901.1592 - val_loss: 19125.7227\n",
      "Epoch 2726/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13913.6191 - val_loss: 19102.3184\n",
      "Epoch 2727/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13855.2881 - val_loss: 19033.5742\n",
      "Epoch 2728/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13640.1699 - val_loss: 18992.6348\n",
      "Epoch 2729/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13511.1699 - val_loss: 18952.6680\n",
      "Epoch 2730/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13384.7666 - val_loss: 18928.0566\n",
      "Epoch 2731/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13286.1133 - val_loss: 18952.5469\n",
      "Epoch 2732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13348.7568 - val_loss: 18940.7988\n",
      "Epoch 2733/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13315.8037 - val_loss: 18936.7422\n",
      "Epoch 2734/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13308.9648 - val_loss: 18968.4355\n",
      "Epoch 2735/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13408.0654 - val_loss: 18970.2754\n",
      "Epoch 2736/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13413.2559 - val_loss: 18965.9883\n",
      "Epoch 2737/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13397.6592 - val_loss: 18927.8672\n",
      "Epoch 2738/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13277.1758 - val_loss: 18878.2422\n",
      "Epoch 2739/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13122.9463 - val_loss: 18824.2227\n",
      "Epoch 2740/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12955.0293 - val_loss: 18802.5977\n",
      "Epoch 2741/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12889.0654 - val_loss: 18781.8398\n",
      "Epoch 2742/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12854.3750 - val_loss: 18766.5684\n",
      "Epoch 2743/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.3379 - val_loss: 18772.2500\n",
      "Epoch 2744/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12822.1533 - val_loss: 18743.8613\n",
      "Epoch 2745/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12731.1992 - val_loss: 18740.3027\n",
      "Epoch 2746/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12722.1865 - val_loss: 18825.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2747/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12974.0400 - val_loss: 18807.8789\n",
      "Epoch 2748/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12929.7002 - val_loss: 18876.8887\n",
      "Epoch 2749/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13147.0889 - val_loss: 18931.7500\n",
      "Epoch 2750/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13320.3623 - val_loss: 18929.8281\n",
      "Epoch 2751/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13315.3457 - val_loss: 18882.7637\n",
      "Epoch 2752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13168.7363 - val_loss: 18822.9414\n",
      "Epoch 2753/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12979.6719 - val_loss: 18833.3496\n",
      "Epoch 2754/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13008.1621 - val_loss: 18851.3867\n",
      "Epoch 2755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13037.5566 - val_loss: 18835.4961\n",
      "Epoch 2756/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12989.9131 - val_loss: 18837.1113\n",
      "Epoch 2757/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 12996.7666 - val_loss: 18812.1895\n",
      "Epoch 2758/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12921.2256 - val_loss: 18784.9453\n",
      "Epoch 2759/10000\n",
      "630/630 [==============================] - 0s 12us/step - loss: 12834.3359 - val_loss: 18742.4570\n",
      "Epoch 2760/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12698.3877 - val_loss: 18734.4883\n",
      "Epoch 2761/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12676.3643 - val_loss: 18712.1172\n",
      "Epoch 2762/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12629.4111 - val_loss: 18739.2910\n",
      "Epoch 2763/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12718.3555 - val_loss: 18749.4453\n",
      "Epoch 2764/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12749.9346 - val_loss: 18796.0449\n",
      "Epoch 2765/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12875.8535 - val_loss: 18804.2461\n",
      "Epoch 2766/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12919.1816 - val_loss: 18943.7520\n",
      "Epoch 2767/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13353.9434 - val_loss: 19015.5020\n",
      "Epoch 2768/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13575.3340 - val_loss: 19045.3184\n",
      "Epoch 2769/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13671.7578 - val_loss: 19034.6758\n",
      "Epoch 2770/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13639.1240 - val_loss: 19028.1758\n",
      "Epoch 2771/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13623.9395 - val_loss: 19066.8320\n",
      "Epoch 2772/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13742.4639 - val_loss: 19063.7812\n",
      "Epoch 2773/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13731.1309 - val_loss: 19014.3125\n",
      "Epoch 2774/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13576.0986 - val_loss: 18980.2969\n",
      "Epoch 2775/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13469.1455 - val_loss: 18964.4258\n",
      "Epoch 2776/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13421.1953 - val_loss: 18936.8301\n",
      "Epoch 2777/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13304.6133 - val_loss: 18902.1211\n",
      "Epoch 2778/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13197.7402 - val_loss: 18889.3730\n",
      "Epoch 2779/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13157.7168 - val_loss: 18862.7305\n",
      "Epoch 2780/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13076.1865 - val_loss: 18863.1270\n",
      "Epoch 2781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13077.7617 - val_loss: 18841.2246\n",
      "Epoch 2782/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13012.0713 - val_loss: 18785.9922\n",
      "Epoch 2783/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12836.8662 - val_loss: 18785.2070\n",
      "Epoch 2784/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12832.5996 - val_loss: 18797.6914\n",
      "Epoch 2785/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12877.7031 - val_loss: 18776.5508\n",
      "Epoch 2786/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12836.2559 - val_loss: 18755.3828\n",
      "Epoch 2787/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12773.3643 - val_loss: 18765.9746\n",
      "Epoch 2788/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12804.7822 - val_loss: 18757.1660\n",
      "Epoch 2789/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12774.6201 - val_loss: 18748.1016\n",
      "Epoch 2790/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12745.6641 - val_loss: 18849.4844\n",
      "Epoch 2791/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13002.1279 - val_loss: 18918.6660\n",
      "Epoch 2792/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13276.1006 - val_loss: 19141.2051\n",
      "Epoch 2793/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13970.8047 - val_loss: 19288.9688\n",
      "Epoch 2794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14433.0195 - val_loss: 19377.0977\n",
      "Epoch 2795/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14710.4756 - val_loss: 19433.4336\n",
      "Epoch 2796/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14883.1035 - val_loss: 19448.9668\n",
      "Epoch 2797/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14931.9697 - val_loss: 19450.8125\n",
      "Epoch 2798/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14936.7949 - val_loss: 19440.4434\n",
      "Epoch 2799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14905.0352 - val_loss: 19397.4805\n",
      "Epoch 2800/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14768.2822 - val_loss: 19350.3750\n",
      "Epoch 2801/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14623.6592 - val_loss: 19325.3125\n",
      "Epoch 2802/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14547.7617 - val_loss: 19306.5625\n",
      "Epoch 2803/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14485.0918 - val_loss: 19292.5234\n",
      "Epoch 2804/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14435.9258 - val_loss: 19237.7773\n",
      "Epoch 2805/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14275.2695 - val_loss: 19183.4316\n",
      "Epoch 2806/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14107.1387 - val_loss: 19144.3145\n",
      "Epoch 2807/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13982.0674 - val_loss: 19090.8633\n",
      "Epoch 2808/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13785.7266 - val_loss: 19049.8398\n",
      "Epoch 2809/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13662.4570 - val_loss: 19042.7207\n",
      "Epoch 2810/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13641.5264 - val_loss: 19056.5625\n",
      "Epoch 2811/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13679.3311 - val_loss: 19033.6523\n",
      "Epoch 2812/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13606.2031 - val_loss: 18987.6934\n",
      "Epoch 2813/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13465.3906 - val_loss: 18970.4727\n",
      "Epoch 2814/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13414.3740 - val_loss: 18953.3281\n",
      "Epoch 2815/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13358.4268 - val_loss: 18940.2090\n",
      "Epoch 2816/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13315.5625 - val_loss: 18908.8320\n",
      "Epoch 2817/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13218.4268 - val_loss: 18869.8594\n",
      "Epoch 2818/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13123.6621 - val_loss: 18850.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2819/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13069.4043 - val_loss: 18863.0527\n",
      "Epoch 2820/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13107.2910 - val_loss: 18868.6953\n",
      "Epoch 2821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13121.2666 - val_loss: 18838.8262\n",
      "Epoch 2822/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13031.4043 - val_loss: 18817.7695\n",
      "Epoch 2823/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12966.0859 - val_loss: 18808.7266\n",
      "Epoch 2824/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12936.2012 - val_loss: 18743.2773\n",
      "Epoch 2825/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12721.8555 - val_loss: 18726.3965\n",
      "Epoch 2826/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.8926 - val_loss: 18758.5410\n",
      "Epoch 2827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12752.6396 - val_loss: 18756.4551\n",
      "Epoch 2828/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.6680 - val_loss: 18737.5352\n",
      "Epoch 2829/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12682.3828 - val_loss: 18807.4082\n",
      "Epoch 2830/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12862.1709 - val_loss: 18875.9395\n",
      "Epoch 2831/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13142.6016 - val_loss: 19084.8516\n",
      "Epoch 2832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13794.0625 - val_loss: 19196.1797\n",
      "Epoch 2833/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14142.1680 - val_loss: 19270.4707\n",
      "Epoch 2834/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14376.6924 - val_loss: 19312.8906\n",
      "Epoch 2835/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14508.5059 - val_loss: 19349.6094\n",
      "Epoch 2836/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14622.2051 - val_loss: 19377.3945\n",
      "Epoch 2837/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14709.0615 - val_loss: 19365.8711\n",
      "Epoch 2838/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14674.3379 - val_loss: 19325.5000\n",
      "Epoch 2839/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14546.7637 - val_loss: 19263.0566\n",
      "Epoch 2840/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14351.8008 - val_loss: 19251.2461\n",
      "Epoch 2841/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14313.5264 - val_loss: 19215.7363\n",
      "Epoch 2842/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14207.5254 - val_loss: 19184.1602\n",
      "Epoch 2843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14107.0771 - val_loss: 19171.8438\n",
      "Epoch 2844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14066.2842 - val_loss: 19102.7676\n",
      "Epoch 2845/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13852.2324 - val_loss: 19022.9336\n",
      "Epoch 2846/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13604.7920 - val_loss: 18978.7168\n",
      "Epoch 2847/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13466.6289 - val_loss: 18913.1230\n",
      "Epoch 2848/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13261.4385 - val_loss: 18890.6777\n",
      "Epoch 2849/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13193.8867 - val_loss: 18893.8965\n",
      "Epoch 2850/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13176.5889 - val_loss: 18933.0020\n",
      "Epoch 2851/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13297.4404 - val_loss: 18993.6230\n",
      "Epoch 2852/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13475.7773 - val_loss: 18998.7617\n",
      "Epoch 2853/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13499.2871 - val_loss: 18952.0684\n",
      "Epoch 2854/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13353.4854 - val_loss: 18907.2090\n",
      "Epoch 2855/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13212.7979 - val_loss: 18872.0410\n",
      "Epoch 2856/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13104.4570 - val_loss: 18842.0352\n",
      "Epoch 2857/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13014.1328 - val_loss: 18789.6562\n",
      "Epoch 2858/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12851.1260 - val_loss: 18767.7988\n",
      "Epoch 2859/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12778.4580 - val_loss: 18742.8496\n",
      "Epoch 2860/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12700.4434 - val_loss: 18753.0332\n",
      "Epoch 2861/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12764.2539 - val_loss: 18729.9629\n",
      "Epoch 2862/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12692.0811 - val_loss: 18729.4062\n",
      "Epoch 2863/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12688.5381 - val_loss: 18814.5527\n",
      "Epoch 2864/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12936.4219 - val_loss: 18818.5488\n",
      "Epoch 2865/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12961.6602 - val_loss: 18920.0840\n",
      "Epoch 2866/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13280.7119 - val_loss: 18991.3984\n",
      "Epoch 2867/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13506.3311 - val_loss: 19022.6523\n",
      "Epoch 2868/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13601.6689 - val_loss: 19008.6855\n",
      "Epoch 2869/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13557.3369 - val_loss: 18947.1074\n",
      "Epoch 2870/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13366.7119 - val_loss: 18935.7891\n",
      "Epoch 2871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13332.0918 - val_loss: 18930.6973\n",
      "Epoch 2872/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13313.7480 - val_loss: 18934.6289\n",
      "Epoch 2873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13329.8096 - val_loss: 18906.3574\n",
      "Epoch 2874/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13241.9531 - val_loss: 18887.2715\n",
      "Epoch 2875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13184.7383 - val_loss: 18863.2246\n",
      "Epoch 2876/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13109.7764 - val_loss: 18837.8203\n",
      "Epoch 2877/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13025.9805 - val_loss: 18856.2734\n",
      "Epoch 2878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13054.3418 - val_loss: 18831.2617\n",
      "Epoch 2879/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12978.9658 - val_loss: 18811.1309\n",
      "Epoch 2880/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12911.3848 - val_loss: 18817.3652\n",
      "Epoch 2881/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12936.8125 - val_loss: 18802.4219\n",
      "Epoch 2882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12888.8730 - val_loss: 18789.8359\n",
      "Epoch 2883/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12849.8828 - val_loss: 18787.9902\n",
      "Epoch 2884/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12842.3037 - val_loss: 18744.6113\n",
      "Epoch 2885/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12704.2637 - val_loss: 18716.5273\n",
      "Epoch 2886/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12616.9023 - val_loss: 18735.3887\n",
      "Epoch 2887/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12709.6992 - val_loss: 18736.2969\n",
      "Epoch 2888/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12712.5068 - val_loss: 18732.9023\n",
      "Epoch 2889/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.3643 - val_loss: 18713.1914\n",
      "Epoch 2890/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.0996 - val_loss: 18708.1777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.9121 - val_loss: 18734.6758\n",
      "Epoch 2892/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.1084 - val_loss: 18749.7227\n",
      "Epoch 2893/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12753.2529 - val_loss: 18735.4043\n",
      "Epoch 2894/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.1279 - val_loss: 18721.2773\n",
      "Epoch 2895/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12660.9756 - val_loss: 18722.4922\n",
      "Epoch 2896/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12632.3271 - val_loss: 18711.5371\n",
      "Epoch 2897/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12601.4062 - val_loss: 18743.2559\n",
      "Epoch 2898/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.2490 - val_loss: 18759.4883\n",
      "Epoch 2899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.4551 - val_loss: 18754.9160\n",
      "Epoch 2900/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.7373 - val_loss: 18736.5312\n",
      "Epoch 2901/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12705.7002 - val_loss: 18742.8555\n",
      "Epoch 2902/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12730.7354 - val_loss: 18724.8320\n",
      "Epoch 2903/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.1475 - val_loss: 18701.4004\n",
      "Epoch 2904/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12592.0635 - val_loss: 18710.2520\n",
      "Epoch 2905/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12612.4756 - val_loss: 18742.4863\n",
      "Epoch 2906/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12696.6553 - val_loss: 18718.7109\n",
      "Epoch 2907/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.2656 - val_loss: 18705.7129\n",
      "Epoch 2908/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12601.8105 - val_loss: 18681.9492\n",
      "Epoch 2909/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12530.1768 - val_loss: 18728.7148\n",
      "Epoch 2910/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12652.0986 - val_loss: 18763.1699\n",
      "Epoch 2911/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12790.3594 - val_loss: 18811.4492\n",
      "Epoch 2912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12945.3789 - val_loss: 18856.8379\n",
      "Epoch 2913/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13084.9170 - val_loss: 18852.0840\n",
      "Epoch 2914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13070.2354 - val_loss: 18847.1895\n",
      "Epoch 2915/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13056.5234 - val_loss: 18839.5059\n",
      "Epoch 2916/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13035.2480 - val_loss: 18828.6406\n",
      "Epoch 2917/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12998.2510 - val_loss: 18810.7207\n",
      "Epoch 2918/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12941.1338 - val_loss: 18778.5684\n",
      "Epoch 2919/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12837.1338 - val_loss: 18775.7246\n",
      "Epoch 2920/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12805.5986 - val_loss: 18798.8418\n",
      "Epoch 2921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.5449 - val_loss: 18811.0898\n",
      "Epoch 2922/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12914.4346 - val_loss: 18813.1387\n",
      "Epoch 2923/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12921.6055 - val_loss: 18788.9766\n",
      "Epoch 2924/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12848.0352 - val_loss: 18781.7969\n",
      "Epoch 2925/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12825.4648 - val_loss: 18772.1035\n",
      "Epoch 2926/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12796.5283 - val_loss: 18738.8496\n",
      "Epoch 2927/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12718.4902 - val_loss: 18719.1621\n",
      "Epoch 2928/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12659.6289 - val_loss: 18727.7090\n",
      "Epoch 2929/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.4961 - val_loss: 18728.7793\n",
      "Epoch 2930/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.6113 - val_loss: 18720.2461\n",
      "Epoch 2931/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.4736 - val_loss: 18811.5137\n",
      "Epoch 2932/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12910.3154 - val_loss: 18903.4121\n",
      "Epoch 2933/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13227.4248 - val_loss: 19108.9199\n",
      "Epoch 2934/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13868.3965 - val_loss: 19258.3750\n",
      "Epoch 2935/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14337.7783 - val_loss: 19344.3320\n",
      "Epoch 2936/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14604.1094 - val_loss: 19380.3281\n",
      "Epoch 2937/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14716.8193 - val_loss: 19379.0469\n",
      "Epoch 2938/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14714.3916 - val_loss: 19366.4590\n",
      "Epoch 2939/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14673.4512 - val_loss: 19339.2520\n",
      "Epoch 2940/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14587.9160 - val_loss: 19303.6543\n",
      "Epoch 2941/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14474.8701 - val_loss: 19242.8613\n",
      "Epoch 2942/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14287.0029 - val_loss: 19192.5898\n",
      "Epoch 2943/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14132.3164 - val_loss: 19159.7598\n",
      "Epoch 2944/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14029.1846 - val_loss: 19100.5820\n",
      "Epoch 2945/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13845.3857 - val_loss: 19076.5156\n",
      "Epoch 2946/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13773.3408 - val_loss: 19044.6562\n",
      "Epoch 2947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13674.6523 - val_loss: 19010.5195\n",
      "Epoch 2948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13538.5908 - val_loss: 19020.1699\n",
      "Epoch 2949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13567.6387 - val_loss: 18980.5371\n",
      "Epoch 2950/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13447.2783 - val_loss: 18926.2305\n",
      "Epoch 2951/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13277.4365 - val_loss: 18913.1543\n",
      "Epoch 2952/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13231.6934 - val_loss: 18917.7461\n",
      "Epoch 2953/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13246.3633 - val_loss: 18907.5566\n",
      "Epoch 2954/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13217.2012 - val_loss: 18898.2832\n",
      "Epoch 2955/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13189.5938 - val_loss: 18864.5410\n",
      "Epoch 2956/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13083.8105 - val_loss: 18824.3652\n",
      "Epoch 2957/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12954.7529 - val_loss: 18833.9824\n",
      "Epoch 2958/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13013.2324 - val_loss: 18834.7891\n",
      "Epoch 2959/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13017.0908 - val_loss: 18834.0156\n",
      "Epoch 2960/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13016.6445 - val_loss: 18821.2754\n",
      "Epoch 2961/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12978.3584 - val_loss: 18785.3164\n",
      "Epoch 2962/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12864.9053 - val_loss: 18756.0430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2963/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.6240 - val_loss: 18729.3359\n",
      "Epoch 2964/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12683.7061 - val_loss: 18710.4590\n",
      "Epoch 2965/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12601.5039 - val_loss: 19001.0020\n",
      "Epoch 2966/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13473.4531 - val_loss: 18996.4043\n",
      "Epoch 2967/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13518.7861 - val_loss: 19259.8848\n",
      "Epoch 2968/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14340.6279 - val_loss: 19459.0078\n",
      "Epoch 2969/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14962.6484 - val_loss: 19584.2773\n",
      "Epoch 2970/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15353.6230 - val_loss: 19654.0586\n",
      "Epoch 2971/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15571.9668 - val_loss: 19696.9980\n",
      "Epoch 2972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15704.5010 - val_loss: 19727.8086\n",
      "Epoch 2973/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15801.4531 - val_loss: 19734.6641\n",
      "Epoch 2974/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15822.0908 - val_loss: 19707.9023\n",
      "Epoch 2975/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15741.7295 - val_loss: 19645.9707\n",
      "Epoch 2976/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15548.7090 - val_loss: 19578.2695\n",
      "Epoch 2977/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15337.6016 - val_loss: 19560.0605\n",
      "Epoch 2978/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 15278.5596 - val_loss: 19585.3906\n",
      "Epoch 2979/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15357.1924 - val_loss: 19557.7734\n",
      "Epoch 2980/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15272.7246 - val_loss: 19522.7383\n",
      "Epoch 2981/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15165.8818 - val_loss: 19496.0742\n",
      "Epoch 2982/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15081.0352 - val_loss: 19432.8926\n",
      "Epoch 2983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14883.9033 - val_loss: 19349.1113\n",
      "Epoch 2984/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14617.8545 - val_loss: 19277.1289\n",
      "Epoch 2985/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14394.0205 - val_loss: 19212.5977\n",
      "Epoch 2986/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14195.3877 - val_loss: 19146.0117\n",
      "Epoch 2987/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13990.3594 - val_loss: 19093.7988\n",
      "Epoch 2988/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13828.6045 - val_loss: 19069.0820\n",
      "Epoch 2989/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13721.6318 - val_loss: 19088.4629\n",
      "Epoch 2990/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13782.9355 - val_loss: 19117.4609\n",
      "Epoch 2991/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13862.1533 - val_loss: 19085.4434\n",
      "Epoch 2992/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13770.6807 - val_loss: 19044.9941\n",
      "Epoch 2993/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13642.0869 - val_loss: 18991.7441\n",
      "Epoch 2994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13478.5215 - val_loss: 18984.6660\n",
      "Epoch 2995/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13457.7012 - val_loss: 18955.1836\n",
      "Epoch 2996/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13368.0488 - val_loss: 18955.6719\n",
      "Epoch 2997/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13366.1357 - val_loss: 18931.0000\n",
      "Epoch 2998/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13289.4141 - val_loss: 18916.3652\n",
      "Epoch 2999/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13243.7529 - val_loss: 18885.9590\n",
      "Epoch 3000/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13149.4473 - val_loss: 18857.7227\n",
      "Epoch 3001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13080.9248 - val_loss: 18843.8672\n",
      "Epoch 3002/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13046.0576 - val_loss: 18848.9141\n",
      "Epoch 3003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13060.5049 - val_loss: 18830.6562\n",
      "Epoch 3004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.9902 - val_loss: 18793.2090\n",
      "Epoch 3005/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12882.4248 - val_loss: 18781.2305\n",
      "Epoch 3006/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12836.3398 - val_loss: 18760.7969\n",
      "Epoch 3007/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.9766 - val_loss: 18724.2617\n",
      "Epoch 3008/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12673.0654 - val_loss: 18774.2461\n",
      "Epoch 3009/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.4941 - val_loss: 18887.6934\n",
      "Epoch 3010/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13166.5400 - val_loss: 19084.3574\n",
      "Epoch 3011/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13772.7578 - val_loss: 19187.8750\n",
      "Epoch 3012/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14094.4678 - val_loss: 19210.9180\n",
      "Epoch 3013/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14170.5254 - val_loss: 19200.3320\n",
      "Epoch 3014/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14154.9160 - val_loss: 19214.5723\n",
      "Epoch 3015/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14201.3604 - val_loss: 19215.8301\n",
      "Epoch 3016/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14204.0693 - val_loss: 19147.7188\n",
      "Epoch 3017/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13993.0068 - val_loss: 19083.0547\n",
      "Epoch 3018/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13791.4697 - val_loss: 19049.3242\n",
      "Epoch 3019/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13660.6211 - val_loss: 18995.2520\n",
      "Epoch 3020/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13489.6758 - val_loss: 18948.3848\n",
      "Epoch 3021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13345.2871 - val_loss: 18968.7559\n",
      "Epoch 3022/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13408.8232 - val_loss: 19001.0020\n",
      "Epoch 3023/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13509.9707 - val_loss: 18970.7266\n",
      "Epoch 3024/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13415.0020 - val_loss: 18911.8828\n",
      "Epoch 3025/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13229.6826 - val_loss: 18850.9043\n",
      "Epoch 3026/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13044.1777 - val_loss: 18831.0156\n",
      "Epoch 3027/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13010.8779 - val_loss: 18834.7402\n",
      "Epoch 3028/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13021.5322 - val_loss: 18831.7363\n",
      "Epoch 3029/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.7295 - val_loss: 18800.7656\n",
      "Epoch 3030/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12909.4307 - val_loss: 18818.1348\n",
      "Epoch 3031/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12959.7676 - val_loss: 18817.1719\n",
      "Epoch 3032/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12958.1084 - val_loss: 18806.3105\n",
      "Epoch 3033/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12918.8271 - val_loss: 18797.4434\n",
      "Epoch 3034/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12883.7998 - val_loss: 18812.5703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12922.3389 - val_loss: 18803.6777\n",
      "Epoch 3036/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12890.5332 - val_loss: 18780.6426\n",
      "Epoch 3037/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12823.3047 - val_loss: 18785.0234\n",
      "Epoch 3038/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12844.2588 - val_loss: 18787.0566\n",
      "Epoch 3039/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.5918 - val_loss: 18792.3301\n",
      "Epoch 3040/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12873.2656 - val_loss: 18775.1758\n",
      "Epoch 3041/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12824.3916 - val_loss: 18755.2109\n",
      "Epoch 3042/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12766.5137 - val_loss: 18750.9629\n",
      "Epoch 3043/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12752.3516 - val_loss: 18751.7129\n",
      "Epoch 3044/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12749.3916 - val_loss: 18755.3457\n",
      "Epoch 3045/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12753.0361 - val_loss: 18731.3340\n",
      "Epoch 3046/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12670.8711 - val_loss: 18722.6758\n",
      "Epoch 3047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.8584 - val_loss: 18746.4883\n",
      "Epoch 3048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.1611 - val_loss: 18745.7734\n",
      "Epoch 3049/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.7061 - val_loss: 18741.0645\n",
      "Epoch 3050/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12716.2451 - val_loss: 18742.4395\n",
      "Epoch 3051/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12720.1670 - val_loss: 18723.0293\n",
      "Epoch 3052/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.3633 - val_loss: 18716.6445\n",
      "Epoch 3053/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.6836 - val_loss: 18726.6328\n",
      "Epoch 3054/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12655.8984 - val_loss: 18748.6699\n",
      "Epoch 3055/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12738.6426 - val_loss: 18734.6289\n",
      "Epoch 3056/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12699.4707 - val_loss: 18744.2500\n",
      "Epoch 3057/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12736.4707 - val_loss: 18751.5449\n",
      "Epoch 3058/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.7715 - val_loss: 18747.8184\n",
      "Epoch 3059/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.3057 - val_loss: 18738.9434\n",
      "Epoch 3060/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12688.9385 - val_loss: 18700.3633\n",
      "Epoch 3061/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12569.3818 - val_loss: 18687.8789\n",
      "Epoch 3062/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12536.0352 - val_loss: 18711.9766\n",
      "Epoch 3063/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12622.9854 - val_loss: 18715.1836\n",
      "Epoch 3064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.2441 - val_loss: 18721.4668\n",
      "Epoch 3065/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.4795 - val_loss: 18685.1191\n",
      "Epoch 3066/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12543.6338 - val_loss: 18680.4238\n",
      "Epoch 3067/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12522.7988 - val_loss: 18704.1133\n",
      "Epoch 3068/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12583.8887 - val_loss: 18731.6289\n",
      "Epoch 3069/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12690.0127 - val_loss: 18753.8145\n",
      "Epoch 3070/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12764.5332 - val_loss: 18780.3359\n",
      "Epoch 3071/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12847.6689 - val_loss: 18771.5098\n",
      "Epoch 3072/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12816.1504 - val_loss: 18736.7344\n",
      "Epoch 3073/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.0781 - val_loss: 18710.2930\n",
      "Epoch 3074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.7744 - val_loss: 18756.0957\n",
      "Epoch 3075/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12746.5400 - val_loss: 18799.3086\n",
      "Epoch 3076/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12881.0244 - val_loss: 18789.9473\n",
      "Epoch 3077/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12852.5508 - val_loss: 18745.0332\n",
      "Epoch 3078/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12722.5029 - val_loss: 18706.8223\n",
      "Epoch 3079/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12612.6113 - val_loss: 18710.8594\n",
      "Epoch 3080/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12626.5625 - val_loss: 18714.4355\n",
      "Epoch 3081/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12636.2012 - val_loss: 18696.7695\n",
      "Epoch 3082/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.3594 - val_loss: 18709.1973\n",
      "Epoch 3083/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.7207 - val_loss: 18813.3828\n",
      "Epoch 3084/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12942.0928 - val_loss: 18931.8672\n",
      "Epoch 3085/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13314.3271 - val_loss: 19169.9043\n",
      "Epoch 3086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14056.9043 - val_loss: 19331.2637\n",
      "Epoch 3087/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14560.6895 - val_loss: 19427.3652\n",
      "Epoch 3088/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14862.2900 - val_loss: 19480.0312\n",
      "Epoch 3089/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15026.4258 - val_loss: 19495.0820\n",
      "Epoch 3090/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15073.5566 - val_loss: 19464.5234\n",
      "Epoch 3091/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14977.0977 - val_loss: 19395.4629\n",
      "Epoch 3092/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14761.5000 - val_loss: 19365.4551\n",
      "Epoch 3093/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14667.8623 - val_loss: 19346.4648\n",
      "Epoch 3094/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14608.0938 - val_loss: 19317.8965\n",
      "Epoch 3095/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14517.1572 - val_loss: 19282.6621\n",
      "Epoch 3096/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14407.0264 - val_loss: 19225.8809\n",
      "Epoch 3097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14227.8740 - val_loss: 19152.8516\n",
      "Epoch 3098/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14001.4355 - val_loss: 19100.4688\n",
      "Epoch 3099/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13842.2959 - val_loss: 19074.9961\n",
      "Epoch 3100/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13763.8135 - val_loss: 19021.2930\n",
      "Epoch 3101/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13596.8105 - val_loss: 18960.6211\n",
      "Epoch 3102/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13385.2783 - val_loss: 18971.1797\n",
      "Epoch 3103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13419.2090 - val_loss: 19031.0254\n",
      "Epoch 3104/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13603.8105 - val_loss: 19050.2949\n",
      "Epoch 3105/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13663.2197 - val_loss: 19017.3203\n",
      "Epoch 3106/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13561.8760 - val_loss: 18983.7754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3107/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13456.5684 - val_loss: 18969.5762\n",
      "Epoch 3108/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13413.6465 - val_loss: 18967.0215\n",
      "Epoch 3109/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13404.5000 - val_loss: 18934.6719\n",
      "Epoch 3110/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13303.0713 - val_loss: 18882.3281\n",
      "Epoch 3111/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13140.6094 - val_loss: 18800.4043\n",
      "Epoch 3112/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12891.7861 - val_loss: 18786.5527\n",
      "Epoch 3113/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12867.3857 - val_loss: 18812.5781\n",
      "Epoch 3114/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12946.9414 - val_loss: 18830.7832\n",
      "Epoch 3115/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13003.4287 - val_loss: 18819.0859\n",
      "Epoch 3116/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12965.3867 - val_loss: 18773.3398\n",
      "Epoch 3117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12823.1299 - val_loss: 18734.2871\n",
      "Epoch 3118/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.3672 - val_loss: 18714.4648\n",
      "Epoch 3119/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12624.3691 - val_loss: 18714.1973\n",
      "Epoch 3120/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12616.4941 - val_loss: 19154.1426\n",
      "Epoch 3121/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14016.8184 - val_loss: 19024.0273\n",
      "Epoch 3122/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13602.4688 - val_loss: 19341.7031\n",
      "Epoch 3123/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14592.8711 - val_loss: 19562.4434\n",
      "Epoch 3124/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15284.2998 - val_loss: 19701.9004\n",
      "Epoch 3125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15720.0850 - val_loss: 19781.2461\n",
      "Epoch 3126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15966.7227 - val_loss: 19812.9062\n",
      "Epoch 3127/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16063.9395 - val_loss: 19806.3594\n",
      "Epoch 3128/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16046.0498 - val_loss: 19737.5234\n",
      "Epoch 3129/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15831.8311 - val_loss: 19675.5977\n",
      "Epoch 3130/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15636.4727 - val_loss: 19654.8926\n",
      "Epoch 3131/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 15570.6211 - val_loss: 19620.4277\n",
      "Epoch 3132/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15465.7979 - val_loss: 19552.4102\n",
      "Epoch 3133/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 15255.1113 - val_loss: 19463.1602\n",
      "Epoch 3134/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14974.5596 - val_loss: 19361.1406\n",
      "Epoch 3135/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14657.7402 - val_loss: 19284.9902\n",
      "Epoch 3136/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14423.8320 - val_loss: 19219.9844\n",
      "Epoch 3137/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14222.3271 - val_loss: 19247.8086\n",
      "Epoch 3138/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14306.2070 - val_loss: 19274.7871\n",
      "Epoch 3139/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14389.7559 - val_loss: 19243.1934\n",
      "Epoch 3140/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14292.7500 - val_loss: 19174.0703\n",
      "Epoch 3141/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14074.7295 - val_loss: 19104.2188\n",
      "Epoch 3142/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13847.5586 - val_loss: 19088.0586\n",
      "Epoch 3143/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13780.2080 - val_loss: 19077.0859\n",
      "Epoch 3144/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13748.6230 - val_loss: 19080.0254\n",
      "Epoch 3145/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13755.8721 - val_loss: 19091.9160\n",
      "Epoch 3146/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13790.6094 - val_loss: 19081.8652\n",
      "Epoch 3147/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13760.0020 - val_loss: 19025.7012\n",
      "Epoch 3148/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13585.6904 - val_loss: 19032.4297\n",
      "Epoch 3149/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13606.4102 - val_loss: 19001.4316\n",
      "Epoch 3150/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13506.0518 - val_loss: 18971.2031\n",
      "Epoch 3151/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13413.9414 - val_loss: 18928.3223\n",
      "Epoch 3152/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13283.0703 - val_loss: 18893.1426\n",
      "Epoch 3153/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13172.0869 - val_loss: 18844.8906\n",
      "Epoch 3154/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13035.2461 - val_loss: 18868.9629\n",
      "Epoch 3155/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13114.2178 - val_loss: 18872.2852\n",
      "Epoch 3156/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13121.6211 - val_loss: 18844.3320\n",
      "Epoch 3157/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13046.3750 - val_loss: 18865.4512\n",
      "Epoch 3158/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13110.0781 - val_loss: 18844.9453\n",
      "Epoch 3159/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13044.1064 - val_loss: 18783.5059\n",
      "Epoch 3160/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12856.3125 - val_loss: 18735.7695\n",
      "Epoch 3161/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12709.7568 - val_loss: 18753.8281\n",
      "Epoch 3162/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12749.4414 - val_loss: 18768.2910\n",
      "Epoch 3163/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12789.6074 - val_loss: 18744.7637\n",
      "Epoch 3164/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12710.4297 - val_loss: 18794.4590\n",
      "Epoch 3165/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12865.8672 - val_loss: 18928.1348\n",
      "Epoch 3166/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13304.9580 - val_loss: 19165.1211\n",
      "Epoch 3167/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14032.4170 - val_loss: 19329.5762\n",
      "Epoch 3168/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14542.2686 - val_loss: 19414.3535\n",
      "Epoch 3169/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14802.5127 - val_loss: 19450.3555\n",
      "Epoch 3170/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14914.3779 - val_loss: 19501.6465\n",
      "Epoch 3171/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15074.5840 - val_loss: 19553.4219\n",
      "Epoch 3172/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15241.1143 - val_loss: 19539.9258\n",
      "Epoch 3173/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15215.4736 - val_loss: 19506.8086\n",
      "Epoch 3174/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15113.5938 - val_loss: 19441.2207\n",
      "Epoch 3175/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14909.2754 - val_loss: 19405.9160\n",
      "Epoch 3176/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14798.2842 - val_loss: 19383.7285\n",
      "Epoch 3177/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14728.7676 - val_loss: 19311.9238\n",
      "Epoch 3178/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14504.0088 - val_loss: 19222.7168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3179/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14225.0654 - val_loss: 19131.1152\n",
      "Epoch 3180/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13939.4463 - val_loss: 19092.9609\n",
      "Epoch 3181/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13821.7168 - val_loss: 19057.6719\n",
      "Epoch 3182/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13690.6299 - val_loss: 19043.2793\n",
      "Epoch 3183/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13643.1973 - val_loss: 19061.5996\n",
      "Epoch 3184/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13702.6318 - val_loss: 19050.3281\n",
      "Epoch 3185/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13666.3135 - val_loss: 19045.7422\n",
      "Epoch 3186/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13650.0166 - val_loss: 19024.9062\n",
      "Epoch 3187/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13583.6055 - val_loss: 18970.9941\n",
      "Epoch 3188/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13415.9355 - val_loss: 18894.8359\n",
      "Epoch 3189/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13179.3184 - val_loss: 18838.1973\n",
      "Epoch 3190/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.0010 - val_loss: 18833.7773\n",
      "Epoch 3191/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12989.1855 - val_loss: 18834.0391\n",
      "Epoch 3192/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12991.8271 - val_loss: 18817.4414\n",
      "Epoch 3193/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12965.0527 - val_loss: 18830.9551\n",
      "Epoch 3194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13006.9707 - val_loss: 18823.1289\n",
      "Epoch 3195/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12980.9453 - val_loss: 18820.1660\n",
      "Epoch 3196/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12969.9648 - val_loss: 18798.2578\n",
      "Epoch 3197/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12905.7090 - val_loss: 19046.9570\n",
      "Epoch 3198/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13722.3398 - val_loss: 19055.4160\n",
      "Epoch 3199/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13704.2178 - val_loss: 19375.2500\n",
      "Epoch 3200/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14702.7041 - val_loss: 19586.2480\n",
      "Epoch 3201/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15358.6592 - val_loss: 19716.1113\n",
      "Epoch 3202/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15762.9199 - val_loss: 19760.3340\n",
      "Epoch 3203/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15902.9932 - val_loss: 19774.5898\n",
      "Epoch 3204/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15948.9746 - val_loss: 19773.2188\n",
      "Epoch 3205/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15944.4414 - val_loss: 19726.7949\n",
      "Epoch 3206/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15797.0303 - val_loss: 19688.6719\n",
      "Epoch 3207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15679.7891 - val_loss: 19613.7832\n",
      "Epoch 3208/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15444.3018 - val_loss: 19547.5117\n",
      "Epoch 3209/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15238.3779 - val_loss: 19508.1328\n",
      "Epoch 3210/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15115.2500 - val_loss: 19493.3926\n",
      "Epoch 3211/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15070.3750 - val_loss: 19513.5664\n",
      "Epoch 3212/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15132.8574 - val_loss: 19475.7832\n",
      "Epoch 3213/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15013.9014 - val_loss: 19446.2930\n",
      "Epoch 3214/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14921.9795 - val_loss: 19435.9199\n",
      "Epoch 3215/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14865.5547 - val_loss: 19374.4551\n",
      "Epoch 3216/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14674.4141 - val_loss: 19342.4590\n",
      "Epoch 3217/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14575.5547 - val_loss: 19289.1875\n",
      "Epoch 3218/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14408.0215 - val_loss: 19216.8965\n",
      "Epoch 3219/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14184.4053 - val_loss: 19144.8203\n",
      "Epoch 3220/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13959.5098 - val_loss: 19124.1660\n",
      "Epoch 3221/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13894.7969 - val_loss: 19131.8477\n",
      "Epoch 3222/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13905.2754 - val_loss: 19082.6016\n",
      "Epoch 3223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13766.7168 - val_loss: 19029.2188\n",
      "Epoch 3224/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13598.5205 - val_loss: 19008.5410\n",
      "Epoch 3225/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13548.3555 - val_loss: 18971.2910\n",
      "Epoch 3226/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13441.6289 - val_loss: 18979.7754\n",
      "Epoch 3227/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13470.6191 - val_loss: 18984.2637\n",
      "Epoch 3228/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13484.9316 - val_loss: 18975.0137\n",
      "Epoch 3229/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13456.1523 - val_loss: 18941.2559\n",
      "Epoch 3230/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13350.2734 - val_loss: 18951.8477\n",
      "Epoch 3231/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13383.3594 - val_loss: 18907.1328\n",
      "Epoch 3232/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13242.1924 - val_loss: 18850.4688\n",
      "Epoch 3233/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13043.6875 - val_loss: 18852.6250\n",
      "Epoch 3234/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13048.5596 - val_loss: 18874.8379\n",
      "Epoch 3235/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13116.1387 - val_loss: 18901.3340\n",
      "Epoch 3236/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13194.8818 - val_loss: 18870.0645\n",
      "Epoch 3237/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13097.9609 - val_loss: 18809.0723\n",
      "Epoch 3238/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12913.9951 - val_loss: 18760.5488\n",
      "Epoch 3239/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12778.6680 - val_loss: 18779.3887\n",
      "Epoch 3240/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12845.4072 - val_loss: 18774.5117\n",
      "Epoch 3241/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12831.8965 - val_loss: 18971.1211\n",
      "Epoch 3242/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13435.4062 - val_loss: 19028.5488\n",
      "Epoch 3243/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13621.1904 - val_loss: 19380.5605\n",
      "Epoch 3244/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14718.2559 - val_loss: 19629.9980\n",
      "Epoch 3245/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15496.6357 - val_loss: 19770.6152\n",
      "Epoch 3246/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15935.0498 - val_loss: 19819.8906\n",
      "Epoch 3247/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16089.2695 - val_loss: 19794.0352\n",
      "Epoch 3248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16008.6592 - val_loss: 19777.1582\n",
      "Epoch 3249/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15957.8086 - val_loss: 19751.3457\n",
      "Epoch 3250/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15862.5137 - val_loss: 19689.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15667.0537 - val_loss: 19702.6367\n",
      "Epoch 3252/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15703.7695 - val_loss: 19672.8398\n",
      "Epoch 3253/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15608.7119 - val_loss: 19577.9609\n",
      "Epoch 3254/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15312.6426 - val_loss: 19510.0371\n",
      "Epoch 3255/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15098.7344 - val_loss: 19428.3535\n",
      "Epoch 3256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14844.6709 - val_loss: 19335.6113\n",
      "Epoch 3257/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14557.1592 - val_loss: 19236.4766\n",
      "Epoch 3258/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14249.1201 - val_loss: 19164.0547\n",
      "Epoch 3259/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14026.4326 - val_loss: 19171.0117\n",
      "Epoch 3260/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14023.1074 - val_loss: 19200.3711\n",
      "Epoch 3261/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14130.8496 - val_loss: 19228.3711\n",
      "Epoch 3262/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14219.2168 - val_loss: 19200.0547\n",
      "Epoch 3263/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14131.7070 - val_loss: 19128.8516\n",
      "Epoch 3264/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13910.2832 - val_loss: 19072.3242\n",
      "Epoch 3265/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13733.0156 - val_loss: 19054.0801\n",
      "Epoch 3266/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13676.7510 - val_loss: 19037.7461\n",
      "Epoch 3267/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13624.6016 - val_loss: 19015.8145\n",
      "Epoch 3268/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13555.4736 - val_loss: 18966.7891\n",
      "Epoch 3269/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13402.3994 - val_loss: 18938.8418\n",
      "Epoch 3270/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13320.5820 - val_loss: 18922.4902\n",
      "Epoch 3271/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13293.5703 - val_loss: 18880.6445\n",
      "Epoch 3272/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13164.2998 - val_loss: 18879.2520\n",
      "Epoch 3273/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13158.0576 - val_loss: 18878.1367\n",
      "Epoch 3274/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13153.2480 - val_loss: 18854.8184\n",
      "Epoch 3275/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13083.2119 - val_loss: 18799.2559\n",
      "Epoch 3276/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12908.3779 - val_loss: 18743.1016\n",
      "Epoch 3277/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12723.1807 - val_loss: 18748.1738\n",
      "Epoch 3278/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12720.7773 - val_loss: 18793.6465\n",
      "Epoch 3279/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.3096 - val_loss: 18802.2285\n",
      "Epoch 3280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12887.3467 - val_loss: 18781.8789\n",
      "Epoch 3281/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.2559 - val_loss: 18782.4453\n",
      "Epoch 3282/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.1367 - val_loss: 18766.6426\n",
      "Epoch 3283/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12806.9844 - val_loss: 18764.1035\n",
      "Epoch 3284/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.7012 - val_loss: 18764.4121\n",
      "Epoch 3285/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12798.8828 - val_loss: 18786.1523\n",
      "Epoch 3286/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12861.9834 - val_loss: 18773.7207\n",
      "Epoch 3287/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.0889 - val_loss: 18753.0352\n",
      "Epoch 3288/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12735.3574 - val_loss: 18717.0742\n",
      "Epoch 3289/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.3701 - val_loss: 18705.7168\n",
      "Epoch 3290/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12604.9678 - val_loss: 18726.9434\n",
      "Epoch 3291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.1465 - val_loss: 18716.2500\n",
      "Epoch 3292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.1846 - val_loss: 18729.3945\n",
      "Epoch 3293/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12685.4336 - val_loss: 18743.5488\n",
      "Epoch 3294/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12722.2559 - val_loss: 18754.1426\n",
      "Epoch 3295/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.1230 - val_loss: 18757.7070\n",
      "Epoch 3296/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12751.3301 - val_loss: 18775.2402\n",
      "Epoch 3297/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12829.8057 - val_loss: 18846.7637\n",
      "Epoch 3298/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13052.1973 - val_loss: 18863.3184\n",
      "Epoch 3299/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13106.0117 - val_loss: 18876.6270\n",
      "Epoch 3300/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13148.3291 - val_loss: 18843.7051\n",
      "Epoch 3301/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13046.0586 - val_loss: 18814.3809\n",
      "Epoch 3302/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12954.1387 - val_loss: 18775.9199\n",
      "Epoch 3303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12829.9795 - val_loss: 18763.2031\n",
      "Epoch 3304/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.3232 - val_loss: 18780.1328\n",
      "Epoch 3305/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.1826 - val_loss: 18779.9688\n",
      "Epoch 3306/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12820.0820 - val_loss: 18770.0547\n",
      "Epoch 3307/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12791.3535 - val_loss: 18726.0410\n",
      "Epoch 3308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12652.7822 - val_loss: 18721.0723\n",
      "Epoch 3309/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.7344 - val_loss: 18746.5469\n",
      "Epoch 3310/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.2305 - val_loss: 18807.8086\n",
      "Epoch 3311/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12931.0801 - val_loss: 18833.5176\n",
      "Epoch 3312/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13015.6221 - val_loss: 18842.4277\n",
      "Epoch 3313/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13042.3652 - val_loss: 18841.8906\n",
      "Epoch 3314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13042.0762 - val_loss: 18834.1953\n",
      "Epoch 3315/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13015.3779 - val_loss: 18784.3223\n",
      "Epoch 3316/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12859.5518 - val_loss: 18761.3672\n",
      "Epoch 3317/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12785.0957 - val_loss: 18748.2852\n",
      "Epoch 3318/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.3779 - val_loss: 18757.5801\n",
      "Epoch 3319/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.4307 - val_loss: 18750.0020\n",
      "Epoch 3320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.6064 - val_loss: 19016.2480\n",
      "Epoch 3321/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13583.1973 - val_loss: 19025.3184\n",
      "Epoch 3322/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13610.7773 - val_loss: 19378.7246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3323/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14712.4092 - val_loss: 19607.6426\n",
      "Epoch 3324/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15426.2188 - val_loss: 19773.7266\n",
      "Epoch 3325/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15944.6289 - val_loss: 19870.4883\n",
      "Epoch 3326/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16246.8018 - val_loss: 19874.5293\n",
      "Epoch 3327/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16260.0811 - val_loss: 19830.1836\n",
      "Epoch 3328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16121.9688 - val_loss: 19806.4141\n",
      "Epoch 3329/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16046.2080 - val_loss: 19779.0332\n",
      "Epoch 3330/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15960.9961 - val_loss: 19777.7773\n",
      "Epoch 3331/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15957.6953 - val_loss: 19763.7891\n",
      "Epoch 3332/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15914.7168 - val_loss: 19706.9492\n",
      "Epoch 3333/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15738.9639 - val_loss: 19652.6602\n",
      "Epoch 3334/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15570.9053 - val_loss: 19585.1445\n",
      "Epoch 3335/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15345.9824 - val_loss: 19480.7520\n",
      "Epoch 3336/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15033.8115 - val_loss: 19393.3574\n",
      "Epoch 3337/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14762.4404 - val_loss: 19295.1094\n",
      "Epoch 3338/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14453.7236 - val_loss: 19248.2539\n",
      "Epoch 3339/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14306.4648 - val_loss: 19253.3105\n",
      "Epoch 3340/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14316.2080 - val_loss: 19282.4805\n",
      "Epoch 3341/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14379.1650 - val_loss: 19254.4473\n",
      "Epoch 3342/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14299.7490 - val_loss: 19222.0000\n",
      "Epoch 3343/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14201.4150 - val_loss: 19182.2070\n",
      "Epoch 3344/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14077.1885 - val_loss: 19127.5176\n",
      "Epoch 3345/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13905.1367 - val_loss: 19079.4707\n",
      "Epoch 3346/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13754.3945 - val_loss: 19058.7617\n",
      "Epoch 3347/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13689.6992 - val_loss: 19031.3164\n",
      "Epoch 3348/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13603.5889 - val_loss: 18999.5195\n",
      "Epoch 3349/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13505.0371 - val_loss: 18982.7383\n",
      "Epoch 3350/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13454.9502 - val_loss: 18982.3066\n",
      "Epoch 3351/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13456.3174 - val_loss: 18974.2129\n",
      "Epoch 3352/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13451.6553 - val_loss: 18958.2012\n",
      "Epoch 3353/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13403.7686 - val_loss: 18920.9023\n",
      "Epoch 3354/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13287.4199 - val_loss: 18893.5234\n",
      "Epoch 3355/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13203.5801 - val_loss: 18859.3770\n",
      "Epoch 3356/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13093.7471 - val_loss: 18827.8320\n",
      "Epoch 3357/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12995.8809 - val_loss: 18821.8008\n",
      "Epoch 3358/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12977.3867 - val_loss: 18818.3887\n",
      "Epoch 3359/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12950.2949 - val_loss: 18798.9590\n",
      "Epoch 3360/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.8975 - val_loss: 18761.9336\n",
      "Epoch 3361/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12767.5762 - val_loss: 18752.0059\n",
      "Epoch 3362/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.6455 - val_loss: 18734.7031\n",
      "Epoch 3363/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12678.1230 - val_loss: 18777.3574\n",
      "Epoch 3364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12826.0703 - val_loss: 18900.5820\n",
      "Epoch 3365/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13223.2900 - val_loss: 19117.5840\n",
      "Epoch 3366/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13899.6113 - val_loss: 19237.3867\n",
      "Epoch 3367/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14272.9434 - val_loss: 19293.0273\n",
      "Epoch 3368/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14446.4502 - val_loss: 19322.5742\n",
      "Epoch 3369/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14539.6045 - val_loss: 19312.9902\n",
      "Epoch 3370/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14511.2881 - val_loss: 19288.8066\n",
      "Epoch 3371/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14433.8838 - val_loss: 19262.2695\n",
      "Epoch 3372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14351.4004 - val_loss: 19243.4023\n",
      "Epoch 3373/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14293.1816 - val_loss: 19210.1055\n",
      "Epoch 3374/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14189.5771 - val_loss: 19196.0098\n",
      "Epoch 3375/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14145.4766 - val_loss: 19138.2324\n",
      "Epoch 3376/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13964.8994 - val_loss: 19084.2578\n",
      "Epoch 3377/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13798.4443 - val_loss: 19027.4199\n",
      "Epoch 3378/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13621.1895 - val_loss: 18919.2227\n",
      "Epoch 3379/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13284.2705 - val_loss: 18864.8145\n",
      "Epoch 3380/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13085.7178 - val_loss: 18901.5684\n",
      "Epoch 3381/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13200.8945 - val_loss: 18904.2656\n",
      "Epoch 3382/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13208.5732 - val_loss: 18902.8398\n",
      "Epoch 3383/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13207.3115 - val_loss: 18895.2422\n",
      "Epoch 3384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13189.2061 - val_loss: 18823.0254\n",
      "Epoch 3385/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12945.9639 - val_loss: 18841.8770\n",
      "Epoch 3386/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13029.5234 - val_loss: 18891.7148\n",
      "Epoch 3387/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13196.4971 - val_loss: 18931.5215\n",
      "Epoch 3388/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13321.2080 - val_loss: 18954.3262\n",
      "Epoch 3389/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13394.4404 - val_loss: 18959.2129\n",
      "Epoch 3390/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13407.1357 - val_loss: 18946.3594\n",
      "Epoch 3391/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13366.8496 - val_loss: 18952.6660\n",
      "Epoch 3392/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13385.4805 - val_loss: 18937.2168\n",
      "Epoch 3393/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13338.6016 - val_loss: 18899.4258\n",
      "Epoch 3394/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13219.0391 - val_loss: 18838.0508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3395/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13027.8359 - val_loss: 18823.7227\n",
      "Epoch 3396/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12980.7109 - val_loss: 18829.6055\n",
      "Epoch 3397/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12978.3008 - val_loss: 18829.3340\n",
      "Epoch 3398/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12976.7012 - val_loss: 18823.5898\n",
      "Epoch 3399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12956.8301 - val_loss: 18776.7930\n",
      "Epoch 3400/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12809.8672 - val_loss: 18799.6641\n",
      "Epoch 3401/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12880.7617 - val_loss: 18805.5430\n",
      "Epoch 3402/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12900.5820 - val_loss: 18797.9336\n",
      "Epoch 3403/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12877.9717 - val_loss: 18778.9980\n",
      "Epoch 3404/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12848.8350 - val_loss: 18753.3320\n",
      "Epoch 3405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.9150 - val_loss: 18761.8809\n",
      "Epoch 3406/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12791.5068 - val_loss: 18779.5195\n",
      "Epoch 3407/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12848.5000 - val_loss: 18790.1543\n",
      "Epoch 3408/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12878.5107 - val_loss: 18773.5664\n",
      "Epoch 3409/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12828.6074 - val_loss: 18755.8945\n",
      "Epoch 3410/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.9014 - val_loss: 18752.7070\n",
      "Epoch 3411/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12763.7412 - val_loss: 18759.4883\n",
      "Epoch 3412/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12781.2881 - val_loss: 18737.3691\n",
      "Epoch 3413/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12692.8418 - val_loss: 18712.6016\n",
      "Epoch 3414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.4189 - val_loss: 18775.4492\n",
      "Epoch 3415/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12804.6143 - val_loss: 18860.1465\n",
      "Epoch 3416/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13089.1787 - val_loss: 18886.6719\n",
      "Epoch 3417/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13178.2422 - val_loss: 18860.8828\n",
      "Epoch 3418/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13100.2705 - val_loss: 18828.5254\n",
      "Epoch 3419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12999.8105 - val_loss: 18818.0566\n",
      "Epoch 3420/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.4180 - val_loss: 18823.1094\n",
      "Epoch 3421/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12972.4248 - val_loss: 18829.9160\n",
      "Epoch 3422/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12975.6426 - val_loss: 18799.1719\n",
      "Epoch 3423/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.7949 - val_loss: 18768.8672\n",
      "Epoch 3424/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.8223 - val_loss: 18797.7109\n",
      "Epoch 3425/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12876.8750 - val_loss: 18792.0586\n",
      "Epoch 3426/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12866.5811 - val_loss: 18764.6309\n",
      "Epoch 3427/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12792.2549 - val_loss: 18782.3086\n",
      "Epoch 3428/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.5078 - val_loss: 18766.4336\n",
      "Epoch 3429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12806.5625 - val_loss: 18736.5000\n",
      "Epoch 3430/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12706.7754 - val_loss: 18751.9551\n",
      "Epoch 3431/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.3916 - val_loss: 18748.4004\n",
      "Epoch 3432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.6836 - val_loss: 18748.3086\n",
      "Epoch 3433/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12721.6230 - val_loss: 18759.5586\n",
      "Epoch 3434/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.4170 - val_loss: 18721.8770\n",
      "Epoch 3435/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12639.8232 - val_loss: 18702.0332\n",
      "Epoch 3436/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12587.7822 - val_loss: 18804.4473\n",
      "Epoch 3437/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12967.1309 - val_loss: 18898.6270\n",
      "Epoch 3438/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13214.7441 - val_loss: 19125.0332\n",
      "Epoch 3439/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13921.9922 - val_loss: 19261.4102\n",
      "Epoch 3440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14347.5557 - val_loss: 19304.1992\n",
      "Epoch 3441/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14481.2480 - val_loss: 19308.3789\n",
      "Epoch 3442/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14494.1387 - val_loss: 19274.0078\n",
      "Epoch 3443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14387.3711 - val_loss: 19240.4609\n",
      "Epoch 3444/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14281.9492 - val_loss: 19240.9258\n",
      "Epoch 3445/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14283.3633 - val_loss: 19248.5977\n",
      "Epoch 3446/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14310.4082 - val_loss: 19234.8613\n",
      "Epoch 3447/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14267.5059 - val_loss: 19210.6270\n",
      "Epoch 3448/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14190.5410 - val_loss: 19165.8496\n",
      "Epoch 3449/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14051.1113 - val_loss: 19139.0078\n",
      "Epoch 3450/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13967.5713 - val_loss: 19118.0059\n",
      "Epoch 3451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13876.6943 - val_loss: 19061.4629\n",
      "Epoch 3452/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13700.6484 - val_loss: 19029.6348\n",
      "Epoch 3453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13600.9053 - val_loss: 19022.6289\n",
      "Epoch 3454/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13579.4619 - val_loss: 18964.3125\n",
      "Epoch 3455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13396.9531 - val_loss: 18883.1641\n",
      "Epoch 3456/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13142.2158 - val_loss: 18857.0723\n",
      "Epoch 3457/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13061.2676 - val_loss: 18839.5059\n",
      "Epoch 3458/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13005.3320 - val_loss: 18827.3652\n",
      "Epoch 3459/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12970.4736 - val_loss: 18841.5098\n",
      "Epoch 3460/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13042.4385 - val_loss: 18822.9707\n",
      "Epoch 3461/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12983.7090 - val_loss: 18809.6035\n",
      "Epoch 3462/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12942.1230 - val_loss: 18813.3750\n",
      "Epoch 3463/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12953.2266 - val_loss: 18803.0430\n",
      "Epoch 3464/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12920.3525 - val_loss: 18778.0625\n",
      "Epoch 3465/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12845.8271 - val_loss: 18718.0176\n",
      "Epoch 3466/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12650.7070 - val_loss: 18706.4062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.9766 - val_loss: 18718.6094\n",
      "Epoch 3468/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.7822 - val_loss: 18763.0391\n",
      "Epoch 3469/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12772.9404 - val_loss: 18791.5508\n",
      "Epoch 3470/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12858.7832 - val_loss: 18795.6562\n",
      "Epoch 3471/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12870.2217 - val_loss: 18772.1348\n",
      "Epoch 3472/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12802.8408 - val_loss: 18760.9160\n",
      "Epoch 3473/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12787.1045 - val_loss: 18777.0332\n",
      "Epoch 3474/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12839.3516 - val_loss: 18771.0410\n",
      "Epoch 3475/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12821.7793 - val_loss: 18763.3633\n",
      "Epoch 3476/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12798.4541 - val_loss: 18747.8613\n",
      "Epoch 3477/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12740.8896 - val_loss: 18720.4102\n",
      "Epoch 3478/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.3115 - val_loss: 18703.0449\n",
      "Epoch 3479/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.0449 - val_loss: 18718.5195\n",
      "Epoch 3480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12632.2080 - val_loss: 18713.3066\n",
      "Epoch 3481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.3604 - val_loss: 18705.0664\n",
      "Epoch 3482/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12612.4404 - val_loss: 18688.0508\n",
      "Epoch 3483/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.5381 - val_loss: 18691.7148\n",
      "Epoch 3484/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12570.7939 - val_loss: 18720.2051\n",
      "Epoch 3485/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12651.3154 - val_loss: 18703.3379\n",
      "Epoch 3486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12590.9355 - val_loss: 18696.5898\n",
      "Epoch 3487/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12562.1895 - val_loss: 18712.1777\n",
      "Epoch 3488/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.9385 - val_loss: 18692.2871\n",
      "Epoch 3489/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.1836 - val_loss: 18677.3711\n",
      "Epoch 3490/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.5459 - val_loss: 18679.0527\n",
      "Epoch 3491/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.5859 - val_loss: 18678.2227\n",
      "Epoch 3492/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12525.8906 - val_loss: 18672.1660\n",
      "Epoch 3493/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12506.9033 - val_loss: 18678.2520\n",
      "Epoch 3494/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.9316 - val_loss: 18685.7988\n",
      "Epoch 3495/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12547.7344 - val_loss: 18678.4688\n",
      "Epoch 3496/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12518.5020 - val_loss: 18676.8574\n",
      "Epoch 3497/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.6777 - val_loss: 18688.9570\n",
      "Epoch 3498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.8555 - val_loss: 18698.6680\n",
      "Epoch 3499/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12569.7471 - val_loss: 18679.8770\n",
      "Epoch 3500/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12515.3906 - val_loss: 18675.3008\n",
      "Epoch 3501/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12503.4775 - val_loss: 18699.0449\n",
      "Epoch 3502/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12588.5791 - val_loss: 18678.9277\n",
      "Epoch 3503/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12522.2734 - val_loss: 18657.0781\n",
      "Epoch 3504/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12454.0410 - val_loss: 18692.5742\n",
      "Epoch 3505/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12560.9961 - val_loss: 18686.5117\n",
      "Epoch 3506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12542.5400 - val_loss: 18709.6875\n",
      "Epoch 3507/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12657.6230 - val_loss: 18858.0879\n",
      "Epoch 3508/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13089.3340 - val_loss: 19031.6152\n",
      "Epoch 3509/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13628.1602 - val_loss: 19132.0371\n",
      "Epoch 3510/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13942.1143 - val_loss: 19171.5977\n",
      "Epoch 3511/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14064.9268 - val_loss: 19171.4590\n",
      "Epoch 3512/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14065.0850 - val_loss: 19170.7871\n",
      "Epoch 3513/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14065.0635 - val_loss: 19139.9629\n",
      "Epoch 3514/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13969.5752 - val_loss: 19085.5859\n",
      "Epoch 3515/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13799.7715 - val_loss: 19027.8828\n",
      "Epoch 3516/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13617.5977 - val_loss: 19011.3770\n",
      "Epoch 3517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13542.0059 - val_loss: 18996.7520\n",
      "Epoch 3518/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13498.6953 - val_loss: 19008.3047\n",
      "Epoch 3519/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13534.1562 - val_loss: 18974.2266\n",
      "Epoch 3520/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13427.8125 - val_loss: 18939.7383\n",
      "Epoch 3521/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13321.0098 - val_loss: 18900.0723\n",
      "Epoch 3522/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13196.6475 - val_loss: 18870.7188\n",
      "Epoch 3523/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13108.4180 - val_loss: 18842.1543\n",
      "Epoch 3524/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13039.6914 - val_loss: 18859.8438\n",
      "Epoch 3525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13095.7197 - val_loss: 18899.9824\n",
      "Epoch 3526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13220.9043 - val_loss: 18889.4414\n",
      "Epoch 3527/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13189.4980 - val_loss: 18868.4004\n",
      "Epoch 3528/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13122.2402 - val_loss: 18825.0957\n",
      "Epoch 3529/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12975.1650 - val_loss: 18812.4902\n",
      "Epoch 3530/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12924.8965 - val_loss: 18811.4375\n",
      "Epoch 3531/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12922.7920 - val_loss: 18806.9004\n",
      "Epoch 3532/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12904.8545 - val_loss: 18779.7051\n",
      "Epoch 3533/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.6875 - val_loss: 18750.4590\n",
      "Epoch 3534/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.7822 - val_loss: 18731.0078\n",
      "Epoch 3535/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12687.8965 - val_loss: 18722.5859\n",
      "Epoch 3536/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12665.4502 - val_loss: 18723.0879\n",
      "Epoch 3537/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.0811 - val_loss: 18750.9316\n",
      "Epoch 3538/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.7793 - val_loss: 18880.0566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3539/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13213.8525 - val_loss: 18989.0352\n",
      "Epoch 3540/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13497.4834 - val_loss: 19230.9473\n",
      "Epoch 3541/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14251.7490 - val_loss: 19393.5430\n",
      "Epoch 3542/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14759.4521 - val_loss: 19493.0254\n",
      "Epoch 3543/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15069.5283 - val_loss: 19526.6680\n",
      "Epoch 3544/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15174.9043 - val_loss: 19505.2012\n",
      "Epoch 3545/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15106.6143 - val_loss: 19447.7930\n",
      "Epoch 3546/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14927.6543 - val_loss: 19417.3047\n",
      "Epoch 3547/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14831.5137 - val_loss: 19365.9355\n",
      "Epoch 3548/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14675.7617 - val_loss: 19302.0996\n",
      "Epoch 3549/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14476.6689 - val_loss: 19247.8320\n",
      "Epoch 3550/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14307.6943 - val_loss: 19248.4023\n",
      "Epoch 3551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14307.2764 - val_loss: 19284.5957\n",
      "Epoch 3552/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14394.6123 - val_loss: 19298.7422\n",
      "Epoch 3553/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14439.7969 - val_loss: 19273.4238\n",
      "Epoch 3554/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14360.8613 - val_loss: 19213.5176\n",
      "Epoch 3555/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14175.7197 - val_loss: 19163.4863\n",
      "Epoch 3556/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14021.1875 - val_loss: 19108.1250\n",
      "Epoch 3557/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13850.5342 - val_loss: 19028.7363\n",
      "Epoch 3558/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13601.0342 - val_loss: 18970.4180\n",
      "Epoch 3559/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13415.5869 - val_loss: 18959.9531\n",
      "Epoch 3560/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13385.9385 - val_loss: 18969.1621\n",
      "Epoch 3561/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13437.0615 - val_loss: 18979.0938\n",
      "Epoch 3562/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13469.7529 - val_loss: 18990.2031\n",
      "Epoch 3563/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13503.1797 - val_loss: 18985.2637\n",
      "Epoch 3564/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13486.8330 - val_loss: 18959.7188\n",
      "Epoch 3565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13408.5098 - val_loss: 18914.7324\n",
      "Epoch 3566/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13266.9258 - val_loss: 18905.7285\n",
      "Epoch 3567/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13209.9404 - val_loss: 18886.6016\n",
      "Epoch 3568/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13156.1719 - val_loss: 18867.5996\n",
      "Epoch 3569/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13096.3750 - val_loss: 18863.3086\n",
      "Epoch 3570/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13083.9893 - val_loss: 18846.1680\n",
      "Epoch 3571/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13031.2578 - val_loss: 18812.1738\n",
      "Epoch 3572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12921.8428 - val_loss: 18784.6230\n",
      "Epoch 3573/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12846.2998 - val_loss: 18752.9824\n",
      "Epoch 3574/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.9561 - val_loss: 18753.8203\n",
      "Epoch 3575/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12766.4990 - val_loss: 18740.8340\n",
      "Epoch 3576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12723.1816 - val_loss: 18756.5918\n",
      "Epoch 3577/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12768.6738 - val_loss: 18749.4316\n",
      "Epoch 3578/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12742.1748 - val_loss: 18729.4277\n",
      "Epoch 3579/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12670.4258 - val_loss: 18727.2383\n",
      "Epoch 3580/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.0781 - val_loss: 18725.0020\n",
      "Epoch 3581/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12667.8174 - val_loss: 18704.0449\n",
      "Epoch 3582/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12601.1982 - val_loss: 18707.3262\n",
      "Epoch 3583/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12611.0664 - val_loss: 18693.8984\n",
      "Epoch 3584/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12569.3740 - val_loss: 18675.5410\n",
      "Epoch 3585/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12510.0410 - val_loss: 18696.6230\n",
      "Epoch 3586/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.5361 - val_loss: 18728.2090\n",
      "Epoch 3587/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.2197 - val_loss: 18722.6699\n",
      "Epoch 3588/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12647.1680 - val_loss: 18703.7031\n",
      "Epoch 3589/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12590.0078 - val_loss: 18689.0566\n",
      "Epoch 3590/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12547.2998 - val_loss: 18671.0801\n",
      "Epoch 3591/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12491.3027 - val_loss: 18700.4961\n",
      "Epoch 3592/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12582.1104 - val_loss: 18708.9824\n",
      "Epoch 3593/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12609.6191 - val_loss: 18690.1289\n",
      "Epoch 3594/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12547.0020 - val_loss: 18692.5039\n",
      "Epoch 3595/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12599.6621 - val_loss: 18899.3398\n",
      "Epoch 3596/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13217.4941 - val_loss: 19098.7148\n",
      "Epoch 3597/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13838.7891 - val_loss: 19212.0156\n",
      "Epoch 3598/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14192.7812 - val_loss: 19250.6699\n",
      "Epoch 3599/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14313.2832 - val_loss: 19241.6914\n",
      "Epoch 3600/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14285.2266 - val_loss: 19254.4336\n",
      "Epoch 3601/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14325.8291 - val_loss: 19269.8926\n",
      "Epoch 3602/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14374.2861 - val_loss: 19283.2402\n",
      "Epoch 3603/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14415.4355 - val_loss: 19245.6133\n",
      "Epoch 3604/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14298.0068 - val_loss: 19220.1992\n",
      "Epoch 3605/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14218.8662 - val_loss: 19157.7227\n",
      "Epoch 3606/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14024.4775 - val_loss: 19113.5293\n",
      "Epoch 3607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13870.9521 - val_loss: 19104.3613\n",
      "Epoch 3608/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13835.1885 - val_loss: 19093.1016\n",
      "Epoch 3609/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13802.2842 - val_loss: 19060.2773\n",
      "Epoch 3610/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13700.5459 - val_loss: 19012.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3611/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13553.2783 - val_loss: 18959.9668\n",
      "Epoch 3612/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13386.9980 - val_loss: 18919.5117\n",
      "Epoch 3613/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13259.0283 - val_loss: 18880.6641\n",
      "Epoch 3614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13137.9941 - val_loss: 18865.2871\n",
      "Epoch 3615/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13089.0859 - val_loss: 18879.6895\n",
      "Epoch 3616/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13154.8057 - val_loss: 18881.6191\n",
      "Epoch 3617/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13160.7637 - val_loss: 18871.1094\n",
      "Epoch 3618/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13129.7188 - val_loss: 18870.1504\n",
      "Epoch 3619/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13128.2793 - val_loss: 18865.9199\n",
      "Epoch 3620/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13114.2861 - val_loss: 18869.3242\n",
      "Epoch 3621/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13125.5898 - val_loss: 18822.1738\n",
      "Epoch 3622/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12976.7393 - val_loss: 18806.1738\n",
      "Epoch 3623/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12907.6553 - val_loss: 18764.0332\n",
      "Epoch 3624/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12774.3193 - val_loss: 18748.2285\n",
      "Epoch 3625/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12724.5361 - val_loss: 18757.8613\n",
      "Epoch 3626/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.3018 - val_loss: 18749.2109\n",
      "Epoch 3627/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12737.3154 - val_loss: 18807.1914\n",
      "Epoch 3628/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12929.6992 - val_loss: 18820.8398\n",
      "Epoch 3629/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12975.8320 - val_loss: 18773.1504\n",
      "Epoch 3630/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12830.4600 - val_loss: 18750.1543\n",
      "Epoch 3631/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12752.1846 - val_loss: 18767.8848\n",
      "Epoch 3632/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12802.2012 - val_loss: 18797.0137\n",
      "Epoch 3633/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12885.2061 - val_loss: 18781.0176\n",
      "Epoch 3634/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12828.5713 - val_loss: 18738.5684\n",
      "Epoch 3635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12691.5312 - val_loss: 18719.6055\n",
      "Epoch 3636/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.9111 - val_loss: 18760.6777\n",
      "Epoch 3637/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12796.4033 - val_loss: 18754.2441\n",
      "Epoch 3638/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12765.5527 - val_loss: 18812.6641\n",
      "Epoch 3639/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12947.0430 - val_loss: 18837.5723\n",
      "Epoch 3640/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13024.7793 - val_loss: 18841.8145\n",
      "Epoch 3641/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13038.9111 - val_loss: 18844.9316\n",
      "Epoch 3642/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13048.6396 - val_loss: 18810.9512\n",
      "Epoch 3643/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12944.6133 - val_loss: 18827.9531\n",
      "Epoch 3644/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12978.2637 - val_loss: 18827.0918\n",
      "Epoch 3645/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12972.9336 - val_loss: 18810.5586\n",
      "Epoch 3646/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12919.8701 - val_loss: 18834.8535\n",
      "Epoch 3647/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12994.2568 - val_loss: 18825.3613\n",
      "Epoch 3648/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12965.2900 - val_loss: 18774.6660\n",
      "Epoch 3649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12807.7734 - val_loss: 18754.5898\n",
      "Epoch 3650/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12763.2998 - val_loss: 18752.5508\n",
      "Epoch 3651/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12762.0049 - val_loss: 18735.7891\n",
      "Epoch 3652/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12708.9697 - val_loss: 18705.9961\n",
      "Epoch 3653/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12615.2002 - val_loss: 18673.2930\n",
      "Epoch 3654/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.5117 - val_loss: 18685.2988\n",
      "Epoch 3655/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12530.6865 - val_loss: 18709.1328\n",
      "Epoch 3656/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12601.2070 - val_loss: 18903.0957\n",
      "Epoch 3657/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13280.9307 - val_loss: 19008.2832\n",
      "Epoch 3658/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13557.3115 - val_loss: 19307.6387\n",
      "Epoch 3659/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14490.4502 - val_loss: 19490.5781\n",
      "Epoch 3660/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15061.0254 - val_loss: 19602.5391\n",
      "Epoch 3661/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15410.1562 - val_loss: 19668.2793\n",
      "Epoch 3662/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 15617.1191 - val_loss: 19715.0996\n",
      "Epoch 3663/10000\n",
      "630/630 [==============================] - 0s 24us/step - loss: 15763.7695 - val_loss: 19750.7695\n",
      "Epoch 3664/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 15874.2725 - val_loss: 19739.1445\n",
      "Epoch 3665/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15830.4814 - val_loss: 19710.3457\n",
      "Epoch 3666/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15746.8340 - val_loss: 19687.0117\n",
      "Epoch 3667/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 15674.0352 - val_loss: 19626.9414\n",
      "Epoch 3668/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15487.5596 - val_loss: 19522.4473\n",
      "Epoch 3669/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15163.4287 - val_loss: 19463.2207\n",
      "Epoch 3670/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14977.3887 - val_loss: 19407.8965\n",
      "Epoch 3671/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14804.0977 - val_loss: 19369.3672\n",
      "Epoch 3672/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14683.2871 - val_loss: 19343.0508\n",
      "Epoch 3673/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14593.7607 - val_loss: 19315.6211\n",
      "Epoch 3674/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14496.3623 - val_loss: 19269.3750\n",
      "Epoch 3675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14348.3848 - val_loss: 19231.7637\n",
      "Epoch 3676/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14234.4434 - val_loss: 19230.0703\n",
      "Epoch 3677/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14228.6328 - val_loss: 19202.0020\n",
      "Epoch 3678/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14143.5303 - val_loss: 19147.2051\n",
      "Epoch 3679/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13972.6650 - val_loss: 19060.7598\n",
      "Epoch 3680/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13702.2715 - val_loss: 18978.5098\n",
      "Epoch 3681/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13444.3184 - val_loss: 18958.2285\n",
      "Epoch 3682/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13380.1113 - val_loss: 18911.9414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3683/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13236.8398 - val_loss: 18926.3672\n",
      "Epoch 3684/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13304.4326 - val_loss: 18945.2480\n",
      "Epoch 3685/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13362.2949 - val_loss: 18963.8574\n",
      "Epoch 3686/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13419.5342 - val_loss: 18953.5391\n",
      "Epoch 3687/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13386.3086 - val_loss: 18944.2754\n",
      "Epoch 3688/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13358.1836 - val_loss: 18933.7500\n",
      "Epoch 3689/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13327.3164 - val_loss: 18917.6934\n",
      "Epoch 3690/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13276.9775 - val_loss: 18889.2754\n",
      "Epoch 3691/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13169.1768 - val_loss: 18873.7715\n",
      "Epoch 3692/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13118.0967 - val_loss: 18849.8418\n",
      "Epoch 3693/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13043.3262 - val_loss: 18840.0781\n",
      "Epoch 3694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13012.8564 - val_loss: 18826.4355\n",
      "Epoch 3695/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12970.3662 - val_loss: 18782.9316\n",
      "Epoch 3696/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.7705 - val_loss: 18750.1836\n",
      "Epoch 3697/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12733.8672 - val_loss: 18721.3008\n",
      "Epoch 3698/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12664.5908 - val_loss: 18778.6055\n",
      "Epoch 3699/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12877.2490 - val_loss: 18887.6758\n",
      "Epoch 3700/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13169.6338 - val_loss: 19033.0547\n",
      "Epoch 3701/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13636.1279 - val_loss: 19092.9121\n",
      "Epoch 3702/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13823.5928 - val_loss: 19135.6152\n",
      "Epoch 3703/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13958.0176 - val_loss: 19145.0879\n",
      "Epoch 3704/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13986.2041 - val_loss: 19128.8125\n",
      "Epoch 3705/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13935.8125 - val_loss: 19125.0859\n",
      "Epoch 3706/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13924.1309 - val_loss: 19107.6270\n",
      "Epoch 3707/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13869.3486 - val_loss: 19085.2383\n",
      "Epoch 3708/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13800.1641 - val_loss: 19043.4297\n",
      "Epoch 3709/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13660.5557 - val_loss: 19013.3457\n",
      "Epoch 3710/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13553.3193 - val_loss: 19007.4180\n",
      "Epoch 3711/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13536.0986 - val_loss: 18977.8906\n",
      "Epoch 3712/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13442.7549 - val_loss: 18929.8574\n",
      "Epoch 3713/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13293.2441 - val_loss: 18861.1465\n",
      "Epoch 3714/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13078.1338 - val_loss: 18851.9590\n",
      "Epoch 3715/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13051.3711 - val_loss: 18865.7578\n",
      "Epoch 3716/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13094.1514 - val_loss: 18852.2207\n",
      "Epoch 3717/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13059.5166 - val_loss: 18884.4805\n",
      "Epoch 3718/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13204.9482 - val_loss: 18898.9160\n",
      "Epoch 3719/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13219.0312 - val_loss: 18981.1816\n",
      "Epoch 3720/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13476.3311 - val_loss: 19049.6055\n",
      "Epoch 3721/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13690.1768 - val_loss: 19064.5488\n",
      "Epoch 3722/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13735.3564 - val_loss: 19092.4004\n",
      "Epoch 3723/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13820.3477 - val_loss: 19056.5098\n",
      "Epoch 3724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13707.7510 - val_loss: 19065.8613\n",
      "Epoch 3725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13738.8564 - val_loss: 19044.6699\n",
      "Epoch 3726/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13672.5576 - val_loss: 18986.8027\n",
      "Epoch 3727/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13492.0312 - val_loss: 18926.6074\n",
      "Epoch 3728/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13302.4531 - val_loss: 18899.9141\n",
      "Epoch 3729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13222.6289 - val_loss: 18908.8438\n",
      "Epoch 3730/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13228.1797 - val_loss: 18910.7090\n",
      "Epoch 3731/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13233.7822 - val_loss: 18880.6504\n",
      "Epoch 3732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13141.5615 - val_loss: 18834.8086\n",
      "Epoch 3733/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12998.6562 - val_loss: 18816.6797\n",
      "Epoch 3734/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12940.5322 - val_loss: 18827.3223\n",
      "Epoch 3735/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12971.5908 - val_loss: 18816.2852\n",
      "Epoch 3736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12940.1436 - val_loss: 18811.5820\n",
      "Epoch 3737/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12922.6250 - val_loss: 18799.4531\n",
      "Epoch 3738/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.4023 - val_loss: 18803.1426\n",
      "Epoch 3739/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12920.8535 - val_loss: 18766.6875\n",
      "Epoch 3740/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.7988 - val_loss: 18745.4375\n",
      "Epoch 3741/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12739.9062 - val_loss: 18741.1445\n",
      "Epoch 3742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12727.9639 - val_loss: 18778.1855\n",
      "Epoch 3743/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12864.7871 - val_loss: 18818.6406\n",
      "Epoch 3744/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12967.5000 - val_loss: 18903.5859\n",
      "Epoch 3745/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13235.1484 - val_loss: 18937.8457\n",
      "Epoch 3746/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13341.7959 - val_loss: 18939.9492\n",
      "Epoch 3747/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13346.5762 - val_loss: 18928.7246\n",
      "Epoch 3748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13309.2402 - val_loss: 18927.3711\n",
      "Epoch 3749/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13286.8975 - val_loss: 18911.0176\n",
      "Epoch 3750/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13236.1025 - val_loss: 18882.0332\n",
      "Epoch 3751/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13142.5156 - val_loss: 18878.4062\n",
      "Epoch 3752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13129.9678 - val_loss: 18857.2012\n",
      "Epoch 3753/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13066.1855 - val_loss: 18839.5117\n",
      "Epoch 3754/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13019.0537 - val_loss: 18813.2051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12951.1953 - val_loss: 18791.0898\n",
      "Epoch 3756/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12882.8438 - val_loss: 18781.7109\n",
      "Epoch 3757/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12854.2959 - val_loss: 18776.7812\n",
      "Epoch 3758/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12832.3623 - val_loss: 18780.1289\n",
      "Epoch 3759/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12827.3945 - val_loss: 18862.1309\n",
      "Epoch 3760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13098.3691 - val_loss: 18849.0410\n",
      "Epoch 3761/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13062.7783 - val_loss: 19047.6484\n",
      "Epoch 3762/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13683.3096 - val_loss: 19161.1211\n",
      "Epoch 3763/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14036.9170 - val_loss: 19202.7461\n",
      "Epoch 3764/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14167.2959 - val_loss: 19170.4570\n",
      "Epoch 3765/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 14067.0830 - val_loss: 19135.5957\n",
      "Epoch 3766/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13958.1582 - val_loss: 19132.9395\n",
      "Epoch 3767/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13950.2422 - val_loss: 19134.9336\n",
      "Epoch 3768/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13955.5586 - val_loss: 19109.0078\n",
      "Epoch 3769/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13874.3164 - val_loss: 19054.0117\n",
      "Epoch 3770/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13701.6104 - val_loss: 19037.8926\n",
      "Epoch 3771/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13639.8955 - val_loss: 19027.5586\n",
      "Epoch 3772/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13585.0684 - val_loss: 18989.3965\n",
      "Epoch 3773/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13475.1113 - val_loss: 19008.4707\n",
      "Epoch 3774/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13537.3975 - val_loss: 18988.5039\n",
      "Epoch 3775/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13476.4229 - val_loss: 18995.7031\n",
      "Epoch 3776/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13499.0293 - val_loss: 18987.0586\n",
      "Epoch 3777/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13468.4814 - val_loss: 18922.7910\n",
      "Epoch 3778/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13266.4082 - val_loss: 18853.1582\n",
      "Epoch 3779/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13052.5225 - val_loss: 18787.0801\n",
      "Epoch 3780/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12865.5830 - val_loss: 18798.4863\n",
      "Epoch 3781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12905.6816 - val_loss: 18837.6797\n",
      "Epoch 3782/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13028.8213 - val_loss: 18821.1992\n",
      "Epoch 3783/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12978.1445 - val_loss: 18770.7949\n",
      "Epoch 3784/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12818.3008 - val_loss: 18869.5215\n",
      "Epoch 3785/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13155.5977 - val_loss: 19029.5273\n",
      "Epoch 3786/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13617.5576 - val_loss: 19346.9082\n",
      "Epoch 3787/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14612.9238 - val_loss: 19541.3398\n",
      "Epoch 3788/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15222.5098 - val_loss: 19644.3496\n",
      "Epoch 3789/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15542.8027 - val_loss: 19667.5703\n",
      "Epoch 3790/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15615.1709 - val_loss: 19631.1582\n",
      "Epoch 3791/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15502.8242 - val_loss: 19657.1387\n",
      "Epoch 3792/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15586.2080 - val_loss: 19667.8359\n",
      "Epoch 3793/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15618.5352 - val_loss: 19635.0117\n",
      "Epoch 3794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15516.1631 - val_loss: 19531.0527\n",
      "Epoch 3795/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15192.5410 - val_loss: 19388.4375\n",
      "Epoch 3796/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14748.0098 - val_loss: 19300.2070\n",
      "Epoch 3797/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14470.9512 - val_loss: 19296.8516\n",
      "Epoch 3798/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14439.8662 - val_loss: 19384.8125\n",
      "Epoch 3799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14711.0635 - val_loss: 19403.8594\n",
      "Epoch 3800/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14771.3252 - val_loss: 19367.3770\n",
      "Epoch 3801/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14658.6367 - val_loss: 19305.2480\n",
      "Epoch 3802/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14459.4883 - val_loss: 19200.7168\n",
      "Epoch 3803/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14137.1914 - val_loss: 19151.4980\n",
      "Epoch 3804/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13984.9551 - val_loss: 19136.0430\n",
      "Epoch 3805/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13936.5957 - val_loss: 19087.2148\n",
      "Epoch 3806/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13784.9648 - val_loss: 19034.3828\n",
      "Epoch 3807/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13620.2021 - val_loss: 18947.6621\n",
      "Epoch 3808/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13371.5879 - val_loss: 18912.9941\n",
      "Epoch 3809/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13265.8916 - val_loss: 18904.8379\n",
      "Epoch 3810/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13240.0273 - val_loss: 18901.0215\n",
      "Epoch 3811/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13226.1309 - val_loss: 18906.3359\n",
      "Epoch 3812/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13241.9316 - val_loss: 18923.3652\n",
      "Epoch 3813/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13295.2314 - val_loss: 18899.8066\n",
      "Epoch 3814/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13219.5801 - val_loss: 18851.2051\n",
      "Epoch 3815/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13043.2998 - val_loss: 18849.2168\n",
      "Epoch 3816/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13039.9658 - val_loss: 18869.1211\n",
      "Epoch 3817/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13102.8584 - val_loss: 18802.0840\n",
      "Epoch 3818/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12893.9287 - val_loss: 18744.0137\n",
      "Epoch 3819/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12724.9707 - val_loss: 18756.3906\n",
      "Epoch 3820/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12774.1455 - val_loss: 18741.1211\n",
      "Epoch 3821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.4746 - val_loss: 18743.2637\n",
      "Epoch 3822/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.2451 - val_loss: 18761.3555\n",
      "Epoch 3823/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12787.0801 - val_loss: 18782.1406\n",
      "Epoch 3824/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12838.1016 - val_loss: 18774.2773\n",
      "Epoch 3825/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12808.8018 - val_loss: 18757.2266\n",
      "Epoch 3826/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12757.4326 - val_loss: 18750.8770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12735.9834 - val_loss: 18765.6641\n",
      "Epoch 3828/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12793.8672 - val_loss: 18754.0254\n",
      "Epoch 3829/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.2275 - val_loss: 18738.6055\n",
      "Epoch 3830/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12719.6016 - val_loss: 18716.2852\n",
      "Epoch 3831/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12644.1162 - val_loss: 18708.5527\n",
      "Epoch 3832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.1504 - val_loss: 18939.9336\n",
      "Epoch 3833/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13348.9600 - val_loss: 18992.5586\n",
      "Epoch 3834/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13510.7588 - val_loss: 19325.7617\n",
      "Epoch 3835/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14549.3184 - val_loss: 19565.0605\n",
      "Epoch 3836/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15295.8330 - val_loss: 19697.2832\n",
      "Epoch 3837/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15707.6895 - val_loss: 19752.4922\n",
      "Epoch 3838/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15878.2021 - val_loss: 19788.2207\n",
      "Epoch 3839/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15989.4512 - val_loss: 19774.8008\n",
      "Epoch 3840/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15951.0332 - val_loss: 19733.4395\n",
      "Epoch 3841/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15822.7627 - val_loss: 19697.4590\n",
      "Epoch 3842/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15710.7490 - val_loss: 19649.9004\n",
      "Epoch 3843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15560.8662 - val_loss: 19607.5117\n",
      "Epoch 3844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15429.0166 - val_loss: 19540.7988\n",
      "Epoch 3845/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15221.1826 - val_loss: 19465.6797\n",
      "Epoch 3846/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14987.9766 - val_loss: 19391.5195\n",
      "Epoch 3847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14756.9668 - val_loss: 19342.5352\n",
      "Epoch 3848/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14602.8525 - val_loss: 19307.0742\n",
      "Epoch 3849/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14491.4150 - val_loss: 19296.6992\n",
      "Epoch 3850/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14457.5508 - val_loss: 19300.4473\n",
      "Epoch 3851/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14449.2842 - val_loss: 19257.3691\n",
      "Epoch 3852/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14314.9688 - val_loss: 19240.5059\n",
      "Epoch 3853/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14263.8457 - val_loss: 19198.2676\n",
      "Epoch 3854/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14132.1992 - val_loss: 19137.5586\n",
      "Epoch 3855/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13942.2969 - val_loss: 19113.9121\n",
      "Epoch 3856/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13865.8955 - val_loss: 19067.8184\n",
      "Epoch 3857/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13721.4912 - val_loss: 19044.8418\n",
      "Epoch 3858/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13649.7354 - val_loss: 19053.3301\n",
      "Epoch 3859/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13678.0938 - val_loss: 19086.2500\n",
      "Epoch 3860/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13778.5996 - val_loss: 19061.8555\n",
      "Epoch 3861/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13723.9336 - val_loss: 19053.1738\n",
      "Epoch 3862/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13698.9014 - val_loss: 19027.1582\n",
      "Epoch 3863/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13620.0693 - val_loss: 19014.6895\n",
      "Epoch 3864/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13580.9990 - val_loss: 18960.0996\n",
      "Epoch 3865/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13411.2119 - val_loss: 18908.6074\n",
      "Epoch 3866/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13249.6211 - val_loss: 18897.4062\n",
      "Epoch 3867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13212.9971 - val_loss: 18911.3105\n",
      "Epoch 3868/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13252.4434 - val_loss: 18925.4590\n",
      "Epoch 3869/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13279.4092 - val_loss: 18926.9512\n",
      "Epoch 3870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13284.4189 - val_loss: 18898.9512\n",
      "Epoch 3871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13197.2646 - val_loss: 18868.5430\n",
      "Epoch 3872/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13103.3193 - val_loss: 18828.3945\n",
      "Epoch 3873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12978.1250 - val_loss: 18836.5566\n",
      "Epoch 3874/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.5469 - val_loss: 18846.4004\n",
      "Epoch 3875/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13040.5273 - val_loss: 18829.3164\n",
      "Epoch 3876/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13000.8594 - val_loss: 18777.7578\n",
      "Epoch 3877/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12843.4336 - val_loss: 18748.3047\n",
      "Epoch 3878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12746.3877 - val_loss: 18719.0527\n",
      "Epoch 3879/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.4004 - val_loss: 18747.2441\n",
      "Epoch 3880/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.3252 - val_loss: 18939.8105\n",
      "Epoch 3881/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13347.3242 - val_loss: 18990.8887\n",
      "Epoch 3882/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13507.6436 - val_loss: 19322.4727\n",
      "Epoch 3883/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14540.4170 - val_loss: 19557.4688\n",
      "Epoch 3884/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15272.3350 - val_loss: 19707.9453\n",
      "Epoch 3885/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15742.1592 - val_loss: 19788.9902\n",
      "Epoch 3886/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15995.6152 - val_loss: 19812.8906\n",
      "Epoch 3887/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16070.8135 - val_loss: 19764.7754\n",
      "Epoch 3888/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15920.7607 - val_loss: 19697.3496\n",
      "Epoch 3889/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15711.1572 - val_loss: 19660.3828\n",
      "Epoch 3890/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15595.4453 - val_loss: 19655.7617\n",
      "Epoch 3891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15580.4746 - val_loss: 19670.8164\n",
      "Epoch 3892/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15625.3838 - val_loss: 19657.3555\n",
      "Epoch 3893/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15582.8604 - val_loss: 19584.1914\n",
      "Epoch 3894/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15351.6465 - val_loss: 19487.0176\n",
      "Epoch 3895/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15043.5322 - val_loss: 19388.3691\n",
      "Epoch 3896/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14741.6377 - val_loss: 19286.7363\n",
      "Epoch 3897/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14428.8965 - val_loss: 19233.6348\n",
      "Epoch 3898/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14258.9482 - val_loss: 19239.2031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14259.2793 - val_loss: 19297.8789\n",
      "Epoch 3900/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14442.8691 - val_loss: 19303.3496\n",
      "Epoch 3901/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14460.0928 - val_loss: 19237.8262\n",
      "Epoch 3902/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14254.9707 - val_loss: 19155.0234\n",
      "Epoch 3903/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13996.3955 - val_loss: 19084.0059\n",
      "Epoch 3904/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13774.8984 - val_loss: 19029.6660\n",
      "Epoch 3905/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13605.7412 - val_loss: 18978.0664\n",
      "Epoch 3906/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13443.1719 - val_loss: 18955.9297\n",
      "Epoch 3907/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13374.3906 - val_loss: 18998.9609\n",
      "Epoch 3908/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13507.6807 - val_loss: 18983.2266\n",
      "Epoch 3909/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13475.5566 - val_loss: 18971.5430\n",
      "Epoch 3910/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13446.7412 - val_loss: 18952.3125\n",
      "Epoch 3911/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13385.2744 - val_loss: 18906.7383\n",
      "Epoch 3912/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13244.1113 - val_loss: 18890.6211\n",
      "Epoch 3913/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13192.9492 - val_loss: 18862.1543\n",
      "Epoch 3914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13101.7695 - val_loss: 18823.4355\n",
      "Epoch 3915/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12983.7305 - val_loss: 18769.7969\n",
      "Epoch 3916/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12818.8828 - val_loss: 18776.0039\n",
      "Epoch 3917/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12815.1826 - val_loss: 18763.2930\n",
      "Epoch 3918/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12774.3496 - val_loss: 18787.5781\n",
      "Epoch 3919/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.5723 - val_loss: 18829.3809\n",
      "Epoch 3920/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12991.8584 - val_loss: 18782.1152\n",
      "Epoch 3921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12838.5732 - val_loss: 18887.7852\n",
      "Epoch 3922/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13187.1514 - val_loss: 18965.4551\n",
      "Epoch 3923/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13429.5215 - val_loss: 18974.4414\n",
      "Epoch 3924/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13458.0381 - val_loss: 18938.5156\n",
      "Epoch 3925/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13344.8330 - val_loss: 18855.7793\n",
      "Epoch 3926/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13084.8809 - val_loss: 18844.7715\n",
      "Epoch 3927/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13050.4570 - val_loss: 18871.8359\n",
      "Epoch 3928/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13132.1426 - val_loss: 18849.0840\n",
      "Epoch 3929/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13049.5596 - val_loss: 18841.5273\n",
      "Epoch 3930/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13018.6914 - val_loss: 18810.8047\n",
      "Epoch 3931/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12930.2451 - val_loss: 18746.9395\n",
      "Epoch 3932/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12723.7891 - val_loss: 18768.2324\n",
      "Epoch 3933/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.4658 - val_loss: 18803.5352\n",
      "Epoch 3934/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12900.6562 - val_loss: 18816.1426\n",
      "Epoch 3935/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12961.9668 - val_loss: 18797.9121\n",
      "Epoch 3936/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12902.2266 - val_loss: 18760.8594\n",
      "Epoch 3937/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.0664 - val_loss: 18742.2539\n",
      "Epoch 3938/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12729.4287 - val_loss: 18748.7461\n",
      "Epoch 3939/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12749.6934 - val_loss: 18757.6328\n",
      "Epoch 3940/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.2783 - val_loss: 18767.4473\n",
      "Epoch 3941/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12812.9561 - val_loss: 18762.9844\n",
      "Epoch 3942/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12787.3027 - val_loss: 18742.8633\n",
      "Epoch 3943/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12709.9609 - val_loss: 18723.6816\n",
      "Epoch 3944/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12649.8252 - val_loss: 18861.4180\n",
      "Epoch 3945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13123.7119 - val_loss: 19002.8398\n",
      "Epoch 3946/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13531.3730 - val_loss: 19288.0254\n",
      "Epoch 3947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14422.6953 - val_loss: 19490.2695\n",
      "Epoch 3948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15064.3779 - val_loss: 19605.1660\n",
      "Epoch 3949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15423.7744 - val_loss: 19652.9414\n",
      "Epoch 3950/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15572.1543 - val_loss: 19663.1523\n",
      "Epoch 3951/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15602.0117 - val_loss: 19689.3359\n",
      "Epoch 3952/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15683.9375 - val_loss: 19656.5859\n",
      "Epoch 3953/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15582.2744 - val_loss: 19578.1113\n",
      "Epoch 3954/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15339.3623 - val_loss: 19494.7520\n",
      "Epoch 3955/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15079.4785 - val_loss: 19475.6328\n",
      "Epoch 3956/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15018.6982 - val_loss: 19446.2070\n",
      "Epoch 3957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14926.4717 - val_loss: 19398.1543\n",
      "Epoch 3958/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14777.8174 - val_loss: 19336.2754\n",
      "Epoch 3959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14585.8311 - val_loss: 19287.3398\n",
      "Epoch 3960/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14415.7930 - val_loss: 19288.4219\n",
      "Epoch 3961/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14409.6914 - val_loss: 19279.8184\n",
      "Epoch 3962/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14384.6953 - val_loss: 19226.1113\n",
      "Epoch 3963/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14217.3730 - val_loss: 19222.8184\n",
      "Epoch 3964/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14208.2510 - val_loss: 19183.3223\n",
      "Epoch 3965/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14085.3125 - val_loss: 19114.5957\n",
      "Epoch 3966/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13869.2090 - val_loss: 19058.9199\n",
      "Epoch 3967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13696.5459 - val_loss: 19013.2715\n",
      "Epoch 3968/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13553.9053 - val_loss: 18985.8184\n",
      "Epoch 3969/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13466.7158 - val_loss: 18988.0391\n",
      "Epoch 3970/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13490.0391 - val_loss: 19021.9238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3971/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13603.5732 - val_loss: 19048.5586\n",
      "Epoch 3972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13685.3857 - val_loss: 19045.9453\n",
      "Epoch 3973/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13676.4932 - val_loss: 18994.8945\n",
      "Epoch 3974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13517.6133 - val_loss: 18939.9883\n",
      "Epoch 3975/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13346.7207 - val_loss: 18894.8535\n",
      "Epoch 3976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13206.1885 - val_loss: 18906.5078\n",
      "Epoch 3977/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13220.7148 - val_loss: 18902.0820\n",
      "Epoch 3978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13195.4258 - val_loss: 18895.1934\n",
      "Epoch 3979/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13173.2998 - val_loss: 18869.0078\n",
      "Epoch 3980/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13095.1572 - val_loss: 18828.3359\n",
      "Epoch 3981/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12977.0879 - val_loss: 18797.2656\n",
      "Epoch 3982/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12880.1992 - val_loss: 18775.7578\n",
      "Epoch 3983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12830.4863 - val_loss: 18782.7832\n",
      "Epoch 3984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12859.0684 - val_loss: 18755.2402\n",
      "Epoch 3985/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12772.2148 - val_loss: 18760.9727\n",
      "Epoch 3986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.6211 - val_loss: 18734.2676\n",
      "Epoch 3987/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12702.9287 - val_loss: 18793.7090\n",
      "Epoch 3988/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12922.1572 - val_loss: 18883.5059\n",
      "Epoch 3989/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13172.6006 - val_loss: 19079.6309\n",
      "Epoch 3990/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13784.0312 - val_loss: 19204.5762\n",
      "Epoch 3991/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14174.5146 - val_loss: 19248.4395\n",
      "Epoch 3992/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14311.1992 - val_loss: 19236.4473\n",
      "Epoch 3993/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14273.4648 - val_loss: 19216.6152\n",
      "Epoch 3994/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14210.2744 - val_loss: 19167.5254\n",
      "Epoch 3995/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14053.6680 - val_loss: 19123.7969\n",
      "Epoch 3996/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13897.1338 - val_loss: 19117.4551\n",
      "Epoch 3997/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13879.1914 - val_loss: 19127.2988\n",
      "Epoch 3998/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13910.2002 - val_loss: 19094.6484\n",
      "Epoch 3999/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13808.9219 - val_loss: 19030.7344\n",
      "Epoch 4000/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13609.9736 - val_loss: 18971.6445\n",
      "Epoch 4001/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13424.8262 - val_loss: 18938.7324\n",
      "Epoch 4002/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13334.1406 - val_loss: 18938.1250\n",
      "Epoch 4003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13336.4531 - val_loss: 18914.0137\n",
      "Epoch 4004/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13266.4922 - val_loss: 18884.6660\n",
      "Epoch 4005/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13176.7119 - val_loss: 18868.6035\n",
      "Epoch 4006/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13125.0059 - val_loss: 18879.4824\n",
      "Epoch 4007/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13144.0166 - val_loss: 18883.0254\n",
      "Epoch 4008/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13146.7002 - val_loss: 18866.5430\n",
      "Epoch 4009/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13095.1084 - val_loss: 18846.5117\n",
      "Epoch 4010/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13033.5283 - val_loss: 18802.9492\n",
      "Epoch 4011/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12897.5244 - val_loss: 18796.1816\n",
      "Epoch 4012/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12885.0264 - val_loss: 18775.9727\n",
      "Epoch 4013/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12835.1611 - val_loss: 18775.5410\n",
      "Epoch 4014/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12834.9082 - val_loss: 18781.9492\n",
      "Epoch 4015/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12855.1191 - val_loss: 18765.9395\n",
      "Epoch 4016/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12793.8652 - val_loss: 18776.6953\n",
      "Epoch 4017/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.8369 - val_loss: 18781.6230\n",
      "Epoch 4018/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12850.4287 - val_loss: 18840.9023\n",
      "Epoch 4019/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13039.3496 - val_loss: 18886.4805\n",
      "Epoch 4020/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13181.5068 - val_loss: 18910.5488\n",
      "Epoch 4021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13256.4844 - val_loss: 18914.0215\n",
      "Epoch 4022/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13254.6523 - val_loss: 18892.3535\n",
      "Epoch 4023/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13177.2100 - val_loss: 18863.5156\n",
      "Epoch 4024/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13087.7109 - val_loss: 18844.6562\n",
      "Epoch 4025/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13030.2783 - val_loss: 18830.9453\n",
      "Epoch 4026/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12986.2725 - val_loss: 18793.0723\n",
      "Epoch 4027/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12881.4980 - val_loss: 18817.3359\n",
      "Epoch 4028/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12965.1270 - val_loss: 18812.6992\n",
      "Epoch 4029/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12951.3164 - val_loss: 18789.5195\n",
      "Epoch 4030/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12873.1484 - val_loss: 18763.7773\n",
      "Epoch 4031/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12783.4277 - val_loss: 18780.6211\n",
      "Epoch 4032/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.9805 - val_loss: 18800.4355\n",
      "Epoch 4033/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12902.2148 - val_loss: 18788.3457\n",
      "Epoch 4034/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12874.0859 - val_loss: 18827.6621\n",
      "Epoch 4035/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12994.4355 - val_loss: 18821.5703\n",
      "Epoch 4036/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12963.4717 - val_loss: 18815.8066\n",
      "Epoch 4037/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12949.1748 - val_loss: 18817.3477\n",
      "Epoch 4038/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12946.0762 - val_loss: 18774.2109\n",
      "Epoch 4039/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12809.5938 - val_loss: 18742.6152\n",
      "Epoch 4040/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12709.8564 - val_loss: 18722.0664\n",
      "Epoch 4041/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.3623 - val_loss: 18713.5918\n",
      "Epoch 4042/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12629.3750 - val_loss: 18702.9199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4043/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12619.3252 - val_loss: 18719.0391\n",
      "Epoch 4044/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12658.0078 - val_loss: 18721.8828\n",
      "Epoch 4045/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.2061 - val_loss: 18750.9258\n",
      "Epoch 4046/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12752.2031 - val_loss: 18767.1152\n",
      "Epoch 4047/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.7256 - val_loss: 18746.4961\n",
      "Epoch 4048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.5000 - val_loss: 18740.1738\n",
      "Epoch 4049/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12702.7236 - val_loss: 18747.5820\n",
      "Epoch 4050/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.4229 - val_loss: 18706.2617\n",
      "Epoch 4051/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.9648 - val_loss: 18726.8906\n",
      "Epoch 4052/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.7832 - val_loss: 18748.0801\n",
      "Epoch 4053/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12746.5830 - val_loss: 18745.0938\n",
      "Epoch 4054/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12739.8135 - val_loss: 18762.5605\n",
      "Epoch 4055/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.0420 - val_loss: 18745.0859\n",
      "Epoch 4056/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.6924 - val_loss: 18749.8418\n",
      "Epoch 4057/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.6953 - val_loss: 18744.9609\n",
      "Epoch 4058/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12717.1992 - val_loss: 18745.0449\n",
      "Epoch 4059/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12716.4590 - val_loss: 18737.9883\n",
      "Epoch 4060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.6211 - val_loss: 18742.7148\n",
      "Epoch 4061/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12729.8174 - val_loss: 18810.9473\n",
      "Epoch 4062/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12944.0449 - val_loss: 18841.3945\n",
      "Epoch 4063/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13039.2412 - val_loss: 18826.8301\n",
      "Epoch 4064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12994.8867 - val_loss: 18796.4336\n",
      "Epoch 4065/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12900.6768 - val_loss: 18736.2168\n",
      "Epoch 4066/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.3486 - val_loss: 18781.2578\n",
      "Epoch 4067/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.8262 - val_loss: 18786.5996\n",
      "Epoch 4068/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.5137 - val_loss: 18797.1562\n",
      "Epoch 4069/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.4697 - val_loss: 18798.9121\n",
      "Epoch 4070/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12886.3945 - val_loss: 18774.0703\n",
      "Epoch 4071/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12809.3711 - val_loss: 18742.7324\n",
      "Epoch 4072/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.0186 - val_loss: 18724.7949\n",
      "Epoch 4073/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12667.0527 - val_loss: 18748.1055\n",
      "Epoch 4074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.4209 - val_loss: 18734.3301\n",
      "Epoch 4075/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12707.3115 - val_loss: 18739.8477\n",
      "Epoch 4076/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12774.4971 - val_loss: 18875.0938\n",
      "Epoch 4077/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13141.8311 - val_loss: 19019.0039\n",
      "Epoch 4078/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13583.5088 - val_loss: 19109.4336\n",
      "Epoch 4079/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13865.0439 - val_loss: 19115.3164\n",
      "Epoch 4080/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13895.1973 - val_loss: 19065.4355\n",
      "Epoch 4081/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13739.5176 - val_loss: 19036.1953\n",
      "Epoch 4082/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13640.7354 - val_loss: 19039.2207\n",
      "Epoch 4083/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13636.9678 - val_loss: 19046.5430\n",
      "Epoch 4084/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13659.9531 - val_loss: 18978.7246\n",
      "Epoch 4085/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13447.5645 - val_loss: 18881.5273\n",
      "Epoch 4086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13143.7666 - val_loss: 18812.9043\n",
      "Epoch 4087/10000\n",
      "630/630 [==============================] - 0s 27us/step - loss: 12929.2617 - val_loss: 18883.6641\n",
      "Epoch 4088/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13161.7031 - val_loss: 18941.6250\n",
      "Epoch 4089/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13351.4980 - val_loss: 18953.7812\n",
      "Epoch 4090/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13389.4434 - val_loss: 18932.0371\n",
      "Epoch 4091/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13321.1514 - val_loss: 18862.6660\n",
      "Epoch 4092/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13101.3740 - val_loss: 18810.3789\n",
      "Epoch 4093/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12922.8877 - val_loss: 18817.8457\n",
      "Epoch 4094/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12944.0283 - val_loss: 18822.3125\n",
      "Epoch 4095/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12958.6270 - val_loss: 18811.9004\n",
      "Epoch 4096/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12926.8750 - val_loss: 18780.5762\n",
      "Epoch 4097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12838.2148 - val_loss: 18786.9277\n",
      "Epoch 4098/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12868.7529 - val_loss: 18782.8555\n",
      "Epoch 4099/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.6797 - val_loss: 18764.6348\n",
      "Epoch 4100/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12798.5645 - val_loss: 18706.2598\n",
      "Epoch 4101/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.5986 - val_loss: 18711.0469\n",
      "Epoch 4102/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12614.5332 - val_loss: 18978.3555\n",
      "Epoch 4103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13529.5576 - val_loss: 19035.2695\n",
      "Epoch 4104/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13644.5732 - val_loss: 19391.1348\n",
      "Epoch 4105/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14755.0791 - val_loss: 19638.6172\n",
      "Epoch 4106/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15526.7803 - val_loss: 19772.3867\n",
      "Epoch 4107/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15943.9180 - val_loss: 19814.2305\n",
      "Epoch 4108/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16073.9189 - val_loss: 19831.8594\n",
      "Epoch 4109/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16129.3594 - val_loss: 19818.0273\n",
      "Epoch 4110/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16086.3350 - val_loss: 19765.7383\n",
      "Epoch 4111/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15924.0420 - val_loss: 19761.0566\n",
      "Epoch 4112/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15907.9980 - val_loss: 19730.2188\n",
      "Epoch 4113/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15812.3506 - val_loss: 19679.2461\n",
      "Epoch 4114/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15653.0996 - val_loss: 19598.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4115/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15401.4453 - val_loss: 19492.8184\n",
      "Epoch 4116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15071.4697 - val_loss: 19419.4355\n",
      "Epoch 4117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14822.4219 - val_loss: 19373.4980\n",
      "Epoch 4118/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14676.8369 - val_loss: 19332.5781\n",
      "Epoch 4119/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14551.4521 - val_loss: 19306.4336\n",
      "Epoch 4120/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14469.9043 - val_loss: 19304.7363\n",
      "Epoch 4121/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14465.1533 - val_loss: 19284.4648\n",
      "Epoch 4122/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14401.9307 - val_loss: 19239.4805\n",
      "Epoch 4123/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14261.1826 - val_loss: 19150.3301\n",
      "Epoch 4124/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13982.3535 - val_loss: 19035.9590\n",
      "Epoch 4125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13624.9854 - val_loss: 18974.7793\n",
      "Epoch 4126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13453.3027 - val_loss: 18975.2793\n",
      "Epoch 4127/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13457.6172 - val_loss: 19015.2637\n",
      "Epoch 4128/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13583.9678 - val_loss: 19034.2148\n",
      "Epoch 4129/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13642.4395 - val_loss: 19048.5645\n",
      "Epoch 4130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13686.5488 - val_loss: 19016.2891\n",
      "Epoch 4131/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13585.4121 - val_loss: 18961.6387\n",
      "Epoch 4132/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13412.7822 - val_loss: 18981.4336\n",
      "Epoch 4133/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13442.1064 - val_loss: 18994.0781\n",
      "Epoch 4134/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13481.4873 - val_loss: 18936.2578\n",
      "Epoch 4135/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13313.0723 - val_loss: 18899.3574\n",
      "Epoch 4136/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13199.6279 - val_loss: 18866.2285\n",
      "Epoch 4137/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13096.2344 - val_loss: 18826.5586\n",
      "Epoch 4138/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12981.5400 - val_loss: 18791.1484\n",
      "Epoch 4139/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12885.3301 - val_loss: 18816.2852\n",
      "Epoch 4140/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12962.8193 - val_loss: 18840.4082\n",
      "Epoch 4141/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13037.7275 - val_loss: 18848.4980\n",
      "Epoch 4142/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13053.9033 - val_loss: 18811.3066\n",
      "Epoch 4143/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12926.3760 - val_loss: 18728.1523\n",
      "Epoch 4144/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12664.9609 - val_loss: 18706.6895\n",
      "Epoch 4145/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.9131 - val_loss: 18739.4531\n",
      "Epoch 4146/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.8398 - val_loss: 18757.2949\n",
      "Epoch 4147/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.5000 - val_loss: 18902.5527\n",
      "Epoch 4148/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13219.7686 - val_loss: 19054.7520\n",
      "Epoch 4149/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13689.0283 - val_loss: 19139.9902\n",
      "Epoch 4150/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13952.4912 - val_loss: 19162.2188\n",
      "Epoch 4151/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14021.0625 - val_loss: 19133.5742\n",
      "Epoch 4152/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13934.9424 - val_loss: 19083.7383\n",
      "Epoch 4153/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13784.3662 - val_loss: 19042.4395\n",
      "Epoch 4154/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13667.0293 - val_loss: 19025.6250\n",
      "Epoch 4155/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13616.7744 - val_loss: 19002.5957\n",
      "Epoch 4156/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13522.9551 - val_loss: 18946.4473\n",
      "Epoch 4157/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13346.9023 - val_loss: 18909.2910\n",
      "Epoch 4158/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13231.4385 - val_loss: 18918.2383\n",
      "Epoch 4159/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13259.2832 - val_loss: 18888.2500\n",
      "Epoch 4160/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13165.7441 - val_loss: 18864.3711\n",
      "Epoch 4161/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13088.5156 - val_loss: 18839.7012\n",
      "Epoch 4162/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13014.3369 - val_loss: 18852.0762\n",
      "Epoch 4163/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13067.8564 - val_loss: 18851.0645\n",
      "Epoch 4164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13077.3740 - val_loss: 18822.3652\n",
      "Epoch 4165/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12981.6924 - val_loss: 18804.9883\n",
      "Epoch 4166/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12926.3584 - val_loss: 18770.2949\n",
      "Epoch 4167/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12817.9023 - val_loss: 18759.2812\n",
      "Epoch 4168/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12779.9404 - val_loss: 18758.4336\n",
      "Epoch 4169/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12760.6768 - val_loss: 18740.2734\n",
      "Epoch 4170/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.7051 - val_loss: 18732.3379\n",
      "Epoch 4171/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.0078 - val_loss: 18738.2539\n",
      "Epoch 4172/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12703.1152 - val_loss: 18730.6621\n",
      "Epoch 4173/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12683.7217 - val_loss: 18736.5938\n",
      "Epoch 4174/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.0469 - val_loss: 18738.0820\n",
      "Epoch 4175/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12717.0605 - val_loss: 18736.7559\n",
      "Epoch 4176/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12713.2764 - val_loss: 18720.6094\n",
      "Epoch 4177/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.4238 - val_loss: 18723.0605\n",
      "Epoch 4178/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12660.1045 - val_loss: 18717.9570\n",
      "Epoch 4179/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12633.8779 - val_loss: 18716.2832\n",
      "Epoch 4180/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12627.3887 - val_loss: 18707.5781\n",
      "Epoch 4181/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12600.3125 - val_loss: 18706.1230\n",
      "Epoch 4182/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12599.8848 - val_loss: 18696.3770\n",
      "Epoch 4183/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.8086 - val_loss: 18686.8242\n",
      "Epoch 4184/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.1973 - val_loss: 18705.3242\n",
      "Epoch 4185/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12636.3359 - val_loss: 18734.0371\n",
      "Epoch 4186/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12707.2578 - val_loss: 18750.7910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4187/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.7832 - val_loss: 18743.7500\n",
      "Epoch 4188/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12738.9688 - val_loss: 18748.0254\n",
      "Epoch 4189/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12743.0264 - val_loss: 18774.3984\n",
      "Epoch 4190/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12810.1816 - val_loss: 18761.6953\n",
      "Epoch 4191/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12770.4980 - val_loss: 18742.8984\n",
      "Epoch 4192/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.5283 - val_loss: 18741.1348\n",
      "Epoch 4193/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12714.2100 - val_loss: 18709.3887\n",
      "Epoch 4194/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12622.6201 - val_loss: 18723.0664\n",
      "Epoch 4195/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12671.6426 - val_loss: 18731.8926\n",
      "Epoch 4196/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12700.3252 - val_loss: 18741.1934\n",
      "Epoch 4197/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.4639 - val_loss: 18728.8477\n",
      "Epoch 4198/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.5830 - val_loss: 18731.3535\n",
      "Epoch 4199/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12694.5557 - val_loss: 18716.3867\n",
      "Epoch 4200/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12629.4209 - val_loss: 18725.8086\n",
      "Epoch 4201/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.1133 - val_loss: 18723.2109\n",
      "Epoch 4202/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.5869 - val_loss: 18745.4883\n",
      "Epoch 4203/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.0264 - val_loss: 18755.7598\n",
      "Epoch 4204/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12757.3672 - val_loss: 18723.5625\n",
      "Epoch 4205/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.3428 - val_loss: 18707.6348\n",
      "Epoch 4206/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12612.9219 - val_loss: 18709.8848\n",
      "Epoch 4207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12615.3037 - val_loss: 18729.8750\n",
      "Epoch 4208/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.5615 - val_loss: 18729.8125\n",
      "Epoch 4209/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.8047 - val_loss: 18703.5137\n",
      "Epoch 4210/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12601.0498 - val_loss: 18703.6465\n",
      "Epoch 4211/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.7207 - val_loss: 18702.5938\n",
      "Epoch 4212/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12600.1582 - val_loss: 18723.7031\n",
      "Epoch 4213/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12665.2646 - val_loss: 18733.2363\n",
      "Epoch 4214/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12692.3223 - val_loss: 18712.7344\n",
      "Epoch 4215/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12624.8506 - val_loss: 18679.0879\n",
      "Epoch 4216/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12514.3545 - val_loss: 18679.5762\n",
      "Epoch 4217/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12514.2061 - val_loss: 18710.5469\n",
      "Epoch 4218/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12615.8887 - val_loss: 18688.1973\n",
      "Epoch 4219/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12557.5566 - val_loss: 18690.2949\n",
      "Epoch 4220/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.9980 - val_loss: 18702.1309\n",
      "Epoch 4221/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.7891 - val_loss: 18696.1016\n",
      "Epoch 4222/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12582.5039 - val_loss: 18676.7246\n",
      "Epoch 4223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12517.4023 - val_loss: 18720.8477\n",
      "Epoch 4224/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12716.6875 - val_loss: 18994.0605\n",
      "Epoch 4225/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13515.5557 - val_loss: 19278.9414\n",
      "Epoch 4226/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14403.7812 - val_loss: 19476.6191\n",
      "Epoch 4227/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15020.6348 - val_loss: 19584.1367\n",
      "Epoch 4228/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15354.7979 - val_loss: 19637.6523\n",
      "Epoch 4229/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15521.9648 - val_loss: 19640.0176\n",
      "Epoch 4230/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15529.9629 - val_loss: 19619.0762\n",
      "Epoch 4231/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15466.9775 - val_loss: 19554.4590\n",
      "Epoch 4232/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15263.6855 - val_loss: 19485.2129\n",
      "Epoch 4233/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15046.8613 - val_loss: 19438.7422\n",
      "Epoch 4234/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14900.6875 - val_loss: 19373.0059\n",
      "Epoch 4235/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14696.1895 - val_loss: 19288.1836\n",
      "Epoch 4236/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14412.4365 - val_loss: 19308.1543\n",
      "Epoch 4237/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14474.1270 - val_loss: 19318.6211\n",
      "Epoch 4238/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14507.0762 - val_loss: 19261.4746\n",
      "Epoch 4239/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14329.0283 - val_loss: 19208.5469\n",
      "Epoch 4240/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14165.0781 - val_loss: 19166.6230\n",
      "Epoch 4241/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14034.7422 - val_loss: 19188.0352\n",
      "Epoch 4242/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14101.4785 - val_loss: 19164.8418\n",
      "Epoch 4243/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14028.7002 - val_loss: 19118.2051\n",
      "Epoch 4244/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13900.3262 - val_loss: 19042.7891\n",
      "Epoch 4245/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13666.4160 - val_loss: 19021.7520\n",
      "Epoch 4246/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13603.0049 - val_loss: 19011.5098\n",
      "Epoch 4247/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13569.6182 - val_loss: 19000.1250\n",
      "Epoch 4248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13534.1982 - val_loss: 19004.3203\n",
      "Epoch 4249/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13544.4688 - val_loss: 19005.1289\n",
      "Epoch 4250/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13535.4551 - val_loss: 18984.4023\n",
      "Epoch 4251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13466.4775 - val_loss: 18933.6855\n",
      "Epoch 4252/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13309.2285 - val_loss: 18940.2891\n",
      "Epoch 4253/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13329.6309 - val_loss: 18957.5215\n",
      "Epoch 4254/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13382.0596 - val_loss: 18931.9375\n",
      "Epoch 4255/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13302.9902 - val_loss: 18894.0449\n",
      "Epoch 4256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13201.9961 - val_loss: 18832.8066\n",
      "Epoch 4257/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13013.3682 - val_loss: 18825.3086\n",
      "Epoch 4258/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12986.3379 - val_loss: 18812.8184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4259/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12950.3145 - val_loss: 18800.3340\n",
      "Epoch 4260/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.0430 - val_loss: 18806.2617\n",
      "Epoch 4261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12910.7021 - val_loss: 18812.4297\n",
      "Epoch 4262/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12931.5928 - val_loss: 18780.5352\n",
      "Epoch 4263/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12831.1035 - val_loss: 18724.0234\n",
      "Epoch 4264/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12654.8281 - val_loss: 18732.3945\n",
      "Epoch 4265/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12706.5127 - val_loss: 18732.3320\n",
      "Epoch 4266/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12700.9482 - val_loss: 18787.8672\n",
      "Epoch 4267/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12870.7998 - val_loss: 18766.7129\n",
      "Epoch 4268/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.8340 - val_loss: 18771.6777\n",
      "Epoch 4269/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12822.0684 - val_loss: 18753.4805\n",
      "Epoch 4270/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12766.1875 - val_loss: 18763.0918\n",
      "Epoch 4271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12781.8574 - val_loss: 18751.7266\n",
      "Epoch 4272/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12740.7324 - val_loss: 18708.6289\n",
      "Epoch 4273/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12620.8457 - val_loss: 18723.8594\n",
      "Epoch 4274/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.1465 - val_loss: 18771.0449\n",
      "Epoch 4275/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12806.1572 - val_loss: 18797.5449\n",
      "Epoch 4276/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12902.9326 - val_loss: 18763.1250\n",
      "Epoch 4277/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12796.8936 - val_loss: 18716.5781\n",
      "Epoch 4278/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12649.8994 - val_loss: 18720.8242\n",
      "Epoch 4279/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12652.5410 - val_loss: 18754.9062\n",
      "Epoch 4280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12749.3359 - val_loss: 18764.6582\n",
      "Epoch 4281/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12779.9668 - val_loss: 18725.9375\n",
      "Epoch 4282/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12659.4336 - val_loss: 18699.8887\n",
      "Epoch 4283/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.5898 - val_loss: 18700.8496\n",
      "Epoch 4284/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12601.2168 - val_loss: 18706.5723\n",
      "Epoch 4285/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.1943 - val_loss: 18705.6133\n",
      "Epoch 4286/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12618.3516 - val_loss: 18709.5000\n",
      "Epoch 4287/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12619.0303 - val_loss: 18684.4219\n",
      "Epoch 4288/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12535.9355 - val_loss: 18675.9102\n",
      "Epoch 4289/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12505.8037 - val_loss: 18691.9453\n",
      "Epoch 4290/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12559.5205 - val_loss: 18690.1816\n",
      "Epoch 4291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.1602 - val_loss: 18685.8184\n",
      "Epoch 4292/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12548.3320 - val_loss: 18696.5625\n",
      "Epoch 4293/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12583.5049 - val_loss: 18703.1465\n",
      "Epoch 4294/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12602.3477 - val_loss: 18700.8750\n",
      "Epoch 4295/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12587.7100 - val_loss: 18697.6719\n",
      "Epoch 4296/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12574.8965 - val_loss: 18679.7734\n",
      "Epoch 4297/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12521.6348 - val_loss: 18703.8164\n",
      "Epoch 4298/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12599.9756 - val_loss: 18690.1699\n",
      "Epoch 4299/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12562.8174 - val_loss: 18674.9141\n",
      "Epoch 4300/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.1572 - val_loss: 18672.5527\n",
      "Epoch 4301/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.4922 - val_loss: 18688.9727\n",
      "Epoch 4302/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.8623 - val_loss: 18698.2520\n",
      "Epoch 4303/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12579.4297 - val_loss: 18696.9219\n",
      "Epoch 4304/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12569.4209 - val_loss: 18687.7422\n",
      "Epoch 4305/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12542.6934 - val_loss: 18676.5176\n",
      "Epoch 4306/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12512.8154 - val_loss: 18680.9902\n",
      "Epoch 4307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.3047 - val_loss: 18691.8418\n",
      "Epoch 4308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12567.2178 - val_loss: 18696.9570\n",
      "Epoch 4309/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12587.6572 - val_loss: 18714.9180\n",
      "Epoch 4310/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12639.3047 - val_loss: 18724.9824\n",
      "Epoch 4311/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.4111 - val_loss: 18696.6328\n",
      "Epoch 4312/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12567.9209 - val_loss: 18702.3457\n",
      "Epoch 4313/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.2168 - val_loss: 18724.9688\n",
      "Epoch 4314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.9170 - val_loss: 18730.2578\n",
      "Epoch 4315/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12690.8525 - val_loss: 18737.6543\n",
      "Epoch 4316/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12714.4160 - val_loss: 18736.0820\n",
      "Epoch 4317/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12710.6074 - val_loss: 18748.7500\n",
      "Epoch 4318/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.9688 - val_loss: 18731.5977\n",
      "Epoch 4319/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.2637 - val_loss: 18711.8867\n",
      "Epoch 4320/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12615.7725 - val_loss: 18842.9707\n",
      "Epoch 4321/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13118.0088 - val_loss: 19042.8535\n",
      "Epoch 4322/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13667.7754 - val_loss: 19439.2891\n",
      "Epoch 4323/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14904.2305 - val_loss: 19717.5273\n",
      "Epoch 4324/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15771.7021 - val_loss: 19894.4043\n",
      "Epoch 4325/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16323.1846 - val_loss: 19987.8867\n",
      "Epoch 4326/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16616.0020 - val_loss: 19989.3164\n",
      "Epoch 4327/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16620.5430 - val_loss: 19952.8281\n",
      "Epoch 4328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16506.9238 - val_loss: 19926.0527\n",
      "Epoch 4329/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16423.3652 - val_loss: 19831.0332\n",
      "Epoch 4330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16127.0977 - val_loss: 19687.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4331/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15678.0303 - val_loss: 19614.9629\n",
      "Epoch 4332/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15443.2109 - val_loss: 19563.0938\n",
      "Epoch 4333/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15287.6182 - val_loss: 19590.1094\n",
      "Epoch 4334/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15353.7363 - val_loss: 19616.1699\n",
      "Epoch 4335/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15433.8809 - val_loss: 19572.9609\n",
      "Epoch 4336/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15299.6494 - val_loss: 19490.9980\n",
      "Epoch 4337/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15044.1416 - val_loss: 19403.8848\n",
      "Epoch 4338/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14773.2500 - val_loss: 19284.8262\n",
      "Epoch 4339/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14404.4434 - val_loss: 19207.0371\n",
      "Epoch 4340/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14165.4648 - val_loss: 19183.7793\n",
      "Epoch 4341/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14092.4746 - val_loss: 19137.3555\n",
      "Epoch 4342/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13950.4521 - val_loss: 19135.7734\n",
      "Epoch 4343/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13958.1348 - val_loss: 19113.1074\n",
      "Epoch 4344/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13887.1494 - val_loss: 19102.2480\n",
      "Epoch 4345/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13851.3652 - val_loss: 19069.3340\n",
      "Epoch 4346/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13747.4648 - val_loss: 19096.3711\n",
      "Epoch 4347/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13830.1836 - val_loss: 19100.5508\n",
      "Epoch 4348/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13818.4482 - val_loss: 19042.7734\n",
      "Epoch 4349/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13643.8770 - val_loss: 18994.0625\n",
      "Epoch 4350/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13495.2695 - val_loss: 18987.1836\n",
      "Epoch 4351/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13475.1221 - val_loss: 18944.1836\n",
      "Epoch 4352/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13346.4355 - val_loss: 18915.2305\n",
      "Epoch 4353/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13270.0615 - val_loss: 18923.4609\n",
      "Epoch 4354/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13296.2246 - val_loss: 18867.5039\n",
      "Epoch 4355/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13119.6240 - val_loss: 18874.9316\n",
      "Epoch 4356/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13130.9873 - val_loss: 18865.7031\n",
      "Epoch 4357/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13097.8623 - val_loss: 18839.6855\n",
      "Epoch 4358/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13016.0381 - val_loss: 18788.8887\n",
      "Epoch 4359/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12858.4590 - val_loss: 18759.4688\n",
      "Epoch 4360/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.3916 - val_loss: 18760.7363\n",
      "Epoch 4361/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12784.7109 - val_loss: 18780.4707\n",
      "Epoch 4362/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12848.8730 - val_loss: 18782.7637\n",
      "Epoch 4363/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.0703 - val_loss: 18780.4727\n",
      "Epoch 4364/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12832.1074 - val_loss: 18886.2285\n",
      "Epoch 4365/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13244.0684 - val_loss: 19025.0586\n",
      "Epoch 4366/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13614.4678 - val_loss: 19332.0234\n",
      "Epoch 4367/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14571.7988 - val_loss: 19554.0898\n",
      "Epoch 4368/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15264.4248 - val_loss: 19695.9316\n",
      "Epoch 4369/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15707.3271 - val_loss: 19755.6484\n",
      "Epoch 4370/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15892.6104 - val_loss: 19748.5840\n",
      "Epoch 4371/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15870.2188 - val_loss: 19718.7461\n",
      "Epoch 4372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15777.0039 - val_loss: 19643.6816\n",
      "Epoch 4373/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15543.6758 - val_loss: 19640.2559\n",
      "Epoch 4374/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15531.3027 - val_loss: 19650.9473\n",
      "Epoch 4375/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15563.5117 - val_loss: 19600.0684\n",
      "Epoch 4376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15404.8340 - val_loss: 19532.5996\n",
      "Epoch 4377/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15190.8193 - val_loss: 19522.1816\n",
      "Epoch 4378/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15143.8164 - val_loss: 19481.1582\n",
      "Epoch 4379/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15015.8760 - val_loss: 19408.9102\n",
      "Epoch 4380/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14790.5000 - val_loss: 19350.6836\n",
      "Epoch 4381/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14610.5420 - val_loss: 19312.6074\n",
      "Epoch 4382/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14492.8613 - val_loss: 19257.4668\n",
      "Epoch 4383/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14322.7236 - val_loss: 19192.9414\n",
      "Epoch 4384/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14118.3682 - val_loss: 19110.0469\n",
      "Epoch 4385/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13859.1357 - val_loss: 19063.5742\n",
      "Epoch 4386/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13726.6982 - val_loss: 19048.9766\n",
      "Epoch 4387/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13684.4609 - val_loss: 19011.1562\n",
      "Epoch 4388/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13567.1523 - val_loss: 18987.5859\n",
      "Epoch 4389/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13493.5811 - val_loss: 18967.4844\n",
      "Epoch 4390/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13431.8809 - val_loss: 18973.3672\n",
      "Epoch 4391/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13450.6846 - val_loss: 18928.2148\n",
      "Epoch 4392/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13308.9209 - val_loss: 18907.6055\n",
      "Epoch 4393/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13225.8652 - val_loss: 18881.5000\n",
      "Epoch 4394/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13144.9609 - val_loss: 18893.5957\n",
      "Epoch 4395/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13185.6758 - val_loss: 18906.9062\n",
      "Epoch 4396/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13227.4658 - val_loss: 18898.2969\n",
      "Epoch 4397/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13198.5576 - val_loss: 18873.8555\n",
      "Epoch 4398/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13131.7627 - val_loss: 18843.6406\n",
      "Epoch 4399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13043.9961 - val_loss: 18806.1914\n",
      "Epoch 4400/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12930.5625 - val_loss: 18739.7090\n",
      "Epoch 4401/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12724.6846 - val_loss: 18718.7266\n",
      "Epoch 4402/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.0840 - val_loss: 18768.0195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12856.9316 - val_loss: 18953.7578\n",
      "Epoch 4404/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13393.3848 - val_loss: 19188.3887\n",
      "Epoch 4405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14125.3574 - val_loss: 19343.4297\n",
      "Epoch 4406/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14610.7627 - val_loss: 19430.7168\n",
      "Epoch 4407/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14881.3984 - val_loss: 19445.8535\n",
      "Epoch 4408/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14926.1465 - val_loss: 19441.8828\n",
      "Epoch 4409/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14914.5117 - val_loss: 19412.6641\n",
      "Epoch 4410/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14823.1533 - val_loss: 19400.6660\n",
      "Epoch 4411/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14784.4873 - val_loss: 19382.9199\n",
      "Epoch 4412/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14729.8564 - val_loss: 19403.4043\n",
      "Epoch 4413/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14771.3584 - val_loss: 19413.1738\n",
      "Epoch 4414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14803.0430 - val_loss: 19377.8359\n",
      "Epoch 4415/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14694.3115 - val_loss: 19362.0625\n",
      "Epoch 4416/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14644.9971 - val_loss: 19321.5469\n",
      "Epoch 4417/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14518.0527 - val_loss: 19298.9082\n",
      "Epoch 4418/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14447.7188 - val_loss: 19255.7676\n",
      "Epoch 4419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14316.5508 - val_loss: 19212.4082\n",
      "Epoch 4420/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14196.7666 - val_loss: 19175.7090\n",
      "Epoch 4421/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14084.7539 - val_loss: 19154.0352\n",
      "Epoch 4422/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14014.3701 - val_loss: 19121.3086\n",
      "Epoch 4423/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13912.5430 - val_loss: 19090.3184\n",
      "Epoch 4424/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13815.8652 - val_loss: 19054.4258\n",
      "Epoch 4425/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13705.4658 - val_loss: 19044.9238\n",
      "Epoch 4426/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13660.8115 - val_loss: 19031.8613\n",
      "Epoch 4427/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13616.6816 - val_loss: 19020.2188\n",
      "Epoch 4428/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13580.8896 - val_loss: 18953.4121\n",
      "Epoch 4429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13370.6738 - val_loss: 18917.0430\n",
      "Epoch 4430/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13254.9092 - val_loss: 18901.1250\n",
      "Epoch 4431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13224.1738 - val_loss: 18859.7324\n",
      "Epoch 4432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13098.6260 - val_loss: 18840.6797\n",
      "Epoch 4433/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13038.2197 - val_loss: 18767.1094\n",
      "Epoch 4434/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12810.6475 - val_loss: 18700.1270\n",
      "Epoch 4435/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12585.7725 - val_loss: 18705.4512\n",
      "Epoch 4436/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.0684 - val_loss: 18879.5371\n",
      "Epoch 4437/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13198.3076 - val_loss: 19057.4844\n",
      "Epoch 4438/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13718.4736 - val_loss: 19390.4395\n",
      "Epoch 4439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14757.0938 - val_loss: 19641.7832\n",
      "Epoch 4440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15541.0010 - val_loss: 19799.2520\n",
      "Epoch 4441/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 16031.3604 - val_loss: 19875.0645\n",
      "Epoch 4442/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 16267.6211 - val_loss: 19923.7148\n",
      "Epoch 4443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16419.4414 - val_loss: 19898.8359\n",
      "Epoch 4444/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16341.9189 - val_loss: 19834.5410\n",
      "Epoch 4445/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16140.4814 - val_loss: 19770.8438\n",
      "Epoch 4446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15941.4717 - val_loss: 19673.1582\n",
      "Epoch 4447/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15626.2090 - val_loss: 19600.7656\n",
      "Epoch 4448/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15399.2754 - val_loss: 19550.0039\n",
      "Epoch 4449/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15235.4766 - val_loss: 19471.3770\n",
      "Epoch 4450/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14990.7207 - val_loss: 19399.4473\n",
      "Epoch 4451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14764.1377 - val_loss: 19344.5293\n",
      "Epoch 4452/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14589.3496 - val_loss: 19357.2812\n",
      "Epoch 4453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14628.7822 - val_loss: 19336.9492\n",
      "Epoch 4454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14564.6992 - val_loss: 19283.1562\n",
      "Epoch 4455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14397.8984 - val_loss: 19240.7461\n",
      "Epoch 4456/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14267.4277 - val_loss: 19204.5371\n",
      "Epoch 4457/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14172.5107 - val_loss: 19156.3262\n",
      "Epoch 4458/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14022.1729 - val_loss: 19042.6992\n",
      "Epoch 4459/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13667.9580 - val_loss: 18931.5645\n",
      "Epoch 4460/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13320.1572 - val_loss: 18909.1465\n",
      "Epoch 4461/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13253.5908 - val_loss: 18933.3809\n",
      "Epoch 4462/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13329.6123 - val_loss: 18939.4004\n",
      "Epoch 4463/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13329.1543 - val_loss: 18967.2168\n",
      "Epoch 4464/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13416.2061 - val_loss: 18936.8398\n",
      "Epoch 4465/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13320.9619 - val_loss: 18886.6016\n",
      "Epoch 4466/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13164.4170 - val_loss: 18873.0801\n",
      "Epoch 4467/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13120.4775 - val_loss: 18869.5078\n",
      "Epoch 4468/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13116.1182 - val_loss: 18856.5352\n",
      "Epoch 4469/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13075.6172 - val_loss: 18845.8125\n",
      "Epoch 4470/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13052.0469 - val_loss: 18800.1230\n",
      "Epoch 4471/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12909.8027 - val_loss: 18777.9375\n",
      "Epoch 4472/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12839.3799 - val_loss: 18765.6270\n",
      "Epoch 4473/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12787.3418 - val_loss: 18753.5703\n",
      "Epoch 4474/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.8818 - val_loss: 18740.5859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4475/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12708.3545 - val_loss: 18744.8496\n",
      "Epoch 4476/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12721.1182 - val_loss: 18753.6543\n",
      "Epoch 4477/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12766.1406 - val_loss: 18748.9707\n",
      "Epoch 4478/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12754.8584 - val_loss: 18951.4316\n",
      "Epoch 4479/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13444.6240 - val_loss: 19046.1348\n",
      "Epoch 4480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13684.5205 - val_loss: 19361.6055\n",
      "Epoch 4481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14667.3867 - val_loss: 19577.8047\n",
      "Epoch 4482/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15341.8770 - val_loss: 19692.6152\n",
      "Epoch 4483/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15699.9473 - val_loss: 19733.6582\n",
      "Epoch 4484/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15828.8574 - val_loss: 19714.5215\n",
      "Epoch 4485/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15768.4336 - val_loss: 19683.6289\n",
      "Epoch 4486/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15672.9668 - val_loss: 19625.1484\n",
      "Epoch 4487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15490.4746 - val_loss: 19595.9551\n",
      "Epoch 4488/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15378.0225 - val_loss: 19563.3672\n",
      "Epoch 4489/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15274.8770 - val_loss: 19501.8203\n",
      "Epoch 4490/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15083.4951 - val_loss: 19454.3301\n",
      "Epoch 4491/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14935.3281 - val_loss: 19391.8848\n",
      "Epoch 4492/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14740.0645 - val_loss: 19359.1309\n",
      "Epoch 4493/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14632.8740 - val_loss: 19339.6172\n",
      "Epoch 4494/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14574.0254 - val_loss: 19324.1914\n",
      "Epoch 4495/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14544.2490 - val_loss: 19337.8945\n",
      "Epoch 4496/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14589.5029 - val_loss: 19310.5293\n",
      "Epoch 4497/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14505.6465 - val_loss: 19253.5156\n",
      "Epoch 4498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14329.1807 - val_loss: 19216.4160\n",
      "Epoch 4499/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14210.9521 - val_loss: 19129.1816\n",
      "Epoch 4500/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13925.7285 - val_loss: 19034.3809\n",
      "Epoch 4501/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13623.0625 - val_loss: 18980.8320\n",
      "Epoch 4502/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13458.6191 - val_loss: 18965.1348\n",
      "Epoch 4503/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13412.7998 - val_loss: 18980.7949\n",
      "Epoch 4504/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13457.9385 - val_loss: 18966.4160\n",
      "Epoch 4505/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13415.9326 - val_loss: 18968.9219\n",
      "Epoch 4506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13437.1875 - val_loss: 18964.6172\n",
      "Epoch 4507/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13426.5488 - val_loss: 18927.5293\n",
      "Epoch 4508/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13312.3018 - val_loss: 18913.5977\n",
      "Epoch 4509/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13252.2979 - val_loss: 18913.7539\n",
      "Epoch 4510/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13244.5049 - val_loss: 18921.6719\n",
      "Epoch 4511/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13266.4199 - val_loss: 18901.5820\n",
      "Epoch 4512/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13207.0986 - val_loss: 18861.2129\n",
      "Epoch 4513/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13089.8652 - val_loss: 18817.7520\n",
      "Epoch 4514/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12964.6270 - val_loss: 18793.1250\n",
      "Epoch 4515/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12891.3574 - val_loss: 18761.0371\n",
      "Epoch 4516/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.3701 - val_loss: 18758.0000\n",
      "Epoch 4517/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.3037 - val_loss: 18769.5938\n",
      "Epoch 4518/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12790.0977 - val_loss: 18760.3691\n",
      "Epoch 4519/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12773.0713 - val_loss: 18748.3047\n",
      "Epoch 4520/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.6299 - val_loss: 18760.3770\n",
      "Epoch 4521/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12781.2539 - val_loss: 18797.5410\n",
      "Epoch 4522/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12912.1592 - val_loss: 18839.9043\n",
      "Epoch 4523/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13031.1074 - val_loss: 18973.1094\n",
      "Epoch 4524/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13447.2529 - val_loss: 19052.2031\n",
      "Epoch 4525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13694.8770 - val_loss: 19068.0527\n",
      "Epoch 4526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13742.8564 - val_loss: 19058.0039\n",
      "Epoch 4527/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13722.4971 - val_loss: 19002.0000\n",
      "Epoch 4528/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13546.7227 - val_loss: 18924.8516\n",
      "Epoch 4529/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13285.9033 - val_loss: 18906.2070\n",
      "Epoch 4530/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13225.6455 - val_loss: 18941.4141\n",
      "Epoch 4531/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13321.4014 - val_loss: 18965.9453\n",
      "Epoch 4532/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13397.8535 - val_loss: 18923.6973\n",
      "Epoch 4533/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13265.2451 - val_loss: 18877.7129\n",
      "Epoch 4534/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13126.8516 - val_loss: 18835.5566\n",
      "Epoch 4535/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13007.8379 - val_loss: 18813.6855\n",
      "Epoch 4536/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12956.2070 - val_loss: 18795.6211\n",
      "Epoch 4537/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12897.0498 - val_loss: 18789.3359\n",
      "Epoch 4538/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.2266 - val_loss: 18799.9473\n",
      "Epoch 4539/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12910.6191 - val_loss: 18821.5684\n",
      "Epoch 4540/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12965.7100 - val_loss: 18839.5352\n",
      "Epoch 4541/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13038.2373 - val_loss: 18832.6309\n",
      "Epoch 4542/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13006.2100 - val_loss: 18988.3887\n",
      "Epoch 4543/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13506.1309 - val_loss: 19069.5566\n",
      "Epoch 4544/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13758.6914 - val_loss: 19082.4551\n",
      "Epoch 4545/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13798.2539 - val_loss: 19093.8965\n",
      "Epoch 4546/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13820.8438 - val_loss: 19071.4629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4547/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13743.6426 - val_loss: 19014.1113\n",
      "Epoch 4548/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13564.8779 - val_loss: 18994.2305\n",
      "Epoch 4549/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13498.8711 - val_loss: 18981.5938\n",
      "Epoch 4550/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13462.1416 - val_loss: 18985.6230\n",
      "Epoch 4551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13485.7139 - val_loss: 18981.9727\n",
      "Epoch 4552/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13478.6504 - val_loss: 18951.4141\n",
      "Epoch 4553/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13383.4385 - val_loss: 18886.9277\n",
      "Epoch 4554/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13174.1387 - val_loss: 18846.0273\n",
      "Epoch 4555/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13042.6973 - val_loss: 18818.9883\n",
      "Epoch 4556/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12952.5459 - val_loss: 18763.3027\n",
      "Epoch 4557/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.9941 - val_loss: 18714.5703\n",
      "Epoch 4558/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12637.3135 - val_loss: 18726.0254\n",
      "Epoch 4559/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12673.2559 - val_loss: 19174.8223\n",
      "Epoch 4560/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14137.0127 - val_loss: 18991.8984\n",
      "Epoch 4561/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13514.8291 - val_loss: 19277.5488\n",
      "Epoch 4562/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14406.2578 - val_loss: 19477.7910\n",
      "Epoch 4563/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15031.7197 - val_loss: 19611.3828\n",
      "Epoch 4564/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15446.9131 - val_loss: 19689.8633\n",
      "Epoch 4565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15690.9219 - val_loss: 19719.4121\n",
      "Epoch 4566/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15783.9404 - val_loss: 19733.3965\n",
      "Epoch 4567/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15825.1104 - val_loss: 19729.0820\n",
      "Epoch 4568/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15811.7383 - val_loss: 19688.3730\n",
      "Epoch 4569/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15685.2334 - val_loss: 19652.9727\n",
      "Epoch 4570/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15565.6602 - val_loss: 19587.9844\n",
      "Epoch 4571/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15353.6055 - val_loss: 19527.7129\n",
      "Epoch 4572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15168.4746 - val_loss: 19447.1992\n",
      "Epoch 4573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14918.2373 - val_loss: 19332.5547\n",
      "Epoch 4574/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14559.4434 - val_loss: 19223.7363\n",
      "Epoch 4575/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14217.5234 - val_loss: 19169.0332\n",
      "Epoch 4576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14047.4834 - val_loss: 19097.0059\n",
      "Epoch 4577/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13822.8516 - val_loss: 19042.2422\n",
      "Epoch 4578/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13662.1650 - val_loss: 19068.4043\n",
      "Epoch 4579/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13748.1924 - val_loss: 19047.4531\n",
      "Epoch 4580/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13682.6074 - val_loss: 19007.8203\n",
      "Epoch 4581/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13557.0820 - val_loss: 18990.0840\n",
      "Epoch 4582/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13498.9561 - val_loss: 18973.3828\n",
      "Epoch 4583/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13445.3760 - val_loss: 18963.8652\n",
      "Epoch 4584/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13402.0566 - val_loss: 18962.8574\n",
      "Epoch 4585/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13400.5059 - val_loss: 18956.2461\n",
      "Epoch 4586/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13381.7305 - val_loss: 18939.8379\n",
      "Epoch 4587/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13329.9316 - val_loss: 18907.8281\n",
      "Epoch 4588/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13228.6094 - val_loss: 18875.5371\n",
      "Epoch 4589/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13145.5010 - val_loss: 18824.4746\n",
      "Epoch 4590/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12988.0420 - val_loss: 18860.2188\n",
      "Epoch 4591/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13098.3252 - val_loss: 18865.6172\n",
      "Epoch 4592/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13110.9492 - val_loss: 18830.5176\n",
      "Epoch 4593/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12993.2568 - val_loss: 18791.1953\n",
      "Epoch 4594/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12868.7051 - val_loss: 18763.7246\n",
      "Epoch 4595/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12785.2363 - val_loss: 18742.7324\n",
      "Epoch 4596/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12720.7656 - val_loss: 18729.9277\n",
      "Epoch 4597/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12677.3223 - val_loss: 18710.3906\n",
      "Epoch 4598/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12630.1602 - val_loss: 18787.3105\n",
      "Epoch 4599/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12893.9023 - val_loss: 18999.7539\n",
      "Epoch 4600/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13542.2949 - val_loss: 19281.2188\n",
      "Epoch 4601/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14418.8037 - val_loss: 19487.3848\n",
      "Epoch 4602/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15061.6631 - val_loss: 19636.3086\n",
      "Epoch 4603/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15524.7021 - val_loss: 19738.3027\n",
      "Epoch 4604/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15842.7783 - val_loss: 19795.7246\n",
      "Epoch 4605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 16021.0762 - val_loss: 19779.3633\n",
      "Epoch 4606/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15970.1543 - val_loss: 19735.9785\n",
      "Epoch 4607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15834.9795 - val_loss: 19703.6641\n",
      "Epoch 4608/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15729.4385 - val_loss: 19631.9141\n",
      "Epoch 4609/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15494.8301 - val_loss: 19541.9512\n",
      "Epoch 4610/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15213.7529 - val_loss: 19441.7988\n",
      "Epoch 4611/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14897.5947 - val_loss: 19366.2402\n",
      "Epoch 4612/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14662.4570 - val_loss: 19287.4062\n",
      "Epoch 4613/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14418.0801 - val_loss: 19229.0391\n",
      "Epoch 4614/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14235.7393 - val_loss: 19117.6172\n",
      "Epoch 4615/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13887.8213 - val_loss: 19096.3379\n",
      "Epoch 4616/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13823.3711 - val_loss: 19055.4395\n",
      "Epoch 4617/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13706.3135 - val_loss: 19020.5664\n",
      "Epoch 4618/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13592.6748 - val_loss: 19029.2617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4619/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13624.6387 - val_loss: 19184.3027\n",
      "Epoch 4620/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14124.3633 - val_loss: 18972.9531\n",
      "Epoch 4621/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13448.9570 - val_loss: 19024.9355\n",
      "Epoch 4622/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13620.7324 - val_loss: 19212.9727\n",
      "Epoch 4623/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14205.7793 - val_loss: 19328.1211\n",
      "Epoch 4624/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14565.1719 - val_loss: 19392.0898\n",
      "Epoch 4625/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14765.0605 - val_loss: 19423.0352\n",
      "Epoch 4626/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14861.4268 - val_loss: 19427.2988\n",
      "Epoch 4627/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14871.8584 - val_loss: 19407.6094\n",
      "Epoch 4628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14795.5537 - val_loss: 19348.4766\n",
      "Epoch 4629/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14611.2930 - val_loss: 19268.1602\n",
      "Epoch 4630/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14360.3262 - val_loss: 19188.5215\n",
      "Epoch 4631/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14111.2549 - val_loss: 19136.7285\n",
      "Epoch 4632/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13951.2695 - val_loss: 19089.2988\n",
      "Epoch 4633/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13799.3994 - val_loss: 19023.8320\n",
      "Epoch 4634/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13608.4131 - val_loss: 18989.8184\n",
      "Epoch 4635/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13500.1436 - val_loss: 18945.1719\n",
      "Epoch 4636/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13361.5205 - val_loss: 18922.5586\n",
      "Epoch 4637/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13288.3809 - val_loss: 18962.7051\n",
      "Epoch 4638/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13413.9336 - val_loss: 18990.3262\n",
      "Epoch 4639/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13481.9072 - val_loss: 18983.7441\n",
      "Epoch 4640/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13460.1934 - val_loss: 18937.3105\n",
      "Epoch 4641/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13316.8594 - val_loss: 18885.6328\n",
      "Epoch 4642/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13163.2227 - val_loss: 18850.3887\n",
      "Epoch 4643/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13055.3174 - val_loss: 18823.2188\n",
      "Epoch 4644/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12983.7617 - val_loss: 18798.3164\n",
      "Epoch 4645/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12905.9072 - val_loss: 18768.4453\n",
      "Epoch 4646/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12818.2744 - val_loss: 18773.5977\n",
      "Epoch 4647/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12823.4814 - val_loss: 18753.7031\n",
      "Epoch 4648/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12751.6768 - val_loss: 18740.3145\n",
      "Epoch 4649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12706.4756 - val_loss: 18739.0156\n",
      "Epoch 4650/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12697.7812 - val_loss: 18769.2168\n",
      "Epoch 4651/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12817.4619 - val_loss: 18863.3516\n",
      "Epoch 4652/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13115.8232 - val_loss: 19048.3906\n",
      "Epoch 4653/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13692.7666 - val_loss: 19167.2520\n",
      "Epoch 4654/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14062.5967 - val_loss: 19248.2891\n",
      "Epoch 4655/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14314.8398 - val_loss: 19272.2051\n",
      "Epoch 4656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14389.2607 - val_loss: 19246.5898\n",
      "Epoch 4657/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14310.1338 - val_loss: 19212.8555\n",
      "Epoch 4658/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14205.3604 - val_loss: 19139.8496\n",
      "Epoch 4659/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13978.1934 - val_loss: 19052.1172\n",
      "Epoch 4660/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13704.7744 - val_loss: 18990.5820\n",
      "Epoch 4661/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13508.9746 - val_loss: 18951.5586\n",
      "Epoch 4662/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13385.8135 - val_loss: 18941.1367\n",
      "Epoch 4663/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13334.3232 - val_loss: 18919.3477\n",
      "Epoch 4664/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13266.2754 - val_loss: 18902.5059\n",
      "Epoch 4665/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13210.0479 - val_loss: 18896.7285\n",
      "Epoch 4666/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13192.2246 - val_loss: 18898.4473\n",
      "Epoch 4667/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13198.8945 - val_loss: 18842.7520\n",
      "Epoch 4668/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13024.3457 - val_loss: 18863.5508\n",
      "Epoch 4669/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13091.8496 - val_loss: 18878.3418\n",
      "Epoch 4670/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13158.8193 - val_loss: 18913.9473\n",
      "Epoch 4671/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13272.1709 - val_loss: 18927.1016\n",
      "Epoch 4672/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13314.4326 - val_loss: 18943.1719\n",
      "Epoch 4673/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13363.4004 - val_loss: 18918.0840\n",
      "Epoch 4674/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13285.3906 - val_loss: 18835.7363\n",
      "Epoch 4675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13029.3193 - val_loss: 18770.9609\n",
      "Epoch 4676/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12825.6885 - val_loss: 18765.3828\n",
      "Epoch 4677/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12800.7715 - val_loss: 18786.8477\n",
      "Epoch 4678/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12851.5967 - val_loss: 19139.2402\n",
      "Epoch 4679/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13987.0410 - val_loss: 18918.3652\n",
      "Epoch 4680/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13288.3438 - val_loss: 19246.7324\n",
      "Epoch 4681/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14310.9512 - val_loss: 19480.3320\n",
      "Epoch 4682/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15039.4482 - val_loss: 19627.7930\n",
      "Epoch 4683/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15499.1152 - val_loss: 19730.7891\n",
      "Epoch 4684/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15820.2959 - val_loss: 19767.2402\n",
      "Epoch 4685/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15934.6279 - val_loss: 19746.9961\n",
      "Epoch 4686/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15871.5811 - val_loss: 19714.6172\n",
      "Epoch 4687/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15767.0537 - val_loss: 19684.6484\n",
      "Epoch 4688/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15675.8145 - val_loss: 19624.6758\n",
      "Epoch 4689/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15487.6260 - val_loss: 19614.1113\n",
      "Epoch 4690/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15436.6631 - val_loss: 19610.5098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4691/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15420.0674 - val_loss: 19555.5820\n",
      "Epoch 4692/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15250.0566 - val_loss: 19468.7559\n",
      "Epoch 4693/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14980.0713 - val_loss: 19394.4336\n",
      "Epoch 4694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14747.1582 - val_loss: 19310.4082\n",
      "Epoch 4695/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14486.5566 - val_loss: 19237.0801\n",
      "Epoch 4696/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14257.0117 - val_loss: 19182.6309\n",
      "Epoch 4697/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14084.8086 - val_loss: 19169.9180\n",
      "Epoch 4698/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14063.2402 - val_loss: 19173.3594\n",
      "Epoch 4699/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14079.8066 - val_loss: 19157.6641\n",
      "Epoch 4700/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14031.8730 - val_loss: 19115.2051\n",
      "Epoch 4701/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13896.7324 - val_loss: 19064.2676\n",
      "Epoch 4702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13737.2246 - val_loss: 19040.9688\n",
      "Epoch 4703/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13662.7559 - val_loss: 19014.6445\n",
      "Epoch 4704/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13565.1816 - val_loss: 19008.1426\n",
      "Epoch 4705/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13538.9893 - val_loss: 18981.3203\n",
      "Epoch 4706/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13457.5371 - val_loss: 18958.2500\n",
      "Epoch 4707/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13386.4404 - val_loss: 19001.9609\n",
      "Epoch 4708/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13512.5264 - val_loss: 18988.3105\n",
      "Epoch 4709/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13476.6553 - val_loss: 18952.6816\n",
      "Epoch 4710/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13372.2227 - val_loss: 18924.8672\n",
      "Epoch 4711/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13300.8535 - val_loss: 18875.0137\n",
      "Epoch 4712/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13145.9453 - val_loss: 18820.7539\n",
      "Epoch 4713/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12975.0879 - val_loss: 18775.4258\n",
      "Epoch 4714/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12818.9385 - val_loss: 18748.1055\n",
      "Epoch 4715/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12736.1514 - val_loss: 18763.1152\n",
      "Epoch 4716/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12779.3809 - val_loss: 18785.4160\n",
      "Epoch 4717/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12856.1318 - val_loss: 18763.5391\n",
      "Epoch 4718/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.1504 - val_loss: 18730.8008\n",
      "Epoch 4719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12695.5762 - val_loss: 18724.2324\n",
      "Epoch 4720/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12674.3877 - val_loss: 18715.2578\n",
      "Epoch 4721/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12650.9736 - val_loss: 18722.8809\n",
      "Epoch 4722/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12686.3115 - val_loss: 18787.8516\n",
      "Epoch 4723/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12877.4873 - val_loss: 18857.5859\n",
      "Epoch 4724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13088.5508 - val_loss: 18878.9473\n",
      "Epoch 4725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13153.6943 - val_loss: 18868.8672\n",
      "Epoch 4726/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13128.6855 - val_loss: 18844.9902\n",
      "Epoch 4727/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13044.8789 - val_loss: 18828.7695\n",
      "Epoch 4728/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12986.4727 - val_loss: 18810.8984\n",
      "Epoch 4729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12929.8252 - val_loss: 18799.8848\n",
      "Epoch 4730/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12894.4854 - val_loss: 18790.9512\n",
      "Epoch 4731/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12865.0586 - val_loss: 18790.3613\n",
      "Epoch 4732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12875.8535 - val_loss: 18789.1816\n",
      "Epoch 4733/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.7598 - val_loss: 18806.0176\n",
      "Epoch 4734/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12929.6406 - val_loss: 18799.5879\n",
      "Epoch 4735/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12908.8145 - val_loss: 18765.8906\n",
      "Epoch 4736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.3271 - val_loss: 18741.6934\n",
      "Epoch 4737/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12717.1943 - val_loss: 18714.2129\n",
      "Epoch 4738/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12628.3760 - val_loss: 18749.7520\n",
      "Epoch 4739/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12735.9395 - val_loss: 18750.7090\n",
      "Epoch 4740/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12752.7041 - val_loss: 18729.2363\n",
      "Epoch 4741/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12689.7852 - val_loss: 18721.1309\n",
      "Epoch 4742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.3389 - val_loss: 18727.8535\n",
      "Epoch 4743/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12679.1572 - val_loss: 18729.6152\n",
      "Epoch 4744/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12676.9551 - val_loss: 18875.7734\n",
      "Epoch 4745/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13192.6328 - val_loss: 18940.2773\n",
      "Epoch 4746/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13354.2412 - val_loss: 19158.4453\n",
      "Epoch 4747/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14035.6562 - val_loss: 19317.2930\n",
      "Epoch 4748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14531.4883 - val_loss: 19414.8809\n",
      "Epoch 4749/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14835.2256 - val_loss: 19457.7578\n",
      "Epoch 4750/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14968.3652 - val_loss: 19476.4023\n",
      "Epoch 4751/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15024.2998 - val_loss: 19440.5371\n",
      "Epoch 4752/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14912.3877 - val_loss: 19430.6855\n",
      "Epoch 4753/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14880.2314 - val_loss: 19421.8477\n",
      "Epoch 4754/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14852.1348 - val_loss: 19405.8887\n",
      "Epoch 4755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14793.8174 - val_loss: 19380.0020\n",
      "Epoch 4756/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14702.8828 - val_loss: 19342.6035\n",
      "Epoch 4757/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14585.7275 - val_loss: 19283.5801\n",
      "Epoch 4758/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14392.7832 - val_loss: 19201.2676\n",
      "Epoch 4759/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14139.7705 - val_loss: 19172.0293\n",
      "Epoch 4760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14050.1035 - val_loss: 19160.6406\n",
      "Epoch 4761/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14021.0703 - val_loss: 19122.3301\n",
      "Epoch 4762/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13901.3721 - val_loss: 19081.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4763/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13792.1748 - val_loss: 19049.2656\n",
      "Epoch 4764/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13689.2090 - val_loss: 19042.3672\n",
      "Epoch 4765/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13664.6230 - val_loss: 19024.1055\n",
      "Epoch 4766/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13609.5137 - val_loss: 18988.7129\n",
      "Epoch 4767/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13499.9658 - val_loss: 18911.8047\n",
      "Epoch 4768/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13263.8379 - val_loss: 18887.6484\n",
      "Epoch 4769/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13171.2266 - val_loss: 18936.2793\n",
      "Epoch 4770/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13318.7012 - val_loss: 18954.8066\n",
      "Epoch 4771/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13373.7900 - val_loss: 18930.3926\n",
      "Epoch 4772/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13298.5928 - val_loss: 18893.3711\n",
      "Epoch 4773/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13184.8408 - val_loss: 18847.1289\n",
      "Epoch 4774/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13056.7812 - val_loss: 18828.7988\n",
      "Epoch 4775/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.2793 - val_loss: 18824.1152\n",
      "Epoch 4776/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12985.2852 - val_loss: 18812.9668\n",
      "Epoch 4777/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12949.6777 - val_loss: 18779.8340\n",
      "Epoch 4778/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12846.8096 - val_loss: 18763.3086\n",
      "Epoch 4779/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12783.6914 - val_loss: 18752.7305\n",
      "Epoch 4780/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.0576 - val_loss: 18748.6230\n",
      "Epoch 4781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12736.1738 - val_loss: 18745.0176\n",
      "Epoch 4782/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12727.5352 - val_loss: 18720.6191\n",
      "Epoch 4783/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.0059 - val_loss: 18709.5508\n",
      "Epoch 4784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.0488 - val_loss: 18714.9844\n",
      "Epoch 4785/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12647.6240 - val_loss: 18730.6113\n",
      "Epoch 4786/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12683.9551 - val_loss: 18862.5469\n",
      "Epoch 4787/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13146.3447 - val_loss: 19007.0332\n",
      "Epoch 4788/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13564.3301 - val_loss: 19290.1855\n",
      "Epoch 4789/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14446.9072 - val_loss: 19470.7090\n",
      "Epoch 4790/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15009.8076 - val_loss: 19560.6582\n",
      "Epoch 4791/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15290.4121 - val_loss: 19582.3203\n",
      "Epoch 4792/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15358.4590 - val_loss: 19589.4297\n",
      "Epoch 4793/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15381.1572 - val_loss: 19580.0215\n",
      "Epoch 4794/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15348.4707 - val_loss: 19579.5625\n",
      "Epoch 4795/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15345.1670 - val_loss: 19564.5215\n",
      "Epoch 4796/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15280.8926 - val_loss: 19582.9062\n",
      "Epoch 4797/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15337.8760 - val_loss: 19559.0879\n",
      "Epoch 4798/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 15263.8633 - val_loss: 19508.9023\n",
      "Epoch 4799/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15106.8369 - val_loss: 19474.7793\n",
      "Epoch 4800/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15002.1924 - val_loss: 19411.5762\n",
      "Epoch 4801/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14803.3125 - val_loss: 19385.9922\n",
      "Epoch 4802/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14729.2920 - val_loss: 19360.1484\n",
      "Epoch 4803/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14659.3418 - val_loss: 19320.8926\n",
      "Epoch 4804/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14536.8057 - val_loss: 19248.0742\n",
      "Epoch 4805/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14311.6670 - val_loss: 19186.6562\n",
      "Epoch 4806/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14119.5098 - val_loss: 19119.7676\n",
      "Epoch 4807/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13906.1191 - val_loss: 19054.4082\n",
      "Epoch 4808/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13688.7812 - val_loss: 19011.5195\n",
      "Epoch 4809/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13554.0322 - val_loss: 18971.4707\n",
      "Epoch 4810/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13429.0684 - val_loss: 18955.2070\n",
      "Epoch 4811/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13381.4824 - val_loss: 18986.0391\n",
      "Epoch 4812/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13491.0020 - val_loss: 19001.6250\n",
      "Epoch 4813/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13541.1328 - val_loss: 19021.3516\n",
      "Epoch 4814/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13598.2070 - val_loss: 18985.9395\n",
      "Epoch 4815/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13486.8389 - val_loss: 18946.4121\n",
      "Epoch 4816/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13347.1973 - val_loss: 18909.1680\n",
      "Epoch 4817/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13231.8369 - val_loss: 18898.9922\n",
      "Epoch 4818/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13202.6309 - val_loss: 18872.4062\n",
      "Epoch 4819/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13124.0234 - val_loss: 18836.3418\n",
      "Epoch 4820/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13022.4863 - val_loss: 18819.8145\n",
      "Epoch 4821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12974.0889 - val_loss: 18778.5898\n",
      "Epoch 4822/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12845.2295 - val_loss: 18785.4785\n",
      "Epoch 4823/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.4434 - val_loss: 18786.0430\n",
      "Epoch 4824/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12844.9639 - val_loss: 18747.8457\n",
      "Epoch 4825/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.8477 - val_loss: 18733.5352\n",
      "Epoch 4826/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.9941 - val_loss: 18774.5156\n",
      "Epoch 4827/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12853.0352 - val_loss: 18893.7109\n",
      "Epoch 4828/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13199.4092 - val_loss: 19070.3945\n",
      "Epoch 4829/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13748.4170 - val_loss: 19161.4648\n",
      "Epoch 4830/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14030.7266 - val_loss: 19191.5723\n",
      "Epoch 4831/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14124.3350 - val_loss: 19168.8398\n",
      "Epoch 4832/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14054.2910 - val_loss: 19141.2773\n",
      "Epoch 4833/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13967.9736 - val_loss: 19146.0117\n",
      "Epoch 4834/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13965.9170 - val_loss: 19157.3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4835/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14001.7266 - val_loss: 19117.3457\n",
      "Epoch 4836/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13879.6553 - val_loss: 19050.0059\n",
      "Epoch 4837/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13672.3232 - val_loss: 19032.0254\n",
      "Epoch 4838/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13621.8076 - val_loss: 19000.1758\n",
      "Epoch 4839/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13520.6279 - val_loss: 18964.3594\n",
      "Epoch 4840/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13424.8008 - val_loss: 18920.3711\n",
      "Epoch 4841/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13288.5254 - val_loss: 18908.7754\n",
      "Epoch 4842/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13251.9150 - val_loss: 18932.7070\n",
      "Epoch 4843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13323.2842 - val_loss: 18912.9961\n",
      "Epoch 4844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13257.4961 - val_loss: 18854.4277\n",
      "Epoch 4845/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13062.0322 - val_loss: 18823.8516\n",
      "Epoch 4846/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12969.4346 - val_loss: 18814.5234\n",
      "Epoch 4847/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12939.4463 - val_loss: 18794.1230\n",
      "Epoch 4848/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12873.9551 - val_loss: 18780.4434\n",
      "Epoch 4849/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12852.1875 - val_loss: 18821.7598\n",
      "Epoch 4850/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.3555 - val_loss: 18798.7129\n",
      "Epoch 4851/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12901.2207 - val_loss: 18861.1484\n",
      "Epoch 4852/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13100.0869 - val_loss: 18887.3809\n",
      "Epoch 4853/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13190.3252 - val_loss: 18892.4082\n",
      "Epoch 4854/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13187.3105 - val_loss: 18909.8984\n",
      "Epoch 4855/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13240.9033 - val_loss: 18948.7129\n",
      "Epoch 4856/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13360.4512 - val_loss: 18921.9414\n",
      "Epoch 4857/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13276.0303 - val_loss: 18907.2754\n",
      "Epoch 4858/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13245.3926 - val_loss: 18891.4746\n",
      "Epoch 4859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13200.3047 - val_loss: 18855.4297\n",
      "Epoch 4860/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13089.2158 - val_loss: 18815.0391\n",
      "Epoch 4861/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12962.9922 - val_loss: 18783.5977\n",
      "Epoch 4862/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12847.8877 - val_loss: 18728.7305\n",
      "Epoch 4863/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12670.9717 - val_loss: 18721.6309\n",
      "Epoch 4864/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12673.6201 - val_loss: 18715.4688\n",
      "Epoch 4865/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12646.9121 - val_loss: 18731.1973\n",
      "Epoch 4866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12699.2539 - val_loss: 18790.0020\n",
      "Epoch 4867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12885.1250 - val_loss: 18802.7266\n",
      "Epoch 4868/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12923.9443 - val_loss: 18773.3379\n",
      "Epoch 4869/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12823.2275 - val_loss: 18730.5664\n",
      "Epoch 4870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12679.3047 - val_loss: 18711.1328\n",
      "Epoch 4871/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12615.6768 - val_loss: 18882.9688\n",
      "Epoch 4872/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13206.2832 - val_loss: 18932.1719\n",
      "Epoch 4873/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13333.4131 - val_loss: 19204.1660\n",
      "Epoch 4874/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14181.2197 - val_loss: 19369.5762\n",
      "Epoch 4875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14694.8457 - val_loss: 19453.3184\n",
      "Epoch 4876/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14955.7402 - val_loss: 19527.2734\n",
      "Epoch 4877/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15185.6963 - val_loss: 19555.9473\n",
      "Epoch 4878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15274.9531 - val_loss: 19560.7812\n",
      "Epoch 4879/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15289.4229 - val_loss: 19540.5195\n",
      "Epoch 4880/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15226.3799 - val_loss: 19498.4648\n",
      "Epoch 4881/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15094.2285 - val_loss: 19488.3613\n",
      "Epoch 4882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15045.1445 - val_loss: 19426.7539\n",
      "Epoch 4883/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14854.1201 - val_loss: 19329.6719\n",
      "Epoch 4884/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14550.8857 - val_loss: 19328.2461\n",
      "Epoch 4885/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14544.2002 - val_loss: 19292.6426\n",
      "Epoch 4886/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14433.2412 - val_loss: 19263.7246\n",
      "Epoch 4887/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14342.9180 - val_loss: 19231.1523\n",
      "Epoch 4888/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14241.8984 - val_loss: 19186.7695\n",
      "Epoch 4889/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14120.8994 - val_loss: 19119.8359\n",
      "Epoch 4890/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13911.7119 - val_loss: 19031.0410\n",
      "Epoch 4891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13631.6611 - val_loss: 18998.8340\n",
      "Epoch 4892/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13532.6904 - val_loss: 18990.7832\n",
      "Epoch 4893/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13506.1475 - val_loss: 19023.4316\n",
      "Epoch 4894/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13606.4053 - val_loss: 19034.7891\n",
      "Epoch 4895/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13625.5264 - val_loss: 18995.8379\n",
      "Epoch 4896/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13506.1299 - val_loss: 19010.0449\n",
      "Epoch 4897/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13553.9854 - val_loss: 19016.8887\n",
      "Epoch 4898/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13572.7715 - val_loss: 18988.7227\n",
      "Epoch 4899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13482.1318 - val_loss: 18930.3750\n",
      "Epoch 4900/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13316.1953 - val_loss: 18887.0000\n",
      "Epoch 4901/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13179.4121 - val_loss: 18871.0918\n",
      "Epoch 4902/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13132.7539 - val_loss: 18851.4941\n",
      "Epoch 4903/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13072.4844 - val_loss: 18832.0566\n",
      "Epoch 4904/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12997.6230 - val_loss: 18817.2422\n",
      "Epoch 4905/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12949.7598 - val_loss: 18819.8047\n",
      "Epoch 4906/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12963.7168 - val_loss: 18805.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4907/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12920.2383 - val_loss: 18768.1816\n",
      "Epoch 4908/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12816.7568 - val_loss: 18754.2988\n",
      "Epoch 4909/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12768.6904 - val_loss: 18748.0918\n",
      "Epoch 4910/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.6553 - val_loss: 18715.8594\n",
      "Epoch 4911/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12643.3379 - val_loss: 18724.9316\n",
      "Epoch 4912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12686.4697 - val_loss: 18791.2734\n",
      "Epoch 4913/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12885.6426 - val_loss: 18883.6973\n",
      "Epoch 4914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13171.3301 - val_loss: 18945.4629\n",
      "Epoch 4915/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13359.1045 - val_loss: 18941.5273\n",
      "Epoch 4916/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13339.8037 - val_loss: 18908.3379\n",
      "Epoch 4917/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13237.4590 - val_loss: 18904.3281\n",
      "Epoch 4918/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13224.3291 - val_loss: 18885.0000\n",
      "Epoch 4919/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13169.2725 - val_loss: 18851.6445\n",
      "Epoch 4920/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13068.9941 - val_loss: 18811.7480\n",
      "Epoch 4921/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12943.1104 - val_loss: 18766.8398\n",
      "Epoch 4922/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12803.9316 - val_loss: 18742.0332\n",
      "Epoch 4923/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.4766 - val_loss: 19005.2051\n",
      "Epoch 4924/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13610.6035 - val_loss: 18928.7441\n",
      "Epoch 4925/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13320.6260 - val_loss: 19194.7930\n",
      "Epoch 4926/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14149.4580 - val_loss: 19353.3438\n",
      "Epoch 4927/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14644.6797 - val_loss: 19436.1758\n",
      "Epoch 4928/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14901.7549 - val_loss: 19476.7207\n",
      "Epoch 4929/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15028.5537 - val_loss: 19516.4004\n",
      "Epoch 4930/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15134.5264 - val_loss: 19496.8242\n",
      "Epoch 4931/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15073.4736 - val_loss: 19467.0215\n",
      "Epoch 4932/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14978.7100 - val_loss: 19451.3008\n",
      "Epoch 4933/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14929.7188 - val_loss: 19401.0996\n",
      "Epoch 4934/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14781.9473 - val_loss: 19396.3789\n",
      "Epoch 4935/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14764.4609 - val_loss: 19415.0215\n",
      "Epoch 4936/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14819.9209 - val_loss: 19421.4805\n",
      "Epoch 4937/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14845.0596 - val_loss: 19381.9883\n",
      "Epoch 4938/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14712.5752 - val_loss: 19324.4824\n",
      "Epoch 4939/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14534.0742 - val_loss: 19258.5410\n",
      "Epoch 4940/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14328.9121 - val_loss: 19166.8223\n",
      "Epoch 4941/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14052.9521 - val_loss: 19154.2051\n",
      "Epoch 4942/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14016.5127 - val_loss: 19117.0664\n",
      "Epoch 4943/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13897.1943 - val_loss: 19133.0312\n",
      "Epoch 4944/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13942.7109 - val_loss: 19122.6914\n",
      "Epoch 4945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13906.5879 - val_loss: 19072.0859\n",
      "Epoch 4946/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13748.3223 - val_loss: 19020.1992\n",
      "Epoch 4947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13594.3818 - val_loss: 18973.0391\n",
      "Epoch 4948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13449.6914 - val_loss: 18951.0605\n",
      "Epoch 4949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13379.7568 - val_loss: 18974.1230\n",
      "Epoch 4950/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13443.9199 - val_loss: 18981.5215\n",
      "Epoch 4951/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13459.9844 - val_loss: 18959.9199\n",
      "Epoch 4952/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13389.2793 - val_loss: 18926.0215\n",
      "Epoch 4953/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13289.3887 - val_loss: 18927.8008\n",
      "Epoch 4954/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13303.6045 - val_loss: 18909.0645\n",
      "Epoch 4955/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13250.0186 - val_loss: 18874.3262\n",
      "Epoch 4956/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13139.1826 - val_loss: 18856.9219\n",
      "Epoch 4957/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13080.4121 - val_loss: 18838.8066\n",
      "Epoch 4958/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13017.1455 - val_loss: 18804.7422\n",
      "Epoch 4959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12914.0693 - val_loss: 18757.4746\n",
      "Epoch 4960/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12772.5498 - val_loss: 18752.2051\n",
      "Epoch 4961/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12759.3818 - val_loss: 18779.9609\n",
      "Epoch 4962/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12841.5430 - val_loss: 18773.4102\n",
      "Epoch 4963/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12819.9609 - val_loss: 18746.0449\n",
      "Epoch 4964/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.3184 - val_loss: 18755.7637\n",
      "Epoch 4965/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12805.5068 - val_loss: 18846.6504\n",
      "Epoch 4966/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13063.2988 - val_loss: 19012.2793\n",
      "Epoch 4967/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13579.9170 - val_loss: 19081.5195\n",
      "Epoch 4968/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13796.5508 - val_loss: 19090.2461\n",
      "Epoch 4969/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13817.3760 - val_loss: 19094.2871\n",
      "Epoch 4970/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13819.1494 - val_loss: 19091.8574\n",
      "Epoch 4971/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13809.9385 - val_loss: 19092.0176\n",
      "Epoch 4972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13810.5830 - val_loss: 19083.2773\n",
      "Epoch 4973/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13791.5820 - val_loss: 19073.4375\n",
      "Epoch 4974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13763.9033 - val_loss: 19043.5723\n",
      "Epoch 4975/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13672.0332 - val_loss: 18987.2871\n",
      "Epoch 4976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13491.4375 - val_loss: 18970.0391\n",
      "Epoch 4977/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13428.0488 - val_loss: 18945.4043\n",
      "Epoch 4978/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13352.7148 - val_loss: 18909.2676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4979/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13243.8291 - val_loss: 18859.7715\n",
      "Epoch 4980/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13100.4668 - val_loss: 18820.2656\n",
      "Epoch 4981/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12976.3262 - val_loss: 18781.9219\n",
      "Epoch 4982/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12850.1768 - val_loss: 18731.5664\n",
      "Epoch 4983/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12683.9336 - val_loss: 18914.8125\n",
      "Epoch 4984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13321.1973 - val_loss: 18887.2676\n",
      "Epoch 4985/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13190.7666 - val_loss: 19138.5566\n",
      "Epoch 4986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13975.1152 - val_loss: 19295.6113\n",
      "Epoch 4987/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14465.1182 - val_loss: 19391.5645\n",
      "Epoch 4988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14760.9600 - val_loss: 19422.3789\n",
      "Epoch 4989/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14856.6377 - val_loss: 19403.7754\n",
      "Epoch 4990/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14797.9688 - val_loss: 19369.2891\n",
      "Epoch 4991/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14679.7041 - val_loss: 19356.9727\n",
      "Epoch 4992/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14639.6260 - val_loss: 19383.8359\n",
      "Epoch 4993/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14721.7578 - val_loss: 19361.9551\n",
      "Epoch 4994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14650.4395 - val_loss: 19312.8926\n",
      "Epoch 4995/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14498.4658 - val_loss: 19262.5938\n",
      "Epoch 4996/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14352.5869 - val_loss: 19206.1289\n",
      "Epoch 4997/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14182.5732 - val_loss: 19146.0488\n",
      "Epoch 4998/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13996.7217 - val_loss: 19051.4707\n",
      "Epoch 4999/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13700.2852 - val_loss: 19067.0820\n",
      "Epoch 5000/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13741.6152 - val_loss: 19091.2949\n",
      "Epoch 5001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13805.0107 - val_loss: 19090.2812\n",
      "Epoch 5002/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13801.9912 - val_loss: 19071.8359\n",
      "Epoch 5003/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13744.8896 - val_loss: 19054.3418\n",
      "Epoch 5004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13689.3535 - val_loss: 19024.3613\n",
      "Epoch 5005/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13601.3262 - val_loss: 18959.1094\n",
      "Epoch 5006/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13399.9561 - val_loss: 18900.8379\n",
      "Epoch 5007/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13225.7725 - val_loss: 18883.6699\n",
      "Epoch 5008/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13170.4834 - val_loss: 18849.7852\n",
      "Epoch 5009/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13059.9639 - val_loss: 18826.9297\n",
      "Epoch 5010/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12983.9346 - val_loss: 18840.1953\n",
      "Epoch 5011/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13024.7871 - val_loss: 18850.7676\n",
      "Epoch 5012/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13069.5693 - val_loss: 18850.6895\n",
      "Epoch 5013/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13073.2119 - val_loss: 18794.6465\n",
      "Epoch 5014/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.9316 - val_loss: 18779.2812\n",
      "Epoch 5015/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12833.1885 - val_loss: 18798.2227\n",
      "Epoch 5016/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12888.2275 - val_loss: 18787.4707\n",
      "Epoch 5017/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12854.7314 - val_loss: 18772.6914\n",
      "Epoch 5018/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.9834 - val_loss: 18731.3086\n",
      "Epoch 5019/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12694.2939 - val_loss: 18707.8438\n",
      "Epoch 5020/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12623.4463 - val_loss: 18674.1113\n",
      "Epoch 5021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12519.9912 - val_loss: 18694.7441\n",
      "Epoch 5022/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12573.3682 - val_loss: 18719.4277\n",
      "Epoch 5023/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12649.2939 - val_loss: 18718.3594\n",
      "Epoch 5024/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12650.0020 - val_loss: 18730.3242\n",
      "Epoch 5025/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.2441 - val_loss: 18723.4316\n",
      "Epoch 5026/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12665.9102 - val_loss: 18738.8945\n",
      "Epoch 5027/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12717.5312 - val_loss: 18742.4180\n",
      "Epoch 5028/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.2900 - val_loss: 18713.1406\n",
      "Epoch 5029/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12636.8887 - val_loss: 18663.7402\n",
      "Epoch 5030/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12472.2061 - val_loss: 18688.5684\n",
      "Epoch 5031/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.8086 - val_loss: 18702.5859\n",
      "Epoch 5032/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.4355 - val_loss: 18696.5918\n",
      "Epoch 5033/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.3594 - val_loss: 18698.1406\n",
      "Epoch 5034/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.9707 - val_loss: 18675.3008\n",
      "Epoch 5035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12521.6152 - val_loss: 18690.5078\n",
      "Epoch 5036/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12560.8320 - val_loss: 18689.5645\n",
      "Epoch 5037/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12557.8672 - val_loss: 18682.4023\n",
      "Epoch 5038/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.4443 - val_loss: 18668.5234\n",
      "Epoch 5039/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.5332 - val_loss: 18690.4785\n",
      "Epoch 5040/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12566.2461 - val_loss: 18696.7422\n",
      "Epoch 5041/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.7744 - val_loss: 18701.0957\n",
      "Epoch 5042/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12601.7305 - val_loss: 18719.7891\n",
      "Epoch 5043/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.3916 - val_loss: 18726.2461\n",
      "Epoch 5044/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12671.0186 - val_loss: 18737.2422\n",
      "Epoch 5045/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.3613 - val_loss: 18730.7930\n",
      "Epoch 5046/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12690.5420 - val_loss: 18711.0859\n",
      "Epoch 5047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12633.3125 - val_loss: 18702.8750\n",
      "Epoch 5048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.9756 - val_loss: 18725.7305\n",
      "Epoch 5049/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12665.2754 - val_loss: 18742.5098\n",
      "Epoch 5050/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12715.8740 - val_loss: 18702.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5051/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12592.8652 - val_loss: 18691.4277\n",
      "Epoch 5052/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12569.0469 - val_loss: 18712.1836\n",
      "Epoch 5053/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12636.7891 - val_loss: 18720.4590\n",
      "Epoch 5054/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12704.1338 - val_loss: 18777.2832\n",
      "Epoch 5055/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12843.6611 - val_loss: 18835.8066\n",
      "Epoch 5056/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13022.7422 - val_loss: 18864.0020\n",
      "Epoch 5057/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13104.7686 - val_loss: 18900.9336\n",
      "Epoch 5058/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13213.5723 - val_loss: 18902.7344\n",
      "Epoch 5059/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13221.9580 - val_loss: 18856.6230\n",
      "Epoch 5060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13082.8984 - val_loss: 18830.8789\n",
      "Epoch 5061/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13003.2930 - val_loss: 18813.3262\n",
      "Epoch 5062/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12948.1611 - val_loss: 18794.5801\n",
      "Epoch 5063/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12883.0098 - val_loss: 18793.1406\n",
      "Epoch 5064/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12874.6924 - val_loss: 18767.7188\n",
      "Epoch 5065/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12800.2510 - val_loss: 18755.6172\n",
      "Epoch 5066/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.1992 - val_loss: 18761.5547\n",
      "Epoch 5067/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12782.6787 - val_loss: 18751.1328\n",
      "Epoch 5068/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12746.3389 - val_loss: 18718.5176\n",
      "Epoch 5069/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.7861 - val_loss: 18709.1543\n",
      "Epoch 5070/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.8574 - val_loss: 18747.3984\n",
      "Epoch 5071/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12739.8252 - val_loss: 18739.6484\n",
      "Epoch 5072/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12716.3115 - val_loss: 18811.7324\n",
      "Epoch 5073/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13022.0576 - val_loss: 18935.3203\n",
      "Epoch 5074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13335.5801 - val_loss: 19169.9297\n",
      "Epoch 5075/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14059.3906 - val_loss: 19314.4375\n",
      "Epoch 5076/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14510.1719 - val_loss: 19364.1836\n",
      "Epoch 5077/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14674.6709 - val_loss: 19387.0215\n",
      "Epoch 5078/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14733.4072 - val_loss: 19412.9102\n",
      "Epoch 5079/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14813.9121 - val_loss: 19418.8633\n",
      "Epoch 5080/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14833.2773 - val_loss: 19464.3008\n",
      "Epoch 5081/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14973.2490 - val_loss: 19468.5645\n",
      "Epoch 5082/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14990.6240 - val_loss: 19433.4492\n",
      "Epoch 5083/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14886.3545 - val_loss: 19351.4629\n",
      "Epoch 5084/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14632.3516 - val_loss: 19262.0508\n",
      "Epoch 5085/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14353.0527 - val_loss: 19230.6348\n",
      "Epoch 5086/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14244.8984 - val_loss: 19216.5176\n",
      "Epoch 5087/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14199.9014 - val_loss: 19229.8086\n",
      "Epoch 5088/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14242.9199 - val_loss: 19195.2715\n",
      "Epoch 5089/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14142.5684 - val_loss: 19122.3867\n",
      "Epoch 5090/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13919.2285 - val_loss: 19023.5410\n",
      "Epoch 5091/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13608.8691 - val_loss: 18988.7949\n",
      "Epoch 5092/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13487.2109 - val_loss: 18987.0449\n",
      "Epoch 5093/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13479.8389 - val_loss: 18989.6602\n",
      "Epoch 5094/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13487.5137 - val_loss: 18963.5449\n",
      "Epoch 5095/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13413.0312 - val_loss: 18954.7715\n",
      "Epoch 5096/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13386.2637 - val_loss: 18966.3398\n",
      "Epoch 5097/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13421.2959 - val_loss: 18967.6914\n",
      "Epoch 5098/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13419.2842 - val_loss: 18949.2109\n",
      "Epoch 5099/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13362.2842 - val_loss: 18916.0742\n",
      "Epoch 5100/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13265.7656 - val_loss: 18889.4746\n",
      "Epoch 5101/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13184.6621 - val_loss: 18841.7148\n",
      "Epoch 5102/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13030.5508 - val_loss: 18824.7070\n",
      "Epoch 5103/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12973.9717 - val_loss: 18834.9961\n",
      "Epoch 5104/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13009.8633 - val_loss: 18805.0508\n",
      "Epoch 5105/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12919.2324 - val_loss: 18766.5586\n",
      "Epoch 5106/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12800.2432 - val_loss: 18785.3906\n",
      "Epoch 5107/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12859.5840 - val_loss: 18779.8887\n",
      "Epoch 5108/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12842.1748 - val_loss: 18759.6934\n",
      "Epoch 5109/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12780.6953 - val_loss: 18730.9082\n",
      "Epoch 5110/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12692.7324 - val_loss: 18726.3164\n",
      "Epoch 5111/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12670.7422 - val_loss: 18983.4707\n",
      "Epoch 5112/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13554.9268 - val_loss: 18964.8223\n",
      "Epoch 5113/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13429.9082 - val_loss: 19194.8164\n",
      "Epoch 5114/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14147.1621 - val_loss: 19315.9180\n",
      "Epoch 5115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14524.0449 - val_loss: 19376.5410\n",
      "Epoch 5116/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14711.9824 - val_loss: 19411.0430\n",
      "Epoch 5117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14809.6094 - val_loss: 19387.0918\n",
      "Epoch 5118/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14735.7041 - val_loss: 19387.5723\n",
      "Epoch 5119/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14738.6045 - val_loss: 19396.3105\n",
      "Epoch 5120/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14765.4209 - val_loss: 19329.0820\n",
      "Epoch 5121/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14567.5068 - val_loss: 19262.2812\n",
      "Epoch 5122/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14358.6348 - val_loss: 19239.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5123/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14284.8545 - val_loss: 19278.2598\n",
      "Epoch 5124/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14392.0674 - val_loss: 19308.0410\n",
      "Epoch 5125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14484.1230 - val_loss: 19262.0156\n",
      "Epoch 5126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14340.5859 - val_loss: 19174.2207\n",
      "Epoch 5127/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14075.9141 - val_loss: 19090.2070\n",
      "Epoch 5128/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13816.7686 - val_loss: 19038.1523\n",
      "Epoch 5129/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13654.6406 - val_loss: 18976.7227\n",
      "Epoch 5130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13455.5107 - val_loss: 18920.9805\n",
      "Epoch 5131/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13279.1572 - val_loss: 18956.3828\n",
      "Epoch 5132/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13386.3574 - val_loss: 19002.8242\n",
      "Epoch 5133/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13538.7158 - val_loss: 19010.0195\n",
      "Epoch 5134/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13562.3691 - val_loss: 18983.8418\n",
      "Epoch 5135/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13472.4727 - val_loss: 18956.6035\n",
      "Epoch 5136/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13384.9180 - val_loss: 18946.2227\n",
      "Epoch 5137/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13353.3311 - val_loss: 18943.0371\n",
      "Epoch 5138/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13346.4785 - val_loss: 18906.2988\n",
      "Epoch 5139/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13237.1641 - val_loss: 18852.6992\n",
      "Epoch 5140/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13063.8105 - val_loss: 18824.1328\n",
      "Epoch 5141/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12972.7676 - val_loss: 18811.5703\n",
      "Epoch 5142/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12935.1025 - val_loss: 18794.6484\n",
      "Epoch 5143/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.3721 - val_loss: 18788.4648\n",
      "Epoch 5144/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12878.1133 - val_loss: 18790.8945\n",
      "Epoch 5145/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12878.6104 - val_loss: 18762.6777\n",
      "Epoch 5146/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12787.0811 - val_loss: 18726.4824\n",
      "Epoch 5147/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12676.7783 - val_loss: 18742.2148\n",
      "Epoch 5148/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12729.8389 - val_loss: 18765.4902\n",
      "Epoch 5149/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12800.9492 - val_loss: 18752.9551\n",
      "Epoch 5150/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12767.2168 - val_loss: 18709.4980\n",
      "Epoch 5151/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12614.9756 - val_loss: 18723.0547\n",
      "Epoch 5152/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.9717 - val_loss: 18730.0977\n",
      "Epoch 5153/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12686.7783 - val_loss: 18732.9824\n",
      "Epoch 5154/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12691.1797 - val_loss: 18728.6406\n",
      "Epoch 5155/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12687.1602 - val_loss: 18709.6797\n",
      "Epoch 5156/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12619.2676 - val_loss: 18686.4688\n",
      "Epoch 5157/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12547.5420 - val_loss: 18697.8516\n",
      "Epoch 5158/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12583.9062 - val_loss: 18709.5605\n",
      "Epoch 5159/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.9824 - val_loss: 18700.4473\n",
      "Epoch 5160/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12591.6172 - val_loss: 18701.2637\n",
      "Epoch 5161/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12591.1562 - val_loss: 18682.3203\n",
      "Epoch 5162/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12534.4102 - val_loss: 18679.0410\n",
      "Epoch 5163/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.4541 - val_loss: 18687.0273\n",
      "Epoch 5164/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12548.6494 - val_loss: 18696.9453\n",
      "Epoch 5165/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.6445 - val_loss: 18694.6230\n",
      "Epoch 5166/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.5303 - val_loss: 18810.6855\n",
      "Epoch 5167/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12947.5029 - val_loss: 18929.5000\n",
      "Epoch 5168/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13318.4658 - val_loss: 18999.9941\n",
      "Epoch 5169/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13537.5557 - val_loss: 19022.0586\n",
      "Epoch 5170/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13604.7061 - val_loss: 19007.0957\n",
      "Epoch 5171/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13552.3018 - val_loss: 18985.1992\n",
      "Epoch 5172/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13482.5479 - val_loss: 19013.5859\n",
      "Epoch 5173/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13568.4561 - val_loss: 19040.5176\n",
      "Epoch 5174/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13652.0186 - val_loss: 19021.0332\n",
      "Epoch 5175/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13599.1367 - val_loss: 18988.7656\n",
      "Epoch 5176/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13499.8076 - val_loss: 18956.1406\n",
      "Epoch 5177/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13398.3730 - val_loss: 18946.8711\n",
      "Epoch 5178/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13363.4629 - val_loss: 18936.8242\n",
      "Epoch 5179/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13331.1143 - val_loss: 18916.2969\n",
      "Epoch 5180/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13268.3223 - val_loss: 18871.8359\n",
      "Epoch 5181/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13129.1973 - val_loss: 18829.9355\n",
      "Epoch 5182/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12996.6729 - val_loss: 18807.2090\n",
      "Epoch 5183/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12931.1846 - val_loss: 18805.0469\n",
      "Epoch 5184/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12921.8770 - val_loss: 18812.3242\n",
      "Epoch 5185/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12941.5947 - val_loss: 18794.6836\n",
      "Epoch 5186/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12881.6885 - val_loss: 18789.9785\n",
      "Epoch 5187/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12867.2637 - val_loss: 18783.4199\n",
      "Epoch 5188/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.5332 - val_loss: 18780.7246\n",
      "Epoch 5189/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12844.7871 - val_loss: 18760.3281\n",
      "Epoch 5190/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12794.8662 - val_loss: 18720.5176\n",
      "Epoch 5191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.1201 - val_loss: 18692.5645\n",
      "Epoch 5192/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.3672 - val_loss: 18701.2285\n",
      "Epoch 5193/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12594.3682 - val_loss: 18712.3672\n",
      "Epoch 5194/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12627.7363 - val_loss: 18710.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5195/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12625.1865 - val_loss: 18699.6914\n",
      "Epoch 5196/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12593.2080 - val_loss: 18754.7891\n",
      "Epoch 5197/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12759.6367 - val_loss: 18782.6992\n",
      "Epoch 5198/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12847.6523 - val_loss: 18765.8008\n",
      "Epoch 5199/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12801.6445 - val_loss: 18719.1250\n",
      "Epoch 5200/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.4336 - val_loss: 18699.5664\n",
      "Epoch 5201/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12590.1348 - val_loss: 18728.2637\n",
      "Epoch 5202/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12676.7422 - val_loss: 18748.8008\n",
      "Epoch 5203/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12738.9512 - val_loss: 18734.1914\n",
      "Epoch 5204/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12734.0342 - val_loss: 18752.8789\n",
      "Epoch 5205/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12764.5801 - val_loss: 18824.3770\n",
      "Epoch 5206/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12989.7227 - val_loss: 18864.5527\n",
      "Epoch 5207/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13107.7490 - val_loss: 18839.0039\n",
      "Epoch 5208/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13025.3164 - val_loss: 18793.8320\n",
      "Epoch 5209/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12883.3369 - val_loss: 18783.5293\n",
      "Epoch 5210/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.6221 - val_loss: 18761.4863\n",
      "Epoch 5211/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.3887 - val_loss: 18771.4395\n",
      "Epoch 5212/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12812.3584 - val_loss: 18781.7754\n",
      "Epoch 5213/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12841.7393 - val_loss: 18780.5898\n",
      "Epoch 5214/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12838.7637 - val_loss: 18757.0547\n",
      "Epoch 5215/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12768.9434 - val_loss: 18747.7305\n",
      "Epoch 5216/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.5449 - val_loss: 18728.2227\n",
      "Epoch 5217/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12683.6963 - val_loss: 18723.7812\n",
      "Epoch 5218/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.8291 - val_loss: 18713.8711\n",
      "Epoch 5219/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12636.0098 - val_loss: 18678.8574\n",
      "Epoch 5220/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.2988 - val_loss: 18676.1562\n",
      "Epoch 5221/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12521.8457 - val_loss: 18692.7969\n",
      "Epoch 5222/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.9023 - val_loss: 18716.7285\n",
      "Epoch 5223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.6514 - val_loss: 18742.5449\n",
      "Epoch 5224/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.8887 - val_loss: 18738.3359\n",
      "Epoch 5225/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12717.2900 - val_loss: 18725.5176\n",
      "Epoch 5226/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12672.1396 - val_loss: 18694.1797\n",
      "Epoch 5227/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12572.4912 - val_loss: 18708.9688\n",
      "Epoch 5228/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12632.6279 - val_loss: 18724.8535\n",
      "Epoch 5229/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12675.0137 - val_loss: 18725.5527\n",
      "Epoch 5230/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12675.7354 - val_loss: 18708.0547\n",
      "Epoch 5231/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.6152 - val_loss: 18717.3945\n",
      "Epoch 5232/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12646.0547 - val_loss: 18707.3711\n",
      "Epoch 5233/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12619.4023 - val_loss: 18714.8477\n",
      "Epoch 5234/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12639.8516 - val_loss: 18712.4473\n",
      "Epoch 5235/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12626.0127 - val_loss: 18701.6328\n",
      "Epoch 5236/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12587.4141 - val_loss: 18702.7656\n",
      "Epoch 5237/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12597.0400 - val_loss: 18707.0020\n",
      "Epoch 5238/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12623.2344 - val_loss: 18681.5352\n",
      "Epoch 5239/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12541.6250 - val_loss: 18686.1328\n",
      "Epoch 5240/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12548.5625 - val_loss: 18702.9043\n",
      "Epoch 5241/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12596.8770 - val_loss: 18737.1895\n",
      "Epoch 5242/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12768.9785 - val_loss: 18927.7910\n",
      "Epoch 5243/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13313.8584 - val_loss: 19151.7715\n",
      "Epoch 5244/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14011.5244 - val_loss: 19274.9023\n",
      "Epoch 5245/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14395.5625 - val_loss: 19303.4531\n",
      "Epoch 5246/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14484.3125 - val_loss: 19284.6309\n",
      "Epoch 5247/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14425.1602 - val_loss: 19264.3457\n",
      "Epoch 5248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14355.3086 - val_loss: 19283.7070\n",
      "Epoch 5249/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14412.1104 - val_loss: 19254.2637\n",
      "Epoch 5250/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14320.0312 - val_loss: 19219.4727\n",
      "Epoch 5251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14212.0137 - val_loss: 19208.7090\n",
      "Epoch 5252/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14179.2129 - val_loss: 19191.7617\n",
      "Epoch 5253/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14125.8613 - val_loss: 19180.0410\n",
      "Epoch 5254/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14098.3467 - val_loss: 19150.5586\n",
      "Epoch 5255/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14004.4482 - val_loss: 19091.6895\n",
      "Epoch 5256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13820.5059 - val_loss: 18988.6641\n",
      "Epoch 5257/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13500.5986 - val_loss: 18956.0195\n",
      "Epoch 5258/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13398.4824 - val_loss: 18990.6836\n",
      "Epoch 5259/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13492.3340 - val_loss: 19003.0977\n",
      "Epoch 5260/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13532.3906 - val_loss: 19001.7422\n",
      "Epoch 5261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13529.1084 - val_loss: 18947.6738\n",
      "Epoch 5262/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13356.5557 - val_loss: 18942.7188\n",
      "Epoch 5263/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13341.8096 - val_loss: 18935.8145\n",
      "Epoch 5264/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13328.6924 - val_loss: 18966.9219\n",
      "Epoch 5265/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13425.3096 - val_loss: 18932.0371\n",
      "Epoch 5266/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13317.2754 - val_loss: 18877.3906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5267/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13146.4277 - val_loss: 18834.0137\n",
      "Epoch 5268/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13004.1348 - val_loss: 18810.9707\n",
      "Epoch 5269/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12936.4131 - val_loss: 18840.4316\n",
      "Epoch 5270/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13029.3633 - val_loss: 18855.4961\n",
      "Epoch 5271/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13077.2373 - val_loss: 18821.2695\n",
      "Epoch 5272/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12974.9141 - val_loss: 18778.7129\n",
      "Epoch 5273/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12842.5381 - val_loss: 18777.4199\n",
      "Epoch 5274/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12834.1660 - val_loss: 18776.4980\n",
      "Epoch 5275/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12833.4092 - val_loss: 18771.5469\n",
      "Epoch 5276/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.3174 - val_loss: 18745.8926\n",
      "Epoch 5277/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12738.3877 - val_loss: 18715.7324\n",
      "Epoch 5278/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12670.2900 - val_loss: 18726.2148\n",
      "Epoch 5279/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12678.6494 - val_loss: 18790.3555\n",
      "Epoch 5280/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12880.8164 - val_loss: 18831.5391\n",
      "Epoch 5281/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13003.4443 - val_loss: 18823.7637\n",
      "Epoch 5282/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12978.5078 - val_loss: 18780.6621\n",
      "Epoch 5283/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12848.6943 - val_loss: 18740.7637\n",
      "Epoch 5284/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.2588 - val_loss: 18719.8828\n",
      "Epoch 5285/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.1982 - val_loss: 18697.8379\n",
      "Epoch 5286/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12583.7402 - val_loss: 19024.8535\n",
      "Epoch 5287/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13678.6748 - val_loss: 18929.1973\n",
      "Epoch 5288/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13321.6826 - val_loss: 19184.6973\n",
      "Epoch 5289/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14118.1699 - val_loss: 19360.5859\n",
      "Epoch 5290/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14666.7178 - val_loss: 19446.1367\n",
      "Epoch 5291/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14931.4385 - val_loss: 19463.0371\n",
      "Epoch 5292/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14983.8643 - val_loss: 19427.5762\n",
      "Epoch 5293/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14873.5928 - val_loss: 19378.3203\n",
      "Epoch 5294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14710.8818 - val_loss: 19370.7852\n",
      "Epoch 5295/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14686.1787 - val_loss: 19362.0215\n",
      "Epoch 5296/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14657.5088 - val_loss: 19326.5176\n",
      "Epoch 5297/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14545.7246 - val_loss: 19278.8613\n",
      "Epoch 5298/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14398.9307 - val_loss: 19213.0547\n",
      "Epoch 5299/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14201.2080 - val_loss: 19145.3027\n",
      "Epoch 5300/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13989.7871 - val_loss: 19093.6836\n",
      "Epoch 5301/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13826.3984 - val_loss: 19057.5762\n",
      "Epoch 5302/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13713.8535 - val_loss: 19043.7461\n",
      "Epoch 5303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13660.8623 - val_loss: 19050.6172\n",
      "Epoch 5304/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13680.2539 - val_loss: 19049.0527\n",
      "Epoch 5305/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13676.1396 - val_loss: 19026.5020\n",
      "Epoch 5306/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13605.7471 - val_loss: 19044.9746\n",
      "Epoch 5307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13669.1689 - val_loss: 19056.0859\n",
      "Epoch 5308/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13702.8096 - val_loss: 19006.5273\n",
      "Epoch 5309/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13544.0498 - val_loss: 18968.8203\n",
      "Epoch 5310/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13423.2617 - val_loss: 18967.6641\n",
      "Epoch 5311/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13423.0400 - val_loss: 18938.3398\n",
      "Epoch 5312/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13331.3516 - val_loss: 18929.9336\n",
      "Epoch 5313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13315.2725 - val_loss: 18909.7500\n",
      "Epoch 5314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13253.9795 - val_loss: 18876.0996\n",
      "Epoch 5315/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13149.2852 - val_loss: 18862.5176\n",
      "Epoch 5316/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13097.9385 - val_loss: 18864.8262\n",
      "Epoch 5317/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13105.7754 - val_loss: 18844.8203\n",
      "Epoch 5318/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13043.8271 - val_loss: 18833.1777\n",
      "Epoch 5319/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13016.0557 - val_loss: 18816.7441\n",
      "Epoch 5320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12961.0205 - val_loss: 18803.9160\n",
      "Epoch 5321/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12915.7188 - val_loss: 18783.0996\n",
      "Epoch 5322/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12846.4131 - val_loss: 18794.8828\n",
      "Epoch 5323/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12888.1865 - val_loss: 18785.6660\n",
      "Epoch 5324/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12862.7168 - val_loss: 18744.2461\n",
      "Epoch 5325/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.9609 - val_loss: 18713.3945\n",
      "Epoch 5326/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12640.1289 - val_loss: 18719.7246\n",
      "Epoch 5327/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.7070 - val_loss: 18719.6484\n",
      "Epoch 5328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12649.3965 - val_loss: 18705.2324\n",
      "Epoch 5329/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.7373 - val_loss: 18661.8965\n",
      "Epoch 5330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12471.0566 - val_loss: 18684.7031\n",
      "Epoch 5331/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.4824 - val_loss: 18746.5527\n",
      "Epoch 5332/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12739.1602 - val_loss: 18763.0566\n",
      "Epoch 5333/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12790.3438 - val_loss: 18769.8750\n",
      "Epoch 5334/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12815.8555 - val_loss: 18782.7637\n",
      "Epoch 5335/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12856.6689 - val_loss: 18760.7871\n",
      "Epoch 5336/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12782.5293 - val_loss: 18728.3984\n",
      "Epoch 5337/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12680.0596 - val_loss: 18708.6660\n",
      "Epoch 5338/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12620.3984 - val_loss: 18683.7812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5339/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.2158 - val_loss: 18697.9902\n",
      "Epoch 5340/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.6738 - val_loss: 18844.4688\n",
      "Epoch 5341/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13100.5654 - val_loss: 18962.2715\n",
      "Epoch 5342/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13421.9229 - val_loss: 19232.1992\n",
      "Epoch 5343/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14263.5381 - val_loss: 19387.2441\n",
      "Epoch 5344/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14747.3477 - val_loss: 19484.7617\n",
      "Epoch 5345/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15050.9863 - val_loss: 19545.5566\n",
      "Epoch 5346/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15241.2881 - val_loss: 19518.5508\n",
      "Epoch 5347/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15156.7734 - val_loss: 19449.6543\n",
      "Epoch 5348/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14934.7764 - val_loss: 19415.3945\n",
      "Epoch 5349/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14826.0049 - val_loss: 19386.1504\n",
      "Epoch 5350/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14734.9385 - val_loss: 19345.4688\n",
      "Epoch 5351/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14609.0879 - val_loss: 19254.7246\n",
      "Epoch 5352/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14326.0215 - val_loss: 19164.0508\n",
      "Epoch 5353/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14049.0508 - val_loss: 19142.6504\n",
      "Epoch 5354/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13976.5439 - val_loss: 19154.0625\n",
      "Epoch 5355/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14013.8037 - val_loss: 19145.2305\n",
      "Epoch 5356/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13984.9375 - val_loss: 19139.8145\n",
      "Epoch 5357/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13959.5654 - val_loss: 19131.4551\n",
      "Epoch 5358/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13931.0762 - val_loss: 19087.2383\n",
      "Epoch 5359/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13791.9883 - val_loss: 19032.8301\n",
      "Epoch 5360/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13627.5068 - val_loss: 18963.4434\n",
      "Epoch 5361/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13411.7207 - val_loss: 18960.4395\n",
      "Epoch 5362/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13401.5117 - val_loss: 19010.8320\n",
      "Epoch 5363/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13560.6797 - val_loss: 19014.1113\n",
      "Epoch 5364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13572.3789 - val_loss: 18970.0762\n",
      "Epoch 5365/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13433.0479 - val_loss: 18908.7754\n",
      "Epoch 5366/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13249.0449 - val_loss: 18898.7070\n",
      "Epoch 5367/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13218.7725 - val_loss: 18901.8320\n",
      "Epoch 5368/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13222.2715 - val_loss: 18890.5781\n",
      "Epoch 5369/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13183.9492 - val_loss: 18872.7148\n",
      "Epoch 5370/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13125.3516 - val_loss: 18832.8809\n",
      "Epoch 5371/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13007.2354 - val_loss: 18806.7109\n",
      "Epoch 5372/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12929.4941 - val_loss: 18789.4473\n",
      "Epoch 5373/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12878.5459 - val_loss: 18785.6387\n",
      "Epoch 5374/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.2510 - val_loss: 18785.9023\n",
      "Epoch 5375/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12859.5342 - val_loss: 18769.4297\n",
      "Epoch 5376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12813.1592 - val_loss: 18743.5254\n",
      "Epoch 5377/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12733.9824 - val_loss: 18722.9277\n",
      "Epoch 5378/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.0098 - val_loss: 18692.1582\n",
      "Epoch 5379/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12563.3945 - val_loss: 18701.3770\n",
      "Epoch 5380/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12601.1504 - val_loss: 18709.3457\n",
      "Epoch 5381/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12627.8516 - val_loss: 18946.4609\n",
      "Epoch 5382/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13425.3994 - val_loss: 18957.2715\n",
      "Epoch 5383/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13400.5742 - val_loss: 19234.5000\n",
      "Epoch 5384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14260.0605 - val_loss: 19404.8691\n",
      "Epoch 5385/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14789.6855 - val_loss: 19484.2090\n",
      "Epoch 5386/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15037.4746 - val_loss: 19482.1426\n",
      "Epoch 5387/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15032.3555 - val_loss: 19487.1113\n",
      "Epoch 5388/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15042.5098 - val_loss: 19473.7168\n",
      "Epoch 5389/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15008.9775 - val_loss: 19440.1719\n",
      "Epoch 5390/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14904.5156 - val_loss: 19378.8125\n",
      "Epoch 5391/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14713.0615 - val_loss: 19310.0586\n",
      "Epoch 5392/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14496.6191 - val_loss: 19234.4414\n",
      "Epoch 5393/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14268.3301 - val_loss: 19189.4238\n",
      "Epoch 5394/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14127.7930 - val_loss: 19185.3906\n",
      "Epoch 5395/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14110.7832 - val_loss: 19198.2090\n",
      "Epoch 5396/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14149.5459 - val_loss: 19161.1113\n",
      "Epoch 5397/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14033.6523 - val_loss: 19150.1055\n",
      "Epoch 5398/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13993.4453 - val_loss: 19135.8242\n",
      "Epoch 5399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13951.8809 - val_loss: 19092.4961\n",
      "Epoch 5400/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13814.3027 - val_loss: 19024.5664\n",
      "Epoch 5401/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13603.2578 - val_loss: 18982.7969\n",
      "Epoch 5402/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13476.7012 - val_loss: 18941.3418\n",
      "Epoch 5403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13346.3740 - val_loss: 18912.7754\n",
      "Epoch 5404/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13259.0479 - val_loss: 18919.5469\n",
      "Epoch 5405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13279.9473 - val_loss: 18940.3477\n",
      "Epoch 5406/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13338.6016 - val_loss: 18966.8320\n",
      "Epoch 5407/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13424.8623 - val_loss: 18962.7480\n",
      "Epoch 5408/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13410.8916 - val_loss: 18921.2285\n",
      "Epoch 5409/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13278.8613 - val_loss: 18880.0078\n",
      "Epoch 5410/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13159.9287 - val_loss: 18824.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5411/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12981.3389 - val_loss: 18804.3691\n",
      "Epoch 5412/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12919.3262 - val_loss: 18769.2129\n",
      "Epoch 5413/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12813.5566 - val_loss: 18802.7285\n",
      "Epoch 5414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12906.7383 - val_loss: 18809.8164\n",
      "Epoch 5415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12923.7432 - val_loss: 18792.1094\n",
      "Epoch 5416/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12872.4697 - val_loss: 18764.1875\n",
      "Epoch 5417/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12792.0889 - val_loss: 18742.3340\n",
      "Epoch 5418/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12732.6006 - val_loss: 18755.0195\n",
      "Epoch 5419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12770.8271 - val_loss: 18760.0254\n",
      "Epoch 5420/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12787.5156 - val_loss: 18839.1777\n",
      "Epoch 5421/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13062.7070 - val_loss: 18987.6465\n",
      "Epoch 5422/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13504.3691 - val_loss: 19236.2598\n",
      "Epoch 5423/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14279.3223 - val_loss: 19373.7012\n",
      "Epoch 5424/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14708.0732 - val_loss: 19413.9082\n",
      "Epoch 5425/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14832.5254 - val_loss: 19419.8711\n",
      "Epoch 5426/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14844.1377 - val_loss: 19398.1582\n",
      "Epoch 5427/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14775.5684 - val_loss: 19390.9180\n",
      "Epoch 5428/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14752.2539 - val_loss: 19431.8262\n",
      "Epoch 5429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14876.2012 - val_loss: 19404.0527\n",
      "Epoch 5430/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14798.1807 - val_loss: 19337.6855\n",
      "Epoch 5431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14590.4561 - val_loss: 19309.8477\n",
      "Epoch 5432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14493.9766 - val_loss: 19260.5234\n",
      "Epoch 5433/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14341.9404 - val_loss: 19242.2461\n",
      "Epoch 5434/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14283.7334 - val_loss: 19198.3125\n",
      "Epoch 5435/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14146.8125 - val_loss: 19158.4336\n",
      "Epoch 5436/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14017.8818 - val_loss: 19110.0098\n",
      "Epoch 5437/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13865.4453 - val_loss: 19072.1445\n",
      "Epoch 5438/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13750.2959 - val_loss: 19021.9492\n",
      "Epoch 5439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13604.0869 - val_loss: 18975.3672\n",
      "Epoch 5440/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13456.4121 - val_loss: 18955.2305\n",
      "Epoch 5441/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13392.0605 - val_loss: 18912.9023\n",
      "Epoch 5442/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13263.3926 - val_loss: 18922.5117\n",
      "Epoch 5443/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13284.3018 - val_loss: 18937.8516\n",
      "Epoch 5444/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13327.3994 - val_loss: 18943.4336\n",
      "Epoch 5445/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13347.8057 - val_loss: 18912.3867\n",
      "Epoch 5446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13255.4893 - val_loss: 18895.4375\n",
      "Epoch 5447/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13207.4541 - val_loss: 18881.3535\n",
      "Epoch 5448/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13160.2188 - val_loss: 18823.9766\n",
      "Epoch 5449/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12984.6855 - val_loss: 18824.8594\n",
      "Epoch 5450/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12981.3770 - val_loss: 18812.4180\n",
      "Epoch 5451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12943.0771 - val_loss: 18822.4629\n",
      "Epoch 5452/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12971.3555 - val_loss: 18828.2969\n",
      "Epoch 5453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12985.1562 - val_loss: 18806.9160\n",
      "Epoch 5454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12927.4248 - val_loss: 18751.9668\n",
      "Epoch 5455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12756.5000 - val_loss: 18695.6523\n",
      "Epoch 5456/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12585.2061 - val_loss: 18722.3770\n",
      "Epoch 5457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.8057 - val_loss: 18757.5723\n",
      "Epoch 5458/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12779.4463 - val_loss: 18776.3730\n",
      "Epoch 5459/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12835.1514 - val_loss: 18747.1523\n",
      "Epoch 5460/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.6250 - val_loss: 18717.3145\n",
      "Epoch 5461/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12652.4648 - val_loss: 18726.8281\n",
      "Epoch 5462/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.1445 - val_loss: 18719.6562\n",
      "Epoch 5463/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12648.5439 - val_loss: 18707.2051\n",
      "Epoch 5464/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.6807 - val_loss: 18685.4590\n",
      "Epoch 5465/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12549.3740 - val_loss: 18695.4570\n",
      "Epoch 5466/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12576.1035 - val_loss: 18725.3340\n",
      "Epoch 5467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.0088 - val_loss: 18724.9590\n",
      "Epoch 5468/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12668.9375 - val_loss: 18719.0938\n",
      "Epoch 5469/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.6357 - val_loss: 18675.5684\n",
      "Epoch 5470/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12518.6719 - val_loss: 18684.5625\n",
      "Epoch 5471/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12544.3828 - val_loss: 18709.8320\n",
      "Epoch 5472/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.2773 - val_loss: 18747.3945\n",
      "Epoch 5473/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12740.2422 - val_loss: 18741.5684\n",
      "Epoch 5474/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.0986 - val_loss: 18676.4941\n",
      "Epoch 5475/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12517.2061 - val_loss: 18667.3789\n",
      "Epoch 5476/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12489.6338 - val_loss: 18704.1016\n",
      "Epoch 5477/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.4824 - val_loss: 18701.0918\n",
      "Epoch 5478/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12594.2910 - val_loss: 18676.7383\n",
      "Epoch 5479/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12526.5645 - val_loss: 18667.0586\n",
      "Epoch 5480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12486.1689 - val_loss: 18663.9727\n",
      "Epoch 5481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12482.2246 - val_loss: 18683.2871\n",
      "Epoch 5482/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.5879 - val_loss: 18676.7656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5483/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.8145 - val_loss: 18688.9844\n",
      "Epoch 5484/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.4590 - val_loss: 18670.3496\n",
      "Epoch 5485/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12496.2715 - val_loss: 18662.0957\n",
      "Epoch 5486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12471.0762 - val_loss: 18688.5137\n",
      "Epoch 5487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12553.7842 - val_loss: 18713.8672\n",
      "Epoch 5488/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.7588 - val_loss: 18961.5684\n",
      "Epoch 5489/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13420.5293 - val_loss: 19240.5801\n",
      "Epoch 5490/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14290.7236 - val_loss: 19414.7695\n",
      "Epoch 5491/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14833.8291 - val_loss: 19513.8398\n",
      "Epoch 5492/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15134.2637 - val_loss: 19553.3301\n",
      "Epoch 5493/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15257.2588 - val_loss: 19519.1816\n",
      "Epoch 5494/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15149.0020 - val_loss: 19466.3184\n",
      "Epoch 5495/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14992.5723 - val_loss: 19392.3926\n",
      "Epoch 5496/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14761.5059 - val_loss: 19283.2090\n",
      "Epoch 5497/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14420.1406 - val_loss: 19256.5039\n",
      "Epoch 5498/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14330.4551 - val_loss: 19249.4082\n",
      "Epoch 5499/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14307.7354 - val_loss: 19214.0176\n",
      "Epoch 5500/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14197.8115 - val_loss: 19180.9902\n",
      "Epoch 5501/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14098.0234 - val_loss: 19134.7598\n",
      "Epoch 5502/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13953.1377 - val_loss: 19072.4727\n",
      "Epoch 5503/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13753.7441 - val_loss: 19064.7773\n",
      "Epoch 5504/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13723.6035 - val_loss: 19068.2109\n",
      "Epoch 5505/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13742.8672 - val_loss: 19052.5898\n",
      "Epoch 5506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13694.4238 - val_loss: 19024.0000\n",
      "Epoch 5507/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13598.4600 - val_loss: 19014.2676\n",
      "Epoch 5508/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13569.3691 - val_loss: 18985.3965\n",
      "Epoch 5509/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13490.6025 - val_loss: 18949.9336\n",
      "Epoch 5510/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13379.0742 - val_loss: 18945.3984\n",
      "Epoch 5511/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13353.1074 - val_loss: 18919.7383\n",
      "Epoch 5512/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13273.1133 - val_loss: 18899.7715\n",
      "Epoch 5513/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13218.6934 - val_loss: 18906.7793\n",
      "Epoch 5514/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13240.1211 - val_loss: 18899.3652\n",
      "Epoch 5515/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13211.8604 - val_loss: 18877.5020\n",
      "Epoch 5516/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13147.2139 - val_loss: 18863.3789\n",
      "Epoch 5517/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13104.1357 - val_loss: 18843.0352\n",
      "Epoch 5518/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13041.2314 - val_loss: 18844.2812\n",
      "Epoch 5519/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13040.4902 - val_loss: 18801.4238\n",
      "Epoch 5520/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12920.5566 - val_loss: 18743.1797\n",
      "Epoch 5521/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12732.4580 - val_loss: 18696.9707\n",
      "Epoch 5522/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12580.1064 - val_loss: 18712.7852\n",
      "Epoch 5523/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12630.2432 - val_loss: 18745.7949\n",
      "Epoch 5524/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.2432 - val_loss: 18781.0859\n",
      "Epoch 5525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12846.2041 - val_loss: 18792.4414\n",
      "Epoch 5526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12881.6162 - val_loss: 18788.1797\n",
      "Epoch 5527/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12860.9004 - val_loss: 18757.9375\n",
      "Epoch 5528/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.4189 - val_loss: 18731.4414\n",
      "Epoch 5529/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.1484 - val_loss: 18734.7969\n",
      "Epoch 5530/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12696.7490 - val_loss: 18756.1113\n",
      "Epoch 5531/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12768.4043 - val_loss: 18725.6191\n",
      "Epoch 5532/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12675.5400 - val_loss: 18759.5645\n",
      "Epoch 5533/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.9209 - val_loss: 18972.9160\n",
      "Epoch 5534/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13446.3604 - val_loss: 19262.8281\n",
      "Epoch 5535/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14346.0244 - val_loss: 19434.9551\n",
      "Epoch 5536/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14881.4277 - val_loss: 19559.0488\n",
      "Epoch 5537/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15260.5156 - val_loss: 19619.5469\n",
      "Epoch 5538/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15449.6406 - val_loss: 19605.9316\n",
      "Epoch 5539/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15408.2930 - val_loss: 19549.0234\n",
      "Epoch 5540/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15236.3545 - val_loss: 19540.0566\n",
      "Epoch 5541/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15212.8096 - val_loss: 19479.0410\n",
      "Epoch 5542/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15030.1582 - val_loss: 19406.3008\n",
      "Epoch 5543/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14799.8301 - val_loss: 19336.1270\n",
      "Epoch 5544/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14577.4072 - val_loss: 19254.2188\n",
      "Epoch 5545/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14328.0742 - val_loss: 19184.3750\n",
      "Epoch 5546/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14110.3115 - val_loss: 19098.1953\n",
      "Epoch 5547/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13834.5771 - val_loss: 19133.8066\n",
      "Epoch 5548/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13942.4531 - val_loss: 19191.3555\n",
      "Epoch 5549/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14120.8564 - val_loss: 19192.2305\n",
      "Epoch 5550/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14128.4785 - val_loss: 19158.9648\n",
      "Epoch 5551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14024.9736 - val_loss: 19086.3438\n",
      "Epoch 5552/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13790.8691 - val_loss: 19079.6680\n",
      "Epoch 5553/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13766.4248 - val_loss: 19058.5312\n",
      "Epoch 5554/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13709.7168 - val_loss: 19049.5430\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5555/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13681.9951 - val_loss: 19011.0312\n",
      "Epoch 5556/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13559.3271 - val_loss: 18966.9414\n",
      "Epoch 5557/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13420.9170 - val_loss: 18981.0820\n",
      "Epoch 5558/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13469.9268 - val_loss: 18989.6621\n",
      "Epoch 5559/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13499.3711 - val_loss: 18956.0020\n",
      "Epoch 5560/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13390.1328 - val_loss: 18901.1797\n",
      "Epoch 5561/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13221.6182 - val_loss: 18876.5117\n",
      "Epoch 5562/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13146.9951 - val_loss: 18862.7812\n",
      "Epoch 5563/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13099.6113 - val_loss: 18848.6289\n",
      "Epoch 5564/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13060.7256 - val_loss: 18831.2051\n",
      "Epoch 5565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13006.6895 - val_loss: 18825.1660\n",
      "Epoch 5566/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12982.3252 - val_loss: 18801.7520\n",
      "Epoch 5567/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12909.6543 - val_loss: 18763.4707\n",
      "Epoch 5568/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12791.1816 - val_loss: 18776.8145\n",
      "Epoch 5569/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12833.5410 - val_loss: 18759.7852\n",
      "Epoch 5570/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12784.9258 - val_loss: 18726.7754\n",
      "Epoch 5571/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12679.8047 - val_loss: 18828.6484\n",
      "Epoch 5572/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13033.2852 - val_loss: 19021.6680\n",
      "Epoch 5573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13613.4473 - val_loss: 19321.7246\n",
      "Epoch 5574/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14547.3154 - val_loss: 19503.4102\n",
      "Epoch 5575/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15114.5996 - val_loss: 19616.9941\n",
      "Epoch 5576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15465.8271 - val_loss: 19698.0859\n",
      "Epoch 5577/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15712.6191 - val_loss: 19722.8867\n",
      "Epoch 5578/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 15789.4238 - val_loss: 19699.7871\n",
      "Epoch 5579/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15717.5312 - val_loss: 19677.8164\n",
      "Epoch 5580/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15647.5059 - val_loss: 19632.5391\n",
      "Epoch 5581/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15513.3545 - val_loss: 19605.0488\n",
      "Epoch 5582/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15425.3594 - val_loss: 19538.4316\n",
      "Epoch 5583/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15218.0996 - val_loss: 19408.1211\n",
      "Epoch 5584/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14805.4814 - val_loss: 19399.2070\n",
      "Epoch 5585/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14770.8057 - val_loss: 19354.1094\n",
      "Epoch 5586/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14633.7422 - val_loss: 19304.3359\n",
      "Epoch 5587/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14479.1904 - val_loss: 19271.3066\n",
      "Epoch 5588/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14372.6230 - val_loss: 19212.9648\n",
      "Epoch 5589/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14196.0693 - val_loss: 19137.8750\n",
      "Epoch 5590/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13966.0244 - val_loss: 19073.9883\n",
      "Epoch 5591/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13765.4648 - val_loss: 18987.5996\n",
      "Epoch 5592/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13495.4512 - val_loss: 18909.6797\n",
      "Epoch 5593/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13250.9229 - val_loss: 18960.6719\n",
      "Epoch 5594/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13404.0684 - val_loss: 19013.9258\n",
      "Epoch 5595/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13569.1328 - val_loss: 19018.3320\n",
      "Epoch 5596/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13584.6992 - val_loss: 19028.5898\n",
      "Epoch 5597/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13615.4707 - val_loss: 19016.3691\n",
      "Epoch 5598/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13583.3438 - val_loss: 18953.3418\n",
      "Epoch 5599/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13376.6855 - val_loss: 18907.7422\n",
      "Epoch 5600/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13239.9814 - val_loss: 18858.4355\n",
      "Epoch 5601/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13088.4609 - val_loss: 18865.3320\n",
      "Epoch 5602/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13112.5225 - val_loss: 18847.2344\n",
      "Epoch 5603/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13057.6709 - val_loss: 18819.4707\n",
      "Epoch 5604/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12967.6963 - val_loss: 18814.2500\n",
      "Epoch 5605/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12948.7734 - val_loss: 18810.7852\n",
      "Epoch 5606/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12936.1709 - val_loss: 18790.7773\n",
      "Epoch 5607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.4346 - val_loss: 18815.7422\n",
      "Epoch 5608/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12961.3848 - val_loss: 18827.0898\n",
      "Epoch 5609/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12996.0068 - val_loss: 18787.0137\n",
      "Epoch 5610/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12865.0342 - val_loss: 18776.1309\n",
      "Epoch 5611/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12843.4463 - val_loss: 18806.2578\n",
      "Epoch 5612/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12933.3955 - val_loss: 18892.4805\n",
      "Epoch 5613/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13210.0635 - val_loss: 18924.7500\n",
      "Epoch 5614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13309.3555 - val_loss: 18903.3574\n",
      "Epoch 5615/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13240.7852 - val_loss: 18894.6562\n",
      "Epoch 5616/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13204.5166 - val_loss: 18847.6133\n",
      "Epoch 5617/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13058.0596 - val_loss: 18804.1484\n",
      "Epoch 5618/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12918.6758 - val_loss: 18796.5684\n",
      "Epoch 5619/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12893.3066 - val_loss: 18810.5000\n",
      "Epoch 5620/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12935.5518 - val_loss: 18819.4824\n",
      "Epoch 5621/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12969.3271 - val_loss: 18817.0078\n",
      "Epoch 5622/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12957.8359 - val_loss: 18800.8223\n",
      "Epoch 5623/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12907.3379 - val_loss: 18794.3711\n",
      "Epoch 5624/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12883.0254 - val_loss: 18775.1289\n",
      "Epoch 5625/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12827.9756 - val_loss: 18741.7227\n",
      "Epoch 5626/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12720.7412 - val_loss: 18754.9551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5627/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12768.3867 - val_loss: 18763.1758\n",
      "Epoch 5628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12797.2490 - val_loss: 18726.3672\n",
      "Epoch 5629/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12676.8643 - val_loss: 18698.2148\n",
      "Epoch 5630/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12589.8799 - val_loss: 18705.5781\n",
      "Epoch 5631/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.7617 - val_loss: 18698.5664\n",
      "Epoch 5632/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12588.0107 - val_loss: 18698.7188\n",
      "Epoch 5633/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12592.3867 - val_loss: 18694.6816\n",
      "Epoch 5634/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12573.5117 - val_loss: 18751.8555\n",
      "Epoch 5635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12771.8994 - val_loss: 18998.7852\n",
      "Epoch 5636/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13541.1631 - val_loss: 19314.8379\n",
      "Epoch 5637/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14526.3242 - val_loss: 19517.5859\n",
      "Epoch 5638/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15158.5146 - val_loss: 19627.1348\n",
      "Epoch 5639/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15499.9473 - val_loss: 19664.7402\n",
      "Epoch 5640/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15617.3164 - val_loss: 19648.6836\n",
      "Epoch 5641/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15566.4971 - val_loss: 19561.3887\n",
      "Epoch 5642/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15288.6855 - val_loss: 19477.1777\n",
      "Epoch 5643/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15025.1221 - val_loss: 19392.4102\n",
      "Epoch 5644/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14760.4277 - val_loss: 19306.1016\n",
      "Epoch 5645/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14480.5078 - val_loss: 19283.3867\n",
      "Epoch 5646/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14408.1953 - val_loss: 19258.9219\n",
      "Epoch 5647/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14343.5322 - val_loss: 19235.6211\n",
      "Epoch 5648/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14266.0713 - val_loss: 19202.0664\n",
      "Epoch 5649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14160.5771 - val_loss: 19176.8145\n",
      "Epoch 5650/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14082.8672 - val_loss: 19161.8926\n",
      "Epoch 5651/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14028.6494 - val_loss: 19144.5781\n",
      "Epoch 5652/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13976.1221 - val_loss: 19082.4922\n",
      "Epoch 5653/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13781.3896 - val_loss: 19039.1211\n",
      "Epoch 5654/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13654.1572 - val_loss: 19031.1016\n",
      "Epoch 5655/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13627.3252 - val_loss: 18981.3281\n",
      "Epoch 5656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13466.8594 - val_loss: 18905.4355\n",
      "Epoch 5657/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13233.5283 - val_loss: 18859.9414\n",
      "Epoch 5658/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13090.8516 - val_loss: 18875.1914\n",
      "Epoch 5659/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13148.1699 - val_loss: 18861.3691\n",
      "Epoch 5660/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13101.6621 - val_loss: 18844.4434\n",
      "Epoch 5661/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13046.1875 - val_loss: 18840.2207\n",
      "Epoch 5662/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13029.4873 - val_loss: 18801.7656\n",
      "Epoch 5663/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.9951 - val_loss: 18783.9492\n",
      "Epoch 5664/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.7646 - val_loss: 18809.2812\n",
      "Epoch 5665/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12954.9795 - val_loss: 18887.4824\n",
      "Epoch 5666/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13187.1309 - val_loss: 19078.1621\n",
      "Epoch 5667/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13783.8770 - val_loss: 19187.8203\n",
      "Epoch 5668/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14128.2207 - val_loss: 19213.7754\n",
      "Epoch 5669/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14212.7012 - val_loss: 19180.8984\n",
      "Epoch 5670/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14103.1230 - val_loss: 19145.4922\n",
      "Epoch 5671/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13992.2900 - val_loss: 19107.7930\n",
      "Epoch 5672/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13874.9258 - val_loss: 19064.7383\n",
      "Epoch 5673/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13734.8604 - val_loss: 19014.9590\n",
      "Epoch 5674/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13577.1699 - val_loss: 18956.5996\n",
      "Epoch 5675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13397.0908 - val_loss: 18948.5977\n",
      "Epoch 5676/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13373.1631 - val_loss: 18944.0488\n",
      "Epoch 5677/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13347.9951 - val_loss: 18935.5176\n",
      "Epoch 5678/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13327.7490 - val_loss: 18940.3203\n",
      "Epoch 5679/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13345.4658 - val_loss: 18912.1855\n",
      "Epoch 5680/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13251.6426 - val_loss: 18884.9492\n",
      "Epoch 5681/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13171.4287 - val_loss: 18860.8867\n",
      "Epoch 5682/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13099.1465 - val_loss: 18818.3125\n",
      "Epoch 5683/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12965.7891 - val_loss: 18785.2832\n",
      "Epoch 5684/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12860.9355 - val_loss: 18781.6016\n",
      "Epoch 5685/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12851.2510 - val_loss: 18829.8691\n",
      "Epoch 5686/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12995.3252 - val_loss: 18823.8457\n",
      "Epoch 5687/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12980.7666 - val_loss: 18799.9160\n",
      "Epoch 5688/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12901.0596 - val_loss: 18793.3711\n",
      "Epoch 5689/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12887.7891 - val_loss: 18757.5293\n",
      "Epoch 5690/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12772.4395 - val_loss: 18765.9805\n",
      "Epoch 5691/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12805.9990 - val_loss: 18785.9766\n",
      "Epoch 5692/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12867.9033 - val_loss: 18754.7383\n",
      "Epoch 5693/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12771.0527 - val_loss: 18746.9863\n",
      "Epoch 5694/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12742.9258 - val_loss: 18745.9141\n",
      "Epoch 5695/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12738.6875 - val_loss: 18737.8652\n",
      "Epoch 5696/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.0049 - val_loss: 18753.1348\n",
      "Epoch 5697/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.3193 - val_loss: 18731.3711\n",
      "Epoch 5698/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12694.4385 - val_loss: 18697.5605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5699/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12591.1670 - val_loss: 18677.7266\n",
      "Epoch 5700/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12520.6738 - val_loss: 18705.9727\n",
      "Epoch 5701/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12610.6729 - val_loss: 18703.6973\n",
      "Epoch 5702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12604.9609 - val_loss: 18684.0430\n",
      "Epoch 5703/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12555.8711 - val_loss: 18743.4531\n",
      "Epoch 5704/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.8379 - val_loss: 18785.0762\n",
      "Epoch 5705/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.1523 - val_loss: 18795.5117\n",
      "Epoch 5706/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12900.5029 - val_loss: 18769.5820\n",
      "Epoch 5707/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12819.4180 - val_loss: 18745.1914\n",
      "Epoch 5708/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.6006 - val_loss: 18726.6719\n",
      "Epoch 5709/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12682.0508 - val_loss: 18721.2402\n",
      "Epoch 5710/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.2305 - val_loss: 18883.6562\n",
      "Epoch 5711/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13213.0420 - val_loss: 18960.3984\n",
      "Epoch 5712/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13421.1768 - val_loss: 19284.1367\n",
      "Epoch 5713/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14429.0342 - val_loss: 19495.1523\n",
      "Epoch 5714/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15086.0752 - val_loss: 19637.8477\n",
      "Epoch 5715/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15528.2314 - val_loss: 19714.9238\n",
      "Epoch 5716/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15766.2861 - val_loss: 19745.2383\n",
      "Epoch 5717/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15860.8291 - val_loss: 19721.1191\n",
      "Epoch 5718/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15782.3564 - val_loss: 19675.0254\n",
      "Epoch 5719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15642.9668 - val_loss: 19608.5137\n",
      "Epoch 5720/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15435.1211 - val_loss: 19529.1797\n",
      "Epoch 5721/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 15188.0947 - val_loss: 19438.9414\n",
      "Epoch 5722/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14905.0049 - val_loss: 19373.5449\n",
      "Epoch 5723/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14699.0107 - val_loss: 19335.1270\n",
      "Epoch 5724/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14578.0000 - val_loss: 19282.4609\n",
      "Epoch 5725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14413.0215 - val_loss: 19250.3633\n",
      "Epoch 5726/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14310.5527 - val_loss: 19234.7559\n",
      "Epoch 5727/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14262.8125 - val_loss: 19192.4238\n",
      "Epoch 5728/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14130.3838 - val_loss: 19107.3320\n",
      "Epoch 5729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13865.1279 - val_loss: 18996.9785\n",
      "Epoch 5730/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13512.4561 - val_loss: 18964.8984\n",
      "Epoch 5731/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13418.9639 - val_loss: 18961.5293\n",
      "Epoch 5732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13405.8779 - val_loss: 18957.6992\n",
      "Epoch 5733/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13396.7188 - val_loss: 18966.9336\n",
      "Epoch 5734/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13423.8525 - val_loss: 18979.4219\n",
      "Epoch 5735/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13464.7646 - val_loss: 18975.7832\n",
      "Epoch 5736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13451.6309 - val_loss: 18942.2266\n",
      "Epoch 5737/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13350.6133 - val_loss: 18922.3145\n",
      "Epoch 5738/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13287.8906 - val_loss: 18870.7246\n",
      "Epoch 5739/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13128.7490 - val_loss: 18830.1680\n",
      "Epoch 5740/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13003.7969 - val_loss: 18798.7031\n",
      "Epoch 5741/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12902.5713 - val_loss: 18769.1641\n",
      "Epoch 5742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12810.6982 - val_loss: 18783.5039\n",
      "Epoch 5743/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12858.5059 - val_loss: 18782.1367\n",
      "Epoch 5744/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12854.7109 - val_loss: 18764.4375\n",
      "Epoch 5745/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.6963 - val_loss: 18710.1875\n",
      "Epoch 5746/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12626.2168 - val_loss: 18713.5703\n",
      "Epoch 5747/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12636.9883 - val_loss: 18719.2949\n",
      "Epoch 5748/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.6953 - val_loss: 18728.8867\n",
      "Epoch 5749/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12690.1230 - val_loss: 18832.5352\n",
      "Epoch 5750/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13043.8545 - val_loss: 18970.7207\n",
      "Epoch 5751/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13436.8760 - val_loss: 19235.7207\n",
      "Epoch 5752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14269.4521 - val_loss: 19433.6777\n",
      "Epoch 5753/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14888.8584 - val_loss: 19555.2285\n",
      "Epoch 5754/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15275.0322 - val_loss: 19638.8887\n",
      "Epoch 5755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15528.8848 - val_loss: 19661.3828\n",
      "Epoch 5756/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15600.4678 - val_loss: 19660.0957\n",
      "Epoch 5757/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15598.6826 - val_loss: 19622.9355\n",
      "Epoch 5758/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15482.6660 - val_loss: 19541.1973\n",
      "Epoch 5759/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15222.7119 - val_loss: 19430.8711\n",
      "Epoch 5760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14878.8408 - val_loss: 19331.1641\n",
      "Epoch 5761/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14571.9932 - val_loss: 19299.5742\n",
      "Epoch 5762/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14474.2314 - val_loss: 19266.8984\n",
      "Epoch 5763/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14366.6738 - val_loss: 19192.7344\n",
      "Epoch 5764/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14135.7500 - val_loss: 19124.5586\n",
      "Epoch 5765/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13927.6680 - val_loss: 19089.9551\n",
      "Epoch 5766/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13816.1045 - val_loss: 19045.8125\n",
      "Epoch 5767/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13668.4199 - val_loss: 19035.7305\n",
      "Epoch 5768/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13635.1309 - val_loss: 19030.7129\n",
      "Epoch 5769/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13621.6553 - val_loss: 19029.1914\n",
      "Epoch 5770/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13622.7227 - val_loss: 19099.5469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5771/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13837.9062 - val_loss: 19116.8750\n",
      "Epoch 5772/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13888.2422 - val_loss: 19066.6445\n",
      "Epoch 5773/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13732.8486 - val_loss: 19002.0176\n",
      "Epoch 5774/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13526.8154 - val_loss: 18928.9766\n",
      "Epoch 5775/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13303.8633 - val_loss: 18890.4727\n",
      "Epoch 5776/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13182.1973 - val_loss: 18887.6426\n",
      "Epoch 5777/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13183.1934 - val_loss: 18889.9629\n",
      "Epoch 5778/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13184.7852 - val_loss: 18871.6934\n",
      "Epoch 5779/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13130.2822 - val_loss: 18844.7246\n",
      "Epoch 5780/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13048.1904 - val_loss: 18824.6016\n",
      "Epoch 5781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12991.4678 - val_loss: 18769.4785\n",
      "Epoch 5782/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12812.7881 - val_loss: 18743.4590\n",
      "Epoch 5783/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12737.3340 - val_loss: 18758.4492\n",
      "Epoch 5784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.9775 - val_loss: 18750.9336\n",
      "Epoch 5785/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12752.6279 - val_loss: 18775.4414\n",
      "Epoch 5786/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12854.9141 - val_loss: 18805.6777\n",
      "Epoch 5787/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12932.8750 - val_loss: 18958.5801\n",
      "Epoch 5788/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13412.4326 - val_loss: 19046.4277\n",
      "Epoch 5789/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13682.2695 - val_loss: 19091.6914\n",
      "Epoch 5790/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13820.2725 - val_loss: 19105.5137\n",
      "Epoch 5791/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13869.8525 - val_loss: 19101.4492\n",
      "Epoch 5792/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13853.9297 - val_loss: 19086.0234\n",
      "Epoch 5793/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13801.3389 - val_loss: 19052.6934\n",
      "Epoch 5794/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13695.1523 - val_loss: 19035.2949\n",
      "Epoch 5795/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13643.3145 - val_loss: 18974.7695\n",
      "Epoch 5796/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13460.8174 - val_loss: 18888.6387\n",
      "Epoch 5797/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13194.3633 - val_loss: 18848.7754\n",
      "Epoch 5798/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13068.3682 - val_loss: 18843.1328\n",
      "Epoch 5799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13046.2529 - val_loss: 18830.7969\n",
      "Epoch 5800/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13003.0967 - val_loss: 18904.7715\n",
      "Epoch 5801/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13249.7188 - val_loss: 18856.6191\n",
      "Epoch 5802/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13089.5146 - val_loss: 19023.2891\n",
      "Epoch 5803/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13611.8896 - val_loss: 19172.7715\n",
      "Epoch 5804/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14082.0381 - val_loss: 19259.5566\n",
      "Epoch 5805/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14351.7744 - val_loss: 19282.7852\n",
      "Epoch 5806/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14425.3594 - val_loss: 19273.1445\n",
      "Epoch 5807/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14392.6641 - val_loss: 19262.0781\n",
      "Epoch 5808/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14356.2871 - val_loss: 19244.6113\n",
      "Epoch 5809/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14302.1572 - val_loss: 19149.2871\n",
      "Epoch 5810/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14004.1553 - val_loss: 19049.5684\n",
      "Epoch 5811/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13687.9238 - val_loss: 19007.5254\n",
      "Epoch 5812/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13553.3555 - val_loss: 18991.5664\n",
      "Epoch 5813/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13500.9971 - val_loss: 18983.7051\n",
      "Epoch 5814/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13475.2188 - val_loss: 18996.0469\n",
      "Epoch 5815/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13512.8398 - val_loss: 18967.6152\n",
      "Epoch 5816/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13421.0684 - val_loss: 18952.0977\n",
      "Epoch 5817/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13368.3613 - val_loss: 18972.8301\n",
      "Epoch 5818/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13435.9482 - val_loss: 18922.9707\n",
      "Epoch 5819/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13279.7324 - val_loss: 18884.6152\n",
      "Epoch 5820/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13177.5811 - val_loss: 18870.7715\n",
      "Epoch 5821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13134.9219 - val_loss: 18867.6191\n",
      "Epoch 5822/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13130.1426 - val_loss: 18883.5605\n",
      "Epoch 5823/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13178.7686 - val_loss: 18892.9805\n",
      "Epoch 5824/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13201.0049 - val_loss: 18863.7988\n",
      "Epoch 5825/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13110.4854 - val_loss: 18799.1719\n",
      "Epoch 5826/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12907.2764 - val_loss: 18754.2949\n",
      "Epoch 5827/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12759.9258 - val_loss: 18748.1152\n",
      "Epoch 5828/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.7324 - val_loss: 18998.6523\n",
      "Epoch 5829/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13560.5068 - val_loss: 18867.8340\n",
      "Epoch 5830/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13127.4688 - val_loss: 19091.8359\n",
      "Epoch 5831/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13827.8574 - val_loss: 19249.7305\n",
      "Epoch 5832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14319.6562 - val_loss: 19324.0820\n",
      "Epoch 5833/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14551.3535 - val_loss: 19340.6504\n",
      "Epoch 5834/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14605.6523 - val_loss: 19336.4219\n",
      "Epoch 5835/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14592.3398 - val_loss: 19338.5469\n",
      "Epoch 5836/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14595.5156 - val_loss: 19297.3516\n",
      "Epoch 5837/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14467.3691 - val_loss: 19273.7090\n",
      "Epoch 5838/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14391.3584 - val_loss: 19281.0137\n",
      "Epoch 5839/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14411.9609 - val_loss: 19229.8398\n",
      "Epoch 5840/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14250.9482 - val_loss: 19154.7715\n",
      "Epoch 5841/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14019.3291 - val_loss: 19086.7383\n",
      "Epoch 5842/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13808.3105 - val_loss: 19086.6523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13804.9854 - val_loss: 19081.6504\n",
      "Epoch 5844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13786.4082 - val_loss: 19028.1992\n",
      "Epoch 5845/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13619.7852 - val_loss: 18980.7012\n",
      "Epoch 5846/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13472.3457 - val_loss: 19002.5605\n",
      "Epoch 5847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13537.5283 - val_loss: 18981.1094\n",
      "Epoch 5848/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13468.5342 - val_loss: 18954.8398\n",
      "Epoch 5849/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13386.5713 - val_loss: 18921.9375\n",
      "Epoch 5850/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13293.1650 - val_loss: 18900.5059\n",
      "Epoch 5851/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13227.0156 - val_loss: 18869.8926\n",
      "Epoch 5852/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13125.6934 - val_loss: 18866.0820\n",
      "Epoch 5853/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13108.3154 - val_loss: 18860.7676\n",
      "Epoch 5854/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13091.2715 - val_loss: 18833.5078\n",
      "Epoch 5855/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13007.4912 - val_loss: 18818.2559\n",
      "Epoch 5856/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12957.0596 - val_loss: 18798.5684\n",
      "Epoch 5857/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12896.2012 - val_loss: 18779.3242\n",
      "Epoch 5858/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12846.5996 - val_loss: 18794.7793\n",
      "Epoch 5859/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12900.8633 - val_loss: 18761.7090\n",
      "Epoch 5860/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12790.3916 - val_loss: 18742.7676\n",
      "Epoch 5861/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.1309 - val_loss: 18750.1426\n",
      "Epoch 5862/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.7314 - val_loss: 18778.5859\n",
      "Epoch 5863/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12838.7695 - val_loss: 18755.3164\n",
      "Epoch 5864/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.6572 - val_loss: 18728.6426\n",
      "Epoch 5865/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12679.9844 - val_loss: 18745.0645\n",
      "Epoch 5866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12736.1748 - val_loss: 18756.1699\n",
      "Epoch 5867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.0625 - val_loss: 18737.8633\n",
      "Epoch 5868/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12709.0000 - val_loss: 18733.5332\n",
      "Epoch 5869/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12699.7441 - val_loss: 18713.2031\n",
      "Epoch 5870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.4766 - val_loss: 18724.4414\n",
      "Epoch 5871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12670.2754 - val_loss: 18734.1113\n",
      "Epoch 5872/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.8135 - val_loss: 18728.4805\n",
      "Epoch 5873/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12686.7861 - val_loss: 18702.2637\n",
      "Epoch 5874/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.4854 - val_loss: 18705.4355\n",
      "Epoch 5875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.9365 - val_loss: 18732.4492\n",
      "Epoch 5876/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12702.0645 - val_loss: 18730.5234\n",
      "Epoch 5877/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.8066 - val_loss: 18710.6191\n",
      "Epoch 5878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12631.2812 - val_loss: 18718.8750\n",
      "Epoch 5879/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.6270 - val_loss: 18708.1426\n",
      "Epoch 5880/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12626.3203 - val_loss: 18692.2246\n",
      "Epoch 5881/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12564.4805 - val_loss: 18685.0566\n",
      "Epoch 5882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12538.2764 - val_loss: 18685.6719\n",
      "Epoch 5883/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.9561 - val_loss: 18678.6562\n",
      "Epoch 5884/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.7227 - val_loss: 18666.7949\n",
      "Epoch 5885/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12491.6973 - val_loss: 18669.6191\n",
      "Epoch 5886/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12500.9043 - val_loss: 18668.9336\n",
      "Epoch 5887/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.2578 - val_loss: 18676.8418\n",
      "Epoch 5888/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.3311 - val_loss: 18673.7969\n",
      "Epoch 5889/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.7207 - val_loss: 18687.5527\n",
      "Epoch 5890/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12559.8379 - val_loss: 18671.2285\n",
      "Epoch 5891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12503.6211 - val_loss: 18683.2246\n",
      "Epoch 5892/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.4541 - val_loss: 18693.4043\n",
      "Epoch 5893/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12572.7402 - val_loss: 18684.1094\n",
      "Epoch 5894/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.7725 - val_loss: 18684.7285\n",
      "Epoch 5895/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12548.3057 - val_loss: 18693.3984\n",
      "Epoch 5896/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12573.5342 - val_loss: 18682.5938\n",
      "Epoch 5897/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12541.3262 - val_loss: 18674.9043\n",
      "Epoch 5898/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12515.8457 - val_loss: 18680.3320\n",
      "Epoch 5899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12527.7490 - val_loss: 18697.4551\n",
      "Epoch 5900/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12588.9873 - val_loss: 18695.2598\n",
      "Epoch 5901/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12583.3672 - val_loss: 18674.0781\n",
      "Epoch 5902/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.7822 - val_loss: 18678.3359\n",
      "Epoch 5903/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12529.9121 - val_loss: 18673.8828\n",
      "Epoch 5904/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12514.7998 - val_loss: 18877.4766\n",
      "Epoch 5905/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13228.2969 - val_loss: 18888.7090\n",
      "Epoch 5906/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13187.9893 - val_loss: 19127.4512\n",
      "Epoch 5907/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13931.9570 - val_loss: 19272.3945\n",
      "Epoch 5908/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14386.4521 - val_loss: 19344.0840\n",
      "Epoch 5909/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14611.2285 - val_loss: 19372.2441\n",
      "Epoch 5910/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14699.1484 - val_loss: 19414.0352\n",
      "Epoch 5911/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14825.8174 - val_loss: 19400.0137\n",
      "Epoch 5912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14780.2920 - val_loss: 19348.4238\n",
      "Epoch 5913/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14619.3936 - val_loss: 19307.5859\n",
      "Epoch 5914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14496.2461 - val_loss: 19261.6582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5915/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14354.3887 - val_loss: 19227.2715\n",
      "Epoch 5916/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14244.5840 - val_loss: 19220.9746\n",
      "Epoch 5917/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14220.9756 - val_loss: 19202.7168\n",
      "Epoch 5918/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14165.4492 - val_loss: 19149.8281\n",
      "Epoch 5919/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13996.6123 - val_loss: 19090.9336\n",
      "Epoch 5920/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13813.2930 - val_loss: 19048.9375\n",
      "Epoch 5921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13678.7334 - val_loss: 19012.1758\n",
      "Epoch 5922/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13566.6641 - val_loss: 19012.8926\n",
      "Epoch 5923/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13566.8936 - val_loss: 19012.4277\n",
      "Epoch 5924/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13567.6484 - val_loss: 18991.2422\n",
      "Epoch 5925/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13503.4053 - val_loss: 18997.5996\n",
      "Epoch 5926/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13520.7246 - val_loss: 19000.5664\n",
      "Epoch 5927/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13525.7832 - val_loss: 18961.8926\n",
      "Epoch 5928/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13411.7842 - val_loss: 18933.3750\n",
      "Epoch 5929/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13325.4795 - val_loss: 18905.3301\n",
      "Epoch 5930/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13240.1934 - val_loss: 18879.9004\n",
      "Epoch 5931/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13156.9766 - val_loss: 18920.6562\n",
      "Epoch 5932/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13285.6494 - val_loss: 18925.6660\n",
      "Epoch 5933/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13300.9648 - val_loss: 18893.2090\n",
      "Epoch 5934/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13200.5020 - val_loss: 18858.0645\n",
      "Epoch 5935/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13082.1465 - val_loss: 18833.9551\n",
      "Epoch 5936/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13010.4287 - val_loss: 18828.8145\n",
      "Epoch 5937/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12995.4805 - val_loss: 18813.2617\n",
      "Epoch 5938/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12950.5508 - val_loss: 18784.7832\n",
      "Epoch 5939/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12862.9551 - val_loss: 18770.6445\n",
      "Epoch 5940/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12818.3242 - val_loss: 18758.0645\n",
      "Epoch 5941/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12779.3242 - val_loss: 18796.6016\n",
      "Epoch 5942/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12894.7490 - val_loss: 18789.4238\n",
      "Epoch 5943/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12874.3213 - val_loss: 18753.5566\n",
      "Epoch 5944/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.3311 - val_loss: 18717.3262\n",
      "Epoch 5945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.7656 - val_loss: 18864.1836\n",
      "Epoch 5946/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13186.6006 - val_loss: 18874.6465\n",
      "Epoch 5947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13147.0127 - val_loss: 19095.9863\n",
      "Epoch 5948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13837.1064 - val_loss: 19250.2754\n",
      "Epoch 5949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14314.6016 - val_loss: 19308.4980\n",
      "Epoch 5950/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14499.8916 - val_loss: 19328.1328\n",
      "Epoch 5951/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14561.8389 - val_loss: 19332.2910\n",
      "Epoch 5952/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14571.1436 - val_loss: 19315.9180\n",
      "Epoch 5953/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14519.8926 - val_loss: 19324.2480\n",
      "Epoch 5954/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14549.2549 - val_loss: 19321.7891\n",
      "Epoch 5955/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14540.2207 - val_loss: 19287.9336\n",
      "Epoch 5956/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14432.2100 - val_loss: 19223.6895\n",
      "Epoch 5957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14225.5674 - val_loss: 19148.1191\n",
      "Epoch 5958/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14001.7686 - val_loss: 19104.7109\n",
      "Epoch 5959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13862.9912 - val_loss: 19091.5137\n",
      "Epoch 5960/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13812.0752 - val_loss: 19097.9883\n",
      "Epoch 5961/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13834.8574 - val_loss: 19080.0312\n",
      "Epoch 5962/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13782.0293 - val_loss: 19060.5566\n",
      "Epoch 5963/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13719.5000 - val_loss: 19016.4238\n",
      "Epoch 5964/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13578.3145 - val_loss: 18963.3066\n",
      "Epoch 5965/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13412.5518 - val_loss: 18905.5742\n",
      "Epoch 5966/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13234.2432 - val_loss: 18854.8008\n",
      "Epoch 5967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13072.1973 - val_loss: 18898.8125\n",
      "Epoch 5968/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13208.6973 - val_loss: 18898.0684\n",
      "Epoch 5969/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13209.8418 - val_loss: 18890.5430\n",
      "Epoch 5970/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13193.8145 - val_loss: 18905.0527\n",
      "Epoch 5971/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13239.9131 - val_loss: 18888.2832\n",
      "Epoch 5972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13187.1289 - val_loss: 18865.5879\n",
      "Epoch 5973/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13112.3604 - val_loss: 18814.4590\n",
      "Epoch 5974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12955.2051 - val_loss: 18797.9238\n",
      "Epoch 5975/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12903.3418 - val_loss: 18794.3320\n",
      "Epoch 5976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12883.3252 - val_loss: 18788.5449\n",
      "Epoch 5977/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12868.1494 - val_loss: 18764.8672\n",
      "Epoch 5978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.6006 - val_loss: 18745.2129\n",
      "Epoch 5979/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12739.2676 - val_loss: 18755.3574\n",
      "Epoch 5980/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12765.1143 - val_loss: 18746.2988\n",
      "Epoch 5981/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.2002 - val_loss: 18716.6914\n",
      "Epoch 5982/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.0859 - val_loss: 18733.5742\n",
      "Epoch 5983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12695.4756 - val_loss: 18746.4785\n",
      "Epoch 5984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12739.9492 - val_loss: 18748.5801\n",
      "Epoch 5985/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.6270 - val_loss: 18729.9883\n",
      "Epoch 5986/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12689.5420 - val_loss: 18724.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5987/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12667.3613 - val_loss: 18742.1621\n",
      "Epoch 5988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12723.6836 - val_loss: 18723.1777\n",
      "Epoch 5989/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12668.1426 - val_loss: 18700.1777\n",
      "Epoch 5990/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12592.6699 - val_loss: 18699.4121\n",
      "Epoch 5991/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.0068 - val_loss: 18693.9043\n",
      "Epoch 5992/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.6113 - val_loss: 18695.1035\n",
      "Epoch 5993/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12581.4180 - val_loss: 18690.8711\n",
      "Epoch 5994/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.3643 - val_loss: 18681.1191\n",
      "Epoch 5995/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12537.8945 - val_loss: 18666.9844\n",
      "Epoch 5996/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12493.0459 - val_loss: 18703.1602\n",
      "Epoch 5997/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12651.8154 - val_loss: 18830.8750\n",
      "Epoch 5998/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13008.9102 - val_loss: 19008.9414\n",
      "Epoch 5999/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13563.6445 - val_loss: 19113.2168\n",
      "Epoch 6000/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13891.3125 - val_loss: 19173.9922\n",
      "Epoch 6001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14081.5684 - val_loss: 19188.8320\n",
      "Epoch 6002/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14127.8643 - val_loss: 19181.3535\n",
      "Epoch 6003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14101.3926 - val_loss: 19174.9531\n",
      "Epoch 6004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14082.0449 - val_loss: 19125.6465\n",
      "Epoch 6005/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13927.6689 - val_loss: 19073.2383\n",
      "Epoch 6006/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13762.7285 - val_loss: 19060.3281\n",
      "Epoch 6007/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13721.5781 - val_loss: 19049.2734\n",
      "Epoch 6008/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13687.9854 - val_loss: 19025.2871\n",
      "Epoch 6009/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13607.6748 - val_loss: 19042.6074\n",
      "Epoch 6010/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13658.4561 - val_loss: 19076.2988\n",
      "Epoch 6011/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13762.9131 - val_loss: 19054.2988\n",
      "Epoch 6012/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13703.0000 - val_loss: 19017.3262\n",
      "Epoch 6013/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13588.5479 - val_loss: 18970.4004\n",
      "Epoch 6014/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13441.4863 - val_loss: 18951.0039\n",
      "Epoch 6015/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13377.9512 - val_loss: 18902.2344\n",
      "Epoch 6016/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13223.4678 - val_loss: 18849.3145\n",
      "Epoch 6017/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13055.3682 - val_loss: 18835.7305\n",
      "Epoch 6018/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13018.3457 - val_loss: 18840.3418\n",
      "Epoch 6019/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13034.7861 - val_loss: 18873.5527\n",
      "Epoch 6020/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13142.7461 - val_loss: 18871.9512\n",
      "Epoch 6021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13134.7041 - val_loss: 18839.5762\n",
      "Epoch 6022/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13032.2656 - val_loss: 18813.7754\n",
      "Epoch 6023/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12948.0449 - val_loss: 18792.9160\n",
      "Epoch 6024/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12887.8291 - val_loss: 18744.9102\n",
      "Epoch 6025/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12739.7139 - val_loss: 18771.7031\n",
      "Epoch 6026/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12819.8350 - val_loss: 18798.7422\n",
      "Epoch 6027/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12899.7197 - val_loss: 18762.4355\n",
      "Epoch 6028/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12785.4844 - val_loss: 18742.6641\n",
      "Epoch 6029/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12723.6357 - val_loss: 18736.1641\n",
      "Epoch 6030/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12707.1797 - val_loss: 18713.1543\n",
      "Epoch 6031/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.8398 - val_loss: 18713.2812\n",
      "Epoch 6032/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12633.4736 - val_loss: 18715.3848\n",
      "Epoch 6033/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.5918 - val_loss: 18702.3398\n",
      "Epoch 6034/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.4814 - val_loss: 18719.8086\n",
      "Epoch 6035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12676.6191 - val_loss: 18766.4375\n",
      "Epoch 6036/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.2070 - val_loss: 18827.3203\n",
      "Epoch 6037/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12999.6729 - val_loss: 18865.8047\n",
      "Epoch 6038/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13119.2705 - val_loss: 18850.5293\n",
      "Epoch 6039/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13071.1104 - val_loss: 18837.4219\n",
      "Epoch 6040/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13034.6865 - val_loss: 18829.3477\n",
      "Epoch 6041/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13005.6396 - val_loss: 18810.8359\n",
      "Epoch 6042/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12946.5029 - val_loss: 18783.7891\n",
      "Epoch 6043/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12861.0078 - val_loss: 18803.6777\n",
      "Epoch 6044/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12913.3506 - val_loss: 18798.9688\n",
      "Epoch 6045/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12898.9512 - val_loss: 18781.3711\n",
      "Epoch 6046/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12842.8428 - val_loss: 18767.2773\n",
      "Epoch 6047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12805.6562 - val_loss: 18798.6191\n",
      "Epoch 6048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12905.3545 - val_loss: 18791.0254\n",
      "Epoch 6049/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12880.7334 - val_loss: 18769.9883\n",
      "Epoch 6050/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12808.3057 - val_loss: 18751.3555\n",
      "Epoch 6051/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12756.6201 - val_loss: 18747.7559\n",
      "Epoch 6052/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.5791 - val_loss: 18719.3828\n",
      "Epoch 6053/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.8584 - val_loss: 18698.8691\n",
      "Epoch 6054/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12599.6396 - val_loss: 18689.5449\n",
      "Epoch 6055/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12571.5703 - val_loss: 18709.2539\n",
      "Epoch 6056/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12623.6729 - val_loss: 18765.3398\n",
      "Epoch 6057/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.8975 - val_loss: 18838.9375\n",
      "Epoch 6058/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13034.8467 - val_loss: 18996.2070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6059/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13525.8428 - val_loss: 19108.5039\n",
      "Epoch 6060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13880.1836 - val_loss: 19169.5293\n",
      "Epoch 6061/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14069.8857 - val_loss: 19216.9434\n",
      "Epoch 6062/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14217.3398 - val_loss: 19241.2285\n",
      "Epoch 6063/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14291.2432 - val_loss: 19222.4219\n",
      "Epoch 6064/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14231.5723 - val_loss: 19161.3965\n",
      "Epoch 6065/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14040.0742 - val_loss: 19145.7266\n",
      "Epoch 6066/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13984.3076 - val_loss: 19124.7168\n",
      "Epoch 6067/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13927.4502 - val_loss: 19101.3613\n",
      "Epoch 6068/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13852.0508 - val_loss: 19057.4082\n",
      "Epoch 6069/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13714.9219 - val_loss: 19017.8691\n",
      "Epoch 6070/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13588.7012 - val_loss: 18966.2441\n",
      "Epoch 6071/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13429.0088 - val_loss: 18927.4297\n",
      "Epoch 6072/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13308.0400 - val_loss: 18893.1758\n",
      "Epoch 6073/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13205.0361 - val_loss: 18857.8789\n",
      "Epoch 6074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13088.9727 - val_loss: 18868.5156\n",
      "Epoch 6075/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13116.6230 - val_loss: 18897.5801\n",
      "Epoch 6076/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13203.1973 - val_loss: 18894.5547\n",
      "Epoch 6077/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13194.5928 - val_loss: 18875.6953\n",
      "Epoch 6078/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13138.4092 - val_loss: 18861.8125\n",
      "Epoch 6079/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13098.0273 - val_loss: 18848.1992\n",
      "Epoch 6080/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13058.9307 - val_loss: 18823.6152\n",
      "Epoch 6081/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12978.4395 - val_loss: 18819.1934\n",
      "Epoch 6082/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12961.5723 - val_loss: 18792.8926\n",
      "Epoch 6083/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12880.4512 - val_loss: 18747.0098\n",
      "Epoch 6084/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 12746.1572 - val_loss: 18743.0762\n",
      "Epoch 6085/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12741.5547 - val_loss: 18724.3184\n",
      "Epoch 6086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12682.9854 - val_loss: 18740.7988\n",
      "Epoch 6087/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.5928 - val_loss: 18744.6152\n",
      "Epoch 6088/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.2500 - val_loss: 18739.0840\n",
      "Epoch 6089/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12709.2744 - val_loss: 18941.9414\n",
      "Epoch 6090/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13387.7852 - val_loss: 18898.6387\n",
      "Epoch 6091/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13221.7871 - val_loss: 19111.5469\n",
      "Epoch 6092/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13886.3428 - val_loss: 19236.2773\n",
      "Epoch 6093/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14279.6543 - val_loss: 19326.9043\n",
      "Epoch 6094/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14562.3789 - val_loss: 19415.6387\n",
      "Epoch 6095/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14838.0771 - val_loss: 19457.0996\n",
      "Epoch 6096/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14964.1348 - val_loss: 19462.4023\n",
      "Epoch 6097/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14980.5537 - val_loss: 19425.9570\n",
      "Epoch 6098/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14868.0127 - val_loss: 19352.6738\n",
      "Epoch 6099/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14643.3242 - val_loss: 19320.7773\n",
      "Epoch 6100/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14542.9590 - val_loss: 19269.8301\n",
      "Epoch 6101/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14383.4658 - val_loss: 19183.2344\n",
      "Epoch 6102/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14106.6377 - val_loss: 19139.9785\n",
      "Epoch 6103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13972.4121 - val_loss: 19075.8711\n",
      "Epoch 6104/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13773.5498 - val_loss: 19088.5664\n",
      "Epoch 6105/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13810.5791 - val_loss: 19082.4355\n",
      "Epoch 6106/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13792.0674 - val_loss: 19050.9512\n",
      "Epoch 6107/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13692.9980 - val_loss: 19001.0586\n",
      "Epoch 6108/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13533.0596 - val_loss: 18994.4844\n",
      "Epoch 6109/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13507.4150 - val_loss: 18990.9551\n",
      "Epoch 6110/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13493.8887 - val_loss: 18982.8418\n",
      "Epoch 6111/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13476.6172 - val_loss: 18945.1113\n",
      "Epoch 6112/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13358.0508 - val_loss: 18936.6777\n",
      "Epoch 6113/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13330.7988 - val_loss: 18918.6914\n",
      "Epoch 6114/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13269.6533 - val_loss: 18952.2832\n",
      "Epoch 6115/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13380.5400 - val_loss: 18939.5840\n",
      "Epoch 6116/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13341.7266 - val_loss: 18877.5781\n",
      "Epoch 6117/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13152.7617 - val_loss: 18844.3242\n",
      "Epoch 6118/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13043.8604 - val_loss: 18837.1699\n",
      "Epoch 6119/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13022.4512 - val_loss: 18801.5332\n",
      "Epoch 6120/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12913.9199 - val_loss: 18804.2852\n",
      "Epoch 6121/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12927.3633 - val_loss: 18782.6016\n",
      "Epoch 6122/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12859.7070 - val_loss: 18752.8105\n",
      "Epoch 6123/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12762.9092 - val_loss: 18748.5352\n",
      "Epoch 6124/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12745.8379 - val_loss: 18781.2871\n",
      "Epoch 6125/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.0576 - val_loss: 19025.5469\n",
      "Epoch 6126/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13642.7686 - val_loss: 18896.1855\n",
      "Epoch 6127/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13213.5312 - val_loss: 19090.6914\n",
      "Epoch 6128/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13822.4326 - val_loss: 19224.4023\n",
      "Epoch 6129/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14240.4834 - val_loss: 19311.2520\n",
      "Epoch 6130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14510.4404 - val_loss: 19346.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6131/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14620.8213 - val_loss: 19351.2988\n",
      "Epoch 6132/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14635.4629 - val_loss: 19375.0098\n",
      "Epoch 6133/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14713.5713 - val_loss: 19368.9277\n",
      "Epoch 6134/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14692.3662 - val_loss: 19355.4238\n",
      "Epoch 6135/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14651.0244 - val_loss: 19272.2344\n",
      "Epoch 6136/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14393.1709 - val_loss: 19164.4570\n",
      "Epoch 6137/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14053.4492 - val_loss: 19153.5508\n",
      "Epoch 6138/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14009.7510 - val_loss: 19202.3105\n",
      "Epoch 6139/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14161.1299 - val_loss: 19201.5098\n",
      "Epoch 6140/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14159.3389 - val_loss: 19171.8203\n",
      "Epoch 6141/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14066.6631 - val_loss: 19121.8105\n",
      "Epoch 6142/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13913.4854 - val_loss: 19057.3281\n",
      "Epoch 6143/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13712.7070 - val_loss: 18979.8750\n",
      "Epoch 6144/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13476.6582 - val_loss: 18911.4668\n",
      "Epoch 6145/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13264.9609 - val_loss: 18857.8652\n",
      "Epoch 6146/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13097.9756 - val_loss: 18854.9238\n",
      "Epoch 6147/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13081.9023 - val_loss: 18882.1230\n",
      "Epoch 6148/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13163.1533 - val_loss: 18891.7285\n",
      "Epoch 6149/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13191.2461 - val_loss: 18876.2539\n",
      "Epoch 6150/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13142.7734 - val_loss: 18891.4473\n",
      "Epoch 6151/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13190.7998 - val_loss: 18883.2363\n",
      "Epoch 6152/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13167.5547 - val_loss: 18836.3223\n",
      "Epoch 6153/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13009.9824 - val_loss: 18802.3477\n",
      "Epoch 6154/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12902.8379 - val_loss: 18766.4336\n",
      "Epoch 6155/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12799.7412 - val_loss: 18759.1660\n",
      "Epoch 6156/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12783.7832 - val_loss: 18764.7930\n",
      "Epoch 6157/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12810.9580 - val_loss: 18793.9941\n",
      "Epoch 6158/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12901.1064 - val_loss: 18815.1113\n",
      "Epoch 6159/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12966.0684 - val_loss: 18798.5977\n",
      "Epoch 6160/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12911.9297 - val_loss: 18773.3359\n",
      "Epoch 6161/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12827.4053 - val_loss: 18735.4688\n",
      "Epoch 6162/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12706.3301 - val_loss: 18740.8555\n",
      "Epoch 6163/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12719.3262 - val_loss: 18725.1836\n",
      "Epoch 6164/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12670.5244 - val_loss: 18685.9297\n",
      "Epoch 6165/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.8008 - val_loss: 19180.4414\n",
      "Epoch 6166/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14143.2070 - val_loss: 18847.9023\n",
      "Epoch 6167/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13066.9062 - val_loss: 19025.6992\n",
      "Epoch 6168/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13621.8799 - val_loss: 19125.5586\n",
      "Epoch 6169/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13931.6641 - val_loss: 19178.3125\n",
      "Epoch 6170/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14095.7725 - val_loss: 19217.8066\n",
      "Epoch 6171/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14216.8984 - val_loss: 19215.2715\n",
      "Epoch 6172/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14210.0020 - val_loss: 19202.2441\n",
      "Epoch 6173/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14165.9609 - val_loss: 19243.4219\n",
      "Epoch 6174/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14298.7705 - val_loss: 19230.6484\n",
      "Epoch 6175/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14259.3389 - val_loss: 19201.3496\n",
      "Epoch 6176/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14167.6963 - val_loss: 19179.5703\n",
      "Epoch 6177/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14100.0986 - val_loss: 19153.8789\n",
      "Epoch 6178/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14024.6416 - val_loss: 19145.5059\n",
      "Epoch 6179/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13995.4512 - val_loss: 19140.3477\n",
      "Epoch 6180/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13974.9414 - val_loss: 19132.7090\n",
      "Epoch 6181/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13949.5439 - val_loss: 19094.1016\n",
      "Epoch 6182/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13826.5186 - val_loss: 19055.6172\n",
      "Epoch 6183/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13706.6289 - val_loss: 18973.8379\n",
      "Epoch 6184/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13450.6006 - val_loss: 18882.6172\n",
      "Epoch 6185/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13168.6377 - val_loss: 18869.6914\n",
      "Epoch 6186/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13129.7422 - val_loss: 18845.3613\n",
      "Epoch 6187/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13054.6611 - val_loss: 18834.5684\n",
      "Epoch 6188/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13016.0107 - val_loss: 18869.6582\n",
      "Epoch 6189/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13122.1201 - val_loss: 18867.5645\n",
      "Epoch 6190/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13113.7441 - val_loss: 18868.4746\n",
      "Epoch 6191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13116.4873 - val_loss: 18874.4727\n",
      "Epoch 6192/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13137.3467 - val_loss: 18847.4746\n",
      "Epoch 6193/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13052.2705 - val_loss: 18802.5156\n",
      "Epoch 6194/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12916.6250 - val_loss: 18787.3691\n",
      "Epoch 6195/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12862.5449 - val_loss: 18764.5156\n",
      "Epoch 6196/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12789.6807 - val_loss: 18722.1914\n",
      "Epoch 6197/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.3486 - val_loss: 18713.1641\n",
      "Epoch 6198/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12635.7900 - val_loss: 18706.9434\n",
      "Epoch 6199/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12623.0215 - val_loss: 18693.8789\n",
      "Epoch 6200/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12582.6973 - val_loss: 18718.6973\n",
      "Epoch 6201/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12651.3047 - val_loss: 18728.0059\n",
      "Epoch 6202/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.1797 - val_loss: 18708.4727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6203/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12626.6094 - val_loss: 18907.2168\n",
      "Epoch 6204/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13266.7148 - val_loss: 18839.1836\n",
      "Epoch 6205/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13038.1387 - val_loss: 19027.7676\n",
      "Epoch 6206/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13627.7568 - val_loss: 19156.8359\n",
      "Epoch 6207/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14029.7520 - val_loss: 19209.8398\n",
      "Epoch 6208/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14195.2822 - val_loss: 19227.6777\n",
      "Epoch 6209/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14250.6270 - val_loss: 19227.2363\n",
      "Epoch 6210/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14253.6309 - val_loss: 19250.8770\n",
      "Epoch 6211/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14322.1709 - val_loss: 19254.3633\n",
      "Epoch 6212/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14334.6738 - val_loss: 19260.9629\n",
      "Epoch 6213/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14355.6240 - val_loss: 19244.3750\n",
      "Epoch 6214/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14298.2764 - val_loss: 19176.4707\n",
      "Epoch 6215/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14086.5107 - val_loss: 19111.8066\n",
      "Epoch 6216/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13884.7363 - val_loss: 19136.0039\n",
      "Epoch 6217/10000\n",
      "630/630 [==============================] - 0s 21us/step - loss: 13965.5908 - val_loss: 19148.8750\n",
      "Epoch 6218/10000\n",
      "630/630 [==============================] - 0s 21us/step - loss: 14005.7256 - val_loss: 19135.3145\n",
      "Epoch 6219/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13960.1826 - val_loss: 19079.5820\n",
      "Epoch 6220/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13781.9316 - val_loss: 19034.6074\n",
      "Epoch 6221/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13642.5547 - val_loss: 18959.1621\n",
      "Epoch 6222/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13411.3311 - val_loss: 18886.7305\n",
      "Epoch 6223/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13185.0713 - val_loss: 18854.1641\n",
      "Epoch 6224/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13084.7119 - val_loss: 18863.0176\n",
      "Epoch 6225/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13109.6299 - val_loss: 18847.8730\n",
      "Epoch 6226/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13063.1816 - val_loss: 18833.4531\n",
      "Epoch 6227/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13007.1680 - val_loss: 18826.4238\n",
      "Epoch 6228/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12983.7480 - val_loss: 18888.1973\n",
      "Epoch 6229/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13177.9688 - val_loss: 18859.1719\n",
      "Epoch 6230/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13090.1533 - val_loss: 18834.2129\n",
      "Epoch 6231/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13023.4443 - val_loss: 18857.7363\n",
      "Epoch 6232/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13102.6455 - val_loss: 18874.6016\n",
      "Epoch 6233/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13150.5576 - val_loss: 18887.3066\n",
      "Epoch 6234/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13187.0615 - val_loss: 18894.8457\n",
      "Epoch 6235/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13213.2148 - val_loss: 18874.4355\n",
      "Epoch 6236/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13147.1836 - val_loss: 18884.9258\n",
      "Epoch 6237/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13180.2031 - val_loss: 18872.6113\n",
      "Epoch 6238/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13141.4795 - val_loss: 18841.8145\n",
      "Epoch 6239/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13039.7764 - val_loss: 18842.0215\n",
      "Epoch 6240/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13041.4033 - val_loss: 18825.8789\n",
      "Epoch 6241/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12994.7969 - val_loss: 18770.5801\n",
      "Epoch 6242/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12821.4414 - val_loss: 18732.5840\n",
      "Epoch 6243/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.5947 - val_loss: 18733.0996\n",
      "Epoch 6244/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12698.9307 - val_loss: 18851.6309\n",
      "Epoch 6245/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13064.1641 - val_loss: 18864.0430\n",
      "Epoch 6246/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13119.7539 - val_loss: 19018.2480\n",
      "Epoch 6247/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13598.7773 - val_loss: 19082.5820\n",
      "Epoch 6248/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13801.6484 - val_loss: 19150.6641\n",
      "Epoch 6249/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14011.3105 - val_loss: 19199.5938\n",
      "Epoch 6250/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14166.0781 - val_loss: 19204.6152\n",
      "Epoch 6251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14182.5371 - val_loss: 19160.7754\n",
      "Epoch 6252/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14043.9609 - val_loss: 19143.6680\n",
      "Epoch 6253/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13987.0703 - val_loss: 19164.1289\n",
      "Epoch 6254/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14052.9238 - val_loss: 19179.7734\n",
      "Epoch 6255/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 14100.8135 - val_loss: 19128.4297\n",
      "Epoch 6256/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13938.9170 - val_loss: 19070.7305\n",
      "Epoch 6257/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13758.8369 - val_loss: 19013.1621\n",
      "Epoch 6258/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13578.6104 - val_loss: 18980.0977\n",
      "Epoch 6259/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13478.0498 - val_loss: 18985.2324\n",
      "Epoch 6260/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13494.8242 - val_loss: 18973.7578\n",
      "Epoch 6261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13456.8203 - val_loss: 18956.1016\n",
      "Epoch 6262/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13396.0029 - val_loss: 18926.5371\n",
      "Epoch 6263/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13303.3711 - val_loss: 18882.2051\n",
      "Epoch 6264/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13166.0410 - val_loss: 18845.3281\n",
      "Epoch 6265/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13047.7393 - val_loss: 18792.3164\n",
      "Epoch 6266/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12876.9346 - val_loss: 18812.0195\n",
      "Epoch 6267/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12939.8555 - val_loss: 18777.8047\n",
      "Epoch 6268/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12832.3926 - val_loss: 18781.5059\n",
      "Epoch 6269/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12843.2129 - val_loss: 18777.8047\n",
      "Epoch 6270/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12834.4658 - val_loss: 18764.3984\n",
      "Epoch 6271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12799.3047 - val_loss: 18738.9941\n",
      "Epoch 6272/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.7080 - val_loss: 18737.6758\n",
      "Epoch 6273/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.5254 - val_loss: 18748.8184\n",
      "Epoch 6274/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.2041 - val_loss: 18745.5273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6275/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.2061 - val_loss: 18746.0723\n",
      "Epoch 6276/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.8281 - val_loss: 18733.5527\n",
      "Epoch 6277/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12695.0420 - val_loss: 18714.6094\n",
      "Epoch 6278/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.7383 - val_loss: 18726.1699\n",
      "Epoch 6279/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12676.9727 - val_loss: 18713.4473\n",
      "Epoch 6280/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12634.4512 - val_loss: 18708.2539\n",
      "Epoch 6281/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12619.2021 - val_loss: 18708.9277\n",
      "Epoch 6282/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12620.7500 - val_loss: 18692.1348\n",
      "Epoch 6283/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12567.0000 - val_loss: 18685.3730\n",
      "Epoch 6284/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12548.8242 - val_loss: 18710.3008\n",
      "Epoch 6285/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12631.5039 - val_loss: 18704.9531\n",
      "Epoch 6286/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12612.4307 - val_loss: 18690.1055\n",
      "Epoch 6287/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12565.9277 - val_loss: 18687.3711\n",
      "Epoch 6288/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12562.2500 - val_loss: 18685.9941\n",
      "Epoch 6289/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12559.9766 - val_loss: 18692.5195\n",
      "Epoch 6290/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12574.5146 - val_loss: 18695.9219\n",
      "Epoch 6291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.3027 - val_loss: 18783.3047\n",
      "Epoch 6292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.8555 - val_loss: 18917.5020\n",
      "Epoch 6293/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13280.0029 - val_loss: 18971.1074\n",
      "Epoch 6294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13446.1416 - val_loss: 18969.2012\n",
      "Epoch 6295/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13438.1641 - val_loss: 18925.8633\n",
      "Epoch 6296/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13301.3467 - val_loss: 18868.0020\n",
      "Epoch 6297/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13132.3115 - val_loss: 18876.9375\n",
      "Epoch 6298/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13157.0088 - val_loss: 18881.7539\n",
      "Epoch 6299/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13169.3076 - val_loss: 18882.2891\n",
      "Epoch 6300/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13170.3076 - val_loss: 18862.8555\n",
      "Epoch 6301/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13107.6309 - val_loss: 18814.6230\n",
      "Epoch 6302/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12957.2598 - val_loss: 18763.7598\n",
      "Epoch 6303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.8184 - val_loss: 18789.3105\n",
      "Epoch 6304/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12870.8584 - val_loss: 18813.6211\n",
      "Epoch 6305/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12944.5273 - val_loss: 18780.2324\n",
      "Epoch 6306/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12840.0039 - val_loss: 18801.6211\n",
      "Epoch 6307/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12909.3213 - val_loss: 18804.2637\n",
      "Epoch 6308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12917.4678 - val_loss: 18767.5488\n",
      "Epoch 6309/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12801.6201 - val_loss: 18739.5039\n",
      "Epoch 6310/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12715.5596 - val_loss: 18724.4414\n",
      "Epoch 6311/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12670.6484 - val_loss: 18673.7910\n",
      "Epoch 6312/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12511.9102 - val_loss: 18696.4023\n",
      "Epoch 6313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12580.4795 - val_loss: 18714.1426\n",
      "Epoch 6314/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12637.4941 - val_loss: 18716.1875\n",
      "Epoch 6315/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12644.4795 - val_loss: 18721.9141\n",
      "Epoch 6316/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12663.1484 - val_loss: 18712.8125\n",
      "Epoch 6317/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12632.6602 - val_loss: 18702.0410\n",
      "Epoch 6318/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12600.5254 - val_loss: 18693.8633\n",
      "Epoch 6319/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12578.2969 - val_loss: 18697.2520\n",
      "Epoch 6320/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12606.2197 - val_loss: 18800.1914\n",
      "Epoch 6321/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12917.6299 - val_loss: 18927.5410\n",
      "Epoch 6322/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13314.7158 - val_loss: 18987.6426\n",
      "Epoch 6323/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13501.3760 - val_loss: 19016.7734\n",
      "Epoch 6324/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13592.1934 - val_loss: 19005.3730\n",
      "Epoch 6325/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13558.2402 - val_loss: 19001.8535\n",
      "Epoch 6326/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13547.1113 - val_loss: 18945.1523\n",
      "Epoch 6327/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13368.6924 - val_loss: 18907.9922\n",
      "Epoch 6328/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13251.3643 - val_loss: 18891.8730\n",
      "Epoch 6329/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13199.1846 - val_loss: 18904.5352\n",
      "Epoch 6330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13237.3477 - val_loss: 18906.2695\n",
      "Epoch 6331/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13233.2285 - val_loss: 18929.8027\n",
      "Epoch 6332/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13306.4648 - val_loss: 18930.6484\n",
      "Epoch 6333/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13311.7988 - val_loss: 18890.1992\n",
      "Epoch 6334/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13183.8867 - val_loss: 18862.9766\n",
      "Epoch 6335/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13102.2217 - val_loss: 18872.9883\n",
      "Epoch 6336/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13132.3691 - val_loss: 18869.7480\n",
      "Epoch 6337/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13121.5869 - val_loss: 18857.4648\n",
      "Epoch 6338/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13083.6221 - val_loss: 18812.3320\n",
      "Epoch 6339/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12947.8896 - val_loss: 18775.4805\n",
      "Epoch 6340/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12839.2529 - val_loss: 18806.2246\n",
      "Epoch 6341/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12933.0127 - val_loss: 18832.8105\n",
      "Epoch 6342/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13015.8213 - val_loss: 18802.1094\n",
      "Epoch 6343/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12922.2588 - val_loss: 18750.4199\n",
      "Epoch 6344/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12759.9014 - val_loss: 18743.6230\n",
      "Epoch 6345/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.9141 - val_loss: 18754.9824\n",
      "Epoch 6346/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.3145 - val_loss: 18720.1562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6347/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.4834 - val_loss: 18728.8770\n",
      "Epoch 6348/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12687.1670 - val_loss: 18724.1484\n",
      "Epoch 6349/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12671.1826 - val_loss: 18705.4141\n",
      "Epoch 6350/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.8291 - val_loss: 18691.1230\n",
      "Epoch 6351/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12565.0449 - val_loss: 18693.0625\n",
      "Epoch 6352/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12569.8643 - val_loss: 18695.1758\n",
      "Epoch 6353/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12578.9512 - val_loss: 18724.8379\n",
      "Epoch 6354/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12673.4854 - val_loss: 18735.3242\n",
      "Epoch 6355/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12706.9648 - val_loss: 18715.8887\n",
      "Epoch 6356/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.7441 - val_loss: 18700.4980\n",
      "Epoch 6357/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.2080 - val_loss: 18738.9062\n",
      "Epoch 6358/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12723.1787 - val_loss: 18739.4570\n",
      "Epoch 6359/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.4297 - val_loss: 18706.3223\n",
      "Epoch 6360/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.4492 - val_loss: 18734.3555\n",
      "Epoch 6361/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12697.8457 - val_loss: 18757.3672\n",
      "Epoch 6362/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12769.4824 - val_loss: 18742.3574\n",
      "Epoch 6363/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12724.8623 - val_loss: 18736.5566\n",
      "Epoch 6364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12707.9727 - val_loss: 18727.5469\n",
      "Epoch 6365/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.0146 - val_loss: 18708.3555\n",
      "Epoch 6366/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12629.9033 - val_loss: 18725.0957\n",
      "Epoch 6367/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12680.2764 - val_loss: 18710.7598\n",
      "Epoch 6368/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.3086 - val_loss: 18701.6543\n",
      "Epoch 6369/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12604.6240 - val_loss: 18727.9590\n",
      "Epoch 6370/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12682.4941 - val_loss: 18807.2246\n",
      "Epoch 6371/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12945.8086 - val_loss: 18903.4707\n",
      "Epoch 6372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13241.6533 - val_loss: 19090.1016\n",
      "Epoch 6373/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13821.2754 - val_loss: 19206.6016\n",
      "Epoch 6374/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14183.5410 - val_loss: 19279.1543\n",
      "Epoch 6375/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14410.8105 - val_loss: 19290.3164\n",
      "Epoch 6376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14443.9395 - val_loss: 19274.2891\n",
      "Epoch 6377/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14393.3281 - val_loss: 19288.5566\n",
      "Epoch 6378/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14437.3262 - val_loss: 19298.9492\n",
      "Epoch 6379/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14472.4512 - val_loss: 19266.9551\n",
      "Epoch 6380/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14372.2832 - val_loss: 19191.8750\n",
      "Epoch 6381/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14138.6172 - val_loss: 19140.4043\n",
      "Epoch 6382/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13977.7295 - val_loss: 19120.3594\n",
      "Epoch 6383/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13915.3799 - val_loss: 19074.6387\n",
      "Epoch 6384/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13774.4697 - val_loss: 19049.9766\n",
      "Epoch 6385/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13686.3486 - val_loss: 19015.9473\n",
      "Epoch 6386/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 13586.9785 - val_loss: 19001.3301\n",
      "Epoch 6387/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 13540.5410 - val_loss: 18974.5078\n",
      "Epoch 6388/10000\n",
      "630/630 [==============================] - 0s 21us/step - loss: 13456.7578 - val_loss: 18919.0215\n",
      "Epoch 6389/10000\n",
      "630/630 [==============================] - 0s 19us/step - loss: 13282.5332 - val_loss: 18871.6445\n",
      "Epoch 6390/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 13131.7988 - val_loss: 18886.5547\n",
      "Epoch 6391/10000\n",
      "630/630 [==============================] - 0s 21us/step - loss: 13173.0918 - val_loss: 18890.4238\n",
      "Epoch 6392/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13184.0479 - val_loss: 18882.1973\n",
      "Epoch 6393/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13161.1543 - val_loss: 18873.4844\n",
      "Epoch 6394/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13136.4854 - val_loss: 18872.2227\n",
      "Epoch 6395/10000\n",
      "630/630 [==============================] - 0s 24us/step - loss: 13129.1025 - val_loss: 18862.3574\n",
      "Epoch 6396/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13097.8828 - val_loss: 18834.1504\n",
      "Epoch 6397/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13008.3389 - val_loss: 18790.9238\n",
      "Epoch 6398/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12875.2246 - val_loss: 18752.2617\n",
      "Epoch 6399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.5479 - val_loss: 18731.8359\n",
      "Epoch 6400/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12694.0879 - val_loss: 18710.2207\n",
      "Epoch 6401/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12631.1621 - val_loss: 18689.4902\n",
      "Epoch 6402/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12568.0371 - val_loss: 18712.1016\n",
      "Epoch 6403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12629.8184 - val_loss: 18767.0469\n",
      "Epoch 6404/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12799.3828 - val_loss: 18790.7559\n",
      "Epoch 6405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12873.4727 - val_loss: 18772.8398\n",
      "Epoch 6406/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.2363 - val_loss: 18740.4355\n",
      "Epoch 6407/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12722.9961 - val_loss: 18740.3223\n",
      "Epoch 6408/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12725.1348 - val_loss: 18747.7891\n",
      "Epoch 6409/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12747.5020 - val_loss: 18713.6621\n",
      "Epoch 6410/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12641.4346 - val_loss: 18934.2715\n",
      "Epoch 6411/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13356.0059 - val_loss: 18929.5684\n",
      "Epoch 6412/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13321.1924 - val_loss: 19131.7246\n",
      "Epoch 6413/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13954.2979 - val_loss: 19257.7676\n",
      "Epoch 6414/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14348.1797 - val_loss: 19296.9004\n",
      "Epoch 6415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14467.5068 - val_loss: 19312.8281\n",
      "Epoch 6416/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14518.6006 - val_loss: 19281.7207\n",
      "Epoch 6417/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14418.5195 - val_loss: 19269.6348\n",
      "Epoch 6418/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14378.7227 - val_loss: 19223.1797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6419/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14236.7061 - val_loss: 19230.8594\n",
      "Epoch 6420/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14261.2412 - val_loss: 19197.0762\n",
      "Epoch 6421/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14152.4521 - val_loss: 19165.5723\n",
      "Epoch 6422/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14052.5293 - val_loss: 19116.5781\n",
      "Epoch 6423/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13898.3623 - val_loss: 19134.0762\n",
      "Epoch 6424/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13953.8848 - val_loss: 19118.7324\n",
      "Epoch 6425/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13908.8154 - val_loss: 19053.8848\n",
      "Epoch 6426/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13705.7070 - val_loss: 18968.9648\n",
      "Epoch 6427/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13437.9805 - val_loss: 19025.3730\n",
      "Epoch 6428/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13608.2832 - val_loss: 19059.3945\n",
      "Epoch 6429/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13711.6211 - val_loss: 19063.6836\n",
      "Epoch 6430/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13724.8252 - val_loss: 19018.3633\n",
      "Epoch 6431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13587.2676 - val_loss: 18968.7383\n",
      "Epoch 6432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13431.8066 - val_loss: 18969.5449\n",
      "Epoch 6433/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13435.6240 - val_loss: 18977.9785\n",
      "Epoch 6434/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13455.8613 - val_loss: 18955.0527\n",
      "Epoch 6435/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13384.4277 - val_loss: 18919.2461\n",
      "Epoch 6436/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13272.7871 - val_loss: 18881.5898\n",
      "Epoch 6437/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13161.0000 - val_loss: 18847.0215\n",
      "Epoch 6438/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13061.8926 - val_loss: 18861.9570\n",
      "Epoch 6439/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13114.5898 - val_loss: 18897.5859\n",
      "Epoch 6440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13219.9922 - val_loss: 18888.4746\n",
      "Epoch 6441/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13191.1621 - val_loss: 18857.0859\n",
      "Epoch 6442/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13094.9053 - val_loss: 18814.3008\n",
      "Epoch 6443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12962.4443 - val_loss: 18785.4199\n",
      "Epoch 6444/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12870.0068 - val_loss: 18768.6465\n",
      "Epoch 6445/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12805.9463 - val_loss: 18763.2754\n",
      "Epoch 6446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.7539 - val_loss: 18743.9824\n",
      "Epoch 6447/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.9932 - val_loss: 18746.8809\n",
      "Epoch 6448/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.9912 - val_loss: 18730.0273\n",
      "Epoch 6449/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12687.3135 - val_loss: 18708.5840\n",
      "Epoch 6450/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12627.7705 - val_loss: 18693.1230\n",
      "Epoch 6451/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12574.7988 - val_loss: 18775.7227\n",
      "Epoch 6452/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12841.4395 - val_loss: 18970.3809\n",
      "Epoch 6453/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13440.8721 - val_loss: 19195.4316\n",
      "Epoch 6454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14144.5527 - val_loss: 19330.8574\n",
      "Epoch 6455/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14569.3936 - val_loss: 19382.3652\n",
      "Epoch 6456/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14729.9766 - val_loss: 19397.0840\n",
      "Epoch 6457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14773.4658 - val_loss: 19411.3066\n",
      "Epoch 6458/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14818.7344 - val_loss: 19375.2363\n",
      "Epoch 6459/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14716.4844 - val_loss: 19297.4395\n",
      "Epoch 6460/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14470.5059 - val_loss: 19204.7891\n",
      "Epoch 6461/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14178.9893 - val_loss: 19193.6504\n",
      "Epoch 6462/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14142.6045 - val_loss: 19199.0684\n",
      "Epoch 6463/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14158.8027 - val_loss: 19166.8477\n",
      "Epoch 6464/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14055.7061 - val_loss: 19138.4922\n",
      "Epoch 6465/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13965.5039 - val_loss: 19101.5273\n",
      "Epoch 6466/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13855.9062 - val_loss: 19070.2637\n",
      "Epoch 6467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13757.8867 - val_loss: 19026.7090\n",
      "Epoch 6468/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13618.7031 - val_loss: 18933.0039\n",
      "Epoch 6469/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13329.3232 - val_loss: 18899.1543\n",
      "Epoch 6470/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13216.1406 - val_loss: 18902.1406\n",
      "Epoch 6471/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13229.4639 - val_loss: 18954.4297\n",
      "Epoch 6472/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13392.0537 - val_loss: 18955.1445\n",
      "Epoch 6473/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13386.7891 - val_loss: 18939.4863\n",
      "Epoch 6474/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13340.0176 - val_loss: 18914.9922\n",
      "Epoch 6475/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13266.8359 - val_loss: 18999.3750\n",
      "Epoch 6476/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13540.8545 - val_loss: 18918.4863\n",
      "Epoch 6477/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13277.9238 - val_loss: 19121.7168\n",
      "Epoch 6478/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13925.6309 - val_loss: 19266.5781\n",
      "Epoch 6479/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14379.3135 - val_loss: 19337.9297\n",
      "Epoch 6480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14601.5312 - val_loss: 19364.0664\n",
      "Epoch 6481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14681.0908 - val_loss: 19370.6973\n",
      "Epoch 6482/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14698.5381 - val_loss: 19352.3770\n",
      "Epoch 6483/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14637.6338 - val_loss: 19312.7344\n",
      "Epoch 6484/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14514.3691 - val_loss: 19232.3418\n",
      "Epoch 6485/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14265.9248 - val_loss: 19208.6621\n",
      "Epoch 6486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14189.5674 - val_loss: 19215.8672\n",
      "Epoch 6487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14211.7471 - val_loss: 19180.1836\n",
      "Epoch 6488/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14100.9863 - val_loss: 19152.9102\n",
      "Epoch 6489/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14015.2920 - val_loss: 19120.8613\n",
      "Epoch 6490/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13915.3936 - val_loss: 19069.6719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6491/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13759.3711 - val_loss: 18993.7461\n",
      "Epoch 6492/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13520.2051 - val_loss: 18938.7910\n",
      "Epoch 6493/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13347.0928 - val_loss: 18928.4434\n",
      "Epoch 6494/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13317.6406 - val_loss: 18917.9844\n",
      "Epoch 6495/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13277.0322 - val_loss: 18882.9590\n",
      "Epoch 6496/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13167.8086 - val_loss: 18834.4629\n",
      "Epoch 6497/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13020.4854 - val_loss: 18814.0410\n",
      "Epoch 6498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12949.6709 - val_loss: 18814.1328\n",
      "Epoch 6499/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12947.2061 - val_loss: 18828.6895\n",
      "Epoch 6500/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12996.4102 - val_loss: 18824.5078\n",
      "Epoch 6501/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12983.6465 - val_loss: 18844.8496\n",
      "Epoch 6502/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13052.9678 - val_loss: 18892.8535\n",
      "Epoch 6503/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13196.3545 - val_loss: 18905.4492\n",
      "Epoch 6504/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13242.0664 - val_loss: 18896.6348\n",
      "Epoch 6505/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13215.1113 - val_loss: 18903.7168\n",
      "Epoch 6506/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13234.9453 - val_loss: 18897.6562\n",
      "Epoch 6507/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13215.8271 - val_loss: 18825.4258\n",
      "Epoch 6508/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12996.8213 - val_loss: 18762.5059\n",
      "Epoch 6509/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12804.3662 - val_loss: 18735.4590\n",
      "Epoch 6510/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12713.6162 - val_loss: 18774.4473\n",
      "Epoch 6511/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12823.5615 - val_loss: 18797.3359\n",
      "Epoch 6512/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12898.8994 - val_loss: 18784.6484\n",
      "Epoch 6513/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12867.0068 - val_loss: 18794.1621\n",
      "Epoch 6514/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12902.5312 - val_loss: 18779.7363\n",
      "Epoch 6515/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.0791 - val_loss: 18739.3340\n",
      "Epoch 6516/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12718.3555 - val_loss: 18709.8613\n",
      "Epoch 6517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12623.9492 - val_loss: 18726.8281\n",
      "Epoch 6518/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12675.0410 - val_loss: 18741.4141\n",
      "Epoch 6519/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.2783 - val_loss: 18773.1738\n",
      "Epoch 6520/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12837.3154 - val_loss: 18906.5039\n",
      "Epoch 6521/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13253.3115 - val_loss: 18980.2070\n",
      "Epoch 6522/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13483.0967 - val_loss: 18987.0918\n",
      "Epoch 6523/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13505.6104 - val_loss: 18974.2031\n",
      "Epoch 6524/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13462.1992 - val_loss: 18934.0000\n",
      "Epoch 6525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13336.3066 - val_loss: 18860.9102\n",
      "Epoch 6526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13108.3486 - val_loss: 18803.6426\n",
      "Epoch 6527/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12927.4326 - val_loss: 18812.5410\n",
      "Epoch 6528/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12947.7676 - val_loss: 18825.3965\n",
      "Epoch 6529/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12983.5381 - val_loss: 18804.4883\n",
      "Epoch 6530/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12911.6680 - val_loss: 18801.4473\n",
      "Epoch 6531/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12899.9775 - val_loss: 18799.4336\n",
      "Epoch 6532/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12895.0811 - val_loss: 18782.2734\n",
      "Epoch 6533/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.3359 - val_loss: 18763.0664\n",
      "Epoch 6534/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12792.2891 - val_loss: 18761.7324\n",
      "Epoch 6535/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.8779 - val_loss: 18724.5605\n",
      "Epoch 6536/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12678.1465 - val_loss: 18696.0840\n",
      "Epoch 6537/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12591.4492 - val_loss: 18707.7500\n",
      "Epoch 6538/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12620.8281 - val_loss: 19006.8047\n",
      "Epoch 6539/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13599.8613 - val_loss: 18962.1680\n",
      "Epoch 6540/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13418.3506 - val_loss: 19256.2949\n",
      "Epoch 6541/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14336.9951 - val_loss: 19462.3828\n",
      "Epoch 6542/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14986.3174 - val_loss: 19581.5469\n",
      "Epoch 6543/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15355.6670 - val_loss: 19630.1992\n",
      "Epoch 6544/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15509.3848 - val_loss: 19650.2598\n",
      "Epoch 6545/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15571.9971 - val_loss: 19622.1055\n",
      "Epoch 6546/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15485.5586 - val_loss: 19548.2266\n",
      "Epoch 6547/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 15253.4453 - val_loss: 19471.4512\n",
      "Epoch 6548/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 15014.7568 - val_loss: 19364.8145\n",
      "Epoch 6549/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14682.1758 - val_loss: 19247.8828\n",
      "Epoch 6550/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14316.9805 - val_loss: 19129.1895\n",
      "Epoch 6551/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13945.3096 - val_loss: 19023.6621\n",
      "Epoch 6552/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13606.6758 - val_loss: 18984.9570\n",
      "Epoch 6553/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13482.3154 - val_loss: 19055.0156\n",
      "Epoch 6554/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13698.3994 - val_loss: 19084.6797\n",
      "Epoch 6555/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13791.6523 - val_loss: 19089.6270\n",
      "Epoch 6556/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13807.8281 - val_loss: 19113.9863\n",
      "Epoch 6557/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13879.2285 - val_loss: 19098.9238\n",
      "Epoch 6558/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13829.4141 - val_loss: 19043.7441\n",
      "Epoch 6559/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13657.9326 - val_loss: 18948.4453\n",
      "Epoch 6560/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13365.3320 - val_loss: 18898.3320\n",
      "Epoch 6561/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13215.7070 - val_loss: 18862.5078\n",
      "Epoch 6562/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13101.6846 - val_loss: 18886.4102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6563/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13179.1924 - val_loss: 18930.1660\n",
      "Epoch 6564/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13316.2656 - val_loss: 18893.5137\n",
      "Epoch 6565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13201.7949 - val_loss: 18886.3652\n",
      "Epoch 6566/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13174.6680 - val_loss: 18845.9180\n",
      "Epoch 6567/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13049.2490 - val_loss: 18803.0820\n",
      "Epoch 6568/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12915.5586 - val_loss: 18790.9023\n",
      "Epoch 6569/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12881.7500 - val_loss: 18758.6973\n",
      "Epoch 6570/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12778.4443 - val_loss: 18740.6113\n",
      "Epoch 6571/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12732.4746 - val_loss: 18741.6680\n",
      "Epoch 6572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12732.0967 - val_loss: 18834.0820\n",
      "Epoch 6573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13020.5479 - val_loss: 18871.7422\n",
      "Epoch 6574/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13139.1123 - val_loss: 18870.4980\n",
      "Epoch 6575/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13134.0137 - val_loss: 18846.6309\n",
      "Epoch 6576/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13058.4824 - val_loss: 18796.1738\n",
      "Epoch 6577/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12901.8877 - val_loss: 18744.8906\n",
      "Epoch 6578/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12739.8330 - val_loss: 18715.7031\n",
      "Epoch 6579/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12644.3418 - val_loss: 19046.0020\n",
      "Epoch 6580/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13718.4297 - val_loss: 18888.1895\n",
      "Epoch 6581/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13196.0527 - val_loss: 19108.0195\n",
      "Epoch 6582/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13881.0742 - val_loss: 19272.8242\n",
      "Epoch 6583/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14395.9131 - val_loss: 19388.7480\n",
      "Epoch 6584/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14757.4004 - val_loss: 19419.1543\n",
      "Epoch 6585/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14852.0215 - val_loss: 19397.6699\n",
      "Epoch 6586/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14784.6006 - val_loss: 19370.0820\n",
      "Epoch 6587/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14697.9561 - val_loss: 19299.2188\n",
      "Epoch 6588/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14474.6631 - val_loss: 19207.0547\n",
      "Epoch 6589/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14186.0107 - val_loss: 19121.8184\n",
      "Epoch 6590/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13923.1748 - val_loss: 19099.4512\n",
      "Epoch 6591/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13845.1670 - val_loss: 19061.2637\n",
      "Epoch 6592/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13726.2881 - val_loss: 19046.1348\n",
      "Epoch 6593/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13667.9980 - val_loss: 19084.7012\n",
      "Epoch 6594/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13786.8857 - val_loss: 19078.0078\n",
      "Epoch 6595/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13765.8193 - val_loss: 19011.5430\n",
      "Epoch 6596/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13556.6143 - val_loss: 19003.2754\n",
      "Epoch 6597/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13533.4248 - val_loss: 18995.8613\n",
      "Epoch 6598/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13510.8369 - val_loss: 19000.5801\n",
      "Epoch 6599/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13535.4102 - val_loss: 18962.1895\n",
      "Epoch 6600/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13416.6260 - val_loss: 18927.4688\n",
      "Epoch 6601/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13310.9971 - val_loss: 18928.1426\n",
      "Epoch 6602/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13317.7021 - val_loss: 18928.1309\n",
      "Epoch 6603/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13315.3408 - val_loss: 18885.9512\n",
      "Epoch 6604/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13184.4561 - val_loss: 18825.5586\n",
      "Epoch 6605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12995.5225 - val_loss: 18833.1641\n",
      "Epoch 6606/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13013.9873 - val_loss: 18852.2988\n",
      "Epoch 6607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13072.9951 - val_loss: 18831.5352\n",
      "Epoch 6608/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.7646 - val_loss: 18822.7969\n",
      "Epoch 6609/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12974.9922 - val_loss: 18800.7305\n",
      "Epoch 6610/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12904.3066 - val_loss: 18765.8789\n",
      "Epoch 6611/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12800.4307 - val_loss: 18729.2402\n",
      "Epoch 6612/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12690.9160 - val_loss: 18732.9180\n",
      "Epoch 6613/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.0703 - val_loss: 18713.0957\n",
      "Epoch 6614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12644.9287 - val_loss: 18699.0039\n",
      "Epoch 6615/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12600.4238 - val_loss: 18676.8691\n",
      "Epoch 6616/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.7012 - val_loss: 18723.1680\n",
      "Epoch 6617/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12674.6260 - val_loss: 18843.8418\n",
      "Epoch 6618/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13057.3691 - val_loss: 19025.5215\n",
      "Epoch 6619/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13626.2373 - val_loss: 19118.3809\n",
      "Epoch 6620/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13914.2344 - val_loss: 19144.8828\n",
      "Epoch 6621/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13997.1357 - val_loss: 19140.2715\n",
      "Epoch 6622/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13981.2900 - val_loss: 19118.6758\n",
      "Epoch 6623/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13915.1289 - val_loss: 19095.8457\n",
      "Epoch 6624/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13840.0918 - val_loss: 19061.6172\n",
      "Epoch 6625/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13735.7197 - val_loss: 19005.9727\n",
      "Epoch 6626/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13562.4521 - val_loss: 18934.9062\n",
      "Epoch 6627/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13337.5547 - val_loss: 18921.8242\n",
      "Epoch 6628/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13290.9385 - val_loss: 18906.8594\n",
      "Epoch 6629/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13241.7578 - val_loss: 18856.5801\n",
      "Epoch 6630/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13086.6348 - val_loss: 18828.6641\n",
      "Epoch 6631/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12999.3613 - val_loss: 18816.8145\n",
      "Epoch 6632/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12953.4893 - val_loss: 18802.7480\n",
      "Epoch 6633/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12912.9746 - val_loss: 18845.3398\n",
      "Epoch 6634/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13045.2402 - val_loss: 18867.4688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13120.1553 - val_loss: 18825.7871\n",
      "Epoch 6636/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12984.8076 - val_loss: 18779.9746\n",
      "Epoch 6637/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12841.2432 - val_loss: 18739.8262\n",
      "Epoch 6638/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.1230 - val_loss: 18723.2832\n",
      "Epoch 6639/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.1436 - val_loss: 18772.4727\n",
      "Epoch 6640/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12830.8379 - val_loss: 18785.1035\n",
      "Epoch 6641/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12869.3037 - val_loss: 18741.7246\n",
      "Epoch 6642/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12730.0488 - val_loss: 18751.8926\n",
      "Epoch 6643/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12756.3555 - val_loss: 18809.7969\n",
      "Epoch 6644/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12941.5293 - val_loss: 18788.8301\n",
      "Epoch 6645/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12879.2383 - val_loss: 18818.9297\n",
      "Epoch 6646/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12980.5908 - val_loss: 18818.0312\n",
      "Epoch 6647/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12978.1953 - val_loss: 18818.7988\n",
      "Epoch 6648/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12982.0850 - val_loss: 18786.0938\n",
      "Epoch 6649/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12875.6504 - val_loss: 18781.1230\n",
      "Epoch 6650/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12851.7646 - val_loss: 18736.4199\n",
      "Epoch 6651/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12713.2588 - val_loss: 18753.2812\n",
      "Epoch 6652/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.4551 - val_loss: 18789.6816\n",
      "Epoch 6653/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12868.0752 - val_loss: 18787.6250\n",
      "Epoch 6654/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.2070 - val_loss: 18774.5215\n",
      "Epoch 6655/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12823.3467 - val_loss: 18758.7734\n",
      "Epoch 6656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12778.5225 - val_loss: 18736.6387\n",
      "Epoch 6657/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12714.3633 - val_loss: 18716.0293\n",
      "Epoch 6658/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12652.9541 - val_loss: 18694.8887\n",
      "Epoch 6659/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12588.6045 - val_loss: 18730.0742\n",
      "Epoch 6660/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12683.8887 - val_loss: 18747.2305\n",
      "Epoch 6661/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12735.3984 - val_loss: 18746.8105\n",
      "Epoch 6662/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.2334 - val_loss: 18753.7422\n",
      "Epoch 6663/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.3311 - val_loss: 18754.7441\n",
      "Epoch 6664/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.0137 - val_loss: 18727.5684\n",
      "Epoch 6665/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12679.2666 - val_loss: 18685.8184\n",
      "Epoch 6666/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12554.7822 - val_loss: 18708.2969\n",
      "Epoch 6667/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12623.9873 - val_loss: 18750.6641\n",
      "Epoch 6668/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12750.7461 - val_loss: 18757.0781\n",
      "Epoch 6669/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12770.8574 - val_loss: 18718.5625\n",
      "Epoch 6670/10000\n",
      "630/630 [==============================] - 0s 17us/step - loss: 12656.0312 - val_loss: 18710.0176\n",
      "Epoch 6671/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12636.7002 - val_loss: 18705.7266\n",
      "Epoch 6672/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12622.1631 - val_loss: 18736.3359\n",
      "Epoch 6673/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12713.3467 - val_loss: 18733.5332\n",
      "Epoch 6674/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12692.6602 - val_loss: 18719.1289\n",
      "Epoch 6675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.5234 - val_loss: 18707.9160\n",
      "Epoch 6676/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12620.8408 - val_loss: 18690.5879\n",
      "Epoch 6677/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12569.8779 - val_loss: 18674.7109\n",
      "Epoch 6678/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12519.2109 - val_loss: 18712.9688\n",
      "Epoch 6679/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.2246 - val_loss: 18903.7383\n",
      "Epoch 6680/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13243.5742 - val_loss: 19104.8242\n",
      "Epoch 6681/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13870.2090 - val_loss: 19218.2676\n",
      "Epoch 6682/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14223.8115 - val_loss: 19271.3438\n",
      "Epoch 6683/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14389.3633 - val_loss: 19262.6211\n",
      "Epoch 6684/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14361.1631 - val_loss: 19198.2422\n",
      "Epoch 6685/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14160.2080 - val_loss: 19180.4727\n",
      "Epoch 6686/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14103.9404 - val_loss: 19184.2148\n",
      "Epoch 6687/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14116.9395 - val_loss: 19165.2617\n",
      "Epoch 6688/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14056.9619 - val_loss: 19130.4082\n",
      "Epoch 6689/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13945.0459 - val_loss: 19050.9375\n",
      "Epoch 6690/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13696.1270 - val_loss: 18972.8828\n",
      "Epoch 6691/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13453.3174 - val_loss: 18988.9043\n",
      "Epoch 6692/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13501.3477 - val_loss: 19005.1719\n",
      "Epoch 6693/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13544.7676 - val_loss: 19005.4395\n",
      "Epoch 6694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13546.9219 - val_loss: 18999.6113\n",
      "Epoch 6695/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13529.8086 - val_loss: 18971.5742\n",
      "Epoch 6696/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13444.8887 - val_loss: 18911.9238\n",
      "Epoch 6697/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13257.0508 - val_loss: 18889.4219\n",
      "Epoch 6698/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13182.8750 - val_loss: 18906.0801\n",
      "Epoch 6699/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13236.8477 - val_loss: 18860.5273\n",
      "Epoch 6700/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13095.6436 - val_loss: 18849.2734\n",
      "Epoch 6701/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13061.9521 - val_loss: 18850.4746\n",
      "Epoch 6702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13071.2148 - val_loss: 18840.1992\n",
      "Epoch 6703/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13037.9404 - val_loss: 18851.0547\n",
      "Epoch 6704/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13069.7080 - val_loss: 18813.5938\n",
      "Epoch 6705/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12954.2285 - val_loss: 18787.9414\n",
      "Epoch 6706/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12875.5498 - val_loss: 18757.4395\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6707/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12779.4727 - val_loss: 18739.3516\n",
      "Epoch 6708/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12721.0156 - val_loss: 18877.4902\n",
      "Epoch 6709/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13184.8828 - val_loss: 18844.1328\n",
      "Epoch 6710/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13058.3838 - val_loss: 19069.7871\n",
      "Epoch 6711/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13762.4590 - val_loss: 19196.8965\n",
      "Epoch 6712/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14159.7314 - val_loss: 19236.5879\n",
      "Epoch 6713/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14283.9150 - val_loss: 19250.7891\n",
      "Epoch 6714/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14326.0352 - val_loss: 19277.4902\n",
      "Epoch 6715/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14405.5166 - val_loss: 19272.8262\n",
      "Epoch 6716/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14393.1865 - val_loss: 19235.4004\n",
      "Epoch 6717/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14277.8633 - val_loss: 19186.2598\n",
      "Epoch 6718/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14123.7646 - val_loss: 19135.2832\n",
      "Epoch 6719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13957.9258 - val_loss: 19090.0723\n",
      "Epoch 6720/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13818.0674 - val_loss: 19077.8320\n",
      "Epoch 6721/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13772.7871 - val_loss: 19061.6562\n",
      "Epoch 6722/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13716.1523 - val_loss: 19028.9648\n",
      "Epoch 6723/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13621.0684 - val_loss: 19022.6523\n",
      "Epoch 6724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13597.5303 - val_loss: 19016.0977\n",
      "Epoch 6725/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13578.9648 - val_loss: 18993.8770\n",
      "Epoch 6726/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13510.4531 - val_loss: 18965.2793\n",
      "Epoch 6727/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13424.2393 - val_loss: 18923.6074\n",
      "Epoch 6728/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13295.7500 - val_loss: 18880.3398\n",
      "Epoch 6729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13166.8320 - val_loss: 18828.5020\n",
      "Epoch 6730/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13006.1182 - val_loss: 18770.0195\n",
      "Epoch 6731/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12825.7373 - val_loss: 18731.6738\n",
      "Epoch 6732/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12703.0625 - val_loss: 18762.1309\n",
      "Epoch 6733/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.4043 - val_loss: 18751.1367\n",
      "Epoch 6734/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.1963 - val_loss: 18933.9316\n",
      "Epoch 6735/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13346.1885 - val_loss: 18957.5137\n",
      "Epoch 6736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13407.5732 - val_loss: 19131.5508\n",
      "Epoch 6737/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13956.3574 - val_loss: 19265.6875\n",
      "Epoch 6738/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14376.1094 - val_loss: 19341.9219\n",
      "Epoch 6739/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14613.9775 - val_loss: 19359.9375\n",
      "Epoch 6740/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14670.1826 - val_loss: 19324.1875\n",
      "Epoch 6741/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14556.8594 - val_loss: 19259.3633\n",
      "Epoch 6742/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14355.5156 - val_loss: 19164.5566\n",
      "Epoch 6743/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14058.6230 - val_loss: 19089.0449\n",
      "Epoch 6744/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13824.1504 - val_loss: 19032.5742\n",
      "Epoch 6745/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13642.3555 - val_loss: 18999.5820\n",
      "Epoch 6746/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13537.8721 - val_loss: 18985.5391\n",
      "Epoch 6747/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13492.2451 - val_loss: 19027.3867\n",
      "Epoch 6748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13612.1494 - val_loss: 19029.2012\n",
      "Epoch 6749/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13618.2031 - val_loss: 18971.4707\n",
      "Epoch 6750/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13439.2754 - val_loss: 18942.0977\n",
      "Epoch 6751/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13351.7373 - val_loss: 18967.8164\n",
      "Epoch 6752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13427.9863 - val_loss: 18974.9688\n",
      "Epoch 6753/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13445.7100 - val_loss: 18940.4199\n",
      "Epoch 6754/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13336.6055 - val_loss: 18889.0645\n",
      "Epoch 6755/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13177.0898 - val_loss: 18842.5996\n",
      "Epoch 6756/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13036.1641 - val_loss: 18820.8184\n",
      "Epoch 6757/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12974.9600 - val_loss: 18820.7695\n",
      "Epoch 6758/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12978.1787 - val_loss: 18827.9902\n",
      "Epoch 6759/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13000.0488 - val_loss: 18800.7148\n",
      "Epoch 6760/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12912.8359 - val_loss: 18771.9082\n",
      "Epoch 6761/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12828.4541 - val_loss: 18743.3301\n",
      "Epoch 6762/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12745.4268 - val_loss: 18746.7754\n",
      "Epoch 6763/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.1992 - val_loss: 18750.8145\n",
      "Epoch 6764/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12756.2012 - val_loss: 18830.7539\n",
      "Epoch 6765/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13016.3662 - val_loss: 18881.7656\n",
      "Epoch 6766/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13172.0166 - val_loss: 19118.0078\n",
      "Epoch 6767/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13908.3750 - val_loss: 19255.2500\n",
      "Epoch 6768/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14334.8896 - val_loss: 19319.9199\n",
      "Epoch 6769/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14532.5273 - val_loss: 19329.4004\n",
      "Epoch 6770/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14571.7979 - val_loss: 19308.3750\n",
      "Epoch 6771/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14506.3438 - val_loss: 19229.2832\n",
      "Epoch 6772/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14263.1172 - val_loss: 19165.4688\n",
      "Epoch 6773/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14063.2588 - val_loss: 19096.8359\n",
      "Epoch 6774/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13846.6992 - val_loss: 19040.1621\n",
      "Epoch 6775/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13665.1836 - val_loss: 19021.0020\n",
      "Epoch 6776/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13602.7422 - val_loss: 19027.9980\n",
      "Epoch 6777/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13620.6064 - val_loss: 19024.8203\n",
      "Epoch 6778/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13612.5645 - val_loss: 19013.0469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6779/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13575.6709 - val_loss: 18962.8223\n",
      "Epoch 6780/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13414.9336 - val_loss: 18909.0039\n",
      "Epoch 6781/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13238.0947 - val_loss: 18916.4238\n",
      "Epoch 6782/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13263.2090 - val_loss: 18899.3926\n",
      "Epoch 6783/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13214.1035 - val_loss: 18874.4160\n",
      "Epoch 6784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13135.7061 - val_loss: 18907.5605\n",
      "Epoch 6785/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13247.7842 - val_loss: 18922.5723\n",
      "Epoch 6786/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13296.6963 - val_loss: 18891.4336\n",
      "Epoch 6787/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13198.1641 - val_loss: 18833.9883\n",
      "Epoch 6788/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13016.7520 - val_loss: 18792.7598\n",
      "Epoch 6789/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12886.8672 - val_loss: 18779.9395\n",
      "Epoch 6790/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12847.9453 - val_loss: 18780.9707\n",
      "Epoch 6791/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12847.9600 - val_loss: 18799.0332\n",
      "Epoch 6792/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12912.5850 - val_loss: 18780.3047\n",
      "Epoch 6793/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12856.8359 - val_loss: 18879.6289\n",
      "Epoch 6794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13169.7217 - val_loss: 18946.6973\n",
      "Epoch 6795/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13380.4443 - val_loss: 18948.2832\n",
      "Epoch 6796/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13384.1055 - val_loss: 18943.4746\n",
      "Epoch 6797/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13369.1074 - val_loss: 18941.3105\n",
      "Epoch 6798/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13355.8086 - val_loss: 18928.1367\n",
      "Epoch 6799/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13314.1055 - val_loss: 18891.5195\n",
      "Epoch 6800/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13197.6787 - val_loss: 18869.0938\n",
      "Epoch 6801/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13125.9395 - val_loss: 18828.9355\n",
      "Epoch 6802/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13005.1699 - val_loss: 18783.4277\n",
      "Epoch 6803/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12858.5684 - val_loss: 18734.4492\n",
      "Epoch 6804/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12702.8418 - val_loss: 18759.8105\n",
      "Epoch 6805/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12780.6797 - val_loss: 18988.4492\n",
      "Epoch 6806/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13523.7949 - val_loss: 18904.3008\n",
      "Epoch 6807/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13248.2510 - val_loss: 19111.8379\n",
      "Epoch 6808/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13895.4775 - val_loss: 19236.1230\n",
      "Epoch 6809/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14283.1299 - val_loss: 19306.4531\n",
      "Epoch 6810/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14503.3643 - val_loss: 19324.5820\n",
      "Epoch 6811/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14559.0986 - val_loss: 19304.4766\n",
      "Epoch 6812/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14495.5947 - val_loss: 19303.5820\n",
      "Epoch 6813/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14493.6504 - val_loss: 19243.6387\n",
      "Epoch 6814/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14306.0967 - val_loss: 19163.4043\n",
      "Epoch 6815/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14054.0898 - val_loss: 19103.8047\n",
      "Epoch 6816/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13866.0391 - val_loss: 19054.9492\n",
      "Epoch 6817/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13717.4453 - val_loss: 19010.2949\n",
      "Epoch 6818/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13564.1299 - val_loss: 18996.3359\n",
      "Epoch 6819/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13513.0195 - val_loss: 18995.5879\n",
      "Epoch 6820/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13510.3867 - val_loss: 18980.0742\n",
      "Epoch 6821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13463.8203 - val_loss: 18960.2109\n",
      "Epoch 6822/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13405.0498 - val_loss: 18955.0703\n",
      "Epoch 6823/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13385.3398 - val_loss: 18949.3672\n",
      "Epoch 6824/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13366.5527 - val_loss: 18904.6582\n",
      "Epoch 6825/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13225.1143 - val_loss: 18864.3027\n",
      "Epoch 6826/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13108.1299 - val_loss: 18868.3535\n",
      "Epoch 6827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13130.0879 - val_loss: 18868.5117\n",
      "Epoch 6828/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13131.7764 - val_loss: 18886.6094\n",
      "Epoch 6829/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13188.3408 - val_loss: 18873.0547\n",
      "Epoch 6830/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13146.6328 - val_loss: 18850.4180\n",
      "Epoch 6831/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13072.6582 - val_loss: 18792.7148\n",
      "Epoch 6832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12888.9824 - val_loss: 18754.3457\n",
      "Epoch 6833/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.4385 - val_loss: 18760.7930\n",
      "Epoch 6834/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.4219 - val_loss: 18784.4199\n",
      "Epoch 6835/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12857.7266 - val_loss: 18792.1719\n",
      "Epoch 6836/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12884.1006 - val_loss: 18765.5488\n",
      "Epoch 6837/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.2031 - val_loss: 18737.4629\n",
      "Epoch 6838/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.6309 - val_loss: 18701.1758\n",
      "Epoch 6839/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.8760 - val_loss: 18665.8945\n",
      "Epoch 6840/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12491.6562 - val_loss: 18950.2812\n",
      "Epoch 6841/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13409.5977 - val_loss: 18913.0645\n",
      "Epoch 6842/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13274.6387 - val_loss: 19131.3945\n",
      "Epoch 6843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13956.9873 - val_loss: 19251.5723\n",
      "Epoch 6844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14331.7539 - val_loss: 19325.7051\n",
      "Epoch 6845/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14563.3213 - val_loss: 19359.8691\n",
      "Epoch 6846/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14669.1445 - val_loss: 19335.6504\n",
      "Epoch 6847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14592.4180 - val_loss: 19273.9004\n",
      "Epoch 6848/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14401.0684 - val_loss: 19220.0977\n",
      "Epoch 6849/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14230.9971 - val_loss: 19165.9609\n",
      "Epoch 6850/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14062.2061 - val_loss: 19143.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6851/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13988.3408 - val_loss: 19121.7227\n",
      "Epoch 6852/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13915.5244 - val_loss: 19080.8125\n",
      "Epoch 6853/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13787.2891 - val_loss: 19050.7656\n",
      "Epoch 6854/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13690.9238 - val_loss: 19019.0723\n",
      "Epoch 6855/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13591.4941 - val_loss: 18984.4980\n",
      "Epoch 6856/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13484.0371 - val_loss: 18923.5391\n",
      "Epoch 6857/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13292.9551 - val_loss: 18876.2168\n",
      "Epoch 6858/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13152.7783 - val_loss: 18853.7891\n",
      "Epoch 6859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13073.6396 - val_loss: 18892.3203\n",
      "Epoch 6860/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13199.0654 - val_loss: 18912.2520\n",
      "Epoch 6861/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13261.6445 - val_loss: 18891.7852\n",
      "Epoch 6862/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13198.1826 - val_loss: 18884.8145\n",
      "Epoch 6863/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13176.8525 - val_loss: 18888.3828\n",
      "Epoch 6864/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13181.5068 - val_loss: 18870.8965\n",
      "Epoch 6865/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13127.2158 - val_loss: 18812.0762\n",
      "Epoch 6866/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12940.0088 - val_loss: 18786.2480\n",
      "Epoch 6867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.5664 - val_loss: 18751.5391\n",
      "Epoch 6868/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12752.0654 - val_loss: 18747.1582\n",
      "Epoch 6869/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.0752 - val_loss: 18743.9961\n",
      "Epoch 6870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.9707 - val_loss: 18749.0527\n",
      "Epoch 6871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12749.3291 - val_loss: 18765.7871\n",
      "Epoch 6872/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12798.9912 - val_loss: 18763.5039\n",
      "Epoch 6873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12793.7227 - val_loss: 18825.9238\n",
      "Epoch 6874/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12987.4814 - val_loss: 18829.2246\n",
      "Epoch 6875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12997.5947 - val_loss: 18927.1250\n",
      "Epoch 6876/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13310.7402 - val_loss: 18987.6602\n",
      "Epoch 6877/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13498.9307 - val_loss: 18978.3359\n",
      "Epoch 6878/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13471.3252 - val_loss: 18954.0020\n",
      "Epoch 6879/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13394.9834 - val_loss: 18909.0918\n",
      "Epoch 6880/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13255.4023 - val_loss: 18900.9297\n",
      "Epoch 6881/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13221.1250 - val_loss: 18884.8066\n",
      "Epoch 6882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13170.3984 - val_loss: 18844.5781\n",
      "Epoch 6883/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13040.9316 - val_loss: 18832.6992\n",
      "Epoch 6884/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13006.9346 - val_loss: 18821.4355\n",
      "Epoch 6885/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12969.6182 - val_loss: 18795.2715\n",
      "Epoch 6886/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12892.0547 - val_loss: 18827.5332\n",
      "Epoch 6887/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12992.4814 - val_loss: 18819.2266\n",
      "Epoch 6888/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12971.8389 - val_loss: 18801.8574\n",
      "Epoch 6889/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12916.4922 - val_loss: 18800.1660\n",
      "Epoch 6890/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12909.9844 - val_loss: 18791.3340\n",
      "Epoch 6891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12876.9004 - val_loss: 18762.8789\n",
      "Epoch 6892/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.3740 - val_loss: 18749.5996\n",
      "Epoch 6893/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.8320 - val_loss: 18731.9551\n",
      "Epoch 6894/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.5889 - val_loss: 18737.2305\n",
      "Epoch 6895/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12718.6631 - val_loss: 18772.5566\n",
      "Epoch 6896/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12819.1885 - val_loss: 18771.0723\n",
      "Epoch 6897/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12827.8037 - val_loss: 18764.8984\n",
      "Epoch 6898/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12794.8555 - val_loss: 18819.5430\n",
      "Epoch 6899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12973.1172 - val_loss: 18844.0664\n",
      "Epoch 6900/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13048.7520 - val_loss: 18848.3535\n",
      "Epoch 6901/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13060.5312 - val_loss: 18827.4980\n",
      "Epoch 6902/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12996.2637 - val_loss: 18802.9570\n",
      "Epoch 6903/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12911.7617 - val_loss: 18794.5137\n",
      "Epoch 6904/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12885.7178 - val_loss: 18780.8984\n",
      "Epoch 6905/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12845.0410 - val_loss: 18764.9355\n",
      "Epoch 6906/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12799.8516 - val_loss: 18842.8750\n",
      "Epoch 6907/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13062.5566 - val_loss: 18907.2871\n",
      "Epoch 6908/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13252.7148 - val_loss: 19178.5469\n",
      "Epoch 6909/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14096.6729 - val_loss: 19346.7598\n",
      "Epoch 6910/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14620.3877 - val_loss: 19437.3750\n",
      "Epoch 6911/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14901.6387 - val_loss: 19451.3359\n",
      "Epoch 6912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14945.4971 - val_loss: 19402.9551\n",
      "Epoch 6913/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14795.7139 - val_loss: 19284.7402\n",
      "Epoch 6914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14427.8672 - val_loss: 19287.6855\n",
      "Epoch 6915/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14434.8154 - val_loss: 19317.1406\n",
      "Epoch 6916/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14528.6719 - val_loss: 19260.2754\n",
      "Epoch 6917/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14350.6240 - val_loss: 19164.4922\n",
      "Epoch 6918/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14051.6318 - val_loss: 19118.8203\n",
      "Epoch 6919/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13903.1660 - val_loss: 19078.7305\n",
      "Epoch 6920/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13775.6494 - val_loss: 19033.7539\n",
      "Epoch 6921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13633.7402 - val_loss: 19091.6641\n",
      "Epoch 6922/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13815.9326 - val_loss: 19106.5234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6923/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13863.9170 - val_loss: 19066.7051\n",
      "Epoch 6924/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13738.8398 - val_loss: 18972.2285\n",
      "Epoch 6925/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13451.8496 - val_loss: 18901.1523\n",
      "Epoch 6926/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13225.9004 - val_loss: 18852.3652\n",
      "Epoch 6927/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13080.1777 - val_loss: 18873.6641\n",
      "Epoch 6928/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13145.0234 - val_loss: 18849.3262\n",
      "Epoch 6929/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13072.8213 - val_loss: 18830.7676\n",
      "Epoch 6930/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13004.9521 - val_loss: 18840.2617\n",
      "Epoch 6931/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13039.3896 - val_loss: 18820.2734\n",
      "Epoch 6932/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12976.7578 - val_loss: 18816.2324\n",
      "Epoch 6933/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12957.2100 - val_loss: 18927.5469\n",
      "Epoch 6934/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13319.2041 - val_loss: 18890.3105\n",
      "Epoch 6935/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13196.6641 - val_loss: 18978.4121\n",
      "Epoch 6936/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13476.5967 - val_loss: 19059.0430\n",
      "Epoch 6937/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13728.4268 - val_loss: 19093.1738\n",
      "Epoch 6938/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13838.0244 - val_loss: 19082.6016\n",
      "Epoch 6939/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13804.7246 - val_loss: 19090.1992\n",
      "Epoch 6940/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13825.3066 - val_loss: 19072.2891\n",
      "Epoch 6941/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13770.5381 - val_loss: 19061.5625\n",
      "Epoch 6942/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13735.8535 - val_loss: 19051.9043\n",
      "Epoch 6943/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13701.0957 - val_loss: 18999.5742\n",
      "Epoch 6944/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13538.6348 - val_loss: 18949.4160\n",
      "Epoch 6945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13385.3662 - val_loss: 18923.6172\n",
      "Epoch 6946/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13302.0918 - val_loss: 18892.4727\n",
      "Epoch 6947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13198.8799 - val_loss: 18881.8848\n",
      "Epoch 6948/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13161.0635 - val_loss: 18870.3535\n",
      "Epoch 6949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13128.5918 - val_loss: 18861.3535\n",
      "Epoch 6950/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13100.9834 - val_loss: 18838.9258\n",
      "Epoch 6951/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13031.9570 - val_loss: 18825.7520\n",
      "Epoch 6952/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12986.0586 - val_loss: 18829.7031\n",
      "Epoch 6953/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13002.2529 - val_loss: 18796.1523\n",
      "Epoch 6954/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12898.4619 - val_loss: 18772.2480\n",
      "Epoch 6955/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12817.9189 - val_loss: 18796.0371\n",
      "Epoch 6956/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12887.6387 - val_loss: 18849.7324\n",
      "Epoch 6957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13056.4014 - val_loss: 18838.0566\n",
      "Epoch 6958/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13017.0771 - val_loss: 18778.9277\n",
      "Epoch 6959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12836.8594 - val_loss: 18724.2852\n",
      "Epoch 6960/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12679.7451 - val_loss: 18745.9922\n",
      "Epoch 6961/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.5234 - val_loss: 18746.0547\n",
      "Epoch 6962/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12742.3291 - val_loss: 18738.4902\n",
      "Epoch 6963/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12720.4199 - val_loss: 18701.7012\n",
      "Epoch 6964/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12604.5840 - val_loss: 18705.2480\n",
      "Epoch 6965/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12610.2705 - val_loss: 18708.3555\n",
      "Epoch 6966/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.0391 - val_loss: 18686.1523\n",
      "Epoch 6967/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12553.5781 - val_loss: 18677.5352\n",
      "Epoch 6968/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.0039 - val_loss: 18677.9023\n",
      "Epoch 6969/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.7266 - val_loss: 18684.3594\n",
      "Epoch 6970/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.2451 - val_loss: 18704.3457\n",
      "Epoch 6971/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12614.0283 - val_loss: 18697.6719\n",
      "Epoch 6972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.7002 - val_loss: 18663.5879\n",
      "Epoch 6973/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12473.5459 - val_loss: 18671.5996\n",
      "Epoch 6974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12504.3330 - val_loss: 18693.6602\n",
      "Epoch 6975/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.6152 - val_loss: 18701.5078\n",
      "Epoch 6976/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12611.5000 - val_loss: 18720.8809\n",
      "Epoch 6977/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12672.4609 - val_loss: 18713.4609\n",
      "Epoch 6978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.2041 - val_loss: 18707.8809\n",
      "Epoch 6979/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12630.5068 - val_loss: 18715.9453\n",
      "Epoch 6980/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12654.3604 - val_loss: 18706.6289\n",
      "Epoch 6981/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.7041 - val_loss: 18697.1367\n",
      "Epoch 6982/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12583.5752 - val_loss: 18713.7051\n",
      "Epoch 6983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.2178 - val_loss: 18735.9766\n",
      "Epoch 6984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12713.3252 - val_loss: 18765.6719\n",
      "Epoch 6985/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.3877 - val_loss: 18746.5215\n",
      "Epoch 6986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12752.3926 - val_loss: 18731.6211\n",
      "Epoch 6987/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.7783 - val_loss: 18714.7031\n",
      "Epoch 6988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12649.3457 - val_loss: 18750.9922\n",
      "Epoch 6989/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.4072 - val_loss: 18843.5059\n",
      "Epoch 6990/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13059.8496 - val_loss: 19084.7480\n",
      "Epoch 6991/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13813.3438 - val_loss: 19227.8789\n",
      "Epoch 6992/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14258.3379 - val_loss: 19292.0254\n",
      "Epoch 6993/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14457.1914 - val_loss: 19289.3027\n",
      "Epoch 6994/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14449.2275 - val_loss: 19240.9219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6995/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14295.9727 - val_loss: 19171.4980\n",
      "Epoch 6996/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14078.6543 - val_loss: 19091.1465\n",
      "Epoch 6997/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13827.2705 - val_loss: 18997.8047\n",
      "Epoch 6998/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13534.3037 - val_loss: 18964.0820\n",
      "Epoch 6999/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13427.4961 - val_loss: 18953.1074\n",
      "Epoch 7000/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13387.3076 - val_loss: 18891.4785\n",
      "Epoch 7001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13192.9746 - val_loss: 18883.0488\n",
      "Epoch 7002/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13157.3281 - val_loss: 18892.6680\n",
      "Epoch 7003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13189.6455 - val_loss: 18900.9590\n",
      "Epoch 7004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13220.3691 - val_loss: 18908.8477\n",
      "Epoch 7005/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13242.2930 - val_loss: 18906.4551\n",
      "Epoch 7006/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13235.1582 - val_loss: 18856.2324\n",
      "Epoch 7007/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13077.7578 - val_loss: 18784.9297\n",
      "Epoch 7008/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12864.3184 - val_loss: 18775.3730\n",
      "Epoch 7009/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12832.8906 - val_loss: 18764.6387\n",
      "Epoch 7010/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.8750 - val_loss: 18779.4375\n",
      "Epoch 7011/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12852.0098 - val_loss: 18767.3398\n",
      "Epoch 7012/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12808.5967 - val_loss: 18720.8555\n",
      "Epoch 7013/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.8633 - val_loss: 18701.2910\n",
      "Epoch 7014/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12601.3633 - val_loss: 18806.6191\n",
      "Epoch 7015/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12951.0684 - val_loss: 18898.1211\n",
      "Epoch 7016/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13228.2256 - val_loss: 19086.0879\n",
      "Epoch 7017/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13811.5801 - val_loss: 19186.0273\n",
      "Epoch 7018/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14130.3867 - val_loss: 19261.3184\n",
      "Epoch 7019/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14364.3203 - val_loss: 19252.8359\n",
      "Epoch 7020/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14337.9961 - val_loss: 19200.7051\n",
      "Epoch 7021/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14172.7607 - val_loss: 19129.4824\n",
      "Epoch 7022/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13949.6885 - val_loss: 19034.6641\n",
      "Epoch 7023/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13651.5352 - val_loss: 19015.7109\n",
      "Epoch 7024/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13589.0615 - val_loss: 18978.5527\n",
      "Epoch 7025/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13474.1191 - val_loss: 18934.0469\n",
      "Epoch 7026/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13332.7070 - val_loss: 18898.5664\n",
      "Epoch 7027/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13206.4980 - val_loss: 18911.2188\n",
      "Epoch 7028/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13244.1328 - val_loss: 18934.8652\n",
      "Epoch 7029/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13319.3174 - val_loss: 18930.6914\n",
      "Epoch 7030/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13313.1533 - val_loss: 18945.6367\n",
      "Epoch 7031/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13360.6641 - val_loss: 18927.5703\n",
      "Epoch 7032/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13304.6436 - val_loss: 18860.6934\n",
      "Epoch 7033/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13093.9727 - val_loss: 18800.8301\n",
      "Epoch 7034/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12904.8867 - val_loss: 18814.7520\n",
      "Epoch 7035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12958.6221 - val_loss: 18811.8047\n",
      "Epoch 7036/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12954.7451 - val_loss: 18814.8711\n",
      "Epoch 7037/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12963.8203 - val_loss: 18805.9570\n",
      "Epoch 7038/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12937.3857 - val_loss: 18772.8223\n",
      "Epoch 7039/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12835.4873 - val_loss: 18722.3027\n",
      "Epoch 7040/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.2139 - val_loss: 18674.4883\n",
      "Epoch 7041/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12515.3770 - val_loss: 19046.7656\n",
      "Epoch 7042/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13715.8320 - val_loss: 18920.5723\n",
      "Epoch 7043/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13302.3213 - val_loss: 19170.1836\n",
      "Epoch 7044/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14081.5088 - val_loss: 19321.2812\n",
      "Epoch 7045/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14552.1660 - val_loss: 19387.6406\n",
      "Epoch 7046/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14758.1699 - val_loss: 19438.7090\n",
      "Epoch 7047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14919.4531 - val_loss: 19419.2207\n",
      "Epoch 7048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14859.2539 - val_loss: 19375.3730\n",
      "Epoch 7049/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14720.6143 - val_loss: 19304.0430\n",
      "Epoch 7050/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14493.2373 - val_loss: 19261.8086\n",
      "Epoch 7051/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14360.5869 - val_loss: 19184.6406\n",
      "Epoch 7052/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14119.5664 - val_loss: 19114.1328\n",
      "Epoch 7053/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13892.6455 - val_loss: 18984.0098\n",
      "Epoch 7054/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13486.9629 - val_loss: 18938.3203\n",
      "Epoch 7055/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13341.2783 - val_loss: 18973.2422\n",
      "Epoch 7056/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13445.6797 - val_loss: 18996.2520\n",
      "Epoch 7057/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13519.4189 - val_loss: 19032.8105\n",
      "Epoch 7058/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13626.0742 - val_loss: 19018.5918\n",
      "Epoch 7059/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13582.0898 - val_loss: 18951.3633\n",
      "Epoch 7060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13375.4443 - val_loss: 18931.3340\n",
      "Epoch 7061/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13313.2500 - val_loss: 18876.2715\n",
      "Epoch 7062/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13146.3047 - val_loss: 18838.3770\n",
      "Epoch 7063/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13033.3506 - val_loss: 18852.3691\n",
      "Epoch 7064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13079.3896 - val_loss: 18845.3340\n",
      "Epoch 7065/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13060.2314 - val_loss: 18809.1562\n",
      "Epoch 7066/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12953.1992 - val_loss: 18782.9688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7067/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12866.3877 - val_loss: 18756.2734\n",
      "Epoch 7068/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.1025 - val_loss: 18770.6445\n",
      "Epoch 7069/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12803.9795 - val_loss: 18999.0020\n",
      "Epoch 7070/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13549.0107 - val_loss: 18922.4180\n",
      "Epoch 7071/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13307.9287 - val_loss: 19139.7988\n",
      "Epoch 7072/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13984.5898 - val_loss: 19281.8164\n",
      "Epoch 7073/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14431.2969 - val_loss: 19334.0684\n",
      "Epoch 7074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14593.2471 - val_loss: 19376.9746\n",
      "Epoch 7075/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14726.7842 - val_loss: 19364.5566\n",
      "Epoch 7076/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14687.9121 - val_loss: 19277.7461\n",
      "Epoch 7077/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14417.8047 - val_loss: 19202.2422\n",
      "Epoch 7078/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14176.1631 - val_loss: 19174.9863\n",
      "Epoch 7079/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 14088.6660 - val_loss: 19158.4609\n",
      "Epoch 7080/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14035.1875 - val_loss: 19100.7734\n",
      "Epoch 7081/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13855.8916 - val_loss: 19003.4316\n",
      "Epoch 7082/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13549.8096 - val_loss: 18896.5352\n",
      "Epoch 7083/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13216.7598 - val_loss: 18851.8398\n",
      "Epoch 7084/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13072.7285 - val_loss: 18917.8145\n",
      "Epoch 7085/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13270.2764 - val_loss: 18958.5430\n",
      "Epoch 7086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13397.2793 - val_loss: 18953.7812\n",
      "Epoch 7087/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13384.6846 - val_loss: 18928.7363\n",
      "Epoch 7088/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13305.5361 - val_loss: 18921.0527\n",
      "Epoch 7089/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13276.3730 - val_loss: 18903.7266\n",
      "Epoch 7090/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13222.9805 - val_loss: 18860.0430\n",
      "Epoch 7091/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13085.7832 - val_loss: 18795.0469\n",
      "Epoch 7092/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12883.9863 - val_loss: 18757.0293\n",
      "Epoch 7093/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12775.8408 - val_loss: 18760.4180\n",
      "Epoch 7094/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12795.9893 - val_loss: 18770.1875\n",
      "Epoch 7095/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12830.5996 - val_loss: 18797.2930\n",
      "Epoch 7096/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.3408 - val_loss: 18792.2266\n",
      "Epoch 7097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12886.6006 - val_loss: 18768.6934\n",
      "Epoch 7098/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12808.1455 - val_loss: 18891.5898\n",
      "Epoch 7099/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13220.6084 - val_loss: 18916.5527\n",
      "Epoch 7100/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13285.7168 - val_loss: 19107.5410\n",
      "Epoch 7101/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13888.5391 - val_loss: 19229.7910\n",
      "Epoch 7102/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14269.5449 - val_loss: 19300.5957\n",
      "Epoch 7103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14489.9570 - val_loss: 19303.4473\n",
      "Epoch 7104/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14498.2393 - val_loss: 19272.4141\n",
      "Epoch 7105/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14398.9746 - val_loss: 19197.7969\n",
      "Epoch 7106/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14163.6836 - val_loss: 19150.0977\n",
      "Epoch 7107/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14009.2139 - val_loss: 19107.3457\n",
      "Epoch 7108/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13876.0273 - val_loss: 19007.7812\n",
      "Epoch 7109/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13563.4258 - val_loss: 18992.8906\n",
      "Epoch 7110/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13515.4980 - val_loss: 18996.1543\n",
      "Epoch 7111/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13521.1768 - val_loss: 19013.5879\n",
      "Epoch 7112/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13566.6934 - val_loss: 18983.7480\n",
      "Epoch 7113/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13475.6582 - val_loss: 18967.6152\n",
      "Epoch 7114/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13423.7031 - val_loss: 18922.6621\n",
      "Epoch 7115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13282.9971 - val_loss: 18868.8574\n",
      "Epoch 7116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13114.1982 - val_loss: 18851.9766\n",
      "Epoch 7117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13067.4072 - val_loss: 18830.1523\n",
      "Epoch 7118/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13005.9229 - val_loss: 18826.5938\n",
      "Epoch 7119/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13000.4160 - val_loss: 18831.1719\n",
      "Epoch 7120/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13011.0186 - val_loss: 18832.2461\n",
      "Epoch 7121/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13018.4023 - val_loss: 18812.1504\n",
      "Epoch 7122/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12953.6260 - val_loss: 18793.4609\n",
      "Epoch 7123/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.5840 - val_loss: 18736.2324\n",
      "Epoch 7124/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12712.7178 - val_loss: 18722.7578\n",
      "Epoch 7125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.1309 - val_loss: 18754.7148\n",
      "Epoch 7126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.6982 - val_loss: 18781.4258\n",
      "Epoch 7127/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12842.0859 - val_loss: 18775.9766\n",
      "Epoch 7128/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12824.2500 - val_loss: 18771.7520\n",
      "Epoch 7129/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12808.8701 - val_loss: 18779.1074\n",
      "Epoch 7130/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12833.2598 - val_loss: 18743.4277\n",
      "Epoch 7131/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12731.4697 - val_loss: 18716.8105\n",
      "Epoch 7132/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.3828 - val_loss: 18723.6641\n",
      "Epoch 7133/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12673.8174 - val_loss: 18726.5137\n",
      "Epoch 7134/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12684.4727 - val_loss: 18728.5527\n",
      "Epoch 7135/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12685.1338 - val_loss: 18701.9902\n",
      "Epoch 7136/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.6865 - val_loss: 18733.7363\n",
      "Epoch 7137/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.3916 - val_loss: 18742.6582\n",
      "Epoch 7138/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12731.4502 - val_loss: 18746.8477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7139/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.7109 - val_loss: 18739.4199\n",
      "Epoch 7140/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12721.7441 - val_loss: 18698.9688\n",
      "Epoch 7141/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.8340 - val_loss: 18682.3145\n",
      "Epoch 7142/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12538.9102 - val_loss: 18719.5645\n",
      "Epoch 7143/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12648.2305 - val_loss: 18723.4258\n",
      "Epoch 7144/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.3525 - val_loss: 18698.8340\n",
      "Epoch 7145/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.2080 - val_loss: 18696.7344\n",
      "Epoch 7146/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12589.1562 - val_loss: 18735.9512\n",
      "Epoch 7147/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.6064 - val_loss: 18798.9258\n",
      "Epoch 7148/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12914.3438 - val_loss: 18801.2246\n",
      "Epoch 7149/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12923.0840 - val_loss: 18781.2930\n",
      "Epoch 7150/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12857.9600 - val_loss: 18786.2812\n",
      "Epoch 7151/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12871.3076 - val_loss: 18760.5859\n",
      "Epoch 7152/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12787.0752 - val_loss: 18764.5977\n",
      "Epoch 7153/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12797.8799 - val_loss: 18786.5586\n",
      "Epoch 7154/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12867.6484 - val_loss: 18740.3574\n",
      "Epoch 7155/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12721.7285 - val_loss: 18739.7559\n",
      "Epoch 7156/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.8037 - val_loss: 18744.2500\n",
      "Epoch 7157/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12727.9238 - val_loss: 18736.7363\n",
      "Epoch 7158/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12715.9932 - val_loss: 18743.3105\n",
      "Epoch 7159/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.8164 - val_loss: 18771.6172\n",
      "Epoch 7160/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12826.6504 - val_loss: 18793.7324\n",
      "Epoch 7161/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12905.1943 - val_loss: 18816.7168\n",
      "Epoch 7162/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12975.4395 - val_loss: 18976.1719\n",
      "Epoch 7163/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13475.2529 - val_loss: 19083.0703\n",
      "Epoch 7164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13807.7129 - val_loss: 19117.1836\n",
      "Epoch 7165/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13914.3838 - val_loss: 19097.3906\n",
      "Epoch 7166/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13848.2773 - val_loss: 19075.1055\n",
      "Epoch 7167/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13776.3555 - val_loss: 19034.1152\n",
      "Epoch 7168/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13648.7803 - val_loss: 18953.4277\n",
      "Epoch 7169/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13395.4834 - val_loss: 18902.0840\n",
      "Epoch 7170/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13231.1660 - val_loss: 18873.3008\n",
      "Epoch 7171/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13135.2715 - val_loss: 18873.7168\n",
      "Epoch 7172/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13139.8369 - val_loss: 18848.4473\n",
      "Epoch 7173/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13066.0391 - val_loss: 18794.2891\n",
      "Epoch 7174/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12886.4414 - val_loss: 18803.1035\n",
      "Epoch 7175/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12919.3457 - val_loss: 18846.1660\n",
      "Epoch 7176/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13060.7793 - val_loss: 18843.6777\n",
      "Epoch 7177/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13054.7393 - val_loss: 18845.9043\n",
      "Epoch 7178/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13064.1289 - val_loss: 18829.3164\n",
      "Epoch 7179/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13011.4922 - val_loss: 18746.7480\n",
      "Epoch 7180/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.7900 - val_loss: 18730.9727\n",
      "Epoch 7181/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12699.3525 - val_loss: 18727.6074\n",
      "Epoch 7182/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12679.9268 - val_loss: 18740.6641\n",
      "Epoch 7183/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12720.3584 - val_loss: 18730.3691\n",
      "Epoch 7184/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12686.9199 - val_loss: 18718.1738\n",
      "Epoch 7185/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.4463 - val_loss: 18715.8203\n",
      "Epoch 7186/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12650.2109 - val_loss: 18728.4629\n",
      "Epoch 7187/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12684.6240 - val_loss: 18722.8984\n",
      "Epoch 7188/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12666.8867 - val_loss: 18813.4375\n",
      "Epoch 7189/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12967.4033 - val_loss: 18879.3730\n",
      "Epoch 7190/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13175.2959 - val_loss: 19119.6816\n",
      "Epoch 7191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13921.8213 - val_loss: 19265.3340\n",
      "Epoch 7192/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14377.0615 - val_loss: 19327.8652\n",
      "Epoch 7193/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14570.2168 - val_loss: 19360.0195\n",
      "Epoch 7194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14674.7871 - val_loss: 19353.3164\n",
      "Epoch 7195/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14646.4092 - val_loss: 19347.6523\n",
      "Epoch 7196/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14627.1025 - val_loss: 19304.0996\n",
      "Epoch 7197/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14491.9199 - val_loss: 19241.1855\n",
      "Epoch 7198/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14294.0811 - val_loss: 19165.1484\n",
      "Epoch 7199/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14057.8135 - val_loss: 19108.1699\n",
      "Epoch 7200/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13876.1406 - val_loss: 19056.2656\n",
      "Epoch 7201/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13715.3037 - val_loss: 19023.2559\n",
      "Epoch 7202/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13612.5391 - val_loss: 19040.9824\n",
      "Epoch 7203/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13664.5010 - val_loss: 19004.7969\n",
      "Epoch 7204/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13546.0195 - val_loss: 18997.0723\n",
      "Epoch 7205/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13520.3730 - val_loss: 18987.4551\n",
      "Epoch 7206/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13491.4736 - val_loss: 18927.4551\n",
      "Epoch 7207/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 13301.9941 - val_loss: 18891.9199\n",
      "Epoch 7208/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13192.6807 - val_loss: 18889.2246\n",
      "Epoch 7209/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13181.9580 - val_loss: 18866.1992\n",
      "Epoch 7210/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13117.0361 - val_loss: 18845.1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7211/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13054.7881 - val_loss: 18854.2734\n",
      "Epoch 7212/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13082.7354 - val_loss: 18845.8555\n",
      "Epoch 7213/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13063.0352 - val_loss: 18806.8418\n",
      "Epoch 7214/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12936.9229 - val_loss: 18800.3066\n",
      "Epoch 7215/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12909.5439 - val_loss: 18792.4785\n",
      "Epoch 7216/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12880.1152 - val_loss: 18792.5488\n",
      "Epoch 7217/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.3018 - val_loss: 18758.3223\n",
      "Epoch 7218/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.0957 - val_loss: 18688.7363\n",
      "Epoch 7219/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12560.1133 - val_loss: 18681.0488\n",
      "Epoch 7220/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.3467 - val_loss: 18748.0801\n",
      "Epoch 7221/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12743.9092 - val_loss: 18786.2812\n",
      "Epoch 7222/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12864.4932 - val_loss: 18769.3066\n",
      "Epoch 7223/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12807.0205 - val_loss: 18746.7148\n",
      "Epoch 7224/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.2383 - val_loss: 18710.9531\n",
      "Epoch 7225/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12630.1025 - val_loss: 18749.2520\n",
      "Epoch 7226/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12758.6729 - val_loss: 18774.2793\n",
      "Epoch 7227/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12833.7734 - val_loss: 18822.2812\n",
      "Epoch 7228/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12995.0566 - val_loss: 18830.8066\n",
      "Epoch 7229/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13021.7129 - val_loss: 18801.9570\n",
      "Epoch 7230/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12929.3848 - val_loss: 18747.6543\n",
      "Epoch 7231/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12757.2002 - val_loss: 18747.2871\n",
      "Epoch 7232/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.1123 - val_loss: 18792.0391\n",
      "Epoch 7233/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12877.8398 - val_loss: 18793.4180\n",
      "Epoch 7234/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12884.4072 - val_loss: 18777.5293\n",
      "Epoch 7235/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12834.1035 - val_loss: 18745.9609\n",
      "Epoch 7236/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.1914 - val_loss: 18761.3262\n",
      "Epoch 7237/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12788.3965 - val_loss: 18745.2246\n",
      "Epoch 7238/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12740.2627 - val_loss: 18762.8242\n",
      "Epoch 7239/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12796.4678 - val_loss: 18758.6250\n",
      "Epoch 7240/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12786.4092 - val_loss: 18719.5312\n",
      "Epoch 7241/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.5977 - val_loss: 18707.6191\n",
      "Epoch 7242/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12619.6113 - val_loss: 18702.4023\n",
      "Epoch 7243/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.1016 - val_loss: 18680.1465\n",
      "Epoch 7244/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12543.4082 - val_loss: 18686.6543\n",
      "Epoch 7245/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12556.0586 - val_loss: 18686.1484\n",
      "Epoch 7246/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.4561 - val_loss: 18716.5195\n",
      "Epoch 7247/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12644.6279 - val_loss: 18731.4727\n",
      "Epoch 7248/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.0400 - val_loss: 18720.0762\n",
      "Epoch 7249/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.5986 - val_loss: 18713.1035\n",
      "Epoch 7250/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.1572 - val_loss: 18798.5977\n",
      "Epoch 7251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12924.2979 - val_loss: 18891.7715\n",
      "Epoch 7252/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13213.0850 - val_loss: 19095.8965\n",
      "Epoch 7253/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13849.7588 - val_loss: 19232.2539\n",
      "Epoch 7254/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14273.6621 - val_loss: 19301.8496\n",
      "Epoch 7255/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14489.8369 - val_loss: 19331.5742\n",
      "Epoch 7256/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 14581.0566 - val_loss: 19299.7344\n",
      "Epoch 7257/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14482.1064 - val_loss: 19241.2090\n",
      "Epoch 7258/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14298.4736 - val_loss: 19193.8164\n",
      "Epoch 7259/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14150.4980 - val_loss: 19165.1348\n",
      "Epoch 7260/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14060.2314 - val_loss: 19128.4121\n",
      "Epoch 7261/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13947.3789 - val_loss: 19031.2617\n",
      "Epoch 7262/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13643.5596 - val_loss: 18986.7305\n",
      "Epoch 7263/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13491.7256 - val_loss: 18990.1426\n",
      "Epoch 7264/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13500.5273 - val_loss: 18994.9258\n",
      "Epoch 7265/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13512.0117 - val_loss: 18985.2949\n",
      "Epoch 7266/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13483.5303 - val_loss: 19022.2832\n",
      "Epoch 7267/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13596.3584 - val_loss: 19033.1621\n",
      "Epoch 7268/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13630.8311 - val_loss: 18987.3535\n",
      "Epoch 7269/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13486.7930 - val_loss: 18898.2910\n",
      "Epoch 7270/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13211.9727 - val_loss: 18861.0137\n",
      "Epoch 7271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13097.5176 - val_loss: 18884.8672\n",
      "Epoch 7272/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13177.0713 - val_loss: 18899.0254\n",
      "Epoch 7273/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13221.5811 - val_loss: 18912.8477\n",
      "Epoch 7274/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13268.1416 - val_loss: 18880.7559\n",
      "Epoch 7275/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13162.9395 - val_loss: 18823.9062\n",
      "Epoch 7276/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12987.5557 - val_loss: 18789.1094\n",
      "Epoch 7277/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12882.9355 - val_loss: 18750.0215\n",
      "Epoch 7278/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.1299 - val_loss: 18726.0137\n",
      "Epoch 7279/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12690.2891 - val_loss: 18744.3125\n",
      "Epoch 7280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.9209 - val_loss: 18747.9473\n",
      "Epoch 7281/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12747.8086 - val_loss: 18736.7090\n",
      "Epoch 7282/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12718.6074 - val_loss: 18786.2520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7283/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12871.4893 - val_loss: 18814.0137\n",
      "Epoch 7284/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12958.3896 - val_loss: 18816.2168\n",
      "Epoch 7285/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12967.9541 - val_loss: 18782.8262\n",
      "Epoch 7286/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12866.6953 - val_loss: 18749.0898\n",
      "Epoch 7287/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.5166 - val_loss: 18726.0684\n",
      "Epoch 7288/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12675.5459 - val_loss: 18793.7051\n",
      "Epoch 7289/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12892.3252 - val_loss: 18818.9531\n",
      "Epoch 7290/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12984.4844 - val_loss: 18955.8008\n",
      "Epoch 7291/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13414.9609 - val_loss: 19041.3535\n",
      "Epoch 7292/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13681.5801 - val_loss: 19073.2070\n",
      "Epoch 7293/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13780.7139 - val_loss: 19048.1484\n",
      "Epoch 7294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13698.7656 - val_loss: 19011.1582\n",
      "Epoch 7295/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13580.4209 - val_loss: 18984.6875\n",
      "Epoch 7296/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13493.6562 - val_loss: 18936.7969\n",
      "Epoch 7297/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13342.5449 - val_loss: 18920.9980\n",
      "Epoch 7298/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13296.1475 - val_loss: 18896.2148\n",
      "Epoch 7299/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13217.1826 - val_loss: 18847.3398\n",
      "Epoch 7300/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13062.5605 - val_loss: 18858.2344\n",
      "Epoch 7301/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13082.9795 - val_loss: 18894.2051\n",
      "Epoch 7302/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13193.9648 - val_loss: 18897.9199\n",
      "Epoch 7303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13209.8066 - val_loss: 18856.5059\n",
      "Epoch 7304/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13078.5176 - val_loss: 18823.9414\n",
      "Epoch 7305/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12975.8438 - val_loss: 18797.5137\n",
      "Epoch 7306/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12896.7480 - val_loss: 18781.2949\n",
      "Epoch 7307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12850.7832 - val_loss: 18767.0312\n",
      "Epoch 7308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12811.3867 - val_loss: 18741.0977\n",
      "Epoch 7309/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.2637 - val_loss: 18702.6016\n",
      "Epoch 7310/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.2568 - val_loss: 18723.8555\n",
      "Epoch 7311/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12679.6494 - val_loss: 18734.7012\n",
      "Epoch 7312/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.6270 - val_loss: 18733.5020\n",
      "Epoch 7313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12694.8184 - val_loss: 18697.5762\n",
      "Epoch 7314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.4355 - val_loss: 18704.6074\n",
      "Epoch 7315/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.9297 - val_loss: 18713.7520\n",
      "Epoch 7316/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.1797 - val_loss: 18714.5273\n",
      "Epoch 7317/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.7070 - val_loss: 18702.6504\n",
      "Epoch 7318/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12601.3105 - val_loss: 18684.8574\n",
      "Epoch 7319/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12548.7393 - val_loss: 18682.8418\n",
      "Epoch 7320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.3857 - val_loss: 18669.1758\n",
      "Epoch 7321/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12497.3584 - val_loss: 18686.4434\n",
      "Epoch 7322/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.2432 - val_loss: 18682.7734\n",
      "Epoch 7323/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.3486 - val_loss: 18655.7617\n",
      "Epoch 7324/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12461.1523 - val_loss: 18649.2969\n",
      "Epoch 7325/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12439.0713 - val_loss: 18683.7148\n",
      "Epoch 7326/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12538.6152 - val_loss: 18696.8164\n",
      "Epoch 7327/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.2461 - val_loss: 18676.9551\n",
      "Epoch 7328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12520.8408 - val_loss: 18661.4902\n",
      "Epoch 7329/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12470.3945 - val_loss: 18662.5527\n",
      "Epoch 7330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12476.1719 - val_loss: 18676.5449\n",
      "Epoch 7331/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12525.8799 - val_loss: 18657.6543\n",
      "Epoch 7332/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12465.0693 - val_loss: 18655.5137\n",
      "Epoch 7333/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12452.5420 - val_loss: 18653.3145\n",
      "Epoch 7334/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12453.2578 - val_loss: 18671.3184\n",
      "Epoch 7335/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.7451 - val_loss: 18663.4766\n",
      "Epoch 7336/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12481.0586 - val_loss: 18648.9531\n",
      "Epoch 7337/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12434.0254 - val_loss: 18662.4004\n",
      "Epoch 7338/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.2998 - val_loss: 18675.4023\n",
      "Epoch 7339/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.1328 - val_loss: 18648.6973\n",
      "Epoch 7340/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12440.3096 - val_loss: 18656.6367\n",
      "Epoch 7341/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12456.9844 - val_loss: 18659.0859\n",
      "Epoch 7342/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12470.1592 - val_loss: 18653.2070\n",
      "Epoch 7343/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12450.2520 - val_loss: 18638.3555\n",
      "Epoch 7344/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12404.0195 - val_loss: 18654.2207\n",
      "Epoch 7345/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12450.0840 - val_loss: 18639.9512\n",
      "Epoch 7346/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12412.8398 - val_loss: 18656.0078\n",
      "Epoch 7347/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12466.1426 - val_loss: 18676.4219\n",
      "Epoch 7348/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12530.3467 - val_loss: 18683.0391\n",
      "Epoch 7349/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12549.3525 - val_loss: 18719.7832\n",
      "Epoch 7350/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12660.6270 - val_loss: 18712.9609\n",
      "Epoch 7351/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.3633 - val_loss: 18693.5273\n",
      "Epoch 7352/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.0332 - val_loss: 18667.2637\n",
      "Epoch 7353/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12490.1836 - val_loss: 18690.7930\n",
      "Epoch 7354/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12608.0742 - val_loss: 18843.8164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7355/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13058.2461 - val_loss: 19002.0449\n",
      "Epoch 7356/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13552.6318 - val_loss: 19074.9414\n",
      "Epoch 7357/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13778.7803 - val_loss: 19113.1816\n",
      "Epoch 7358/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13898.4404 - val_loss: 19098.9277\n",
      "Epoch 7359/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13852.3311 - val_loss: 19100.8535\n",
      "Epoch 7360/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13856.9316 - val_loss: 19076.6582\n",
      "Epoch 7361/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13780.4072 - val_loss: 19003.5176\n",
      "Epoch 7362/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13554.2617 - val_loss: 18947.1895\n",
      "Epoch 7363/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13375.2783 - val_loss: 18904.3164\n",
      "Epoch 7364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13238.0811 - val_loss: 18878.6035\n",
      "Epoch 7365/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13155.5254 - val_loss: 18904.6309\n",
      "Epoch 7366/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13233.7783 - val_loss: 18916.5957\n",
      "Epoch 7367/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13269.3613 - val_loss: 18879.8301\n",
      "Epoch 7368/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13154.3389 - val_loss: 18827.0938\n",
      "Epoch 7369/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12991.0879 - val_loss: 18794.3301\n",
      "Epoch 7370/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12891.1123 - val_loss: 18758.7129\n",
      "Epoch 7371/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12784.5703 - val_loss: 18736.6250\n",
      "Epoch 7372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.5518 - val_loss: 18727.7930\n",
      "Epoch 7373/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12684.3389 - val_loss: 18742.9336\n",
      "Epoch 7374/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12732.7373 - val_loss: 18831.4258\n",
      "Epoch 7375/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13049.8564 - val_loss: 18897.0938\n",
      "Epoch 7376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13221.2627 - val_loss: 19070.5234\n",
      "Epoch 7377/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13768.0088 - val_loss: 19172.9453\n",
      "Epoch 7378/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14087.7217 - val_loss: 19214.1016\n",
      "Epoch 7379/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14215.6055 - val_loss: 19203.4785\n",
      "Epoch 7380/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14182.9492 - val_loss: 19214.5195\n",
      "Epoch 7381/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14211.2979 - val_loss: 19196.6738\n",
      "Epoch 7382/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14152.3740 - val_loss: 19163.4883\n",
      "Epoch 7383/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14052.2324 - val_loss: 19137.3066\n",
      "Epoch 7384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13967.7607 - val_loss: 19083.8945\n",
      "Epoch 7385/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13800.7949 - val_loss: 18986.4922\n",
      "Epoch 7386/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13498.1006 - val_loss: 18933.2031\n",
      "Epoch 7387/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13331.1924 - val_loss: 18916.0293\n",
      "Epoch 7388/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13272.0059 - val_loss: 18909.0703\n",
      "Epoch 7389/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13252.1211 - val_loss: 18861.7363\n",
      "Epoch 7390/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13101.6025 - val_loss: 18890.0020\n",
      "Epoch 7391/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13184.6523 - val_loss: 19023.4277\n",
      "Epoch 7392/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13649.4297 - val_loss: 18875.0898\n",
      "Epoch 7393/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13152.6934 - val_loss: 19074.7578\n",
      "Epoch 7394/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13783.1016 - val_loss: 19219.7930\n",
      "Epoch 7395/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14235.0186 - val_loss: 19300.9551\n",
      "Epoch 7396/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14489.1650 - val_loss: 19364.5586\n",
      "Epoch 7397/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14688.0762 - val_loss: 19376.4277\n",
      "Epoch 7398/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14723.4541 - val_loss: 19318.7344\n",
      "Epoch 7399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14543.8076 - val_loss: 19251.0957\n",
      "Epoch 7400/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14332.2822 - val_loss: 19191.9512\n",
      "Epoch 7401/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14148.1035 - val_loss: 19098.2891\n",
      "Epoch 7402/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13852.7314 - val_loss: 19030.3340\n",
      "Epoch 7403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13633.9355 - val_loss: 18970.0605\n",
      "Epoch 7404/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13442.6377 - val_loss: 18916.9668\n",
      "Epoch 7405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13266.4736 - val_loss: 18907.9941\n",
      "Epoch 7406/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13238.1230 - val_loss: 19071.5898\n",
      "Epoch 7407/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13794.0713 - val_loss: 18882.0117\n",
      "Epoch 7408/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13171.5488 - val_loss: 19030.7598\n",
      "Epoch 7409/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13646.7910 - val_loss: 19177.4629\n",
      "Epoch 7410/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14102.0029 - val_loss: 19260.0410\n",
      "Epoch 7411/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14360.4863 - val_loss: 19273.7441\n",
      "Epoch 7412/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14402.1055 - val_loss: 19222.3418\n",
      "Epoch 7413/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14241.4033 - val_loss: 19195.7148\n",
      "Epoch 7414/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14161.7119 - val_loss: 19139.8047\n",
      "Epoch 7415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13986.3984 - val_loss: 19143.3359\n",
      "Epoch 7416/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13984.9600 - val_loss: 19138.6602\n",
      "Epoch 7417/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13970.6982 - val_loss: 19096.0430\n",
      "Epoch 7418/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13829.9932 - val_loss: 19030.0508\n",
      "Epoch 7419/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13625.3623 - val_loss: 19014.4727\n",
      "Epoch 7420/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13573.0068 - val_loss: 18957.8535\n",
      "Epoch 7421/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13401.9326 - val_loss: 18860.7012\n",
      "Epoch 7422/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13106.5420 - val_loss: 18893.1660\n",
      "Epoch 7423/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13208.0967 - val_loss: 18910.1445\n",
      "Epoch 7424/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13265.0869 - val_loss: 18881.6855\n",
      "Epoch 7425/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13167.3760 - val_loss: 18850.5469\n",
      "Epoch 7426/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13064.4980 - val_loss: 18832.6621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7427/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13004.2109 - val_loss: 18816.3926\n",
      "Epoch 7428/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12970.4023 - val_loss: 18778.5391\n",
      "Epoch 7429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.6572 - val_loss: 18782.0996\n",
      "Epoch 7430/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12862.3828 - val_loss: 18759.8438\n",
      "Epoch 7431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.3125 - val_loss: 18772.8867\n",
      "Epoch 7432/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12823.4434 - val_loss: 18768.8477\n",
      "Epoch 7433/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12813.4678 - val_loss: 18765.8691\n",
      "Epoch 7434/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12804.0039 - val_loss: 18758.4531\n",
      "Epoch 7435/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12774.6104 - val_loss: 18743.2305\n",
      "Epoch 7436/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12729.5273 - val_loss: 18779.8633\n",
      "Epoch 7437/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12844.0938 - val_loss: 18741.0410\n",
      "Epoch 7438/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.1914 - val_loss: 18763.9805\n",
      "Epoch 7439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12807.9961 - val_loss: 18786.0840\n",
      "Epoch 7440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.0244 - val_loss: 18784.1680\n",
      "Epoch 7441/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12869.1621 - val_loss: 18758.7637\n",
      "Epoch 7442/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12786.1680 - val_loss: 18725.6270\n",
      "Epoch 7443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.0703 - val_loss: 18740.9980\n",
      "Epoch 7444/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12717.4619 - val_loss: 18750.8145\n",
      "Epoch 7445/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12754.7998 - val_loss: 18751.4258\n",
      "Epoch 7446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.4990 - val_loss: 18719.9199\n",
      "Epoch 7447/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.2627 - val_loss: 18688.9004\n",
      "Epoch 7448/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12556.6885 - val_loss: 18682.5605\n",
      "Epoch 7449/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.4365 - val_loss: 18689.1328\n",
      "Epoch 7450/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.1328 - val_loss: 18681.1777\n",
      "Epoch 7451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.0205 - val_loss: 18693.2812\n",
      "Epoch 7452/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.7842 - val_loss: 18700.7520\n",
      "Epoch 7453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.5674 - val_loss: 18698.8691\n",
      "Epoch 7454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12599.9414 - val_loss: 18697.9121\n",
      "Epoch 7455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.1650 - val_loss: 18709.0254\n",
      "Epoch 7456/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12628.4180 - val_loss: 18705.5273\n",
      "Epoch 7457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.3828 - val_loss: 18700.2461\n",
      "Epoch 7458/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.1572 - val_loss: 18696.7129\n",
      "Epoch 7459/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.0459 - val_loss: 18694.2637\n",
      "Epoch 7460/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12588.8555 - val_loss: 18688.0352\n",
      "Epoch 7461/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12566.3086 - val_loss: 18679.2422\n",
      "Epoch 7462/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.8848 - val_loss: 18680.6992\n",
      "Epoch 7463/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.2988 - val_loss: 18683.9961\n",
      "Epoch 7464/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12541.2324 - val_loss: 18674.6348\n",
      "Epoch 7465/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12514.9521 - val_loss: 18673.1660\n",
      "Epoch 7466/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12517.0713 - val_loss: 18657.5215\n",
      "Epoch 7467/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12471.8809 - val_loss: 18675.1211\n",
      "Epoch 7468/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12525.4551 - val_loss: 18677.3633\n",
      "Epoch 7469/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12535.1719 - val_loss: 18659.1074\n",
      "Epoch 7470/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12478.2275 - val_loss: 18673.2441\n",
      "Epoch 7471/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.3389 - val_loss: 18703.6914\n",
      "Epoch 7472/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12602.3613 - val_loss: 18698.2676\n",
      "Epoch 7473/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12582.2910 - val_loss: 18676.6934\n",
      "Epoch 7474/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.6533 - val_loss: 18690.5820\n",
      "Epoch 7475/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.8584 - val_loss: 18682.5332\n",
      "Epoch 7476/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.8486 - val_loss: 18703.9082\n",
      "Epoch 7477/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.9697 - val_loss: 18675.0059\n",
      "Epoch 7478/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12516.5967 - val_loss: 18651.1758\n",
      "Epoch 7479/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12440.4658 - val_loss: 18687.9590\n",
      "Epoch 7480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12573.7803 - val_loss: 18771.5156\n",
      "Epoch 7481/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12834.6582 - val_loss: 18894.3477\n",
      "Epoch 7482/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13219.0029 - val_loss: 18930.4355\n",
      "Epoch 7483/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13331.7207 - val_loss: 18919.1406\n",
      "Epoch 7484/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13290.8232 - val_loss: 18888.7168\n",
      "Epoch 7485/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13193.7803 - val_loss: 18882.1484\n",
      "Epoch 7486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13165.7500 - val_loss: 18908.0254\n",
      "Epoch 7487/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13251.4570 - val_loss: 18870.4453\n",
      "Epoch 7488/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13134.9785 - val_loss: 18808.4531\n",
      "Epoch 7489/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12943.0557 - val_loss: 18763.1660\n",
      "Epoch 7490/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12804.1328 - val_loss: 18772.0957\n",
      "Epoch 7491/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12827.1426 - val_loss: 18766.8398\n",
      "Epoch 7492/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.4844 - val_loss: 18767.9102\n",
      "Epoch 7493/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12807.4365 - val_loss: 18764.0234\n",
      "Epoch 7494/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.7383 - val_loss: 18727.2812\n",
      "Epoch 7495/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.4678 - val_loss: 18749.7148\n",
      "Epoch 7496/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12751.1865 - val_loss: 18758.1094\n",
      "Epoch 7497/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.1562 - val_loss: 18733.1660\n",
      "Epoch 7498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12700.1104 - val_loss: 18717.5664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7499/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.7236 - val_loss: 18702.1816\n",
      "Epoch 7500/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12610.1895 - val_loss: 18680.0957\n",
      "Epoch 7501/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12535.3271 - val_loss: 18712.3789\n",
      "Epoch 7502/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.2012 - val_loss: 18710.9531\n",
      "Epoch 7503/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.4668 - val_loss: 18713.7227\n",
      "Epoch 7504/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12632.0156 - val_loss: 18717.6484\n",
      "Epoch 7505/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12647.8594 - val_loss: 18693.5098\n",
      "Epoch 7506/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12568.2158 - val_loss: 18683.0391\n",
      "Epoch 7507/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12544.5000 - val_loss: 18672.1914\n",
      "Epoch 7508/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12515.1680 - val_loss: 18674.9707\n",
      "Epoch 7509/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.8301 - val_loss: 18671.8496\n",
      "Epoch 7510/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12514.3232 - val_loss: 18683.8145\n",
      "Epoch 7511/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12544.7412 - val_loss: 18675.6426\n",
      "Epoch 7512/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.7217 - val_loss: 18675.3027\n",
      "Epoch 7513/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12525.9131 - val_loss: 18713.8906\n",
      "Epoch 7514/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12647.4619 - val_loss: 18711.3477\n",
      "Epoch 7515/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12639.0312 - val_loss: 18680.8145\n",
      "Epoch 7516/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12542.8828 - val_loss: 18679.8965\n",
      "Epoch 7517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12536.1660 - val_loss: 18698.9336\n",
      "Epoch 7518/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12597.2129 - val_loss: 18699.2188\n",
      "Epoch 7519/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.7939 - val_loss: 18702.4531\n",
      "Epoch 7520/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.1201 - val_loss: 18736.5645\n",
      "Epoch 7521/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12721.1016 - val_loss: 18758.9824\n",
      "Epoch 7522/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.6992 - val_loss: 18764.4629\n",
      "Epoch 7523/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12804.0586 - val_loss: 18756.5020\n",
      "Epoch 7524/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12775.8232 - val_loss: 18713.3145\n",
      "Epoch 7525/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.1250 - val_loss: 18676.8320\n",
      "Epoch 7526/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12524.4199 - val_loss: 18745.1445\n",
      "Epoch 7527/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12765.9238 - val_loss: 18860.6191\n",
      "Epoch 7528/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13108.0283 - val_loss: 19042.9727\n",
      "Epoch 7529/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13679.2979 - val_loss: 19158.5020\n",
      "Epoch 7530/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14044.0361 - val_loss: 19199.2129\n",
      "Epoch 7531/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14170.2744 - val_loss: 19159.1016\n",
      "Epoch 7532/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14044.8770 - val_loss: 19113.0234\n",
      "Epoch 7533/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13895.0049 - val_loss: 19077.4609\n",
      "Epoch 7534/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13782.7344 - val_loss: 19062.8457\n",
      "Epoch 7535/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13737.4746 - val_loss: 19029.9180\n",
      "Epoch 7536/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13626.6660 - val_loss: 18995.3320\n",
      "Epoch 7537/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13519.5137 - val_loss: 18996.0195\n",
      "Epoch 7538/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13522.3965 - val_loss: 18979.0254\n",
      "Epoch 7539/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13470.0889 - val_loss: 18963.3223\n",
      "Epoch 7540/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13420.9365 - val_loss: 18923.4453\n",
      "Epoch 7541/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13295.0850 - val_loss: 18889.1523\n",
      "Epoch 7542/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13193.6572 - val_loss: 18889.9043\n",
      "Epoch 7543/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13190.5488 - val_loss: 18894.8008\n",
      "Epoch 7544/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13204.3682 - val_loss: 18887.5391\n",
      "Epoch 7545/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13184.1006 - val_loss: 18881.1641\n",
      "Epoch 7546/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13166.7822 - val_loss: 18830.0410\n",
      "Epoch 7547/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13002.9678 - val_loss: 18775.1855\n",
      "Epoch 7548/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12833.2988 - val_loss: 18797.5859\n",
      "Epoch 7549/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12901.1719 - val_loss: 18806.0254\n",
      "Epoch 7550/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12927.5732 - val_loss: 18783.2754\n",
      "Epoch 7551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.4170 - val_loss: 18708.1016\n",
      "Epoch 7552/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.9785 - val_loss: 18703.5645\n",
      "Epoch 7553/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12600.4199 - val_loss: 18742.8926\n",
      "Epoch 7554/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.0205 - val_loss: 18771.3320\n",
      "Epoch 7555/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12822.9219 - val_loss: 18759.1289\n",
      "Epoch 7556/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12786.1543 - val_loss: 18747.8711\n",
      "Epoch 7557/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12751.6611 - val_loss: 18733.3105\n",
      "Epoch 7558/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.2402 - val_loss: 18750.3574\n",
      "Epoch 7559/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12767.4414 - val_loss: 18767.6875\n",
      "Epoch 7560/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12819.1650 - val_loss: 18769.7070\n",
      "Epoch 7561/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12826.4365 - val_loss: 18779.6406\n",
      "Epoch 7562/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12851.6602 - val_loss: 18782.7227\n",
      "Epoch 7563/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.7188 - val_loss: 18778.3789\n",
      "Epoch 7564/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12842.4814 - val_loss: 18749.2539\n",
      "Epoch 7565/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.7236 - val_loss: 18754.4844\n",
      "Epoch 7566/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.8838 - val_loss: 18752.3359\n",
      "Epoch 7567/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12769.5488 - val_loss: 18752.3613\n",
      "Epoch 7568/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12757.9463 - val_loss: 18758.7949\n",
      "Epoch 7569/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12782.4014 - val_loss: 18755.7168\n",
      "Epoch 7570/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12772.7334 - val_loss: 18742.2852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7571/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.5039 - val_loss: 18714.5156\n",
      "Epoch 7572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12639.0469 - val_loss: 18722.6582\n",
      "Epoch 7573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12668.5928 - val_loss: 18715.9902\n",
      "Epoch 7574/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.9805 - val_loss: 18683.1641\n",
      "Epoch 7575/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.3818 - val_loss: 18660.0977\n",
      "Epoch 7576/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12479.9629 - val_loss: 18673.0820\n",
      "Epoch 7577/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12519.0469 - val_loss: 18670.0312\n",
      "Epoch 7578/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12501.1113 - val_loss: 18807.3438\n",
      "Epoch 7579/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12967.5820 - val_loss: 18848.2676\n",
      "Epoch 7580/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13074.1504 - val_loss: 19027.5449\n",
      "Epoch 7581/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13635.0342 - val_loss: 19137.4707\n",
      "Epoch 7582/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13977.3271 - val_loss: 19167.8301\n",
      "Epoch 7583/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 14070.2178 - val_loss: 19166.4590\n",
      "Epoch 7584/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14063.7490 - val_loss: 19165.5781\n",
      "Epoch 7585/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14060.1221 - val_loss: 19142.5371\n",
      "Epoch 7586/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13990.4502 - val_loss: 19069.3047\n",
      "Epoch 7587/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13762.0713 - val_loss: 19019.1699\n",
      "Epoch 7588/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13603.3252 - val_loss: 18970.9961\n",
      "Epoch 7589/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13451.5752 - val_loss: 18952.7656\n",
      "Epoch 7590/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13390.3613 - val_loss: 18962.7500\n",
      "Epoch 7591/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13418.4023 - val_loss: 18986.6191\n",
      "Epoch 7592/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13488.8662 - val_loss: 18958.3418\n",
      "Epoch 7593/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13400.2598 - val_loss: 18895.6875\n",
      "Epoch 7594/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13208.0225 - val_loss: 18882.1035\n",
      "Epoch 7595/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13167.5732 - val_loss: 18863.0918\n",
      "Epoch 7596/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13113.6406 - val_loss: 18825.2129\n",
      "Epoch 7597/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12999.4219 - val_loss: 18806.6230\n",
      "Epoch 7598/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12937.1582 - val_loss: 18798.7344\n",
      "Epoch 7599/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12910.7236 - val_loss: 18818.4395\n",
      "Epoch 7600/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.1172 - val_loss: 18808.2812\n",
      "Epoch 7601/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12937.1211 - val_loss: 18811.4805\n",
      "Epoch 7602/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12947.9707 - val_loss: 18762.2988\n",
      "Epoch 7603/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12793.3984 - val_loss: 18759.8965\n",
      "Epoch 7604/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12785.1133 - val_loss: 18723.1895\n",
      "Epoch 7605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12671.6523 - val_loss: 18693.3496\n",
      "Epoch 7606/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.3965 - val_loss: 18701.5723\n",
      "Epoch 7607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.9580 - val_loss: 18710.0215\n",
      "Epoch 7608/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12616.0791 - val_loss: 18719.7715\n",
      "Epoch 7609/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.3770 - val_loss: 18696.8984\n",
      "Epoch 7610/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.0918 - val_loss: 18709.8906\n",
      "Epoch 7611/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.2148 - val_loss: 18729.0176\n",
      "Epoch 7612/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12677.3975 - val_loss: 18722.6035\n",
      "Epoch 7613/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.9307 - val_loss: 18704.6895\n",
      "Epoch 7614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12611.4639 - val_loss: 18663.1035\n",
      "Epoch 7615/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12476.8965 - val_loss: 18669.3223\n",
      "Epoch 7616/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12499.7852 - val_loss: 18690.0918\n",
      "Epoch 7617/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12571.2646 - val_loss: 18707.6270\n",
      "Epoch 7618/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12632.5381 - val_loss: 18739.2168\n",
      "Epoch 7619/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12727.0908 - val_loss: 18752.8047\n",
      "Epoch 7620/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12767.4883 - val_loss: 18718.3984\n",
      "Epoch 7621/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12659.7617 - val_loss: 18721.0293\n",
      "Epoch 7622/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.6631 - val_loss: 18746.6875\n",
      "Epoch 7623/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12745.3975 - val_loss: 18754.5137\n",
      "Epoch 7624/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.4570 - val_loss: 18736.4863\n",
      "Epoch 7625/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.3955 - val_loss: 18723.2539\n",
      "Epoch 7626/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12671.0518 - val_loss: 18740.4629\n",
      "Epoch 7627/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.3076 - val_loss: 18718.7363\n",
      "Epoch 7628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.1846 - val_loss: 18704.9668\n",
      "Epoch 7629/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12622.8633 - val_loss: 18696.3398\n",
      "Epoch 7630/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12592.6377 - val_loss: 18674.9727\n",
      "Epoch 7631/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.8428 - val_loss: 18768.4941\n",
      "Epoch 7632/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12846.4531 - val_loss: 18831.2832\n",
      "Epoch 7633/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13020.8369 - val_loss: 19031.8223\n",
      "Epoch 7634/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13647.5254 - val_loss: 19159.2207\n",
      "Epoch 7635/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14045.4912 - val_loss: 19194.4551\n",
      "Epoch 7636/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 14155.5283 - val_loss: 19147.6797\n",
      "Epoch 7637/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 14008.6025 - val_loss: 19107.1289\n",
      "Epoch 7638/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13877.6104 - val_loss: 19105.5488\n",
      "Epoch 7639/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13868.0811 - val_loss: 19076.5898\n",
      "Epoch 7640/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13778.2744 - val_loss: 19061.4648\n",
      "Epoch 7641/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13725.7197 - val_loss: 19018.3496\n",
      "Epoch 7642/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13592.9424 - val_loss: 18988.1758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7643/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13500.6934 - val_loss: 18956.5645\n",
      "Epoch 7644/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13402.9863 - val_loss: 18979.8633\n",
      "Epoch 7645/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13471.1572 - val_loss: 18950.6582\n",
      "Epoch 7646/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13383.0771 - val_loss: 18897.1035\n",
      "Epoch 7647/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13216.4756 - val_loss: 18869.6953\n",
      "Epoch 7648/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13135.3076 - val_loss: 18879.0605\n",
      "Epoch 7649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13158.9053 - val_loss: 18848.9336\n",
      "Epoch 7650/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13064.2529 - val_loss: 18811.4766\n",
      "Epoch 7651/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12941.4922 - val_loss: 18794.7363\n",
      "Epoch 7652/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12892.2520 - val_loss: 18751.6543\n",
      "Epoch 7653/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.3936 - val_loss: 18783.1680\n",
      "Epoch 7654/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12867.5400 - val_loss: 18820.3574\n",
      "Epoch 7655/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12976.5381 - val_loss: 18834.0254\n",
      "Epoch 7656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13010.2510 - val_loss: 18820.4922\n",
      "Epoch 7657/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12966.7021 - val_loss: 18775.5742\n",
      "Epoch 7658/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12825.7695 - val_loss: 18721.4980\n",
      "Epoch 7659/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.1797 - val_loss: 18751.4941\n",
      "Epoch 7660/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.3193 - val_loss: 18759.0449\n",
      "Epoch 7661/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.9199 - val_loss: 18743.5664\n",
      "Epoch 7662/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12727.0322 - val_loss: 18737.3242\n",
      "Epoch 7663/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12716.6416 - val_loss: 18756.9766\n",
      "Epoch 7664/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12776.6543 - val_loss: 18751.0000\n",
      "Epoch 7665/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.3047 - val_loss: 18742.5410\n",
      "Epoch 7666/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12735.5459 - val_loss: 18746.6152\n",
      "Epoch 7667/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.5732 - val_loss: 18714.9512\n",
      "Epoch 7668/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12644.6602 - val_loss: 18746.5078\n",
      "Epoch 7669/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.5225 - val_loss: 18800.3633\n",
      "Epoch 7670/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12926.3848 - val_loss: 18971.6270\n",
      "Epoch 7671/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13460.1387 - val_loss: 19060.7617\n",
      "Epoch 7672/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13739.0967 - val_loss: 19085.4473\n",
      "Epoch 7673/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13816.4883 - val_loss: 19071.1875\n",
      "Epoch 7674/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13770.0938 - val_loss: 19043.9766\n",
      "Epoch 7675/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13680.9092 - val_loss: 19011.2637\n",
      "Epoch 7676/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13575.7852 - val_loss: 18973.1152\n",
      "Epoch 7677/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13458.4453 - val_loss: 18913.3535\n",
      "Epoch 7678/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13264.7188 - val_loss: 18913.7949\n",
      "Epoch 7679/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13266.7822 - val_loss: 18899.4355\n",
      "Epoch 7680/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13225.3428 - val_loss: 18892.3965\n",
      "Epoch 7681/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13200.5137 - val_loss: 18855.2168\n",
      "Epoch 7682/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13084.3555 - val_loss: 18847.8965\n",
      "Epoch 7683/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13055.9434 - val_loss: 18841.5176\n",
      "Epoch 7684/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13040.8906 - val_loss: 18847.4805\n",
      "Epoch 7685/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13058.0742 - val_loss: 18860.5000\n",
      "Epoch 7686/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13098.7373 - val_loss: 18840.4414\n",
      "Epoch 7687/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13039.8428 - val_loss: 18798.0879\n",
      "Epoch 7688/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12906.8047 - val_loss: 18787.1504\n",
      "Epoch 7689/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12868.8848 - val_loss: 18776.8340\n",
      "Epoch 7690/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12835.2666 - val_loss: 18765.9434\n",
      "Epoch 7691/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12804.8691 - val_loss: 18760.4395\n",
      "Epoch 7692/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12791.8613 - val_loss: 18744.6855\n",
      "Epoch 7693/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.7334 - val_loss: 18735.4629\n",
      "Epoch 7694/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12716.4482 - val_loss: 18716.5117\n",
      "Epoch 7695/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.4639 - val_loss: 19009.3398\n",
      "Epoch 7696/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13623.9365 - val_loss: 18810.7598\n",
      "Epoch 7697/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12956.2012 - val_loss: 18953.9102\n",
      "Epoch 7698/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13407.2754 - val_loss: 19040.1387\n",
      "Epoch 7699/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13676.0879 - val_loss: 19061.4023\n",
      "Epoch 7700/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13741.7207 - val_loss: 19065.9590\n",
      "Epoch 7701/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13751.8975 - val_loss: 19044.0391\n",
      "Epoch 7702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13680.4697 - val_loss: 19018.0723\n",
      "Epoch 7703/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13597.8271 - val_loss: 18965.1953\n",
      "Epoch 7704/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13429.8721 - val_loss: 18964.7285\n",
      "Epoch 7705/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13427.5059 - val_loss: 18956.0156\n",
      "Epoch 7706/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13398.8047 - val_loss: 18935.6250\n",
      "Epoch 7707/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13333.9521 - val_loss: 18887.4414\n",
      "Epoch 7708/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13183.6562 - val_loss: 18891.1445\n",
      "Epoch 7709/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13195.2041 - val_loss: 18898.8613\n",
      "Epoch 7710/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13226.4971 - val_loss: 18884.0215\n",
      "Epoch 7711/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13176.3213 - val_loss: 18859.1426\n",
      "Epoch 7712/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13100.3203 - val_loss: 18836.8105\n",
      "Epoch 7713/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13029.7314 - val_loss: 18816.9277\n",
      "Epoch 7714/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12965.9355 - val_loss: 18820.5410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7715/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12974.2305 - val_loss: 18830.7012\n",
      "Epoch 7716/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13004.4004 - val_loss: 18781.6562\n",
      "Epoch 7717/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12851.4824 - val_loss: 18748.4473\n",
      "Epoch 7718/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12750.8262 - val_loss: 18746.9863\n",
      "Epoch 7719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12745.5693 - val_loss: 18749.9141\n",
      "Epoch 7720/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12755.8047 - val_loss: 18727.6211\n",
      "Epoch 7721/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.9561 - val_loss: 18706.3672\n",
      "Epoch 7722/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12611.5547 - val_loss: 18747.6172\n",
      "Epoch 7723/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.3711 - val_loss: 18766.2480\n",
      "Epoch 7724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12794.6025 - val_loss: 18756.3867\n",
      "Epoch 7725/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12767.5918 - val_loss: 18732.5488\n",
      "Epoch 7726/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12694.2236 - val_loss: 18728.6523\n",
      "Epoch 7727/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.7178 - val_loss: 18748.0977\n",
      "Epoch 7728/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12736.6338 - val_loss: 18719.3145\n",
      "Epoch 7729/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.7373 - val_loss: 18677.2695\n",
      "Epoch 7730/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.1367 - val_loss: 18693.8457\n",
      "Epoch 7731/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.1572 - val_loss: 18720.2148\n",
      "Epoch 7732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12665.1143 - val_loss: 18729.1816\n",
      "Epoch 7733/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12688.5088 - val_loss: 18681.5234\n",
      "Epoch 7734/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12537.4453 - val_loss: 18678.9434\n",
      "Epoch 7735/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.3711 - val_loss: 18692.4570\n",
      "Epoch 7736/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.6631 - val_loss: 18678.5000\n",
      "Epoch 7737/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12535.5420 - val_loss: 18676.7168\n",
      "Epoch 7738/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.0762 - val_loss: 18657.6055\n",
      "Epoch 7739/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12461.6992 - val_loss: 18673.2734\n",
      "Epoch 7740/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12510.2285 - val_loss: 18682.2109\n",
      "Epoch 7741/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12538.9355 - val_loss: 18676.0547\n",
      "Epoch 7742/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12522.2920 - val_loss: 18661.1523\n",
      "Epoch 7743/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12478.9336 - val_loss: 18630.4590\n",
      "Epoch 7744/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12377.0684 - val_loss: 18649.2812\n",
      "Epoch 7745/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12431.8965 - val_loss: 18658.9668\n",
      "Epoch 7746/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12467.1611 - val_loss: 18646.9355\n",
      "Epoch 7747/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12426.9150 - val_loss: 18637.2793\n",
      "Epoch 7748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12405.8809 - val_loss: 18649.6211\n",
      "Epoch 7749/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12441.5771 - val_loss: 18641.3887\n",
      "Epoch 7750/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12407.7090 - val_loss: 18643.2266\n",
      "Epoch 7751/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12412.0674 - val_loss: 18654.9473\n",
      "Epoch 7752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12449.0615 - val_loss: 18634.9453\n",
      "Epoch 7753/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12392.7568 - val_loss: 18644.9297\n",
      "Epoch 7754/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12429.6816 - val_loss: 18652.3613\n",
      "Epoch 7755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12447.5869 - val_loss: 18652.9961\n",
      "Epoch 7756/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12451.0479 - val_loss: 18657.7656\n",
      "Epoch 7757/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12465.3486 - val_loss: 18655.1992\n",
      "Epoch 7758/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12457.6201 - val_loss: 18643.0137\n",
      "Epoch 7759/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12428.7031 - val_loss: 18700.4375\n",
      "Epoch 7760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.3330 - val_loss: 18765.5352\n",
      "Epoch 7761/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12813.7979 - val_loss: 18789.4102\n",
      "Epoch 7762/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12887.2979 - val_loss: 18773.9375\n",
      "Epoch 7763/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12839.1445 - val_loss: 18737.9355\n",
      "Epoch 7764/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12722.5947 - val_loss: 18758.4395\n",
      "Epoch 7765/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12782.3809 - val_loss: 18777.3945\n",
      "Epoch 7766/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12837.6807 - val_loss: 18756.5527\n",
      "Epoch 7767/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.3623 - val_loss: 18730.0000\n",
      "Epoch 7768/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12695.0762 - val_loss: 18715.3848\n",
      "Epoch 7769/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.1055 - val_loss: 18698.8438\n",
      "Epoch 7770/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.2881 - val_loss: 18683.9199\n",
      "Epoch 7771/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12552.8057 - val_loss: 18693.3867\n",
      "Epoch 7772/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12572.8398 - val_loss: 18791.4375\n",
      "Epoch 7773/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12928.2949 - val_loss: 18789.9629\n",
      "Epoch 7774/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12890.8916 - val_loss: 18884.3477\n",
      "Epoch 7775/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13185.4844 - val_loss: 18980.3613\n",
      "Epoch 7776/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13483.2568 - val_loss: 19027.3438\n",
      "Epoch 7777/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13630.0107 - val_loss: 19031.7969\n",
      "Epoch 7778/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13643.8340 - val_loss: 19006.1250\n",
      "Epoch 7779/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13562.4600 - val_loss: 19002.2520\n",
      "Epoch 7780/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13549.1221 - val_loss: 18987.5449\n",
      "Epoch 7781/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13504.2207 - val_loss: 18938.0469\n",
      "Epoch 7782/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13348.5107 - val_loss: 18918.1973\n",
      "Epoch 7783/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13283.9111 - val_loss: 18847.2598\n",
      "Epoch 7784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13065.0869 - val_loss: 18857.0488\n",
      "Epoch 7785/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13093.0781 - val_loss: 18875.9609\n",
      "Epoch 7786/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13149.1211 - val_loss: 18865.1855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7787/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13114.0342 - val_loss: 18860.7148\n",
      "Epoch 7788/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13095.1045 - val_loss: 18841.0156\n",
      "Epoch 7789/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13033.4541 - val_loss: 18827.9648\n",
      "Epoch 7790/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12994.3115 - val_loss: 18812.0293\n",
      "Epoch 7791/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12943.4727 - val_loss: 18790.1074\n",
      "Epoch 7792/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12878.1553 - val_loss: 18737.7734\n",
      "Epoch 7793/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12715.9766 - val_loss: 18696.0059\n",
      "Epoch 7794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12589.4082 - val_loss: 18719.7559\n",
      "Epoch 7795/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.7441 - val_loss: 18740.7461\n",
      "Epoch 7796/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12716.5449 - val_loss: 18748.0039\n",
      "Epoch 7797/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12745.3018 - val_loss: 18733.8047\n",
      "Epoch 7798/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12698.8174 - val_loss: 18737.4492\n",
      "Epoch 7799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.3340 - val_loss: 18733.7090\n",
      "Epoch 7800/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12697.3623 - val_loss: 18766.1543\n",
      "Epoch 7801/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12822.9297 - val_loss: 18778.0391\n",
      "Epoch 7802/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12848.8359 - val_loss: 18848.9863\n",
      "Epoch 7803/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13076.6621 - val_loss: 18902.6777\n",
      "Epoch 7804/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13241.2500 - val_loss: 18901.8301\n",
      "Epoch 7805/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13236.8477 - val_loss: 18895.4238\n",
      "Epoch 7806/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13216.8408 - val_loss: 18841.8574\n",
      "Epoch 7807/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13048.5615 - val_loss: 18813.2578\n",
      "Epoch 7808/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12962.2305 - val_loss: 18809.8496\n",
      "Epoch 7809/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12948.8857 - val_loss: 18824.3281\n",
      "Epoch 7810/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12988.2607 - val_loss: 18814.5918\n",
      "Epoch 7811/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12956.5332 - val_loss: 18810.6426\n",
      "Epoch 7812/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12942.9336 - val_loss: 18814.8496\n",
      "Epoch 7813/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12952.2158 - val_loss: 18797.2363\n",
      "Epoch 7814/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12898.8193 - val_loss: 18777.2324\n",
      "Epoch 7815/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12839.8955 - val_loss: 18766.3672\n",
      "Epoch 7816/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12804.0186 - val_loss: 18752.5098\n",
      "Epoch 7817/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12761.6670 - val_loss: 18758.8770\n",
      "Epoch 7818/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.7393 - val_loss: 18786.3125\n",
      "Epoch 7819/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12874.8252 - val_loss: 18786.1621\n",
      "Epoch 7820/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12872.9277 - val_loss: 18734.7793\n",
      "Epoch 7821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12714.4785 - val_loss: 18661.2578\n",
      "Epoch 7822/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.5811 - val_loss: 18683.1895\n",
      "Epoch 7823/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12534.7773 - val_loss: 18935.5000\n",
      "Epoch 7824/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13390.8486 - val_loss: 18820.8125\n",
      "Epoch 7825/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12986.4326 - val_loss: 18955.5098\n",
      "Epoch 7826/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13410.1709 - val_loss: 19042.2051\n",
      "Epoch 7827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13681.5469 - val_loss: 19062.8301\n",
      "Epoch 7828/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13745.8320 - val_loss: 19055.6309\n",
      "Epoch 7829/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13722.4814 - val_loss: 19049.9805\n",
      "Epoch 7830/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13702.5645 - val_loss: 19056.6348\n",
      "Epoch 7831/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13721.6807 - val_loss: 19030.9258\n",
      "Epoch 7832/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13640.6025 - val_loss: 18975.8730\n",
      "Epoch 7833/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13468.3311 - val_loss: 18933.0059\n",
      "Epoch 7834/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13333.5029 - val_loss: 18933.5664\n",
      "Epoch 7835/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13323.5645 - val_loss: 18953.4121\n",
      "Epoch 7836/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13385.1943 - val_loss: 18966.5312\n",
      "Epoch 7837/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13429.0908 - val_loss: 18926.6836\n",
      "Epoch 7838/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13309.0869 - val_loss: 18891.8867\n",
      "Epoch 7839/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13199.5215 - val_loss: 18863.9453\n",
      "Epoch 7840/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13114.3604 - val_loss: 18811.0703\n",
      "Epoch 7841/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12949.4131 - val_loss: 18754.2832\n",
      "Epoch 7842/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.9033 - val_loss: 18786.8418\n",
      "Epoch 7843/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12873.1543 - val_loss: 18829.4180\n",
      "Epoch 7844/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13005.5010 - val_loss: 18854.5254\n",
      "Epoch 7845/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13083.7705 - val_loss: 18851.9023\n",
      "Epoch 7846/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13089.0156 - val_loss: 18816.8262\n",
      "Epoch 7847/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12966.7891 - val_loss: 18891.0098\n",
      "Epoch 7848/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13204.8604 - val_loss: 18923.5605\n",
      "Epoch 7849/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13309.1309 - val_loss: 18893.5527\n",
      "Epoch 7850/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13217.3428 - val_loss: 18870.5605\n",
      "Epoch 7851/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13142.6172 - val_loss: 18793.3281\n",
      "Epoch 7852/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12900.7402 - val_loss: 18792.6348\n",
      "Epoch 7853/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12888.6035 - val_loss: 18822.5215\n",
      "Epoch 7854/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12972.9473 - val_loss: 18860.9199\n",
      "Epoch 7855/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13099.8018 - val_loss: 18854.9609\n",
      "Epoch 7856/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13075.1055 - val_loss: 18823.3887\n",
      "Epoch 7857/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12982.3545 - val_loss: 18782.9141\n",
      "Epoch 7858/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12861.2119 - val_loss: 18805.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12938.4082 - val_loss: 18826.5684\n",
      "Epoch 7860/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13004.9990 - val_loss: 18807.3184\n",
      "Epoch 7861/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12934.4072 - val_loss: 18753.7305\n",
      "Epoch 7862/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12762.3740 - val_loss: 18769.0762\n",
      "Epoch 7863/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12815.4521 - val_loss: 18770.4004\n",
      "Epoch 7864/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12831.9316 - val_loss: 18818.7500\n",
      "Epoch 7865/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12985.2988 - val_loss: 18830.0293\n",
      "Epoch 7866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13019.8994 - val_loss: 18852.1309\n",
      "Epoch 7867/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13087.7178 - val_loss: 18850.5391\n",
      "Epoch 7868/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13080.0469 - val_loss: 18821.4434\n",
      "Epoch 7869/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12981.6230 - val_loss: 18786.9395\n",
      "Epoch 7870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12868.9375 - val_loss: 18792.6465\n",
      "Epoch 7871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12890.3096 - val_loss: 18819.7012\n",
      "Epoch 7872/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12971.5312 - val_loss: 18787.4590\n",
      "Epoch 7873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12868.1641 - val_loss: 18769.6094\n",
      "Epoch 7874/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12807.2822 - val_loss: 18755.2832\n",
      "Epoch 7875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.5420 - val_loss: 18763.8809\n",
      "Epoch 7876/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12800.3799 - val_loss: 18759.5957\n",
      "Epoch 7877/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12792.1543 - val_loss: 18730.9902\n",
      "Epoch 7878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.3467 - val_loss: 18697.2168\n",
      "Epoch 7879/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12598.0879 - val_loss: 18688.8457\n",
      "Epoch 7880/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12562.9834 - val_loss: 18740.8066\n",
      "Epoch 7881/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12727.0605 - val_loss: 18772.9531\n",
      "Epoch 7882/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12840.6182 - val_loss: 18903.9844\n",
      "Epoch 7883/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13252.4629 - val_loss: 18972.6992\n",
      "Epoch 7884/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13467.2891 - val_loss: 19001.2148\n",
      "Epoch 7885/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13555.0332 - val_loss: 19009.1836\n",
      "Epoch 7886/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13578.4375 - val_loss: 18961.4609\n",
      "Epoch 7887/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13430.2568 - val_loss: 18900.2148\n",
      "Epoch 7888/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13241.4297 - val_loss: 18891.9297\n",
      "Epoch 7889/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13209.5908 - val_loss: 18864.0098\n",
      "Epoch 7890/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13118.2188 - val_loss: 18848.3770\n",
      "Epoch 7891/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13067.1016 - val_loss: 18857.7207\n",
      "Epoch 7892/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13089.3389 - val_loss: 18832.7852\n",
      "Epoch 7893/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13013.0820 - val_loss: 18875.6680\n",
      "Epoch 7894/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13151.6436 - val_loss: 18828.4727\n",
      "Epoch 7895/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13002.1973 - val_loss: 18831.6426\n",
      "Epoch 7896/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13019.6328 - val_loss: 18893.4805\n",
      "Epoch 7897/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13220.0801 - val_loss: 18927.7832\n",
      "Epoch 7898/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13325.8486 - val_loss: 18906.4863\n",
      "Epoch 7899/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13260.5605 - val_loss: 18904.8574\n",
      "Epoch 7900/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13246.8740 - val_loss: 18900.1094\n",
      "Epoch 7901/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13231.0352 - val_loss: 18850.4727\n",
      "Epoch 7902/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13077.1387 - val_loss: 18790.7461\n",
      "Epoch 7903/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12890.1230 - val_loss: 18747.7090\n",
      "Epoch 7904/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12742.2373 - val_loss: 18774.7305\n",
      "Epoch 7905/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12825.7656 - val_loss: 18754.1914\n",
      "Epoch 7906/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.0244 - val_loss: 18791.7207\n",
      "Epoch 7907/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12898.3779 - val_loss: 18836.7500\n",
      "Epoch 7908/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13044.7080 - val_loss: 18860.8926\n",
      "Epoch 7909/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13119.4902 - val_loss: 18871.7090\n",
      "Epoch 7910/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13144.2646 - val_loss: 18873.8945\n",
      "Epoch 7911/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13152.3799 - val_loss: 18837.4570\n",
      "Epoch 7912/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13040.0049 - val_loss: 18812.8184\n",
      "Epoch 7913/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12955.6465 - val_loss: 18831.5234\n",
      "Epoch 7914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13012.0654 - val_loss: 18825.1562\n",
      "Epoch 7915/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12990.6846 - val_loss: 18786.2480\n",
      "Epoch 7916/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.3691 - val_loss: 18747.8867\n",
      "Epoch 7917/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.9258 - val_loss: 18730.5820\n",
      "Epoch 7918/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.2100 - val_loss: 18735.4082\n",
      "Epoch 7919/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.1426 - val_loss: 18743.8125\n",
      "Epoch 7920/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12736.8750 - val_loss: 18763.9336\n",
      "Epoch 7921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12800.7578 - val_loss: 18739.5898\n",
      "Epoch 7922/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12738.5615 - val_loss: 18828.1816\n",
      "Epoch 7923/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13018.1143 - val_loss: 18854.6836\n",
      "Epoch 7924/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13099.9238 - val_loss: 18827.2695\n",
      "Epoch 7925/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13010.6348 - val_loss: 18808.2578\n",
      "Epoch 7926/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12946.9336 - val_loss: 18814.4707\n",
      "Epoch 7927/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12957.4082 - val_loss: 18819.6641\n",
      "Epoch 7928/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12972.5479 - val_loss: 18807.6953\n",
      "Epoch 7929/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12927.2412 - val_loss: 18798.0352\n",
      "Epoch 7930/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12899.6494 - val_loss: 18759.7441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7931/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.7607 - val_loss: 18783.3203\n",
      "Epoch 7932/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12857.7744 - val_loss: 18775.5586\n",
      "Epoch 7933/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12833.7168 - val_loss: 18778.1270\n",
      "Epoch 7934/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12851.9111 - val_loss: 18765.2012\n",
      "Epoch 7935/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12811.9766 - val_loss: 18740.4824\n",
      "Epoch 7936/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12736.0576 - val_loss: 18744.8574\n",
      "Epoch 7937/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12734.2930 - val_loss: 18718.7598\n",
      "Epoch 7938/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.0400 - val_loss: 18721.2715\n",
      "Epoch 7939/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12665.1406 - val_loss: 18717.0293\n",
      "Epoch 7940/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12646.3623 - val_loss: 18708.0449\n",
      "Epoch 7941/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.1719 - val_loss: 18722.2559\n",
      "Epoch 7942/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12675.2783 - val_loss: 18762.5840\n",
      "Epoch 7943/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12803.7969 - val_loss: 18749.9238\n",
      "Epoch 7944/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12765.9189 - val_loss: 18751.9922\n",
      "Epoch 7945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12770.2109 - val_loss: 18770.7012\n",
      "Epoch 7946/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12825.0801 - val_loss: 18775.4434\n",
      "Epoch 7947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12838.1250 - val_loss: 18763.2695\n",
      "Epoch 7948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12805.8379 - val_loss: 18717.5371\n",
      "Epoch 7949/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.3750 - val_loss: 18690.6699\n",
      "Epoch 7950/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12577.9590 - val_loss: 18689.0840\n",
      "Epoch 7951/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12559.6025 - val_loss: 18754.8672\n",
      "Epoch 7952/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.3203 - val_loss: 18775.0938\n",
      "Epoch 7953/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12845.2012 - val_loss: 18862.1465\n",
      "Epoch 7954/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13125.1338 - val_loss: 18909.8105\n",
      "Epoch 7955/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13271.8818 - val_loss: 18918.8750\n",
      "Epoch 7956/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13295.6914 - val_loss: 18880.5820\n",
      "Epoch 7957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13176.5156 - val_loss: 18790.5488\n",
      "Epoch 7958/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12891.0547 - val_loss: 18780.7461\n",
      "Epoch 7959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.1631 - val_loss: 18808.4551\n",
      "Epoch 7960/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12940.5254 - val_loss: 18827.3848\n",
      "Epoch 7961/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12988.4521 - val_loss: 18834.2266\n",
      "Epoch 7962/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13013.5527 - val_loss: 18834.8281\n",
      "Epoch 7963/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13011.7861 - val_loss: 18796.8789\n",
      "Epoch 7964/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12892.2725 - val_loss: 18745.7461\n",
      "Epoch 7965/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12739.9854 - val_loss: 18727.5430\n",
      "Epoch 7966/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12684.7295 - val_loss: 18724.9785\n",
      "Epoch 7967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.7432 - val_loss: 18730.9512\n",
      "Epoch 7968/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.1621 - val_loss: 18718.5293\n",
      "Epoch 7969/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12669.7471 - val_loss: 18690.3887\n",
      "Epoch 7970/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.7109 - val_loss: 18701.0020\n",
      "Epoch 7971/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.7256 - val_loss: 18739.8848\n",
      "Epoch 7972/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12716.4277 - val_loss: 18730.0195\n",
      "Epoch 7973/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12705.7891 - val_loss: 18758.8906\n",
      "Epoch 7974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12801.0352 - val_loss: 18763.6465\n",
      "Epoch 7975/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12812.9619 - val_loss: 18741.1191\n",
      "Epoch 7976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12738.9941 - val_loss: 18731.7148\n",
      "Epoch 7977/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12704.4561 - val_loss: 18710.8496\n",
      "Epoch 7978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12627.1855 - val_loss: 18725.8711\n",
      "Epoch 7979/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12675.9512 - val_loss: 18730.4805\n",
      "Epoch 7980/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12688.5986 - val_loss: 18730.2793\n",
      "Epoch 7981/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12697.4814 - val_loss: 18730.4336\n",
      "Epoch 7982/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12700.3730 - val_loss: 18675.3535\n",
      "Epoch 7983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.6270 - val_loss: 18682.1934\n",
      "Epoch 7984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.5771 - val_loss: 18718.9238\n",
      "Epoch 7985/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12649.4795 - val_loss: 18738.6367\n",
      "Epoch 7986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12729.5889 - val_loss: 18801.2500\n",
      "Epoch 7987/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12929.4883 - val_loss: 18846.9277\n",
      "Epoch 7988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13073.9043 - val_loss: 18823.0898\n",
      "Epoch 7989/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13000.4824 - val_loss: 18778.9629\n",
      "Epoch 7990/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12858.3223 - val_loss: 18752.3789\n",
      "Epoch 7991/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12775.6094 - val_loss: 18722.4648\n",
      "Epoch 7992/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12673.0176 - val_loss: 18747.0742\n",
      "Epoch 7993/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12742.3926 - val_loss: 18782.4629\n",
      "Epoch 7994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.8115 - val_loss: 18773.2402\n",
      "Epoch 7995/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12817.5293 - val_loss: 18742.8691\n",
      "Epoch 7996/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.0498 - val_loss: 18705.2285\n",
      "Epoch 7997/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12612.2129 - val_loss: 18685.0059\n",
      "Epoch 7998/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12553.6025 - val_loss: 18708.0957\n",
      "Epoch 7999/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12624.5889 - val_loss: 18687.6602\n",
      "Epoch 8000/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12557.0723 - val_loss: 18700.4746\n",
      "Epoch 8001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.2969 - val_loss: 18695.5254\n",
      "Epoch 8002/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.5762 - val_loss: 18707.0898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8003/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.6709 - val_loss: 18704.5117\n",
      "Epoch 8004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12605.5537 - val_loss: 18680.7246\n",
      "Epoch 8005/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.3984 - val_loss: 18700.1953\n",
      "Epoch 8006/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.3242 - val_loss: 18691.7148\n",
      "Epoch 8007/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12584.1572 - val_loss: 18700.4688\n",
      "Epoch 8008/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12596.2861 - val_loss: 18751.4219\n",
      "Epoch 8009/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12764.5459 - val_loss: 18771.0312\n",
      "Epoch 8010/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.7285 - val_loss: 18919.5898\n",
      "Epoch 8011/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13304.1211 - val_loss: 18994.6895\n",
      "Epoch 8012/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13537.7246 - val_loss: 19006.6484\n",
      "Epoch 8013/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13574.9268 - val_loss: 18983.4688\n",
      "Epoch 8014/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13499.8770 - val_loss: 18957.2070\n",
      "Epoch 8015/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13418.6240 - val_loss: 18923.1172\n",
      "Epoch 8016/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13308.4658 - val_loss: 18878.2285\n",
      "Epoch 8017/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13157.7471 - val_loss: 18885.0039\n",
      "Epoch 8018/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13180.3174 - val_loss: 18892.1895\n",
      "Epoch 8019/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13196.6689 - val_loss: 18882.7891\n",
      "Epoch 8020/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13168.0312 - val_loss: 18846.5820\n",
      "Epoch 8021/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13053.3115 - val_loss: 18818.3926\n",
      "Epoch 8022/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12973.3291 - val_loss: 18790.5098\n",
      "Epoch 8023/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12891.5615 - val_loss: 18779.7520\n",
      "Epoch 8024/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12847.8320 - val_loss: 18785.0000\n",
      "Epoch 8025/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12866.1475 - val_loss: 18800.4629\n",
      "Epoch 8026/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12916.9912 - val_loss: 18799.7031\n",
      "Epoch 8027/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12911.4932 - val_loss: 18775.1621\n",
      "Epoch 8028/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12831.1865 - val_loss: 18748.0918\n",
      "Epoch 8029/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12745.5791 - val_loss: 18738.5918\n",
      "Epoch 8030/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.7930 - val_loss: 18744.7578\n",
      "Epoch 8031/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12738.4873 - val_loss: 18727.0000\n",
      "Epoch 8032/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12698.2686 - val_loss: 18747.5176\n",
      "Epoch 8033/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.2812 - val_loss: 18760.3770\n",
      "Epoch 8034/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12803.7734 - val_loss: 18764.7051\n",
      "Epoch 8035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.7871 - val_loss: 18783.8145\n",
      "Epoch 8036/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12865.1953 - val_loss: 18779.4082\n",
      "Epoch 8037/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12848.6816 - val_loss: 18784.4590\n",
      "Epoch 8038/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12861.3135 - val_loss: 18775.1484\n",
      "Epoch 8039/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12816.4170 - val_loss: 18755.9766\n",
      "Epoch 8040/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12756.0342 - val_loss: 18750.7734\n",
      "Epoch 8041/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.0723 - val_loss: 18732.4688\n",
      "Epoch 8042/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.1484 - val_loss: 18719.1914\n",
      "Epoch 8043/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12656.2949 - val_loss: 18690.4023\n",
      "Epoch 8044/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12573.0908 - val_loss: 18667.2539\n",
      "Epoch 8045/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12492.6797 - val_loss: 18703.9180\n",
      "Epoch 8046/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12603.2334 - val_loss: 18706.2539\n",
      "Epoch 8047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.9043 - val_loss: 18718.2812\n",
      "Epoch 8048/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.2715 - val_loss: 18728.9102\n",
      "Epoch 8049/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12687.3770 - val_loss: 18701.7598\n",
      "Epoch 8050/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.3389 - val_loss: 18689.1504\n",
      "Epoch 8051/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.1602 - val_loss: 18699.4434\n",
      "Epoch 8052/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12608.1270 - val_loss: 18736.3457\n",
      "Epoch 8053/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.4697 - val_loss: 18736.3672\n",
      "Epoch 8054/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.8037 - val_loss: 18718.8691\n",
      "Epoch 8055/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12670.7070 - val_loss: 18739.1523\n",
      "Epoch 8056/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12721.2910 - val_loss: 18734.9727\n",
      "Epoch 8057/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.8174 - val_loss: 18716.3887\n",
      "Epoch 8058/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.8838 - val_loss: 18730.6562\n",
      "Epoch 8059/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12694.5039 - val_loss: 18724.1035\n",
      "Epoch 8060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12669.4023 - val_loss: 18704.0469\n",
      "Epoch 8061/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12606.4707 - val_loss: 18736.6855\n",
      "Epoch 8062/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.3564 - val_loss: 18790.8066\n",
      "Epoch 8063/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12901.0137 - val_loss: 18898.6836\n",
      "Epoch 8064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13238.2969 - val_loss: 18936.5332\n",
      "Epoch 8065/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13356.4854 - val_loss: 18944.0703\n",
      "Epoch 8066/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13377.7842 - val_loss: 18915.2012\n",
      "Epoch 8067/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13287.3760 - val_loss: 18874.8477\n",
      "Epoch 8068/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13159.2539 - val_loss: 18855.2812\n",
      "Epoch 8069/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13094.6768 - val_loss: 18850.3398\n",
      "Epoch 8070/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13069.9092 - val_loss: 18860.5840\n",
      "Epoch 8071/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13100.9570 - val_loss: 18892.5488\n",
      "Epoch 8072/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13188.0830 - val_loss: 18897.3281\n",
      "Epoch 8073/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13203.5850 - val_loss: 18865.2812\n",
      "Epoch 8074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13103.3828 - val_loss: 18855.9473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8075/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13080.0381 - val_loss: 18861.2344\n",
      "Epoch 8076/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13100.5967 - val_loss: 18856.7988\n",
      "Epoch 8077/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13093.7627 - val_loss: 18816.9648\n",
      "Epoch 8078/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12969.0635 - val_loss: 18794.7148\n",
      "Epoch 8079/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12907.4014 - val_loss: 18792.4844\n",
      "Epoch 8080/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12902.1006 - val_loss: 18796.7793\n",
      "Epoch 8081/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12908.4043 - val_loss: 18775.7129\n",
      "Epoch 8082/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.8066 - val_loss: 18787.4707\n",
      "Epoch 8083/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12876.8418 - val_loss: 18776.5605\n",
      "Epoch 8084/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12841.3086 - val_loss: 18727.0820\n",
      "Epoch 8085/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12676.7559 - val_loss: 18694.3496\n",
      "Epoch 8086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.7246 - val_loss: 18736.7129\n",
      "Epoch 8087/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12707.3730 - val_loss: 18787.1270\n",
      "Epoch 8088/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.4834 - val_loss: 18873.1309\n",
      "Epoch 8089/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13154.9785 - val_loss: 18916.1797\n",
      "Epoch 8090/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13287.6055 - val_loss: 18917.6270\n",
      "Epoch 8091/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13296.5342 - val_loss: 18902.9102\n",
      "Epoch 8092/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13249.1807 - val_loss: 18841.0762\n",
      "Epoch 8093/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13057.0049 - val_loss: 18804.5547\n",
      "Epoch 8094/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12936.1504 - val_loss: 18788.3125\n",
      "Epoch 8095/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12879.0947 - val_loss: 18799.6465\n",
      "Epoch 8096/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12917.4453 - val_loss: 18770.5293\n",
      "Epoch 8097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.9766 - val_loss: 18774.1406\n",
      "Epoch 8098/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12835.7461 - val_loss: 18780.4648\n",
      "Epoch 8099/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12862.0879 - val_loss: 18754.7539\n",
      "Epoch 8100/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12775.5029 - val_loss: 18779.0176\n",
      "Epoch 8101/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12849.9062 - val_loss: 18788.8379\n",
      "Epoch 8102/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12875.5322 - val_loss: 18757.0449\n",
      "Epoch 8103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.4238 - val_loss: 18720.1250\n",
      "Epoch 8104/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12660.8906 - val_loss: 18772.0488\n",
      "Epoch 8105/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12822.4551 - val_loss: 18773.3379\n",
      "Epoch 8106/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12844.7080 - val_loss: 18847.2129\n",
      "Epoch 8107/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13078.3496 - val_loss: 18897.2305\n",
      "Epoch 8108/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13233.5557 - val_loss: 18894.8398\n",
      "Epoch 8109/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13226.2656 - val_loss: 18849.7969\n",
      "Epoch 8110/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13078.8057 - val_loss: 18807.8926\n",
      "Epoch 8111/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12939.6260 - val_loss: 18829.7949\n",
      "Epoch 8112/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13004.1973 - val_loss: 18862.8262\n",
      "Epoch 8113/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13103.0234 - val_loss: 18871.3613\n",
      "Epoch 8114/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13141.8174 - val_loss: 18829.4980\n",
      "Epoch 8115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13008.4502 - val_loss: 18764.7559\n",
      "Epoch 8116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12815.8203 - val_loss: 18739.9160\n",
      "Epoch 8117/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12729.2285 - val_loss: 18759.7480\n",
      "Epoch 8118/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12798.3389 - val_loss: 18726.6289\n",
      "Epoch 8119/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12693.5225 - val_loss: 18709.2402\n",
      "Epoch 8120/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.1025 - val_loss: 18888.1992\n",
      "Epoch 8121/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13204.5439 - val_loss: 18794.0781\n",
      "Epoch 8122/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12911.7529 - val_loss: 18943.1211\n",
      "Epoch 8123/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13380.8994 - val_loss: 19021.2812\n",
      "Epoch 8124/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13624.3330 - val_loss: 19024.8535\n",
      "Epoch 8125/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13634.0645 - val_loss: 18993.2051\n",
      "Epoch 8126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13535.4785 - val_loss: 18936.3691\n",
      "Epoch 8127/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13354.0098 - val_loss: 18916.1680\n",
      "Epoch 8128/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13286.2041 - val_loss: 18871.2363\n",
      "Epoch 8129/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13141.1133 - val_loss: 18856.4453\n",
      "Epoch 8130/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13086.0957 - val_loss: 18882.0527\n",
      "Epoch 8131/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13166.9131 - val_loss: 18872.0137\n",
      "Epoch 8132/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13132.2920 - val_loss: 18886.7227\n",
      "Epoch 8133/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13173.5820 - val_loss: 18856.2344\n",
      "Epoch 8134/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13080.2256 - val_loss: 18844.3457\n",
      "Epoch 8135/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13046.5615 - val_loss: 18819.8379\n",
      "Epoch 8136/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.9248 - val_loss: 18816.3828\n",
      "Epoch 8137/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12959.9424 - val_loss: 18827.5586\n",
      "Epoch 8138/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13000.5117 - val_loss: 18808.5645\n",
      "Epoch 8139/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12944.8223 - val_loss: 18781.8105\n",
      "Epoch 8140/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12874.7539 - val_loss: 18764.6680\n",
      "Epoch 8141/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12813.3154 - val_loss: 18721.6992\n",
      "Epoch 8142/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.0615 - val_loss: 18712.9883\n",
      "Epoch 8143/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12643.3877 - val_loss: 18707.7012\n",
      "Epoch 8144/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.6426 - val_loss: 18703.3145\n",
      "Epoch 8145/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12604.4678 - val_loss: 18709.5859\n",
      "Epoch 8146/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.8457 - val_loss: 18693.7090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8147/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12569.3652 - val_loss: 18709.6465\n",
      "Epoch 8148/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12620.2539 - val_loss: 18696.3125\n",
      "Epoch 8149/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12578.9365 - val_loss: 18695.4316\n",
      "Epoch 8150/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12572.5410 - val_loss: 18685.0078\n",
      "Epoch 8151/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12556.3867 - val_loss: 18688.3613\n",
      "Epoch 8152/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12559.5371 - val_loss: 18688.3125\n",
      "Epoch 8153/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12558.1885 - val_loss: 18692.5234\n",
      "Epoch 8154/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.4912 - val_loss: 18687.2871\n",
      "Epoch 8155/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12555.0352 - val_loss: 18672.5508\n",
      "Epoch 8156/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12517.8184 - val_loss: 18655.6680\n",
      "Epoch 8157/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12466.6611 - val_loss: 18668.7910\n",
      "Epoch 8158/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12506.7090 - val_loss: 18676.5449\n",
      "Epoch 8159/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12521.7441 - val_loss: 18711.3770\n",
      "Epoch 8160/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12635.1377 - val_loss: 18764.9531\n",
      "Epoch 8161/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12823.4209 - val_loss: 18893.0312\n",
      "Epoch 8162/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13224.2324 - val_loss: 18955.0293\n",
      "Epoch 8163/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13414.6221 - val_loss: 18968.7695\n",
      "Epoch 8164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13455.8516 - val_loss: 18950.5996\n",
      "Epoch 8165/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13396.6895 - val_loss: 18917.1895\n",
      "Epoch 8166/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13290.1201 - val_loss: 18914.9863\n",
      "Epoch 8167/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13275.6416 - val_loss: 18895.9902\n",
      "Epoch 8168/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13214.1904 - val_loss: 18881.0234\n",
      "Epoch 8169/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13164.4570 - val_loss: 18876.9297\n",
      "Epoch 8170/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13152.0342 - val_loss: 18835.2617\n",
      "Epoch 8171/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13025.1162 - val_loss: 18832.5703\n",
      "Epoch 8172/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13021.5957 - val_loss: 18864.3984\n",
      "Epoch 8173/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13111.2646 - val_loss: 18848.0762\n",
      "Epoch 8174/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13057.2695 - val_loss: 18789.5781\n",
      "Epoch 8175/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12877.0020 - val_loss: 18746.2695\n",
      "Epoch 8176/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12738.9268 - val_loss: 18797.2188\n",
      "Epoch 8177/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12904.3594 - val_loss: 18816.2148\n",
      "Epoch 8178/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12963.0742 - val_loss: 18793.6035\n",
      "Epoch 8179/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12894.4248 - val_loss: 18751.8750\n",
      "Epoch 8180/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.2803 - val_loss: 18715.6875\n",
      "Epoch 8181/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12645.6455 - val_loss: 18717.8359\n",
      "Epoch 8182/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.7744 - val_loss: 18769.0527\n",
      "Epoch 8183/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12820.4131 - val_loss: 18758.9219\n",
      "Epoch 8184/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12803.1299 - val_loss: 18882.1465\n",
      "Epoch 8185/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13190.9814 - val_loss: 18936.6152\n",
      "Epoch 8186/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13358.6504 - val_loss: 18960.4062\n",
      "Epoch 8187/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13428.5586 - val_loss: 18952.0566\n",
      "Epoch 8188/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13397.7021 - val_loss: 18880.1055\n",
      "Epoch 8189/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13173.8252 - val_loss: 18842.7188\n",
      "Epoch 8190/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13054.6504 - val_loss: 18833.8711\n",
      "Epoch 8191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13026.6816 - val_loss: 18881.8203\n",
      "Epoch 8192/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13171.0947 - val_loss: 18868.3184\n",
      "Epoch 8193/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13125.1553 - val_loss: 18825.4766\n",
      "Epoch 8194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12987.1904 - val_loss: 18783.0938\n",
      "Epoch 8195/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12856.6621 - val_loss: 18785.3574\n",
      "Epoch 8196/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.9082 - val_loss: 18778.0977\n",
      "Epoch 8197/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12857.8262 - val_loss: 18726.9082\n",
      "Epoch 8198/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12696.0068 - val_loss: 18718.5820\n",
      "Epoch 8199/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.0215 - val_loss: 18876.3027\n",
      "Epoch 8200/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13167.9893 - val_loss: 18785.6113\n",
      "Epoch 8201/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12874.1924 - val_loss: 18886.4766\n",
      "Epoch 8202/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13204.6182 - val_loss: 18937.8535\n",
      "Epoch 8203/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13363.0283 - val_loss: 18939.1621\n",
      "Epoch 8204/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13363.6406 - val_loss: 18932.0762\n",
      "Epoch 8205/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13341.1660 - val_loss: 18900.0098\n",
      "Epoch 8206/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13238.9014 - val_loss: 18840.9512\n",
      "Epoch 8207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13053.8027 - val_loss: 18840.5488\n",
      "Epoch 8208/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13041.9834 - val_loss: 18846.3281\n",
      "Epoch 8209/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13057.0068 - val_loss: 18853.9648\n",
      "Epoch 8210/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13076.7676 - val_loss: 18858.9004\n",
      "Epoch 8211/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13091.5234 - val_loss: 18847.9707\n",
      "Epoch 8212/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13053.6357 - val_loss: 18826.2871\n",
      "Epoch 8213/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12991.0332 - val_loss: 18777.3105\n",
      "Epoch 8214/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12844.7041 - val_loss: 18773.5137\n",
      "Epoch 8215/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12836.3408 - val_loss: 18774.3711\n",
      "Epoch 8216/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12831.1162 - val_loss: 18791.0234\n",
      "Epoch 8217/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12878.8682 - val_loss: 18754.7637\n",
      "Epoch 8218/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.2412 - val_loss: 18699.5195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8219/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12599.2480 - val_loss: 18714.1348\n",
      "Epoch 8220/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.1621 - val_loss: 18717.3223\n",
      "Epoch 8221/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.8867 - val_loss: 18741.6914\n",
      "Epoch 8222/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12722.1338 - val_loss: 18746.0742\n",
      "Epoch 8223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.8389 - val_loss: 18754.3496\n",
      "Epoch 8224/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12763.3281 - val_loss: 18788.3438\n",
      "Epoch 8225/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12887.0566 - val_loss: 18812.3730\n",
      "Epoch 8226/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12964.2041 - val_loss: 18836.4082\n",
      "Epoch 8227/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13038.7656 - val_loss: 18824.9512\n",
      "Epoch 8228/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13007.5479 - val_loss: 18787.0410\n",
      "Epoch 8229/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.5518 - val_loss: 18776.7598\n",
      "Epoch 8230/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12843.6299 - val_loss: 18759.2480\n",
      "Epoch 8231/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12784.3955 - val_loss: 18722.1250\n",
      "Epoch 8232/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12667.9678 - val_loss: 18716.1426\n",
      "Epoch 8233/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12646.2793 - val_loss: 18748.0645\n",
      "Epoch 8234/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.5938 - val_loss: 18737.6309\n",
      "Epoch 8235/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12719.3691 - val_loss: 18713.5703\n",
      "Epoch 8236/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.7432 - val_loss: 18711.1191\n",
      "Epoch 8237/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12630.9297 - val_loss: 18692.8457\n",
      "Epoch 8238/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12583.0273 - val_loss: 18739.1836\n",
      "Epoch 8239/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12736.0391 - val_loss: 18758.3496\n",
      "Epoch 8240/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12795.1143 - val_loss: 18757.3789\n",
      "Epoch 8241/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.3730 - val_loss: 18751.2344\n",
      "Epoch 8242/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12765.5908 - val_loss: 18732.2363\n",
      "Epoch 8243/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.0068 - val_loss: 18725.7324\n",
      "Epoch 8244/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12675.4551 - val_loss: 18731.6582\n",
      "Epoch 8245/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12683.7910 - val_loss: 18745.5312\n",
      "Epoch 8246/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.2295 - val_loss: 18710.5527\n",
      "Epoch 8247/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12631.6807 - val_loss: 18701.8008\n",
      "Epoch 8248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.2705 - val_loss: 18715.1855\n",
      "Epoch 8249/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12643.8613 - val_loss: 18714.6719\n",
      "Epoch 8250/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.8906 - val_loss: 18725.4492\n",
      "Epoch 8251/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12677.7881 - val_loss: 18697.0684\n",
      "Epoch 8252/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12595.2979 - val_loss: 18702.5137\n",
      "Epoch 8253/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12598.9307 - val_loss: 18745.2520\n",
      "Epoch 8254/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.0391 - val_loss: 18726.7344\n",
      "Epoch 8255/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12677.2959 - val_loss: 18686.7441\n",
      "Epoch 8256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.7158 - val_loss: 18693.9375\n",
      "Epoch 8257/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.1328 - val_loss: 18727.8105\n",
      "Epoch 8258/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12684.5068 - val_loss: 18755.9844\n",
      "Epoch 8259/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12777.9521 - val_loss: 18733.6484\n",
      "Epoch 8260/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.1758 - val_loss: 18696.1582\n",
      "Epoch 8261/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12578.7480 - val_loss: 18716.1562\n",
      "Epoch 8262/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12647.1094 - val_loss: 18720.1621\n",
      "Epoch 8263/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.8711 - val_loss: 18737.3633\n",
      "Epoch 8264/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12723.0410 - val_loss: 18737.7578\n",
      "Epoch 8265/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12726.5312 - val_loss: 18738.1367\n",
      "Epoch 8266/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12733.9561 - val_loss: 18728.2598\n",
      "Epoch 8267/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12701.0195 - val_loss: 18720.0273\n",
      "Epoch 8268/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12660.9375 - val_loss: 18717.7480\n",
      "Epoch 8269/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.0645 - val_loss: 18720.1875\n",
      "Epoch 8270/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12668.0938 - val_loss: 18735.6953\n",
      "Epoch 8271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12727.3525 - val_loss: 18815.8672\n",
      "Epoch 8272/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12978.0449 - val_loss: 18848.5762\n",
      "Epoch 8273/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13079.9736 - val_loss: 18838.1738\n",
      "Epoch 8274/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13049.6113 - val_loss: 18824.1406\n",
      "Epoch 8275/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13001.9072 - val_loss: 18795.8262\n",
      "Epoch 8276/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12913.3750 - val_loss: 18798.7402\n",
      "Epoch 8277/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12913.5762 - val_loss: 18797.1367\n",
      "Epoch 8278/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12902.7969 - val_loss: 18790.6699\n",
      "Epoch 8279/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12884.8857 - val_loss: 18772.9199\n",
      "Epoch 8280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12827.9473 - val_loss: 18745.3633\n",
      "Epoch 8281/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.8535 - val_loss: 18727.7637\n",
      "Epoch 8282/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12677.4414 - val_loss: 18722.9590\n",
      "Epoch 8283/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12665.2393 - val_loss: 18718.4551\n",
      "Epoch 8284/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.7998 - val_loss: 18794.4844\n",
      "Epoch 8285/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12912.9219 - val_loss: 18796.7852\n",
      "Epoch 8286/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12920.8193 - val_loss: 18867.0059\n",
      "Epoch 8287/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13143.4717 - val_loss: 18894.6270\n",
      "Epoch 8288/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13230.0215 - val_loss: 18881.7910\n",
      "Epoch 8289/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13179.2607 - val_loss: 18877.3633\n",
      "Epoch 8290/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13158.6279 - val_loss: 18841.1191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13044.9717 - val_loss: 18849.7148\n",
      "Epoch 8292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13070.1572 - val_loss: 18853.3613\n",
      "Epoch 8293/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13086.6904 - val_loss: 18817.8887\n",
      "Epoch 8294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12979.6484 - val_loss: 18786.5039\n",
      "Epoch 8295/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12876.4453 - val_loss: 18758.8262\n",
      "Epoch 8296/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.6982 - val_loss: 18784.8965\n",
      "Epoch 8297/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.0908 - val_loss: 18776.5801\n",
      "Epoch 8298/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12846.7666 - val_loss: 18774.3086\n",
      "Epoch 8299/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12825.9326 - val_loss: 18750.5527\n",
      "Epoch 8300/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12749.7998 - val_loss: 18747.1719\n",
      "Epoch 8301/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12746.7949 - val_loss: 18751.6348\n",
      "Epoch 8302/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.6865 - val_loss: 18806.6270\n",
      "Epoch 8303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12942.9580 - val_loss: 18831.3203\n",
      "Epoch 8304/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13030.4463 - val_loss: 18851.9941\n",
      "Epoch 8305/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13088.5723 - val_loss: 18840.5977\n",
      "Epoch 8306/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13053.6670 - val_loss: 18779.7402\n",
      "Epoch 8307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12863.6191 - val_loss: 18757.4004\n",
      "Epoch 8308/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12792.1084 - val_loss: 18750.9160\n",
      "Epoch 8309/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.6367 - val_loss: 18751.4922\n",
      "Epoch 8310/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12761.1602 - val_loss: 18872.6465\n",
      "Epoch 8311/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13170.5449 - val_loss: 18770.0410\n",
      "Epoch 8312/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12835.1279 - val_loss: 18864.9023\n",
      "Epoch 8313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13138.5664 - val_loss: 18950.6855\n",
      "Epoch 8314/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13408.1895 - val_loss: 19001.5957\n",
      "Epoch 8315/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13558.5684 - val_loss: 19000.4355\n",
      "Epoch 8316/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13554.5957 - val_loss: 18961.6562\n",
      "Epoch 8317/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13426.2705 - val_loss: 18912.6699\n",
      "Epoch 8318/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13265.8506 - val_loss: 18890.5195\n",
      "Epoch 8319/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13199.0215 - val_loss: 18838.3633\n",
      "Epoch 8320/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13031.4033 - val_loss: 18771.1777\n",
      "Epoch 8321/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12820.3945 - val_loss: 18827.0137\n",
      "Epoch 8322/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12991.1904 - val_loss: 18854.0996\n",
      "Epoch 8323/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13067.1416 - val_loss: 18841.7441\n",
      "Epoch 8324/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 13037.9004 - val_loss: 18834.8770\n",
      "Epoch 8325/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13016.8643 - val_loss: 18776.8086\n",
      "Epoch 8326/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12841.8887 - val_loss: 18759.9180\n",
      "Epoch 8327/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.4824 - val_loss: 18741.4883\n",
      "Epoch 8328/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12739.7314 - val_loss: 18752.9492\n",
      "Epoch 8329/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12780.0391 - val_loss: 18764.4688\n",
      "Epoch 8330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.9521 - val_loss: 18757.0723\n",
      "Epoch 8331/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.9365 - val_loss: 18752.0547\n",
      "Epoch 8332/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.5244 - val_loss: 18749.3047\n",
      "Epoch 8333/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.7061 - val_loss: 18769.2090\n",
      "Epoch 8334/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12815.4883 - val_loss: 18765.0449\n",
      "Epoch 8335/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.7490 - val_loss: 18736.7617\n",
      "Epoch 8336/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12729.7988 - val_loss: 18696.2344\n",
      "Epoch 8337/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.2598 - val_loss: 18689.4258\n",
      "Epoch 8338/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12566.9307 - val_loss: 18716.6016\n",
      "Epoch 8339/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12652.6143 - val_loss: 18737.1094\n",
      "Epoch 8340/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12720.2285 - val_loss: 18717.5312\n",
      "Epoch 8341/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12659.1055 - val_loss: 18724.0996\n",
      "Epoch 8342/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12680.6553 - val_loss: 18730.6543\n",
      "Epoch 8343/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12707.1660 - val_loss: 18729.9141\n",
      "Epoch 8344/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12702.3164 - val_loss: 18717.5586\n",
      "Epoch 8345/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12662.9893 - val_loss: 18704.9277\n",
      "Epoch 8346/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12614.4365 - val_loss: 18700.3262\n",
      "Epoch 8347/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12594.8535 - val_loss: 18686.6152\n",
      "Epoch 8348/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12548.7188 - val_loss: 18714.9668\n",
      "Epoch 8349/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.6494 - val_loss: 18755.1289\n",
      "Epoch 8350/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12794.5186 - val_loss: 18880.9980\n",
      "Epoch 8351/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13189.3711 - val_loss: 18950.3516\n",
      "Epoch 8352/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13400.6836 - val_loss: 18923.8105\n",
      "Epoch 8353/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13319.2920 - val_loss: 18909.5762\n",
      "Epoch 8354/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13272.9287 - val_loss: 18892.8066\n",
      "Epoch 8355/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13218.7158 - val_loss: 18856.3184\n",
      "Epoch 8356/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13094.1270 - val_loss: 18831.0293\n",
      "Epoch 8357/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13015.7646 - val_loss: 18842.2051\n",
      "Epoch 8358/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13050.9717 - val_loss: 18834.9766\n",
      "Epoch 8359/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13026.8760 - val_loss: 18790.2891\n",
      "Epoch 8360/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12874.8721 - val_loss: 18800.2754\n",
      "Epoch 8361/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12907.9844 - val_loss: 18797.5898\n",
      "Epoch 8362/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12895.0156 - val_loss: 18783.5938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8363/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12855.6074 - val_loss: 18737.3965\n",
      "Epoch 8364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12715.0361 - val_loss: 18700.9902\n",
      "Epoch 8365/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12599.2861 - val_loss: 18706.5020\n",
      "Epoch 8366/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.2617 - val_loss: 18737.4434\n",
      "Epoch 8367/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12710.7139 - val_loss: 18750.2598\n",
      "Epoch 8368/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12751.4453 - val_loss: 18736.0156\n",
      "Epoch 8369/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.0967 - val_loss: 18732.3555\n",
      "Epoch 8370/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12708.6396 - val_loss: 18798.5410\n",
      "Epoch 8371/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12924.2373 - val_loss: 18831.6250\n",
      "Epoch 8372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13027.3027 - val_loss: 18843.2891\n",
      "Epoch 8373/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13061.0723 - val_loss: 18817.6680\n",
      "Epoch 8374/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12977.4756 - val_loss: 18781.8691\n",
      "Epoch 8375/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12869.5908 - val_loss: 18741.4277\n",
      "Epoch 8376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12741.4463 - val_loss: 18759.4258\n",
      "Epoch 8377/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.2051 - val_loss: 18775.6055\n",
      "Epoch 8378/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12833.0820 - val_loss: 18777.7422\n",
      "Epoch 8379/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12833.8086 - val_loss: 18774.9082\n",
      "Epoch 8380/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12823.9189 - val_loss: 18745.1680\n",
      "Epoch 8381/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.1348 - val_loss: 18734.2363\n",
      "Epoch 8382/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12698.3652 - val_loss: 18723.3438\n",
      "Epoch 8383/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12670.1045 - val_loss: 18694.8711\n",
      "Epoch 8384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12584.9951 - val_loss: 18692.8574\n",
      "Epoch 8385/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.8545 - val_loss: 18687.5801\n",
      "Epoch 8386/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12562.0928 - val_loss: 18712.1660\n",
      "Epoch 8387/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.1885 - val_loss: 18711.1641\n",
      "Epoch 8388/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12637.9980 - val_loss: 18726.0723\n",
      "Epoch 8389/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12688.2422 - val_loss: 18764.0254\n",
      "Epoch 8390/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12817.7744 - val_loss: 18773.8203\n",
      "Epoch 8391/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12846.8789 - val_loss: 18754.3438\n",
      "Epoch 8392/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.7871 - val_loss: 18746.9805\n",
      "Epoch 8393/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12755.9561 - val_loss: 18745.7422\n",
      "Epoch 8394/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12738.5732 - val_loss: 18765.3457\n",
      "Epoch 8395/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12803.3057 - val_loss: 18750.8105\n",
      "Epoch 8396/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12754.5088 - val_loss: 18705.3008\n",
      "Epoch 8397/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12615.6309 - val_loss: 18700.3730\n",
      "Epoch 8398/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.2852 - val_loss: 18718.0664\n",
      "Epoch 8399/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12664.9893 - val_loss: 18692.9648\n",
      "Epoch 8400/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12591.0615 - val_loss: 18695.1914\n",
      "Epoch 8401/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12582.7832 - val_loss: 18699.6172\n",
      "Epoch 8402/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12593.4082 - val_loss: 18688.3477\n",
      "Epoch 8403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12568.8164 - val_loss: 18679.8516\n",
      "Epoch 8404/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.6738 - val_loss: 18732.5977\n",
      "Epoch 8405/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12724.4355 - val_loss: 18751.0488\n",
      "Epoch 8406/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12779.5449 - val_loss: 18738.0977\n",
      "Epoch 8407/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12734.6445 - val_loss: 18709.0410\n",
      "Epoch 8408/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12639.0615 - val_loss: 18732.3691\n",
      "Epoch 8409/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12697.6318 - val_loss: 18755.5801\n",
      "Epoch 8410/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.8789 - val_loss: 18764.2734\n",
      "Epoch 8411/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12790.5439 - val_loss: 18712.2578\n",
      "Epoch 8412/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12636.4600 - val_loss: 18737.5918\n",
      "Epoch 8413/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.9521 - val_loss: 18794.8223\n",
      "Epoch 8414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12908.4443 - val_loss: 18774.5762\n",
      "Epoch 8415/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12845.0820 - val_loss: 18744.4082\n",
      "Epoch 8416/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.0312 - val_loss: 18733.5176\n",
      "Epoch 8417/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12708.5205 - val_loss: 18748.5039\n",
      "Epoch 8418/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12758.0840 - val_loss: 18721.8594\n",
      "Epoch 8419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12675.4775 - val_loss: 18735.4102\n",
      "Epoch 8420/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12732.5254 - val_loss: 18777.0527\n",
      "Epoch 8421/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12852.4844 - val_loss: 18801.6367\n",
      "Epoch 8422/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12929.8789 - val_loss: 18795.6484\n",
      "Epoch 8423/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12905.0977 - val_loss: 18767.8262\n",
      "Epoch 8424/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12819.8271 - val_loss: 18756.0469\n",
      "Epoch 8425/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12784.6592 - val_loss: 18740.0645\n",
      "Epoch 8426/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12736.3574 - val_loss: 18753.9941\n",
      "Epoch 8427/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12767.5762 - val_loss: 18732.5957\n",
      "Epoch 8428/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12699.6104 - val_loss: 18711.2832\n",
      "Epoch 8429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12637.0869 - val_loss: 18703.2402\n",
      "Epoch 8430/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.7314 - val_loss: 18717.9980\n",
      "Epoch 8431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12657.3477 - val_loss: 18711.0547\n",
      "Epoch 8432/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12632.5352 - val_loss: 18685.9746\n",
      "Epoch 8433/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12549.0049 - val_loss: 18745.9824\n",
      "Epoch 8434/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12745.7217 - val_loss: 18773.1816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8435/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12853.1738 - val_loss: 18872.2070\n",
      "Epoch 8436/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13161.7139 - val_loss: 18895.9238\n",
      "Epoch 8437/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13233.1523 - val_loss: 18885.1152\n",
      "Epoch 8438/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13194.5400 - val_loss: 18923.6074\n",
      "Epoch 8439/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 13311.6680 - val_loss: 18922.6875\n",
      "Epoch 8440/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13308.7314 - val_loss: 18871.3223\n",
      "Epoch 8441/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13152.8584 - val_loss: 18829.3496\n",
      "Epoch 8442/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13018.6504 - val_loss: 18790.2754\n",
      "Epoch 8443/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12895.4385 - val_loss: 18833.0039\n",
      "Epoch 8444/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13012.6689 - val_loss: 18844.8711\n",
      "Epoch 8445/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13053.0264 - val_loss: 18850.3828\n",
      "Epoch 8446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13073.7695 - val_loss: 18787.4805\n",
      "Epoch 8447/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12881.6318 - val_loss: 18745.1973\n",
      "Epoch 8448/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12747.6357 - val_loss: 18718.7441\n",
      "Epoch 8449/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12672.6455 - val_loss: 18769.0020\n",
      "Epoch 8450/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12824.1836 - val_loss: 18746.1113\n",
      "Epoch 8451/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12752.4648 - val_loss: 18757.1094\n",
      "Epoch 8452/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12770.8369 - val_loss: 18808.8223\n",
      "Epoch 8453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12940.2500 - val_loss: 18760.1875\n",
      "Epoch 8454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12793.6348 - val_loss: 18761.1074\n",
      "Epoch 8455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.3828 - val_loss: 18806.4551\n",
      "Epoch 8456/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12950.7686 - val_loss: 18796.4375\n",
      "Epoch 8457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12917.2002 - val_loss: 18778.7578\n",
      "Epoch 8458/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12857.8867 - val_loss: 18779.0020\n",
      "Epoch 8459/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12849.8457 - val_loss: 18853.8184\n",
      "Epoch 8460/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13081.2744 - val_loss: 18852.1836\n",
      "Epoch 8461/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13071.8838 - val_loss: 18801.6250\n",
      "Epoch 8462/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12912.8057 - val_loss: 18738.7129\n",
      "Epoch 8463/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.3545 - val_loss: 18703.8906\n",
      "Epoch 8464/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12631.2861 - val_loss: 18738.5996\n",
      "Epoch 8465/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12733.8857 - val_loss: 18743.3770\n",
      "Epoch 8466/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12742.5205 - val_loss: 18727.2695\n",
      "Epoch 8467/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12672.9629 - val_loss: 18845.6348\n",
      "Epoch 8468/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13072.4062 - val_loss: 18748.2422\n",
      "Epoch 8469/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12764.6328 - val_loss: 18837.0391\n",
      "Epoch 8470/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13055.5010 - val_loss: 18872.6602\n",
      "Epoch 8471/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 13162.7363 - val_loss: 18885.0195\n",
      "Epoch 8472/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13196.0547 - val_loss: 18859.9609\n",
      "Epoch 8473/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 13119.2246 - val_loss: 18814.6289\n",
      "Epoch 8474/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12977.8369 - val_loss: 18819.7695\n",
      "Epoch 8475/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12984.7012 - val_loss: 18839.9023\n",
      "Epoch 8476/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13037.1055 - val_loss: 18819.3730\n",
      "Epoch 8477/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12977.8613 - val_loss: 18821.2734\n",
      "Epoch 8478/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12976.8262 - val_loss: 18811.7031\n",
      "Epoch 8479/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12950.3281 - val_loss: 18759.8945\n",
      "Epoch 8480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12790.9131 - val_loss: 18761.7168\n",
      "Epoch 8481/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12791.4238 - val_loss: 18761.2773\n",
      "Epoch 8482/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.9951 - val_loss: 18781.1504\n",
      "Epoch 8483/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12857.3271 - val_loss: 18769.4746\n",
      "Epoch 8484/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12804.7520 - val_loss: 18735.5000\n",
      "Epoch 8485/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12693.2812 - val_loss: 18748.3242\n",
      "Epoch 8486/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12730.6445 - val_loss: 18766.6289\n",
      "Epoch 8487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12799.8477 - val_loss: 18762.8770\n",
      "Epoch 8488/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12788.2783 - val_loss: 18747.1738\n",
      "Epoch 8489/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12757.0869 - val_loss: 18719.0137\n",
      "Epoch 8490/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12652.9014 - val_loss: 18713.0078\n",
      "Epoch 8491/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12647.0557 - val_loss: 18709.3574\n",
      "Epoch 8492/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.2861 - val_loss: 18733.5234\n",
      "Epoch 8493/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12711.4834 - val_loss: 18753.1465\n",
      "Epoch 8494/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12771.2012 - val_loss: 18752.5938\n",
      "Epoch 8495/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12771.5205 - val_loss: 18743.3594\n",
      "Epoch 8496/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12748.2783 - val_loss: 18717.9199\n",
      "Epoch 8497/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12663.8525 - val_loss: 18675.0293\n",
      "Epoch 8498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12536.1094 - val_loss: 18704.0957\n",
      "Epoch 8499/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12611.3135 - val_loss: 18722.4453\n",
      "Epoch 8500/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.2334 - val_loss: 18702.7832\n",
      "Epoch 8501/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12600.4502 - val_loss: 18691.6797\n",
      "Epoch 8502/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.9375 - val_loss: 18688.7637\n",
      "Epoch 8503/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.3184 - val_loss: 18673.7578\n",
      "Epoch 8504/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12504.2959 - val_loss: 18670.3555\n",
      "Epoch 8505/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12506.5771 - val_loss: 18671.6641\n",
      "Epoch 8506/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12515.4404 - val_loss: 18671.5898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8507/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.3193 - val_loss: 18671.2637\n",
      "Epoch 8508/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12511.3291 - val_loss: 18674.4844\n",
      "Epoch 8509/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12530.4883 - val_loss: 18680.9707\n",
      "Epoch 8510/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12549.8291 - val_loss: 18666.0742\n",
      "Epoch 8511/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12496.0059 - val_loss: 18684.4531\n",
      "Epoch 8512/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12548.9326 - val_loss: 18689.4121\n",
      "Epoch 8513/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12568.5000 - val_loss: 18702.5957\n",
      "Epoch 8514/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.1162 - val_loss: 18699.8809\n",
      "Epoch 8515/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.3223 - val_loss: 18695.0078\n",
      "Epoch 8516/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12590.4619 - val_loss: 18703.0957\n",
      "Epoch 8517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.2793 - val_loss: 18705.9512\n",
      "Epoch 8518/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12642.4668 - val_loss: 18718.5156\n",
      "Epoch 8519/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12677.6387 - val_loss: 18812.2637\n",
      "Epoch 8520/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12972.6895 - val_loss: 18837.2266\n",
      "Epoch 8521/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 13050.4561 - val_loss: 18812.9316\n",
      "Epoch 8522/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12968.7998 - val_loss: 18795.3359\n",
      "Epoch 8523/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12909.2275 - val_loss: 18788.4883\n",
      "Epoch 8524/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12877.9219 - val_loss: 18775.8008\n",
      "Epoch 8525/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12840.6064 - val_loss: 18748.6426\n",
      "Epoch 8526/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12748.8828 - val_loss: 18754.9043\n",
      "Epoch 8527/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12760.7266 - val_loss: 18758.9434\n",
      "Epoch 8528/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12782.5215 - val_loss: 18754.1836\n",
      "Epoch 8529/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12773.6523 - val_loss: 18741.5312\n",
      "Epoch 8530/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12734.8008 - val_loss: 18711.7500\n",
      "Epoch 8531/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12636.4131 - val_loss: 18703.2266\n",
      "Epoch 8532/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.5166 - val_loss: 18707.4941\n",
      "Epoch 8533/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.5361 - val_loss: 18713.9453\n",
      "Epoch 8534/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12628.1191 - val_loss: 18735.1660\n",
      "Epoch 8535/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12695.1406 - val_loss: 18716.6836\n",
      "Epoch 8536/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12645.2461 - val_loss: 18682.3125\n",
      "Epoch 8537/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12536.0020 - val_loss: 18674.2207\n",
      "Epoch 8538/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12514.3945 - val_loss: 18686.5684\n",
      "Epoch 8539/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12556.3701 - val_loss: 18716.6152\n",
      "Epoch 8540/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.5059 - val_loss: 18721.4082\n",
      "Epoch 8541/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12655.4326 - val_loss: 18697.0762\n",
      "Epoch 8542/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12578.4834 - val_loss: 18682.3066\n",
      "Epoch 8543/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12556.9043 - val_loss: 18682.8652\n",
      "Epoch 8544/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.2793 - val_loss: 18677.7754\n",
      "Epoch 8545/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12538.7324 - val_loss: 18695.3027\n",
      "Epoch 8546/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.0615 - val_loss: 18698.2051\n",
      "Epoch 8547/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12574.7744 - val_loss: 18702.9023\n",
      "Epoch 8548/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.7246 - val_loss: 18686.4102\n",
      "Epoch 8549/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.0088 - val_loss: 18710.3828\n",
      "Epoch 8550/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12644.8594 - val_loss: 18741.0859\n",
      "Epoch 8551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12743.6973 - val_loss: 18755.0371\n",
      "Epoch 8552/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12786.9795 - val_loss: 18728.4453\n",
      "Epoch 8553/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12689.1523 - val_loss: 18693.7910\n",
      "Epoch 8554/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12571.7734 - val_loss: 18686.5723\n",
      "Epoch 8555/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12553.4277 - val_loss: 18710.4277\n",
      "Epoch 8556/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12633.6973 - val_loss: 18721.2051\n",
      "Epoch 8557/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12666.3398 - val_loss: 18687.1172\n",
      "Epoch 8558/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12563.7051 - val_loss: 18647.5430\n",
      "Epoch 8559/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12442.4941 - val_loss: 18689.3945\n",
      "Epoch 8560/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12553.0918 - val_loss: 18693.4395\n",
      "Epoch 8561/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12569.8848 - val_loss: 18695.1602\n",
      "Epoch 8562/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12583.4854 - val_loss: 18697.4785\n",
      "Epoch 8563/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.4268 - val_loss: 18709.3086\n",
      "Epoch 8564/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12631.4619 - val_loss: 18683.4023\n",
      "Epoch 8565/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.8330 - val_loss: 18688.6914\n",
      "Epoch 8566/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.7109 - val_loss: 18711.6211\n",
      "Epoch 8567/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12634.3672 - val_loss: 18690.4805\n",
      "Epoch 8568/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.3486 - val_loss: 18684.1602\n",
      "Epoch 8569/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12547.2666 - val_loss: 18697.1074\n",
      "Epoch 8570/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12592.9453 - val_loss: 18696.6289\n",
      "Epoch 8571/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.3018 - val_loss: 18702.5918\n",
      "Epoch 8572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.0605 - val_loss: 18690.6367\n",
      "Epoch 8573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12563.7529 - val_loss: 18667.9102\n",
      "Epoch 8574/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12489.8652 - val_loss: 18680.7188\n",
      "Epoch 8575/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12529.6270 - val_loss: 18719.7402\n",
      "Epoch 8576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12651.9775 - val_loss: 18690.7285\n",
      "Epoch 8577/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.6455 - val_loss: 18686.1016\n",
      "Epoch 8578/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.1611 - val_loss: 18686.1211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8579/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.4590 - val_loss: 18678.8887\n",
      "Epoch 8580/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12526.7861 - val_loss: 18673.1641\n",
      "Epoch 8581/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12512.2666 - val_loss: 18661.1562\n",
      "Epoch 8582/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12481.0840 - val_loss: 18656.7500\n",
      "Epoch 8583/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12460.1445 - val_loss: 18656.1309\n",
      "Epoch 8584/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12451.9541 - val_loss: 18669.3262\n",
      "Epoch 8585/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12496.2607 - val_loss: 18673.7402\n",
      "Epoch 8586/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12518.3936 - val_loss: 18664.0391\n",
      "Epoch 8587/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12490.2754 - val_loss: 18680.6582\n",
      "Epoch 8588/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12535.6172 - val_loss: 18659.7266\n",
      "Epoch 8589/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12474.6035 - val_loss: 18665.4648\n",
      "Epoch 8590/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12492.5508 - val_loss: 18673.2090\n",
      "Epoch 8591/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12515.4463 - val_loss: 18646.5938\n",
      "Epoch 8592/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12423.7656 - val_loss: 18652.3906\n",
      "Epoch 8593/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12442.5352 - val_loss: 18664.3418\n",
      "Epoch 8594/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12479.1064 - val_loss: 18660.0352\n",
      "Epoch 8595/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12471.6670 - val_loss: 18649.3105\n",
      "Epoch 8596/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12432.4512 - val_loss: 18635.6387\n",
      "Epoch 8597/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12388.4795 - val_loss: 18642.2012\n",
      "Epoch 8598/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12412.4287 - val_loss: 18651.3965\n",
      "Epoch 8599/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12449.2402 - val_loss: 18651.4688\n",
      "Epoch 8600/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12447.5596 - val_loss: 18646.9316\n",
      "Epoch 8601/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12424.8398 - val_loss: 18640.2285\n",
      "Epoch 8602/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12409.5303 - val_loss: 18655.9453\n",
      "Epoch 8603/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12467.9717 - val_loss: 18657.9629\n",
      "Epoch 8604/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12469.5840 - val_loss: 18659.7168\n",
      "Epoch 8605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12466.6875 - val_loss: 18636.8828\n",
      "Epoch 8606/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12400.1025 - val_loss: 18658.5234\n",
      "Epoch 8607/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12475.4072 - val_loss: 18661.9043\n",
      "Epoch 8608/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12479.7959 - val_loss: 18652.0215\n",
      "Epoch 8609/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12455.1826 - val_loss: 18644.7461\n",
      "Epoch 8610/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12427.1289 - val_loss: 18657.1094\n",
      "Epoch 8611/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12461.8301 - val_loss: 18660.8672\n",
      "Epoch 8612/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12475.2910 - val_loss: 18661.8008\n",
      "Epoch 8613/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12478.8457 - val_loss: 18646.4648\n",
      "Epoch 8614/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12429.6836 - val_loss: 18648.0312\n",
      "Epoch 8615/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12435.6377 - val_loss: 18641.1406\n",
      "Epoch 8616/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12417.1934 - val_loss: 18652.7656\n",
      "Epoch 8617/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12450.0938 - val_loss: 18667.0391\n",
      "Epoch 8618/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12488.8633 - val_loss: 18668.2480\n",
      "Epoch 8619/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12494.7979 - val_loss: 18670.9004\n",
      "Epoch 8620/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12505.4268 - val_loss: 18671.8594\n",
      "Epoch 8621/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12511.6914 - val_loss: 18657.5625\n",
      "Epoch 8622/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12463.4121 - val_loss: 18639.2324\n",
      "Epoch 8623/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12409.1191 - val_loss: 18670.1934\n",
      "Epoch 8624/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12504.2539 - val_loss: 18675.5430\n",
      "Epoch 8625/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12528.2109 - val_loss: 18639.8008\n",
      "Epoch 8626/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12416.2275 - val_loss: 18670.1543\n",
      "Epoch 8627/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.4717 - val_loss: 18663.4941\n",
      "Epoch 8628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12483.8760 - val_loss: 18661.1250\n",
      "Epoch 8629/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12476.3311 - val_loss: 18669.0586\n",
      "Epoch 8630/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12501.5791 - val_loss: 18661.2207\n",
      "Epoch 8631/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12475.3359 - val_loss: 18662.6699\n",
      "Epoch 8632/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12477.1025 - val_loss: 18664.2930\n",
      "Epoch 8633/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12479.1533 - val_loss: 18664.6992\n",
      "Epoch 8634/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12478.2422 - val_loss: 18639.2070\n",
      "Epoch 8635/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12399.3545 - val_loss: 18655.1699\n",
      "Epoch 8636/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12453.9102 - val_loss: 18678.2441\n",
      "Epoch 8637/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.8213 - val_loss: 18671.9160\n",
      "Epoch 8638/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.9951 - val_loss: 18685.0215\n",
      "Epoch 8639/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12554.3145 - val_loss: 18650.0840\n",
      "Epoch 8640/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12442.2656 - val_loss: 18658.5625\n",
      "Epoch 8641/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12470.1035 - val_loss: 18666.7109\n",
      "Epoch 8642/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12496.0947 - val_loss: 18682.0703\n",
      "Epoch 8643/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.1230 - val_loss: 18687.5957\n",
      "Epoch 8644/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12563.8428 - val_loss: 18686.5215\n",
      "Epoch 8645/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12559.9062 - val_loss: 18672.8789\n",
      "Epoch 8646/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.6055 - val_loss: 18665.9648\n",
      "Epoch 8647/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12499.8779 - val_loss: 18686.5566\n",
      "Epoch 8648/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12553.8701 - val_loss: 18726.6484\n",
      "Epoch 8649/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12686.0752 - val_loss: 18699.1172\n",
      "Epoch 8650/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12605.2295 - val_loss: 18680.2109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8651/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12543.0654 - val_loss: 18709.8242\n",
      "Epoch 8652/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.6182 - val_loss: 18689.8809\n",
      "Epoch 8653/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12655.8506 - val_loss: 18711.6738\n",
      "Epoch 8654/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.5439 - val_loss: 18789.2520\n",
      "Epoch 8655/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12886.2549 - val_loss: 18822.4688\n",
      "Epoch 8656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12990.5029 - val_loss: 18813.2578\n",
      "Epoch 8657/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12961.5918 - val_loss: 18775.9922\n",
      "Epoch 8658/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12846.0889 - val_loss: 18711.3066\n",
      "Epoch 8659/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.6621 - val_loss: 18704.0898\n",
      "Epoch 8660/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.6523 - val_loss: 18729.3809\n",
      "Epoch 8661/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12685.1455 - val_loss: 18726.4492\n",
      "Epoch 8662/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12676.6992 - val_loss: 18728.4297\n",
      "Epoch 8663/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12686.1846 - val_loss: 18692.8418\n",
      "Epoch 8664/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12573.4307 - val_loss: 18690.9316\n",
      "Epoch 8665/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12563.4746 - val_loss: 18720.1621\n",
      "Epoch 8666/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12652.8555 - val_loss: 18731.5254\n",
      "Epoch 8667/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12694.7100 - val_loss: 18718.1270\n",
      "Epoch 8668/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12651.0264 - val_loss: 18710.3887\n",
      "Epoch 8669/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.2529 - val_loss: 18703.2402\n",
      "Epoch 8670/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12597.7773 - val_loss: 18705.2617\n",
      "Epoch 8671/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12614.6748 - val_loss: 18707.2383\n",
      "Epoch 8672/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12620.7852 - val_loss: 18699.3652\n",
      "Epoch 8673/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12589.5693 - val_loss: 18707.3906\n",
      "Epoch 8674/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.1865 - val_loss: 18724.6387\n",
      "Epoch 8675/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12677.8809 - val_loss: 18728.7441\n",
      "Epoch 8676/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12689.3486 - val_loss: 18686.6035\n",
      "Epoch 8677/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12549.0938 - val_loss: 18701.6289\n",
      "Epoch 8678/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12595.2676 - val_loss: 18700.9121\n",
      "Epoch 8679/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12593.0732 - val_loss: 18687.2070\n",
      "Epoch 8680/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.0596 - val_loss: 18699.6016\n",
      "Epoch 8681/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.8232 - val_loss: 18688.9062\n",
      "Epoch 8682/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12560.2764 - val_loss: 18656.5684\n",
      "Epoch 8683/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12464.1680 - val_loss: 18674.3965\n",
      "Epoch 8684/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12512.2520 - val_loss: 18694.9648\n",
      "Epoch 8685/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.5117 - val_loss: 18681.7852\n",
      "Epoch 8686/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.7080 - val_loss: 18673.2812\n",
      "Epoch 8687/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12512.5508 - val_loss: 18689.3691\n",
      "Epoch 8688/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.4473 - val_loss: 18692.5586\n",
      "Epoch 8689/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12567.6943 - val_loss: 18684.5469\n",
      "Epoch 8690/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12543.0254 - val_loss: 18660.3770\n",
      "Epoch 8691/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12476.3115 - val_loss: 18661.0742\n",
      "Epoch 8692/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12479.2363 - val_loss: 18690.9160\n",
      "Epoch 8693/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12571.8877 - val_loss: 18689.4883\n",
      "Epoch 8694/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.4131 - val_loss: 18661.2734\n",
      "Epoch 8695/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12467.1875 - val_loss: 18681.2539\n",
      "Epoch 8696/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12530.0889 - val_loss: 18704.1387\n",
      "Epoch 8697/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12604.3389 - val_loss: 18682.8691\n",
      "Epoch 8698/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12541.1602 - val_loss: 18680.0059\n",
      "Epoch 8699/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.2139 - val_loss: 18663.6094\n",
      "Epoch 8700/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12479.8916 - val_loss: 18689.5977\n",
      "Epoch 8701/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12564.1592 - val_loss: 18699.9395\n",
      "Epoch 8702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.0098 - val_loss: 18695.8281\n",
      "Epoch 8703/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12581.1006 - val_loss: 18687.1133\n",
      "Epoch 8704/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.6885 - val_loss: 18680.4492\n",
      "Epoch 8705/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12529.0449 - val_loss: 18702.1289\n",
      "Epoch 8706/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.3037 - val_loss: 18689.7773\n",
      "Epoch 8707/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12569.0156 - val_loss: 18675.4062\n",
      "Epoch 8708/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12522.3242 - val_loss: 18667.6445\n",
      "Epoch 8709/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12491.3701 - val_loss: 18663.4648\n",
      "Epoch 8710/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12483.0244 - val_loss: 18670.1465\n",
      "Epoch 8711/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12508.3398 - val_loss: 18697.3457\n",
      "Epoch 8712/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.8330 - val_loss: 18692.1738\n",
      "Epoch 8713/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12565.9619 - val_loss: 18663.2461\n",
      "Epoch 8714/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12478.2910 - val_loss: 18663.0469\n",
      "Epoch 8715/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12485.9404 - val_loss: 18655.8203\n",
      "Epoch 8716/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12461.4805 - val_loss: 18689.8184\n",
      "Epoch 8717/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.8779 - val_loss: 18678.0332\n",
      "Epoch 8718/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12523.9014 - val_loss: 18659.2168\n",
      "Epoch 8719/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12469.8096 - val_loss: 18655.4316\n",
      "Epoch 8720/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12459.4199 - val_loss: 18661.8555\n",
      "Epoch 8721/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12476.4111 - val_loss: 18657.3945\n",
      "Epoch 8722/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12457.8994 - val_loss: 18657.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8723/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12463.7959 - val_loss: 18657.4160\n",
      "Epoch 8724/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12468.3174 - val_loss: 18640.4844\n",
      "Epoch 8725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12414.4668 - val_loss: 18683.8203\n",
      "Epoch 8726/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12542.4141 - val_loss: 18697.2383\n",
      "Epoch 8727/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12586.0801 - val_loss: 18668.0039\n",
      "Epoch 8728/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12500.0605 - val_loss: 18669.6133\n",
      "Epoch 8729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12500.4453 - val_loss: 18678.1797\n",
      "Epoch 8730/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.4971 - val_loss: 18696.4082\n",
      "Epoch 8731/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12582.3008 - val_loss: 18668.7871\n",
      "Epoch 8732/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12494.1475 - val_loss: 18675.9570\n",
      "Epoch 8733/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.3164 - val_loss: 18687.5684\n",
      "Epoch 8734/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.6064 - val_loss: 18698.5176\n",
      "Epoch 8735/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.4531 - val_loss: 18677.3320\n",
      "Epoch 8736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12527.5781 - val_loss: 18646.5508\n",
      "Epoch 8737/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12467.8516 - val_loss: 18682.7168\n",
      "Epoch 8738/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12550.6328 - val_loss: 18721.8145\n",
      "Epoch 8739/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12675.1270 - val_loss: 18706.6816\n",
      "Epoch 8740/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12624.6055 - val_loss: 18719.8945\n",
      "Epoch 8741/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12656.0928 - val_loss: 18713.9570\n",
      "Epoch 8742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.1777 - val_loss: 18696.4727\n",
      "Epoch 8743/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12584.4336 - val_loss: 18695.5137\n",
      "Epoch 8744/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.2812 - val_loss: 18691.6270\n",
      "Epoch 8745/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.8379 - val_loss: 18670.6934\n",
      "Epoch 8746/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12506.9297 - val_loss: 18678.6309\n",
      "Epoch 8747/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12525.4746 - val_loss: 18681.7812\n",
      "Epoch 8748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.0244 - val_loss: 18669.2969\n",
      "Epoch 8749/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12498.8672 - val_loss: 18687.8262\n",
      "Epoch 8750/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12560.6377 - val_loss: 18716.0723\n",
      "Epoch 8751/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12657.3389 - val_loss: 18692.5586\n",
      "Epoch 8752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12574.7188 - val_loss: 18694.2266\n",
      "Epoch 8753/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.4609 - val_loss: 18688.6074\n",
      "Epoch 8754/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12557.1475 - val_loss: 18673.5371\n",
      "Epoch 8755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12512.2773 - val_loss: 18685.4238\n",
      "Epoch 8756/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.5537 - val_loss: 18693.2324\n",
      "Epoch 8757/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12577.6934 - val_loss: 18670.7227\n",
      "Epoch 8758/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12511.3496 - val_loss: 18663.9531\n",
      "Epoch 8759/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12483.1709 - val_loss: 18675.4375\n",
      "Epoch 8760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.3779 - val_loss: 18667.4551\n",
      "Epoch 8761/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12487.7725 - val_loss: 18664.9688\n",
      "Epoch 8762/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12488.6738 - val_loss: 18662.9902\n",
      "Epoch 8763/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12478.0488 - val_loss: 18638.7461\n",
      "Epoch 8764/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12405.0957 - val_loss: 18682.6055\n",
      "Epoch 8765/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.9629 - val_loss: 18686.5684\n",
      "Epoch 8766/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12552.8320 - val_loss: 18642.0137\n",
      "Epoch 8767/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12419.7734 - val_loss: 18662.9727\n",
      "Epoch 8768/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12487.1475 - val_loss: 18689.4258\n",
      "Epoch 8769/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12560.0244 - val_loss: 18681.5215\n",
      "Epoch 8770/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12540.4258 - val_loss: 18679.0176\n",
      "Epoch 8771/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12532.1416 - val_loss: 18676.1445\n",
      "Epoch 8772/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.6797 - val_loss: 18667.8301\n",
      "Epoch 8773/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.8770 - val_loss: 18682.1133\n",
      "Epoch 8774/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12538.8574 - val_loss: 18683.2734\n",
      "Epoch 8775/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12547.7559 - val_loss: 18690.3730\n",
      "Epoch 8776/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12565.6543 - val_loss: 18675.1230\n",
      "Epoch 8777/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12516.9180 - val_loss: 18707.7324\n",
      "Epoch 8778/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12619.1611 - val_loss: 18698.5840\n",
      "Epoch 8779/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.7959 - val_loss: 18680.5957\n",
      "Epoch 8780/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.6270 - val_loss: 18675.1895\n",
      "Epoch 8781/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12518.9072 - val_loss: 18688.6309\n",
      "Epoch 8782/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12563.1807 - val_loss: 18691.0273\n",
      "Epoch 8783/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12571.4893 - val_loss: 18704.1074\n",
      "Epoch 8784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12615.2305 - val_loss: 18695.9902\n",
      "Epoch 8785/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.6826 - val_loss: 18670.0234\n",
      "Epoch 8786/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.0840 - val_loss: 18676.6836\n",
      "Epoch 8787/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.8564 - val_loss: 18681.8730\n",
      "Epoch 8788/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.3506 - val_loss: 18706.3320\n",
      "Epoch 8789/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12620.2012 - val_loss: 18689.1953\n",
      "Epoch 8790/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12567.2471 - val_loss: 18694.5020\n",
      "Epoch 8791/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.6855 - val_loss: 18706.5898\n",
      "Epoch 8792/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.2549 - val_loss: 18704.6211\n",
      "Epoch 8793/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12604.7598 - val_loss: 18664.3477\n",
      "Epoch 8794/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12482.9209 - val_loss: 18665.4004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8795/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12487.5156 - val_loss: 18701.0371\n",
      "Epoch 8796/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12600.2969 - val_loss: 18702.8008\n",
      "Epoch 8797/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.3779 - val_loss: 18693.4688\n",
      "Epoch 8798/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12577.5801 - val_loss: 18689.6523\n",
      "Epoch 8799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12571.0146 - val_loss: 18660.2637\n",
      "Epoch 8800/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12476.6396 - val_loss: 18667.5977\n",
      "Epoch 8801/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12500.9443 - val_loss: 18687.0430\n",
      "Epoch 8802/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.7695 - val_loss: 18691.6738\n",
      "Epoch 8803/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12570.6514 - val_loss: 18704.0703\n",
      "Epoch 8804/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12611.1182 - val_loss: 18677.2051\n",
      "Epoch 8805/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.7344 - val_loss: 18677.0312\n",
      "Epoch 8806/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12521.7158 - val_loss: 18701.1816\n",
      "Epoch 8807/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.3359 - val_loss: 18702.6758\n",
      "Epoch 8808/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12624.9736 - val_loss: 18676.9180\n",
      "Epoch 8809/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.6689 - val_loss: 18666.1680\n",
      "Epoch 8810/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12494.1416 - val_loss: 18681.8105\n",
      "Epoch 8811/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12541.2744 - val_loss: 18708.1172\n",
      "Epoch 8812/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12625.0908 - val_loss: 18715.5762\n",
      "Epoch 8813/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.2646 - val_loss: 18691.5312\n",
      "Epoch 8814/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12571.4775 - val_loss: 18665.5527\n",
      "Epoch 8815/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12493.0146 - val_loss: 18692.1211\n",
      "Epoch 8816/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12572.8779 - val_loss: 18712.2637\n",
      "Epoch 8817/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12633.6797 - val_loss: 18701.2910\n",
      "Epoch 8818/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12597.9824 - val_loss: 18709.8164\n",
      "Epoch 8819/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12624.1064 - val_loss: 18693.5273\n",
      "Epoch 8820/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12577.1885 - val_loss: 18690.6543\n",
      "Epoch 8821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12564.8164 - val_loss: 18711.0117\n",
      "Epoch 8822/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.4688 - val_loss: 18707.4863\n",
      "Epoch 8823/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12623.1816 - val_loss: 18703.6328\n",
      "Epoch 8824/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12611.8340 - val_loss: 18698.7891\n",
      "Epoch 8825/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12598.8213 - val_loss: 18684.6035\n",
      "Epoch 8826/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.7480 - val_loss: 18679.0391\n",
      "Epoch 8827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12534.0566 - val_loss: 18670.5176\n",
      "Epoch 8828/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12502.5732 - val_loss: 18690.1816\n",
      "Epoch 8829/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12563.6426 - val_loss: 18704.2305\n",
      "Epoch 8830/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.1504 - val_loss: 18712.7617\n",
      "Epoch 8831/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12640.3613 - val_loss: 18698.8066\n",
      "Epoch 8832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12595.5117 - val_loss: 18681.1094\n",
      "Epoch 8833/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12553.0674 - val_loss: 18680.5195\n",
      "Epoch 8834/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12540.3789 - val_loss: 18681.3613\n",
      "Epoch 8835/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.4014 - val_loss: 18704.7031\n",
      "Epoch 8836/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12618.8076 - val_loss: 18719.7031\n",
      "Epoch 8837/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.7520 - val_loss: 18724.6230\n",
      "Epoch 8838/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.0703 - val_loss: 18686.1992\n",
      "Epoch 8839/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.5186 - val_loss: 18667.0918\n",
      "Epoch 8840/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.6816 - val_loss: 18705.5645\n",
      "Epoch 8841/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.9902 - val_loss: 18696.5879\n",
      "Epoch 8842/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12591.0762 - val_loss: 18693.6953\n",
      "Epoch 8843/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12629.9668 - val_loss: 18723.6934\n",
      "Epoch 8844/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12678.3789 - val_loss: 18743.2402\n",
      "Epoch 8845/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12740.8447 - val_loss: 18742.4492\n",
      "Epoch 8846/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12738.0088 - val_loss: 18745.7168\n",
      "Epoch 8847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12744.2686 - val_loss: 18746.4980\n",
      "Epoch 8848/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12743.1816 - val_loss: 18733.5703\n",
      "Epoch 8849/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12706.2256 - val_loss: 18710.4707\n",
      "Epoch 8850/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.1592 - val_loss: 18689.0527\n",
      "Epoch 8851/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12639.8467 - val_loss: 18715.2207\n",
      "Epoch 8852/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.8730 - val_loss: 18746.8965\n",
      "Epoch 8853/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12749.2461 - val_loss: 18749.2520\n",
      "Epoch 8854/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12754.4648 - val_loss: 18769.0156\n",
      "Epoch 8855/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12820.1631 - val_loss: 18754.8633\n",
      "Epoch 8856/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12777.6436 - val_loss: 18716.0449\n",
      "Epoch 8857/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.9854 - val_loss: 18710.0117\n",
      "Epoch 8858/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12625.2676 - val_loss: 18717.3477\n",
      "Epoch 8859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12647.7637 - val_loss: 18710.9023\n",
      "Epoch 8860/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.1270 - val_loss: 18682.3262\n",
      "Epoch 8861/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12539.6807 - val_loss: 18673.7695\n",
      "Epoch 8862/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12520.2939 - val_loss: 18710.1680\n",
      "Epoch 8863/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12633.6709 - val_loss: 18722.7773\n",
      "Epoch 8864/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12675.8047 - val_loss: 18701.9766\n",
      "Epoch 8865/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12592.6758 - val_loss: 18686.6621\n",
      "Epoch 8866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12558.5479 - val_loss: 18666.4258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12493.3223 - val_loss: 18671.4785\n",
      "Epoch 8868/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12511.7656 - val_loss: 18700.3262\n",
      "Epoch 8869/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12607.6631 - val_loss: 18694.3555\n",
      "Epoch 8870/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12581.0361 - val_loss: 18657.4629\n",
      "Epoch 8871/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12465.1367 - val_loss: 18664.3145\n",
      "Epoch 8872/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12481.7998 - val_loss: 18666.8730\n",
      "Epoch 8873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12494.1035 - val_loss: 18646.7500\n",
      "Epoch 8874/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12430.9727 - val_loss: 18656.8496\n",
      "Epoch 8875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12497.2012 - val_loss: 18687.6582\n",
      "Epoch 8876/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12569.6543 - val_loss: 18710.0137\n",
      "Epoch 8877/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12640.1875 - val_loss: 18683.9277\n",
      "Epoch 8878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.4082 - val_loss: 18700.6621\n",
      "Epoch 8879/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12597.8662 - val_loss: 18688.5645\n",
      "Epoch 8880/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12561.9619 - val_loss: 18714.0898\n",
      "Epoch 8881/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.0469 - val_loss: 18709.0938\n",
      "Epoch 8882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.3779 - val_loss: 18703.7949\n",
      "Epoch 8883/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.0371 - val_loss: 18679.3320\n",
      "Epoch 8884/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12532.7090 - val_loss: 18677.0605\n",
      "Epoch 8885/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12512.8916 - val_loss: 18677.8418\n",
      "Epoch 8886/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12524.5938 - val_loss: 18688.5723\n",
      "Epoch 8887/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12558.1016 - val_loss: 18695.8047\n",
      "Epoch 8888/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.9434 - val_loss: 18692.7617\n",
      "Epoch 8889/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12570.4033 - val_loss: 18668.9453\n",
      "Epoch 8890/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12502.9180 - val_loss: 18663.9727\n",
      "Epoch 8891/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.6748 - val_loss: 18706.2715\n",
      "Epoch 8892/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.4541 - val_loss: 18730.5254\n",
      "Epoch 8893/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12692.0020 - val_loss: 18703.7129\n",
      "Epoch 8894/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.2676 - val_loss: 18664.4316\n",
      "Epoch 8895/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12495.5566 - val_loss: 18681.1016\n",
      "Epoch 8896/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.4385 - val_loss: 18706.5371\n",
      "Epoch 8897/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.1074 - val_loss: 18718.5547\n",
      "Epoch 8898/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12669.4932 - val_loss: 18685.9766\n",
      "Epoch 8899/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12556.7832 - val_loss: 18681.4746\n",
      "Epoch 8900/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12543.6885 - val_loss: 18685.4746\n",
      "Epoch 8901/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12556.9453 - val_loss: 18689.6250\n",
      "Epoch 8902/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.7031 - val_loss: 18669.3594\n",
      "Epoch 8903/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12489.5137 - val_loss: 18684.4004\n",
      "Epoch 8904/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12554.2803 - val_loss: 18703.6309\n",
      "Epoch 8905/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12613.5898 - val_loss: 18674.4375\n",
      "Epoch 8906/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.1855 - val_loss: 18660.8418\n",
      "Epoch 8907/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12484.9570 - val_loss: 18678.6211\n",
      "Epoch 8908/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12539.9365 - val_loss: 18701.9746\n",
      "Epoch 8909/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12598.1221 - val_loss: 18701.9375\n",
      "Epoch 8910/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.3086 - val_loss: 18672.3848\n",
      "Epoch 8911/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.9219 - val_loss: 18659.4590\n",
      "Epoch 8912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.8721 - val_loss: 18657.0078\n",
      "Epoch 8913/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12467.7676 - val_loss: 18669.2070\n",
      "Epoch 8914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12496.5869 - val_loss: 18704.7305\n",
      "Epoch 8915/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12703.0986 - val_loss: 18713.6836\n",
      "Epoch 8916/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12652.2217 - val_loss: 18752.0977\n",
      "Epoch 8917/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.9502 - val_loss: 18745.5234\n",
      "Epoch 8918/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12757.6055 - val_loss: 18755.2109\n",
      "Epoch 8919/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12777.0469 - val_loss: 18753.8848\n",
      "Epoch 8920/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.7480 - val_loss: 18741.1016\n",
      "Epoch 8921/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12728.8193 - val_loss: 18755.0430\n",
      "Epoch 8922/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.5625 - val_loss: 18774.8145\n",
      "Epoch 8923/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12829.0430 - val_loss: 18761.7793\n",
      "Epoch 8924/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12789.8906 - val_loss: 18750.6230\n",
      "Epoch 8925/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12751.5732 - val_loss: 18736.8535\n",
      "Epoch 8926/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12709.9404 - val_loss: 18701.2637\n",
      "Epoch 8927/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12603.0068 - val_loss: 18720.5078\n",
      "Epoch 8928/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12675.2871 - val_loss: 18717.0508\n",
      "Epoch 8929/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12650.8574 - val_loss: 18704.6211\n",
      "Epoch 8930/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12606.5205 - val_loss: 18727.6230\n",
      "Epoch 8931/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12751.5352 - val_loss: 18740.7871\n",
      "Epoch 8932/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12728.6318 - val_loss: 18776.1504\n",
      "Epoch 8933/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12847.1016 - val_loss: 18773.0801\n",
      "Epoch 8934/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12842.1973 - val_loss: 18727.9648\n",
      "Epoch 8935/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12694.1602 - val_loss: 18732.6445\n",
      "Epoch 8936/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12696.4717 - val_loss: 18730.4629\n",
      "Epoch 8937/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12688.0605 - val_loss: 18733.3867\n",
      "Epoch 8938/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12696.7266 - val_loss: 18748.0293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8939/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12748.6465 - val_loss: 18747.3516\n",
      "Epoch 8940/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12752.8564 - val_loss: 18751.3945\n",
      "Epoch 8941/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12766.6299 - val_loss: 18718.0859\n",
      "Epoch 8942/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.6230 - val_loss: 18689.3535\n",
      "Epoch 8943/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.2598 - val_loss: 18688.3945\n",
      "Epoch 8944/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.6309 - val_loss: 18715.3066\n",
      "Epoch 8945/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12654.7871 - val_loss: 18751.7734\n",
      "Epoch 8946/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12774.0293 - val_loss: 18777.8867\n",
      "Epoch 8947/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12854.1406 - val_loss: 18767.3984\n",
      "Epoch 8948/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12815.6885 - val_loss: 18718.9277\n",
      "Epoch 8949/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12664.3975 - val_loss: 18687.2285\n",
      "Epoch 8950/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12560.3252 - val_loss: 18704.3926\n",
      "Epoch 8951/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12606.1982 - val_loss: 18741.9531\n",
      "Epoch 8952/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12776.3916 - val_loss: 18752.7773\n",
      "Epoch 8953/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12771.3066 - val_loss: 18778.8438\n",
      "Epoch 8954/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12853.0732 - val_loss: 18805.2344\n",
      "Epoch 8955/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12943.3320 - val_loss: 18806.8301\n",
      "Epoch 8956/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12949.6787 - val_loss: 18763.3867\n",
      "Epoch 8957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12809.5947 - val_loss: 18728.0371\n",
      "Epoch 8958/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.6025 - val_loss: 18706.8223\n",
      "Epoch 8959/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12622.6582 - val_loss: 18713.8906\n",
      "Epoch 8960/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12698.9609 - val_loss: 18718.2676\n",
      "Epoch 8961/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.0664 - val_loss: 18762.0605\n",
      "Epoch 8962/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12797.4170 - val_loss: 18765.5840\n",
      "Epoch 8963/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12821.0537 - val_loss: 18762.3164\n",
      "Epoch 8964/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12807.3984 - val_loss: 18714.9570\n",
      "Epoch 8965/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.4639 - val_loss: 18682.6836\n",
      "Epoch 8966/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12542.9736 - val_loss: 18717.3184\n",
      "Epoch 8967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.7500 - val_loss: 18721.5195\n",
      "Epoch 8968/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12701.4824 - val_loss: 18714.5176\n",
      "Epoch 8969/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12650.7666 - val_loss: 18745.1348\n",
      "Epoch 8970/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12754.1523 - val_loss: 18726.0273\n",
      "Epoch 8971/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12701.9043 - val_loss: 18714.1270\n",
      "Epoch 8972/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12663.9463 - val_loss: 18706.2871\n",
      "Epoch 8973/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12621.9883 - val_loss: 18683.0234\n",
      "Epoch 8974/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.1768 - val_loss: 18688.2109\n",
      "Epoch 8975/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12544.3066 - val_loss: 18713.4824\n",
      "Epoch 8976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12626.5234 - val_loss: 18693.2324\n",
      "Epoch 8977/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12568.6328 - val_loss: 18665.2559\n",
      "Epoch 8978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12489.7744 - val_loss: 18709.1602\n",
      "Epoch 8979/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.1758 - val_loss: 18739.3457\n",
      "Epoch 8980/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12729.6055 - val_loss: 18691.1758\n",
      "Epoch 8981/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12576.8066 - val_loss: 18691.8457\n",
      "Epoch 8982/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12579.7100 - val_loss: 18698.2715\n",
      "Epoch 8983/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12582.8105 - val_loss: 18723.9277\n",
      "Epoch 8984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.8135 - val_loss: 18723.9160\n",
      "Epoch 8985/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.2451 - val_loss: 18701.7051\n",
      "Epoch 8986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12588.9688 - val_loss: 18680.5703\n",
      "Epoch 8987/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12545.3604 - val_loss: 18685.5938\n",
      "Epoch 8988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.6602 - val_loss: 18705.3848\n",
      "Epoch 8989/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12620.6055 - val_loss: 18702.1699\n",
      "Epoch 8990/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.2529 - val_loss: 18702.3223\n",
      "Epoch 8991/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.0498 - val_loss: 18715.9629\n",
      "Epoch 8992/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.7773 - val_loss: 18696.3164\n",
      "Epoch 8993/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.1328 - val_loss: 18706.3711\n",
      "Epoch 8994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12610.7480 - val_loss: 18702.0410\n",
      "Epoch 8995/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12603.8701 - val_loss: 18704.4102\n",
      "Epoch 8996/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.1602 - val_loss: 18692.6406\n",
      "Epoch 8997/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12574.7285 - val_loss: 18684.5781\n",
      "Epoch 8998/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12554.0010 - val_loss: 18687.4238\n",
      "Epoch 8999/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12554.9941 - val_loss: 18703.0566\n",
      "Epoch 9000/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12595.9717 - val_loss: 18710.2051\n",
      "Epoch 9001/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.2217 - val_loss: 18690.1973\n",
      "Epoch 9002/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12567.5049 - val_loss: 18677.1035\n",
      "Epoch 9003/10000\n",
      "630/630 [==============================] - 0s 28us/step - loss: 12532.5010 - val_loss: 18684.6367\n",
      "Epoch 9004/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.4541 - val_loss: 18663.9766\n",
      "Epoch 9005/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12482.8408 - val_loss: 18665.0566\n",
      "Epoch 9006/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12480.7061 - val_loss: 18678.5273\n",
      "Epoch 9007/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.5547 - val_loss: 18681.1426\n",
      "Epoch 9008/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12548.5371 - val_loss: 18691.6562\n",
      "Epoch 9009/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.9844 - val_loss: 18680.2891\n",
      "Epoch 9010/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12545.6260 - val_loss: 18696.1582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9011/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12585.8672 - val_loss: 18670.2383\n",
      "Epoch 9012/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12499.7227 - val_loss: 18667.3496\n",
      "Epoch 9013/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12497.2100 - val_loss: 18690.5527\n",
      "Epoch 9014/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.1104 - val_loss: 18689.7852\n",
      "Epoch 9015/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12568.4795 - val_loss: 18668.0625\n",
      "Epoch 9016/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.4102 - val_loss: 18652.4395\n",
      "Epoch 9017/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12447.6719 - val_loss: 18673.6875\n",
      "Epoch 9018/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.5439 - val_loss: 18681.6895\n",
      "Epoch 9019/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12544.4287 - val_loss: 18684.5918\n",
      "Epoch 9020/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12547.7832 - val_loss: 18676.4219\n",
      "Epoch 9021/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.8857 - val_loss: 18678.5527\n",
      "Epoch 9022/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.2910 - val_loss: 18694.3828\n",
      "Epoch 9023/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.4648 - val_loss: 18707.4297\n",
      "Epoch 9024/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12615.6299 - val_loss: 18699.6406\n",
      "Epoch 9025/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12590.3145 - val_loss: 18696.2324\n",
      "Epoch 9026/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.8438 - val_loss: 18687.3750\n",
      "Epoch 9027/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.3838 - val_loss: 18698.1465\n",
      "Epoch 9028/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12604.4121 - val_loss: 18696.1777\n",
      "Epoch 9029/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12595.7275 - val_loss: 18691.3359\n",
      "Epoch 9030/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12570.9756 - val_loss: 18719.0938\n",
      "Epoch 9031/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12670.1387 - val_loss: 18694.0078\n",
      "Epoch 9032/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12581.8271 - val_loss: 18692.5977\n",
      "Epoch 9033/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.4629 - val_loss: 18699.1230\n",
      "Epoch 9034/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12604.5498 - val_loss: 18696.1914\n",
      "Epoch 9035/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.7334 - val_loss: 18695.5059\n",
      "Epoch 9036/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12580.2197 - val_loss: 18677.0273\n",
      "Epoch 9037/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12522.0020 - val_loss: 18669.3789\n",
      "Epoch 9038/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12501.9697 - val_loss: 18664.3379\n",
      "Epoch 9039/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12485.5225 - val_loss: 18653.4746\n",
      "Epoch 9040/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12449.8916 - val_loss: 18650.3848\n",
      "Epoch 9041/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12440.1201 - val_loss: 18640.8418\n",
      "Epoch 9042/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12416.9141 - val_loss: 18653.6133\n",
      "Epoch 9043/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12446.1797 - val_loss: 18675.6172\n",
      "Epoch 9044/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.2676 - val_loss: 18666.4121\n",
      "Epoch 9045/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12491.7812 - val_loss: 18648.1230\n",
      "Epoch 9046/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12439.5762 - val_loss: 18678.8496\n",
      "Epoch 9047/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12530.7578 - val_loss: 18675.3750\n",
      "Epoch 9048/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12520.5742 - val_loss: 18659.5820\n",
      "Epoch 9049/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12457.9268 - val_loss: 18652.1523\n",
      "Epoch 9050/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12440.4355 - val_loss: 18664.3926\n",
      "Epoch 9051/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12483.1992 - val_loss: 18658.2090\n",
      "Epoch 9052/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12473.5488 - val_loss: 18650.4102\n",
      "Epoch 9053/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12443.0801 - val_loss: 18651.4570\n",
      "Epoch 9054/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12449.4199 - val_loss: 18671.6465\n",
      "Epoch 9055/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12500.7188 - val_loss: 18681.1855\n",
      "Epoch 9056/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.1064 - val_loss: 18672.1406\n",
      "Epoch 9057/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12500.0752 - val_loss: 18659.3184\n",
      "Epoch 9058/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12470.7578 - val_loss: 18675.2656\n",
      "Epoch 9059/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.2012 - val_loss: 18665.0371\n",
      "Epoch 9060/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12493.0508 - val_loss: 18653.8105\n",
      "Epoch 9061/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12449.7002 - val_loss: 18648.8789\n",
      "Epoch 9062/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12434.7090 - val_loss: 18661.0996\n",
      "Epoch 9063/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12473.2900 - val_loss: 18659.8516\n",
      "Epoch 9064/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12472.8496 - val_loss: 18635.7500\n",
      "Epoch 9065/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12396.9053 - val_loss: 18650.0430\n",
      "Epoch 9066/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12441.4072 - val_loss: 18674.6699\n",
      "Epoch 9067/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.9883 - val_loss: 18671.4883\n",
      "Epoch 9068/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12507.8262 - val_loss: 18654.3750\n",
      "Epoch 9069/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12448.4854 - val_loss: 18673.7051\n",
      "Epoch 9070/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12515.7373 - val_loss: 18668.9844\n",
      "Epoch 9071/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12505.5264 - val_loss: 18686.6250\n",
      "Epoch 9072/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.5752 - val_loss: 18671.0645\n",
      "Epoch 9073/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12504.6504 - val_loss: 18663.8379\n",
      "Epoch 9074/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12480.3350 - val_loss: 18668.1094\n",
      "Epoch 9075/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12499.6758 - val_loss: 18666.3340\n",
      "Epoch 9076/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12496.9678 - val_loss: 18685.2070\n",
      "Epoch 9077/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12559.1875 - val_loss: 18700.1641\n",
      "Epoch 9078/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12605.9160 - val_loss: 18695.2656\n",
      "Epoch 9079/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.9990 - val_loss: 18684.9258\n",
      "Epoch 9080/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12555.2764 - val_loss: 18685.5801\n",
      "Epoch 9081/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12549.0693 - val_loss: 18699.6250\n",
      "Epoch 9082/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.8057 - val_loss: 18722.1641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9083/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12670.7676 - val_loss: 18741.6445\n",
      "Epoch 9084/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12737.5107 - val_loss: 18748.0195\n",
      "Epoch 9085/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12760.4688 - val_loss: 18728.4805\n",
      "Epoch 9086/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12698.8877 - val_loss: 18700.9609\n",
      "Epoch 9087/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12608.6641 - val_loss: 18756.0801\n",
      "Epoch 9088/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12765.7061 - val_loss: 18764.4648\n",
      "Epoch 9089/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12793.7324 - val_loss: 18752.9668\n",
      "Epoch 9090/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.6016 - val_loss: 18705.4043\n",
      "Epoch 9091/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.4541 - val_loss: 18695.0273\n",
      "Epoch 9092/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12581.7949 - val_loss: 18707.9355\n",
      "Epoch 9093/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12623.8291 - val_loss: 18729.1992\n",
      "Epoch 9094/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.5078 - val_loss: 18723.4883\n",
      "Epoch 9095/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12701.0107 - val_loss: 18713.6133\n",
      "Epoch 9096/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12640.3809 - val_loss: 18698.4160\n",
      "Epoch 9097/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.2031 - val_loss: 18717.0547\n",
      "Epoch 9098/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12654.0859 - val_loss: 18722.0195\n",
      "Epoch 9099/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12664.4951 - val_loss: 18721.8105\n",
      "Epoch 9100/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12661.9434 - val_loss: 18711.1719\n",
      "Epoch 9101/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12635.6699 - val_loss: 18711.3008\n",
      "Epoch 9102/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12632.7793 - val_loss: 18700.2715\n",
      "Epoch 9103/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.8779 - val_loss: 18698.1758\n",
      "Epoch 9104/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.1084 - val_loss: 18688.0859\n",
      "Epoch 9105/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.9258 - val_loss: 18668.9609\n",
      "Epoch 9106/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12505.6240 - val_loss: 18707.8887\n",
      "Epoch 9107/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.4990 - val_loss: 18688.5273\n",
      "Epoch 9108/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12562.1396 - val_loss: 18696.7949\n",
      "Epoch 9109/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.3311 - val_loss: 18714.9102\n",
      "Epoch 9110/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.5654 - val_loss: 18696.4453\n",
      "Epoch 9111/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12592.6934 - val_loss: 18708.3496\n",
      "Epoch 9112/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12620.4746 - val_loss: 18665.5605\n",
      "Epoch 9113/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12495.1855 - val_loss: 18680.7578\n",
      "Epoch 9114/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12536.4229 - val_loss: 18692.6914\n",
      "Epoch 9115/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12583.0137 - val_loss: 18703.6543\n",
      "Epoch 9116/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.4414 - val_loss: 18682.2910\n",
      "Epoch 9117/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12538.4814 - val_loss: 18686.6914\n",
      "Epoch 9118/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.8359 - val_loss: 18679.3125\n",
      "Epoch 9119/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12524.4248 - val_loss: 18692.1602\n",
      "Epoch 9120/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12572.7705 - val_loss: 18714.1914\n",
      "Epoch 9121/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12644.6758 - val_loss: 18688.0352\n",
      "Epoch 9122/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12563.4629 - val_loss: 18680.9531\n",
      "Epoch 9123/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12544.2705 - val_loss: 18685.3496\n",
      "Epoch 9124/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.7695 - val_loss: 18710.8809\n",
      "Epoch 9125/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12626.8252 - val_loss: 18710.7832\n",
      "Epoch 9126/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.3174 - val_loss: 18702.4219\n",
      "Epoch 9127/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12609.6729 - val_loss: 18702.4922\n",
      "Epoch 9128/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12606.3516 - val_loss: 18681.5762\n",
      "Epoch 9129/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12538.9258 - val_loss: 18680.6758\n",
      "Epoch 9130/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12543.1562 - val_loss: 18690.4570\n",
      "Epoch 9131/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12564.7871 - val_loss: 18657.5488\n",
      "Epoch 9132/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12478.1338 - val_loss: 18676.1426\n",
      "Epoch 9133/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12529.1133 - val_loss: 18713.4062\n",
      "Epoch 9134/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12639.7031 - val_loss: 18696.5000\n",
      "Epoch 9135/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.9248 - val_loss: 18703.1230\n",
      "Epoch 9136/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.3857 - val_loss: 18682.3340\n",
      "Epoch 9137/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12549.4785 - val_loss: 18702.4453\n",
      "Epoch 9138/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12616.6973 - val_loss: 18720.6660\n",
      "Epoch 9139/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12665.5938 - val_loss: 18712.4316\n",
      "Epoch 9140/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.9053 - val_loss: 18690.1934\n",
      "Epoch 9141/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12560.8213 - val_loss: 18693.7168\n",
      "Epoch 9142/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12575.5830 - val_loss: 18697.4785\n",
      "Epoch 9143/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12589.7812 - val_loss: 18693.5117\n",
      "Epoch 9144/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12574.4434 - val_loss: 18692.8848\n",
      "Epoch 9145/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12572.2861 - val_loss: 18699.1641\n",
      "Epoch 9146/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12595.2773 - val_loss: 18713.3496\n",
      "Epoch 9147/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12640.5215 - val_loss: 18699.4570\n",
      "Epoch 9148/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.7109 - val_loss: 18671.1016\n",
      "Epoch 9149/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12503.1572 - val_loss: 18656.8125\n",
      "Epoch 9150/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12464.2002 - val_loss: 18680.3965\n",
      "Epoch 9151/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.5000 - val_loss: 18670.3594\n",
      "Epoch 9152/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12506.9502 - val_loss: 18688.7637\n",
      "Epoch 9153/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12562.4062 - val_loss: 18693.6230\n",
      "Epoch 9154/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12580.6396 - val_loss: 18667.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9155/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12505.2979 - val_loss: 18676.7637\n",
      "Epoch 9156/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.8027 - val_loss: 18688.7676\n",
      "Epoch 9157/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12560.1445 - val_loss: 18683.5977\n",
      "Epoch 9158/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12589.6670 - val_loss: 18699.6895\n",
      "Epoch 9159/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.8691 - val_loss: 18740.5371\n",
      "Epoch 9160/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.3818 - val_loss: 18752.6934\n",
      "Epoch 9161/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12768.0127 - val_loss: 18759.5938\n",
      "Epoch 9162/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12792.5127 - val_loss: 18752.3184\n",
      "Epoch 9163/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12769.1025 - val_loss: 18729.9258\n",
      "Epoch 9164/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12690.8193 - val_loss: 18720.5195\n",
      "Epoch 9165/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12652.8203 - val_loss: 18727.2402\n",
      "Epoch 9166/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12680.3184 - val_loss: 18717.6641\n",
      "Epoch 9167/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12656.0029 - val_loss: 18708.1074\n",
      "Epoch 9168/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12622.1514 - val_loss: 18718.3125\n",
      "Epoch 9169/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12646.3252 - val_loss: 18703.5078\n",
      "Epoch 9170/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.1113 - val_loss: 18713.9570\n",
      "Epoch 9171/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.9072 - val_loss: 18716.0293\n",
      "Epoch 9172/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.1660 - val_loss: 18720.3555\n",
      "Epoch 9173/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.3379 - val_loss: 18722.0215\n",
      "Epoch 9174/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.2754 - val_loss: 18698.6797\n",
      "Epoch 9175/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12599.0947 - val_loss: 18677.0039\n",
      "Epoch 9176/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12527.4717 - val_loss: 18693.3164\n",
      "Epoch 9177/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12574.9746 - val_loss: 18697.1621\n",
      "Epoch 9178/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12589.3799 - val_loss: 18695.8555\n",
      "Epoch 9179/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.3281 - val_loss: 18673.8809\n",
      "Epoch 9180/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12519.6133 - val_loss: 18653.3184\n",
      "Epoch 9181/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12445.0479 - val_loss: 18680.7461\n",
      "Epoch 9182/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.9570 - val_loss: 18704.8477\n",
      "Epoch 9183/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12616.8281 - val_loss: 18691.3145\n",
      "Epoch 9184/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.7627 - val_loss: 18649.4473\n",
      "Epoch 9185/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12444.1914 - val_loss: 18653.0098\n",
      "Epoch 9186/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12449.6221 - val_loss: 18671.3438\n",
      "Epoch 9187/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12511.2021 - val_loss: 18672.7168\n",
      "Epoch 9188/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12509.1582 - val_loss: 18661.5762\n",
      "Epoch 9189/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12467.3467 - val_loss: 18648.4219\n",
      "Epoch 9190/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12446.5361 - val_loss: 18659.9492\n",
      "Epoch 9191/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12482.3828 - val_loss: 18681.0762\n",
      "Epoch 9192/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.7002 - val_loss: 18666.2246\n",
      "Epoch 9193/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12488.1953 - val_loss: 18666.2422\n",
      "Epoch 9194/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12497.3232 - val_loss: 18668.3672\n",
      "Epoch 9195/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.8789 - val_loss: 18687.1289\n",
      "Epoch 9196/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.7695 - val_loss: 18679.4922\n",
      "Epoch 9197/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12540.0361 - val_loss: 18705.6641\n",
      "Epoch 9198/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12625.7998 - val_loss: 18718.8613\n",
      "Epoch 9199/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12662.3193 - val_loss: 18712.9238\n",
      "Epoch 9200/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.3652 - val_loss: 18679.5664\n",
      "Epoch 9201/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.4277 - val_loss: 18686.4434\n",
      "Epoch 9202/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12556.3174 - val_loss: 18693.6738\n",
      "Epoch 9203/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.6963 - val_loss: 18689.2754\n",
      "Epoch 9204/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12563.1650 - val_loss: 18704.8809\n",
      "Epoch 9205/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12614.3447 - val_loss: 18683.3574\n",
      "Epoch 9206/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.9668 - val_loss: 18657.9258\n",
      "Epoch 9207/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12463.3740 - val_loss: 18680.7363\n",
      "Epoch 9208/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12536.6240 - val_loss: 18673.6074\n",
      "Epoch 9209/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12517.8350 - val_loss: 18667.2676\n",
      "Epoch 9210/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12505.5068 - val_loss: 18654.4531\n",
      "Epoch 9211/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12456.2988 - val_loss: 18651.0195\n",
      "Epoch 9212/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12476.5361 - val_loss: 18663.9336\n",
      "Epoch 9213/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12494.5137 - val_loss: 18706.1211\n",
      "Epoch 9214/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12626.1631 - val_loss: 18696.2988\n",
      "Epoch 9215/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12597.2598 - val_loss: 18672.8711\n",
      "Epoch 9216/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.2490 - val_loss: 18694.1699\n",
      "Epoch 9217/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12574.2812 - val_loss: 18711.7559\n",
      "Epoch 9218/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12632.1582 - val_loss: 18687.9707\n",
      "Epoch 9219/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12562.4736 - val_loss: 18675.8887\n",
      "Epoch 9220/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.2832 - val_loss: 18667.9512\n",
      "Epoch 9221/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12502.2812 - val_loss: 18673.3008\n",
      "Epoch 9222/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.1494 - val_loss: 18706.0938\n",
      "Epoch 9223/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12610.1025 - val_loss: 18687.6211\n",
      "Epoch 9224/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12558.3604 - val_loss: 18669.9316\n",
      "Epoch 9225/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.8330 - val_loss: 18648.6602\n",
      "Epoch 9226/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12435.9785 - val_loss: 18655.5742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9227/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12456.1016 - val_loss: 18652.7461\n",
      "Epoch 9228/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12451.6807 - val_loss: 18674.3535\n",
      "Epoch 9229/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12516.6436 - val_loss: 18678.5977\n",
      "Epoch 9230/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.7197 - val_loss: 18675.7832\n",
      "Epoch 9231/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12517.6875 - val_loss: 18659.3438\n",
      "Epoch 9232/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12463.6035 - val_loss: 18654.5000\n",
      "Epoch 9233/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12462.1895 - val_loss: 18671.5234\n",
      "Epoch 9234/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.2646 - val_loss: 18680.6992\n",
      "Epoch 9235/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12542.3701 - val_loss: 18685.5117\n",
      "Epoch 9236/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12549.3096 - val_loss: 18680.0586\n",
      "Epoch 9237/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.9375 - val_loss: 18675.0117\n",
      "Epoch 9238/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12517.5674 - val_loss: 18684.1680\n",
      "Epoch 9239/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12545.8291 - val_loss: 18692.9160\n",
      "Epoch 9240/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12573.7686 - val_loss: 18683.0547\n",
      "Epoch 9241/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.0859 - val_loss: 18676.3281\n",
      "Epoch 9242/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12514.7441 - val_loss: 18673.7715\n",
      "Epoch 9243/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12512.7734 - val_loss: 18672.4785\n",
      "Epoch 9244/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12515.4482 - val_loss: 18685.9336\n",
      "Epoch 9245/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12555.9697 - val_loss: 18685.2754\n",
      "Epoch 9246/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.7979 - val_loss: 18686.3379\n",
      "Epoch 9247/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12556.7266 - val_loss: 18688.0879\n",
      "Epoch 9248/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.1445 - val_loss: 18684.4062\n",
      "Epoch 9249/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.8789 - val_loss: 18678.6172\n",
      "Epoch 9250/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.7109 - val_loss: 18669.1973\n",
      "Epoch 9251/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12495.6475 - val_loss: 18661.7266\n",
      "Epoch 9252/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12475.8652 - val_loss: 18678.1895\n",
      "Epoch 9253/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12530.6211 - val_loss: 18671.2109\n",
      "Epoch 9254/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.0088 - val_loss: 18682.8809\n",
      "Epoch 9255/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12545.5078 - val_loss: 18672.5469\n",
      "Epoch 9256/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12518.4111 - val_loss: 18661.6445\n",
      "Epoch 9257/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12477.5215 - val_loss: 18656.3926\n",
      "Epoch 9258/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12505.1914 - val_loss: 18681.9121\n",
      "Epoch 9259/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12545.4521 - val_loss: 18708.8066\n",
      "Epoch 9260/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12633.9033 - val_loss: 18711.0586\n",
      "Epoch 9261/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.3389 - val_loss: 18715.6094\n",
      "Epoch 9262/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12648.0527 - val_loss: 18723.1680\n",
      "Epoch 9263/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12672.6904 - val_loss: 18685.5957\n",
      "Epoch 9264/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.0713 - val_loss: 18685.2051\n",
      "Epoch 9265/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.6885 - val_loss: 18692.3809\n",
      "Epoch 9266/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12575.5859 - val_loss: 18672.2402\n",
      "Epoch 9267/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12510.2090 - val_loss: 18668.5527\n",
      "Epoch 9268/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12500.2324 - val_loss: 18668.0215\n",
      "Epoch 9269/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12498.1104 - val_loss: 18661.5645\n",
      "Epoch 9270/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12487.1768 - val_loss: 18680.5332\n",
      "Epoch 9271/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12530.7500 - val_loss: 18680.4980\n",
      "Epoch 9272/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12532.3789 - val_loss: 18659.5488\n",
      "Epoch 9273/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12468.3711 - val_loss: 18676.5977\n",
      "Epoch 9274/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12526.6191 - val_loss: 18691.7695\n",
      "Epoch 9275/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12576.3564 - val_loss: 18699.2773\n",
      "Epoch 9276/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12599.3379 - val_loss: 18676.2695\n",
      "Epoch 9277/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.9102 - val_loss: 18689.7637\n",
      "Epoch 9278/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12572.2607 - val_loss: 18678.6523\n",
      "Epoch 9279/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12532.3916 - val_loss: 18732.4062\n",
      "Epoch 9280/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12699.2744 - val_loss: 18726.4316\n",
      "Epoch 9281/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12683.8125 - val_loss: 18693.5117\n",
      "Epoch 9282/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12586.2676 - val_loss: 18676.1914\n",
      "Epoch 9283/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.0176 - val_loss: 18696.1523\n",
      "Epoch 9284/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12640.0879 - val_loss: 18726.3926\n",
      "Epoch 9285/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12690.0938 - val_loss: 18766.3574\n",
      "Epoch 9286/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12811.6289 - val_loss: 18769.5430\n",
      "Epoch 9287/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12824.0518 - val_loss: 18740.0254\n",
      "Epoch 9288/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12731.6338 - val_loss: 18711.4277\n",
      "Epoch 9289/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12642.8604 - val_loss: 18727.3438\n",
      "Epoch 9290/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12677.0801 - val_loss: 18746.1816\n",
      "Epoch 9291/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12741.6602 - val_loss: 18731.6758\n",
      "Epoch 9292/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12697.6846 - val_loss: 18712.3340\n",
      "Epoch 9293/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.7119 - val_loss: 18699.3281\n",
      "Epoch 9294/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.2715 - val_loss: 18711.3262\n",
      "Epoch 9295/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.1289 - val_loss: 18733.4082\n",
      "Epoch 9296/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12704.7598 - val_loss: 18698.5898\n",
      "Epoch 9297/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12597.4697 - val_loss: 18742.7656\n",
      "Epoch 9298/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12838.3604 - val_loss: 18703.2793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9299/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.3799 - val_loss: 18710.1602\n",
      "Epoch 9300/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.1660 - val_loss: 18727.5508\n",
      "Epoch 9301/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12690.9756 - val_loss: 18751.3281\n",
      "Epoch 9302/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12755.1348 - val_loss: 18736.4160\n",
      "Epoch 9303/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12711.3125 - val_loss: 18742.4160\n",
      "Epoch 9304/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12740.2959 - val_loss: 18722.7266\n",
      "Epoch 9305/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12672.2686 - val_loss: 18706.6797\n",
      "Epoch 9306/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.8887 - val_loss: 18725.8906\n",
      "Epoch 9307/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12675.6338 - val_loss: 18715.0762\n",
      "Epoch 9308/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12652.4111 - val_loss: 18697.5605\n",
      "Epoch 9309/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12594.8711 - val_loss: 18679.3887\n",
      "Epoch 9310/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12539.5527 - val_loss: 18668.5977\n",
      "Epoch 9311/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12505.3848 - val_loss: 18682.1230\n",
      "Epoch 9312/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12538.6270 - val_loss: 18717.5938\n",
      "Epoch 9313/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12758.4688 - val_loss: 18683.9434\n",
      "Epoch 9314/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12556.7686 - val_loss: 18759.6387\n",
      "Epoch 9315/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12792.3604 - val_loss: 18791.2363\n",
      "Epoch 9316/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12891.9365 - val_loss: 18776.4980\n",
      "Epoch 9317/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12854.3809 - val_loss: 18721.1777\n",
      "Epoch 9318/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12679.0020 - val_loss: 18710.6777\n",
      "Epoch 9319/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12633.3975 - val_loss: 18719.5684\n",
      "Epoch 9320/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12654.9160 - val_loss: 18761.0566\n",
      "Epoch 9321/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12866.6729 - val_loss: 18716.7598\n",
      "Epoch 9322/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12648.2588 - val_loss: 18717.1855\n",
      "Epoch 9323/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.3037 - val_loss: 18748.7266\n",
      "Epoch 9324/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12762.6562 - val_loss: 18786.8770\n",
      "Epoch 9325/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12879.2666 - val_loss: 18782.7207\n",
      "Epoch 9326/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12867.5000 - val_loss: 18742.9219\n",
      "Epoch 9327/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12739.2646 - val_loss: 18702.0254\n",
      "Epoch 9328/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12608.0088 - val_loss: 18679.9434\n",
      "Epoch 9329/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.0645 - val_loss: 18701.7637\n",
      "Epoch 9330/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12696.3936 - val_loss: 18726.3672\n",
      "Epoch 9331/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12680.2051 - val_loss: 18738.8242\n",
      "Epoch 9332/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12726.7686 - val_loss: 18713.9141\n",
      "Epoch 9333/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12643.5049 - val_loss: 18691.2109\n",
      "Epoch 9334/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12573.5264 - val_loss: 18711.4258\n",
      "Epoch 9335/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12634.7139 - val_loss: 18710.9590\n",
      "Epoch 9336/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.7998 - val_loss: 18709.6875\n",
      "Epoch 9337/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12646.8242 - val_loss: 18679.1777\n",
      "Epoch 9338/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12541.7900 - val_loss: 18677.9102\n",
      "Epoch 9339/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12525.0674 - val_loss: 18718.2070\n",
      "Epoch 9340/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.5947 - val_loss: 18726.1035\n",
      "Epoch 9341/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.5527 - val_loss: 18718.5684\n",
      "Epoch 9342/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12667.5039 - val_loss: 18723.1055\n",
      "Epoch 9343/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12679.5938 - val_loss: 18713.8398\n",
      "Epoch 9344/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.6191 - val_loss: 18702.9180\n",
      "Epoch 9345/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.1738 - val_loss: 18672.1836\n",
      "Epoch 9346/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12508.1787 - val_loss: 18694.3301\n",
      "Epoch 9347/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.9316 - val_loss: 18710.0918\n",
      "Epoch 9348/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12632.0420 - val_loss: 18740.5215\n",
      "Epoch 9349/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12735.1387 - val_loss: 18717.1406\n",
      "Epoch 9350/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.6494 - val_loss: 18683.9902\n",
      "Epoch 9351/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.3301 - val_loss: 18668.9219\n",
      "Epoch 9352/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12503.8936 - val_loss: 18732.2129\n",
      "Epoch 9353/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12768.6426 - val_loss: 18717.1914\n",
      "Epoch 9354/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.9209 - val_loss: 18710.4141\n",
      "Epoch 9355/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.6455 - val_loss: 18688.3184\n",
      "Epoch 9356/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12576.9248 - val_loss: 18707.3594\n",
      "Epoch 9357/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.3262 - val_loss: 18728.0547\n",
      "Epoch 9358/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12678.9502 - val_loss: 18699.8672\n",
      "Epoch 9359/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.6445 - val_loss: 18686.8164\n",
      "Epoch 9360/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.6318 - val_loss: 18715.6523\n",
      "Epoch 9361/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12643.0566 - val_loss: 18719.3848\n",
      "Epoch 9362/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12671.4326 - val_loss: 18690.5469\n",
      "Epoch 9363/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12567.2656 - val_loss: 18695.4062\n",
      "Epoch 9364/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.4355 - val_loss: 18701.8574\n",
      "Epoch 9365/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12610.2969 - val_loss: 18703.1836\n",
      "Epoch 9366/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12611.1123 - val_loss: 18680.3965\n",
      "Epoch 9367/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12543.1445 - val_loss: 18666.2070\n",
      "Epoch 9368/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12494.2520 - val_loss: 18688.3398\n",
      "Epoch 9369/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12572.8994 - val_loss: 18692.0078\n",
      "Epoch 9370/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12576.8213 - val_loss: 18711.8809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9371/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12638.2344 - val_loss: 18719.4609\n",
      "Epoch 9372/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.9541 - val_loss: 18704.3398\n",
      "Epoch 9373/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.3975 - val_loss: 18682.3320\n",
      "Epoch 9374/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12543.6074 - val_loss: 18693.4395\n",
      "Epoch 9375/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.9648 - val_loss: 18679.6465\n",
      "Epoch 9376/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12542.0391 - val_loss: 18672.9102\n",
      "Epoch 9377/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.6133 - val_loss: 18665.3340\n",
      "Epoch 9378/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12491.1162 - val_loss: 18689.0645\n",
      "Epoch 9379/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.9365 - val_loss: 18680.0039\n",
      "Epoch 9380/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12530.3955 - val_loss: 18686.8027\n",
      "Epoch 9381/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12562.0107 - val_loss: 18685.7793\n",
      "Epoch 9382/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12549.8213 - val_loss: 18666.7676\n",
      "Epoch 9383/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12500.4961 - val_loss: 18667.0586\n",
      "Epoch 9384/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12500.2520 - val_loss: 18703.5742\n",
      "Epoch 9385/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12616.6719 - val_loss: 18703.5859\n",
      "Epoch 9386/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12615.5146 - val_loss: 18676.6328\n",
      "Epoch 9387/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12538.2627 - val_loss: 18673.9727\n",
      "Epoch 9388/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12525.6670 - val_loss: 18684.8555\n",
      "Epoch 9389/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.6211 - val_loss: 18683.9160\n",
      "Epoch 9390/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12540.7627 - val_loss: 18662.4219\n",
      "Epoch 9391/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12480.1240 - val_loss: 18659.7793\n",
      "Epoch 9392/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12466.5352 - val_loss: 18681.1680\n",
      "Epoch 9393/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12538.4453 - val_loss: 18690.6465\n",
      "Epoch 9394/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.5615 - val_loss: 18687.2070\n",
      "Epoch 9395/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.0410 - val_loss: 18674.1445\n",
      "Epoch 9396/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12527.8291 - val_loss: 18674.8320\n",
      "Epoch 9397/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12523.1953 - val_loss: 18683.2930\n",
      "Epoch 9398/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12543.4131 - val_loss: 18686.6289\n",
      "Epoch 9399/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.0576 - val_loss: 18699.0957\n",
      "Epoch 9400/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12597.5547 - val_loss: 18697.0410\n",
      "Epoch 9401/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12589.4775 - val_loss: 18692.0508\n",
      "Epoch 9402/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12582.2217 - val_loss: 18664.3594\n",
      "Epoch 9403/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12487.7119 - val_loss: 18667.4609\n",
      "Epoch 9404/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.1143 - val_loss: 18666.2090\n",
      "Epoch 9405/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12497.7480 - val_loss: 18669.8438\n",
      "Epoch 9406/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12509.2109 - val_loss: 18663.3105\n",
      "Epoch 9407/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12489.3564 - val_loss: 18671.1230\n",
      "Epoch 9408/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12515.1484 - val_loss: 18697.9004\n",
      "Epoch 9409/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.1533 - val_loss: 18684.1641\n",
      "Epoch 9410/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12544.8164 - val_loss: 18680.0645\n",
      "Epoch 9411/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12539.4619 - val_loss: 18678.2051\n",
      "Epoch 9412/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.8115 - val_loss: 18679.6934\n",
      "Epoch 9413/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12528.0586 - val_loss: 18672.2051\n",
      "Epoch 9414/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12504.8604 - val_loss: 18671.2773\n",
      "Epoch 9415/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12511.0586 - val_loss: 18683.0586\n",
      "Epoch 9416/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.1074 - val_loss: 18684.9668\n",
      "Epoch 9417/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12562.7217 - val_loss: 18692.7988\n",
      "Epoch 9418/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.0293 - val_loss: 18692.4199\n",
      "Epoch 9419/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.8418 - val_loss: 18701.2363\n",
      "Epoch 9420/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12600.5537 - val_loss: 18683.0977\n",
      "Epoch 9421/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12544.9629 - val_loss: 18667.0293\n",
      "Epoch 9422/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12496.0449 - val_loss: 18675.7227\n",
      "Epoch 9423/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.7285 - val_loss: 18683.9863\n",
      "Epoch 9424/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12544.6523 - val_loss: 18679.0332\n",
      "Epoch 9425/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12528.6836 - val_loss: 18677.4004\n",
      "Epoch 9426/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.6699 - val_loss: 18657.9297\n",
      "Epoch 9427/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12473.3584 - val_loss: 18669.1934\n",
      "Epoch 9428/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12509.7070 - val_loss: 18683.2031\n",
      "Epoch 9429/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12558.6367 - val_loss: 18675.4395\n",
      "Epoch 9430/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.0879 - val_loss: 18687.8965\n",
      "Epoch 9431/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12565.1064 - val_loss: 18682.3691\n",
      "Epoch 9432/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12542.1904 - val_loss: 18678.3477\n",
      "Epoch 9433/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12531.6484 - val_loss: 18687.1875\n",
      "Epoch 9434/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12567.2842 - val_loss: 18661.9219\n",
      "Epoch 9435/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12487.1279 - val_loss: 18652.9766\n",
      "Epoch 9436/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12455.9219 - val_loss: 18682.3652\n",
      "Epoch 9437/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12542.5967 - val_loss: 18701.6465\n",
      "Epoch 9438/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12596.8145 - val_loss: 18687.0664\n",
      "Epoch 9439/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12563.8496 - val_loss: 18671.2539\n",
      "Epoch 9440/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12498.5400 - val_loss: 18661.1309\n",
      "Epoch 9441/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12474.2559 - val_loss: 18668.3906\n",
      "Epoch 9442/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12494.5391 - val_loss: 18680.8594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9443/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.1924 - val_loss: 18651.5996\n",
      "Epoch 9444/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12451.4346 - val_loss: 18665.8242\n",
      "Epoch 9445/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12497.6055 - val_loss: 18657.1992\n",
      "Epoch 9446/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12466.0225 - val_loss: 18667.7910\n",
      "Epoch 9447/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12493.8213 - val_loss: 18652.9453\n",
      "Epoch 9448/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12440.0801 - val_loss: 18654.5859\n",
      "Epoch 9449/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12440.6367 - val_loss: 18649.0371\n",
      "Epoch 9450/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12431.0146 - val_loss: 18659.3496\n",
      "Epoch 9451/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12472.3779 - val_loss: 18670.3906\n",
      "Epoch 9452/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.8701 - val_loss: 18661.9336\n",
      "Epoch 9453/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12480.3115 - val_loss: 18650.0586\n",
      "Epoch 9454/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12441.5537 - val_loss: 18701.8164\n",
      "Epoch 9455/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.1543 - val_loss: 18695.1738\n",
      "Epoch 9456/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12579.3174 - val_loss: 18696.8398\n",
      "Epoch 9457/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.0518 - val_loss: 18697.2793\n",
      "Epoch 9458/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12582.4961 - val_loss: 18677.2207\n",
      "Epoch 9459/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12520.7734 - val_loss: 18676.8105\n",
      "Epoch 9460/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.5049 - val_loss: 18685.7891\n",
      "Epoch 9461/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12550.7598 - val_loss: 18680.3027\n",
      "Epoch 9462/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12534.1904 - val_loss: 18659.4766\n",
      "Epoch 9463/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12473.7959 - val_loss: 18677.7852\n",
      "Epoch 9464/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.1475 - val_loss: 18691.1074\n",
      "Epoch 9465/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12571.5762 - val_loss: 18698.2480\n",
      "Epoch 9466/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.2139 - val_loss: 18704.2656\n",
      "Epoch 9467/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.0654 - val_loss: 18669.1230\n",
      "Epoch 9468/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12502.9482 - val_loss: 18683.6328\n",
      "Epoch 9469/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12550.4824 - val_loss: 18700.0000\n",
      "Epoch 9470/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.1328 - val_loss: 18693.5215\n",
      "Epoch 9471/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12582.0020 - val_loss: 18666.0391\n",
      "Epoch 9472/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12493.4619 - val_loss: 18678.4219\n",
      "Epoch 9473/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.1299 - val_loss: 18688.2676\n",
      "Epoch 9474/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.6826 - val_loss: 18718.9277\n",
      "Epoch 9475/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.0039 - val_loss: 18717.8984\n",
      "Epoch 9476/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.5488 - val_loss: 18681.2070\n",
      "Epoch 9477/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12539.4854 - val_loss: 18682.4766\n",
      "Epoch 9478/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12549.9209 - val_loss: 18705.7285\n",
      "Epoch 9479/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12623.4580 - val_loss: 18711.9297\n",
      "Epoch 9480/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12638.7227 - val_loss: 18727.0957\n",
      "Epoch 9481/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12682.6650 - val_loss: 18721.7734\n",
      "Epoch 9482/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12653.9062 - val_loss: 18687.5020\n",
      "Epoch 9483/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.7607 - val_loss: 18672.5898\n",
      "Epoch 9484/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12510.1025 - val_loss: 18700.1055\n",
      "Epoch 9485/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12606.2568 - val_loss: 18693.0918\n",
      "Epoch 9486/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12581.1523 - val_loss: 18694.7363\n",
      "Epoch 9487/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.9189 - val_loss: 18704.7227\n",
      "Epoch 9488/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12612.3516 - val_loss: 18708.6543\n",
      "Epoch 9489/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12632.5361 - val_loss: 18664.9668\n",
      "Epoch 9490/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12495.2734 - val_loss: 18694.4395\n",
      "Epoch 9491/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.2979 - val_loss: 18681.2227\n",
      "Epoch 9492/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12539.8555 - val_loss: 18684.0723\n",
      "Epoch 9493/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12545.6143 - val_loss: 18673.4512\n",
      "Epoch 9494/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.0557 - val_loss: 18689.7480\n",
      "Epoch 9495/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12561.8271 - val_loss: 18697.9746\n",
      "Epoch 9496/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.2715 - val_loss: 18683.6797\n",
      "Epoch 9497/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12548.1807 - val_loss: 18665.9492\n",
      "Epoch 9498/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12492.2695 - val_loss: 18670.1152\n",
      "Epoch 9499/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12507.3477 - val_loss: 18673.2480\n",
      "Epoch 9500/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12514.9072 - val_loss: 18679.6074\n",
      "Epoch 9501/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12531.3721 - val_loss: 18654.1660\n",
      "Epoch 9502/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12446.3701 - val_loss: 18666.1250\n",
      "Epoch 9503/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12482.4053 - val_loss: 18673.5508\n",
      "Epoch 9504/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12513.1240 - val_loss: 18666.1055\n",
      "Epoch 9505/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12496.6416 - val_loss: 18640.5938\n",
      "Epoch 9506/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12411.1748 - val_loss: 18669.5293\n",
      "Epoch 9507/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12502.0156 - val_loss: 18692.3906\n",
      "Epoch 9508/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12572.7529 - val_loss: 18686.0293\n",
      "Epoch 9509/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12553.6104 - val_loss: 18669.5996\n",
      "Epoch 9510/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12493.0752 - val_loss: 18688.2168\n",
      "Epoch 9511/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.9189 - val_loss: 18696.5430\n",
      "Epoch 9512/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12583.9990 - val_loss: 18693.1250\n",
      "Epoch 9513/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12581.6533 - val_loss: 18677.6699\n",
      "Epoch 9514/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12535.0908 - val_loss: 18689.0664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9515/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12562.6055 - val_loss: 18703.8027\n",
      "Epoch 9516/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12619.8623 - val_loss: 18700.4551\n",
      "Epoch 9517/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12603.0713 - val_loss: 18662.0781\n",
      "Epoch 9518/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12480.1826 - val_loss: 18692.6641\n",
      "Epoch 9519/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12575.5225 - val_loss: 18725.2129\n",
      "Epoch 9520/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12677.2412 - val_loss: 18732.6543\n",
      "Epoch 9521/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12693.2842 - val_loss: 18704.1426\n",
      "Epoch 9522/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12607.2383 - val_loss: 18665.4785\n",
      "Epoch 9523/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12489.3789 - val_loss: 18686.6367\n",
      "Epoch 9524/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12571.6289 - val_loss: 18692.2070\n",
      "Epoch 9525/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12573.3721 - val_loss: 18688.8438\n",
      "Epoch 9526/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.0156 - val_loss: 18685.1152\n",
      "Epoch 9527/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.9053 - val_loss: 18683.9922\n",
      "Epoch 9528/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12549.0352 - val_loss: 18719.8496\n",
      "Epoch 9529/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.2197 - val_loss: 18702.7324\n",
      "Epoch 9530/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12608.6846 - val_loss: 18689.6367\n",
      "Epoch 9531/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12567.9990 - val_loss: 18680.9082\n",
      "Epoch 9532/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12543.2031 - val_loss: 18696.6504\n",
      "Epoch 9533/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12584.8604 - val_loss: 18682.4492\n",
      "Epoch 9534/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.4355 - val_loss: 18703.3906\n",
      "Epoch 9535/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.1562 - val_loss: 18715.1992\n",
      "Epoch 9536/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12647.3047 - val_loss: 18708.2520\n",
      "Epoch 9537/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12630.0605 - val_loss: 18702.9863\n",
      "Epoch 9538/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.3350 - val_loss: 18718.5879\n",
      "Epoch 9539/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12653.8984 - val_loss: 18727.7930\n",
      "Epoch 9540/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12683.2783 - val_loss: 18676.8145\n",
      "Epoch 9541/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.9277 - val_loss: 18703.1660\n",
      "Epoch 9542/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12609.3174 - val_loss: 18733.4492\n",
      "Epoch 9543/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12698.6543 - val_loss: 18737.2930\n",
      "Epoch 9544/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12708.1162 - val_loss: 18704.9727\n",
      "Epoch 9545/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.0762 - val_loss: 18670.5469\n",
      "Epoch 9546/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12500.9434 - val_loss: 18713.6230\n",
      "Epoch 9547/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.9600 - val_loss: 18729.6152\n",
      "Epoch 9548/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12692.1289 - val_loss: 18690.9219\n",
      "Epoch 9549/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12572.7764 - val_loss: 18662.9473\n",
      "Epoch 9550/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12483.6338 - val_loss: 18692.1348\n",
      "Epoch 9551/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12576.1729 - val_loss: 18697.9434\n",
      "Epoch 9552/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.9609 - val_loss: 18701.5840\n",
      "Epoch 9553/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12607.6885 - val_loss: 18690.4980\n",
      "Epoch 9554/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12572.6221 - val_loss: 18682.4258\n",
      "Epoch 9555/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12546.8916 - val_loss: 18686.6875\n",
      "Epoch 9556/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12553.4531 - val_loss: 18674.0703\n",
      "Epoch 9557/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12515.2012 - val_loss: 18667.5742\n",
      "Epoch 9558/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12495.8438 - val_loss: 18676.1309\n",
      "Epoch 9559/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12610.6094 - val_loss: 18688.2324\n",
      "Epoch 9560/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12565.6230 - val_loss: 18680.6953\n",
      "Epoch 9561/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12537.1299 - val_loss: 18685.6504\n",
      "Epoch 9562/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.9902 - val_loss: 18702.3086\n",
      "Epoch 9563/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12613.9443 - val_loss: 18711.5898\n",
      "Epoch 9564/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12636.9609 - val_loss: 18688.5195\n",
      "Epoch 9565/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12560.8730 - val_loss: 18661.1289\n",
      "Epoch 9566/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12476.8887 - val_loss: 18674.5254\n",
      "Epoch 9567/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12522.5117 - val_loss: 18676.8516\n",
      "Epoch 9568/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12516.9893 - val_loss: 18676.5078\n",
      "Epoch 9569/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.9717 - val_loss: 18692.0879\n",
      "Epoch 9570/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12572.1162 - val_loss: 18683.4941\n",
      "Epoch 9571/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12543.1113 - val_loss: 18691.8203\n",
      "Epoch 9572/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12564.7314 - val_loss: 18670.4023\n",
      "Epoch 9573/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.3877 - val_loss: 18660.2266\n",
      "Epoch 9574/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12479.2383 - val_loss: 18663.5840\n",
      "Epoch 9575/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.1914 - val_loss: 18663.4844\n",
      "Epoch 9576/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.9531 - val_loss: 18654.3633\n",
      "Epoch 9577/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12459.8623 - val_loss: 18669.1152\n",
      "Epoch 9578/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12505.6357 - val_loss: 18666.7422\n",
      "Epoch 9579/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12489.6152 - val_loss: 18639.5234\n",
      "Epoch 9580/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12399.4395 - val_loss: 18652.1797\n",
      "Epoch 9581/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12445.7900 - val_loss: 18664.2031\n",
      "Epoch 9582/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12493.2256 - val_loss: 18666.5078\n",
      "Epoch 9583/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.3955 - val_loss: 18650.8496\n",
      "Epoch 9584/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12440.5928 - val_loss: 18660.2227\n",
      "Epoch 9585/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12463.8398 - val_loss: 18677.9922\n",
      "Epoch 9586/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.9385 - val_loss: 18684.0625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9587/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.4883 - val_loss: 18665.0801\n",
      "Epoch 9588/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12491.2754 - val_loss: 18645.0039\n",
      "Epoch 9589/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12427.1025 - val_loss: 18655.4629\n",
      "Epoch 9590/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12455.3818 - val_loss: 18659.5332\n",
      "Epoch 9591/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12466.4688 - val_loss: 18665.9883\n",
      "Epoch 9592/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12490.5986 - val_loss: 18658.8008\n",
      "Epoch 9593/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12461.3047 - val_loss: 18662.5195\n",
      "Epoch 9594/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12482.1963 - val_loss: 18670.5840\n",
      "Epoch 9595/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12502.0645 - val_loss: 18669.1055\n",
      "Epoch 9596/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12502.3135 - val_loss: 18634.3613\n",
      "Epoch 9597/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12389.7324 - val_loss: 18647.2285\n",
      "Epoch 9598/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12430.1367 - val_loss: 18644.8477\n",
      "Epoch 9599/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12427.7314 - val_loss: 18643.6699\n",
      "Epoch 9600/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12424.4365 - val_loss: 18643.9922\n",
      "Epoch 9601/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12420.1455 - val_loss: 18666.4199\n",
      "Epoch 9602/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12492.6055 - val_loss: 18663.2598\n",
      "Epoch 9603/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12484.9766 - val_loss: 18664.9844\n",
      "Epoch 9604/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12492.3779 - val_loss: 18671.9766\n",
      "Epoch 9605/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12502.4844 - val_loss: 18663.5918\n",
      "Epoch 9606/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12477.9717 - val_loss: 18652.6660\n",
      "Epoch 9607/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12443.1279 - val_loss: 18672.6992\n",
      "Epoch 9608/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12513.7666 - val_loss: 18697.1484\n",
      "Epoch 9609/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12593.8916 - val_loss: 18676.6816\n",
      "Epoch 9610/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12528.0117 - val_loss: 18667.2188\n",
      "Epoch 9611/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12502.5020 - val_loss: 18671.9160\n",
      "Epoch 9612/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12508.5420 - val_loss: 18697.9238\n",
      "Epoch 9613/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12597.3467 - val_loss: 18697.8242\n",
      "Epoch 9614/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.1455 - val_loss: 18685.5293\n",
      "Epoch 9615/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12554.7676 - val_loss: 18657.9902\n",
      "Epoch 9616/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12462.1924 - val_loss: 18666.3789\n",
      "Epoch 9617/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12567.2920 - val_loss: 18680.4277\n",
      "Epoch 9618/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12542.6455 - val_loss: 18704.5664\n",
      "Epoch 9619/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12613.2031 - val_loss: 18727.1152\n",
      "Epoch 9620/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12681.7900 - val_loss: 18717.2285\n",
      "Epoch 9621/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12649.7607 - val_loss: 18692.7578\n",
      "Epoch 9622/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.8447 - val_loss: 18719.8809\n",
      "Epoch 9623/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.4482 - val_loss: 18722.8301\n",
      "Epoch 9624/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12672.2842 - val_loss: 18717.6348\n",
      "Epoch 9625/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12655.5449 - val_loss: 18714.8340\n",
      "Epoch 9626/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12639.6367 - val_loss: 18699.0605\n",
      "Epoch 9627/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12640.5332 - val_loss: 18689.8516\n",
      "Epoch 9628/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.7646 - val_loss: 18699.3086\n",
      "Epoch 9629/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12599.1045 - val_loss: 18712.3809\n",
      "Epoch 9630/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12641.8311 - val_loss: 18701.2578\n",
      "Epoch 9631/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12601.9092 - val_loss: 18686.4609\n",
      "Epoch 9632/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12552.8916 - val_loss: 18686.2559\n",
      "Epoch 9633/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12557.3369 - val_loss: 18691.8594\n",
      "Epoch 9634/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.5605 - val_loss: 18697.7402\n",
      "Epoch 9635/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12618.9980 - val_loss: 18678.2637\n",
      "Epoch 9636/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12534.6963 - val_loss: 18677.3359\n",
      "Epoch 9637/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.9678 - val_loss: 18679.2578\n",
      "Epoch 9638/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.0830 - val_loss: 18683.8652\n",
      "Epoch 9639/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12542.9229 - val_loss: 18696.1133\n",
      "Epoch 9640/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12584.6006 - val_loss: 18686.6250\n",
      "Epoch 9641/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12553.0303 - val_loss: 18670.3145\n",
      "Epoch 9642/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12505.4385 - val_loss: 18666.8125\n",
      "Epoch 9643/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12496.2373 - val_loss: 18655.1680\n",
      "Epoch 9644/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12461.5303 - val_loss: 18683.5664\n",
      "Epoch 9645/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12543.6143 - val_loss: 18698.9102\n",
      "Epoch 9646/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12592.8730 - val_loss: 18672.4668\n",
      "Epoch 9647/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12509.7520 - val_loss: 18659.4766\n",
      "Epoch 9648/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12474.5771 - val_loss: 18675.1367\n",
      "Epoch 9649/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.0557 - val_loss: 18670.7051\n",
      "Epoch 9650/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.0010 - val_loss: 18653.5273\n",
      "Epoch 9651/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12446.9912 - val_loss: 18678.9199\n",
      "Epoch 9652/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12567.0029 - val_loss: 18674.9863\n",
      "Epoch 9653/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.7812 - val_loss: 18706.1172\n",
      "Epoch 9654/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12624.6611 - val_loss: 18704.0488\n",
      "Epoch 9655/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12616.4229 - val_loss: 18694.8457\n",
      "Epoch 9656/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12586.9873 - val_loss: 18701.6465\n",
      "Epoch 9657/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12602.4824 - val_loss: 18700.7617\n",
      "Epoch 9658/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12593.6475 - val_loss: 18682.4102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9659/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12540.6670 - val_loss: 18675.7480\n",
      "Epoch 9660/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.8037 - val_loss: 18689.9004\n",
      "Epoch 9661/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12563.2354 - val_loss: 18689.4688\n",
      "Epoch 9662/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12560.3926 - val_loss: 18681.9258\n",
      "Epoch 9663/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.0947 - val_loss: 18707.1953\n",
      "Epoch 9664/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12622.0645 - val_loss: 18684.7812\n",
      "Epoch 9665/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12550.6943 - val_loss: 18681.4551\n",
      "Epoch 9666/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12540.5781 - val_loss: 18696.6387\n",
      "Epoch 9667/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12580.8164 - val_loss: 18695.2109\n",
      "Epoch 9668/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12580.9951 - val_loss: 18667.5879\n",
      "Epoch 9669/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12500.1934 - val_loss: 18676.5938\n",
      "Epoch 9670/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.7305 - val_loss: 18671.2715\n",
      "Epoch 9671/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12507.6016 - val_loss: 18675.9219\n",
      "Epoch 9672/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12577.2637 - val_loss: 18667.5449\n",
      "Epoch 9673/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12499.4424 - val_loss: 18661.0723\n",
      "Epoch 9674/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12483.8965 - val_loss: 18676.3984\n",
      "Epoch 9675/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.9736 - val_loss: 18683.9297\n",
      "Epoch 9676/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12547.4746 - val_loss: 18662.4277\n",
      "Epoch 9677/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12481.2236 - val_loss: 18675.3105\n",
      "Epoch 9678/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12553.6777 - val_loss: 18712.4668\n",
      "Epoch 9679/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12642.0303 - val_loss: 18717.6504\n",
      "Epoch 9680/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12661.2637 - val_loss: 18699.6211\n",
      "Epoch 9681/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12603.8994 - val_loss: 18713.9922\n",
      "Epoch 9682/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12640.2646 - val_loss: 18710.8965\n",
      "Epoch 9683/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12629.6523 - val_loss: 18697.0859\n",
      "Epoch 9684/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12594.1143 - val_loss: 18673.0449\n",
      "Epoch 9685/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12510.7949 - val_loss: 18695.4004\n",
      "Epoch 9686/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12588.9248 - val_loss: 18733.2988\n",
      "Epoch 9687/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12708.7139 - val_loss: 18729.3750\n",
      "Epoch 9688/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12694.0957 - val_loss: 18681.1738\n",
      "Epoch 9689/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12535.6631 - val_loss: 18645.9180\n",
      "Epoch 9690/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12420.6182 - val_loss: 18671.7656\n",
      "Epoch 9691/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12503.7842 - val_loss: 18692.6348\n",
      "Epoch 9692/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12567.7471 - val_loss: 18693.8457\n",
      "Epoch 9693/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12584.2861 - val_loss: 18683.8105\n",
      "Epoch 9694/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12550.9639 - val_loss: 18645.8730\n",
      "Epoch 9695/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12430.5889 - val_loss: 18664.4336\n",
      "Epoch 9696/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12485.1855 - val_loss: 18660.6641\n",
      "Epoch 9697/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12481.6895 - val_loss: 18646.8457\n",
      "Epoch 9698/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12429.3389 - val_loss: 18640.4180\n",
      "Epoch 9699/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12415.0723 - val_loss: 18665.5898\n",
      "Epoch 9700/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12484.6982 - val_loss: 18667.5605\n",
      "Epoch 9701/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12497.6562 - val_loss: 18658.1309\n",
      "Epoch 9702/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12465.6953 - val_loss: 18645.1348\n",
      "Epoch 9703/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12422.5342 - val_loss: 18674.5840\n",
      "Epoch 9704/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12515.8096 - val_loss: 18673.6855\n",
      "Epoch 9705/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12518.8467 - val_loss: 18665.6758\n",
      "Epoch 9706/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12490.2383 - val_loss: 18671.6113\n",
      "Epoch 9707/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12508.9150 - val_loss: 18685.3906\n",
      "Epoch 9708/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.7500 - val_loss: 18688.2246\n",
      "Epoch 9709/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12559.8613 - val_loss: 18672.5195\n",
      "Epoch 9710/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12520.1396 - val_loss: 18684.8691\n",
      "Epoch 9711/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.8877 - val_loss: 18674.2969\n",
      "Epoch 9712/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.3174 - val_loss: 18659.0039\n",
      "Epoch 9713/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12464.5312 - val_loss: 18675.3281\n",
      "Epoch 9714/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12520.9766 - val_loss: 18667.1992\n",
      "Epoch 9715/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12499.8340 - val_loss: 18674.0723\n",
      "Epoch 9716/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12522.5283 - val_loss: 18674.1055\n",
      "Epoch 9717/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12512.8193 - val_loss: 18677.7598\n",
      "Epoch 9718/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12525.6016 - val_loss: 18661.1426\n",
      "Epoch 9719/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12474.0938 - val_loss: 18664.7246\n",
      "Epoch 9720/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12487.9580 - val_loss: 18690.4375\n",
      "Epoch 9721/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.5918 - val_loss: 18662.0254\n",
      "Epoch 9722/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12480.0703 - val_loss: 18663.0625\n",
      "Epoch 9723/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12484.7900 - val_loss: 18659.9668\n",
      "Epoch 9724/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12474.3398 - val_loss: 18670.2891\n",
      "Epoch 9725/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12501.2090 - val_loss: 18666.8281\n",
      "Epoch 9726/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12488.8193 - val_loss: 18682.2852\n",
      "Epoch 9727/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.5557 - val_loss: 18693.0039\n",
      "Epoch 9728/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12576.4238 - val_loss: 18665.2773\n",
      "Epoch 9729/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12493.0391 - val_loss: 18675.7715\n",
      "Epoch 9730/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12525.8271 - val_loss: 18667.7852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9731/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12500.9277 - val_loss: 18697.2168\n",
      "Epoch 9732/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12590.2158 - val_loss: 18695.1602\n",
      "Epoch 9733/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12585.2354 - val_loss: 18708.0859\n",
      "Epoch 9734/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12623.0986 - val_loss: 18702.2812\n",
      "Epoch 9735/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.8135 - val_loss: 18685.8125\n",
      "Epoch 9736/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12553.5820 - val_loss: 18689.0449\n",
      "Epoch 9737/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12562.9355 - val_loss: 18700.6387\n",
      "Epoch 9738/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.6338 - val_loss: 18704.2227\n",
      "Epoch 9739/10000\n",
      "630/630 [==============================] - 0s 16us/step - loss: 12613.2500 - val_loss: 18710.8555\n",
      "Epoch 9740/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12629.3486 - val_loss: 18697.1602\n",
      "Epoch 9741/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12587.3682 - val_loss: 18684.8945\n",
      "Epoch 9742/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12548.7793 - val_loss: 18682.4414\n",
      "Epoch 9743/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.6396 - val_loss: 18701.7422\n",
      "Epoch 9744/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12604.7861 - val_loss: 18694.3965\n",
      "Epoch 9745/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.9580 - val_loss: 18665.3984\n",
      "Epoch 9746/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12489.6006 - val_loss: 18681.0234\n",
      "Epoch 9747/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12541.2764 - val_loss: 18695.5977\n",
      "Epoch 9748/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12582.8076 - val_loss: 18689.6035\n",
      "Epoch 9749/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12563.5234 - val_loss: 18699.9648\n",
      "Epoch 9750/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12594.2041 - val_loss: 18712.3730\n",
      "Epoch 9751/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.9668 - val_loss: 18704.0430\n",
      "Epoch 9752/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.2900 - val_loss: 18708.4062\n",
      "Epoch 9753/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12619.0352 - val_loss: 18698.3867\n",
      "Epoch 9754/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12592.6084 - val_loss: 18670.4004\n",
      "Epoch 9755/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.2490 - val_loss: 18691.2383\n",
      "Epoch 9756/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12571.4766 - val_loss: 18686.1699\n",
      "Epoch 9757/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12551.4453 - val_loss: 18688.8633\n",
      "Epoch 9758/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12557.5234 - val_loss: 18692.5527\n",
      "Epoch 9759/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12574.8174 - val_loss: 18707.6602\n",
      "Epoch 9760/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12615.6094 - val_loss: 18690.4297\n",
      "Epoch 9761/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.5078 - val_loss: 18670.1562\n",
      "Epoch 9762/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.4883 - val_loss: 18683.1133\n",
      "Epoch 9763/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12546.7178 - val_loss: 18676.4766\n",
      "Epoch 9764/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.9756 - val_loss: 18692.5879\n",
      "Epoch 9765/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12573.4941 - val_loss: 18684.4844\n",
      "Epoch 9766/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.7529 - val_loss: 18662.0312\n",
      "Epoch 9767/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12476.9277 - val_loss: 18675.7129\n",
      "Epoch 9768/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12521.4365 - val_loss: 18684.5176\n",
      "Epoch 9769/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12555.8330 - val_loss: 18678.8418\n",
      "Epoch 9770/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12534.8652 - val_loss: 18648.6055\n",
      "Epoch 9771/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12441.4443 - val_loss: 18695.4570\n",
      "Epoch 9772/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12578.6523 - val_loss: 18724.0840\n",
      "Epoch 9773/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12674.7734 - val_loss: 18704.0078\n",
      "Epoch 9774/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12604.8018 - val_loss: 18659.6465\n",
      "Epoch 9775/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12468.7285 - val_loss: 18661.2617\n",
      "Epoch 9776/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12475.6367 - val_loss: 18692.5918\n",
      "Epoch 9777/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12579.6270 - val_loss: 18699.9336\n",
      "Epoch 9778/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12599.3193 - val_loss: 18700.4707\n",
      "Epoch 9779/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.9658 - val_loss: 18676.5879\n",
      "Epoch 9780/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12519.9648 - val_loss: 18658.9922\n",
      "Epoch 9781/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12467.6348 - val_loss: 18684.5547\n",
      "Epoch 9782/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12551.7734 - val_loss: 18711.6426\n",
      "Epoch 9783/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12633.6006 - val_loss: 18689.8066\n",
      "Epoch 9784/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12565.1865 - val_loss: 18689.0234\n",
      "Epoch 9785/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12561.0176 - val_loss: 18677.7637\n",
      "Epoch 9786/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.1973 - val_loss: 18653.2793\n",
      "Epoch 9787/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12469.0215 - val_loss: 18678.0957\n",
      "Epoch 9788/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.2998 - val_loss: 18704.3789\n",
      "Epoch 9789/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12615.4062 - val_loss: 18694.7012\n",
      "Epoch 9790/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12588.9434 - val_loss: 18673.6387\n",
      "Epoch 9791/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12517.9922 - val_loss: 18683.3301\n",
      "Epoch 9792/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12544.7402 - val_loss: 18671.1621\n",
      "Epoch 9793/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12507.6641 - val_loss: 18671.8184\n",
      "Epoch 9794/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12508.9619 - val_loss: 18669.2598\n",
      "Epoch 9795/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12495.2207 - val_loss: 18681.5000\n",
      "Epoch 9796/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12535.5176 - val_loss: 18690.6543\n",
      "Epoch 9797/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12569.8271 - val_loss: 18690.5410\n",
      "Epoch 9798/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12576.2012 - val_loss: 18666.0801\n",
      "Epoch 9799/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12498.5400 - val_loss: 18681.1074\n",
      "Epoch 9800/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12533.6152 - val_loss: 18686.6758\n",
      "Epoch 9801/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12558.9941 - val_loss: 18677.6523\n",
      "Epoch 9802/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.3467 - val_loss: 18672.1992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9803/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12511.9180 - val_loss: 18672.2715\n",
      "Epoch 9804/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12513.6494 - val_loss: 18684.8867\n",
      "Epoch 9805/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12548.0762 - val_loss: 18710.8301\n",
      "Epoch 9806/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12631.9014 - val_loss: 18698.7559\n",
      "Epoch 9807/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12591.4639 - val_loss: 18660.2637\n",
      "Epoch 9808/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12476.9473 - val_loss: 18676.3770\n",
      "Epoch 9809/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.3760 - val_loss: 18676.7148\n",
      "Epoch 9810/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.5303 - val_loss: 18674.0977\n",
      "Epoch 9811/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12515.9756 - val_loss: 18684.7656\n",
      "Epoch 9812/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12548.4424 - val_loss: 18667.3164\n",
      "Epoch 9813/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12497.0381 - val_loss: 18675.8828\n",
      "Epoch 9814/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.9824 - val_loss: 18670.8789\n",
      "Epoch 9815/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12508.1191 - val_loss: 18670.0605\n",
      "Epoch 9816/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12508.7217 - val_loss: 18667.8320\n",
      "Epoch 9817/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12494.8887 - val_loss: 18703.5293\n",
      "Epoch 9818/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.3164 - val_loss: 18683.0742\n",
      "Epoch 9819/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12542.4600 - val_loss: 18689.1680\n",
      "Epoch 9820/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12566.5234 - val_loss: 18676.8008\n",
      "Epoch 9821/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.4814 - val_loss: 18679.9922\n",
      "Epoch 9822/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.4277 - val_loss: 18697.4238\n",
      "Epoch 9823/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12588.1836 - val_loss: 18690.8965\n",
      "Epoch 9824/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.7607 - val_loss: 18659.5020\n",
      "Epoch 9825/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12467.7930 - val_loss: 18670.6992\n",
      "Epoch 9826/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12502.0186 - val_loss: 18707.1973\n",
      "Epoch 9827/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.8965 - val_loss: 18707.7227\n",
      "Epoch 9828/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12618.6924 - val_loss: 18690.2949\n",
      "Epoch 9829/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12568.7363 - val_loss: 18678.2480\n",
      "Epoch 9830/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12527.5000 - val_loss: 18655.6895\n",
      "Epoch 9831/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12458.3730 - val_loss: 18654.2539\n",
      "Epoch 9832/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12454.2979 - val_loss: 18679.2539\n",
      "Epoch 9833/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12544.6475 - val_loss: 18678.8887\n",
      "Epoch 9834/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12532.8828 - val_loss: 18662.1816\n",
      "Epoch 9835/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12483.1016 - val_loss: 18658.9844\n",
      "Epoch 9836/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12466.4082 - val_loss: 18684.2441\n",
      "Epoch 9837/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12545.4053 - val_loss: 18706.1562\n",
      "Epoch 9838/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12609.9873 - val_loss: 18690.9336\n",
      "Epoch 9839/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.6543 - val_loss: 18685.7539\n",
      "Epoch 9840/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12555.5771 - val_loss: 18688.0078\n",
      "Epoch 9841/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.6582 - val_loss: 18675.3652\n",
      "Epoch 9842/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12516.7998 - val_loss: 18677.1504\n",
      "Epoch 9843/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12525.3350 - val_loss: 18670.4082\n",
      "Epoch 9844/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12506.8252 - val_loss: 18700.4473\n",
      "Epoch 9845/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.8760 - val_loss: 18711.9102\n",
      "Epoch 9846/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12639.4062 - val_loss: 18675.5566\n",
      "Epoch 9847/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12526.4717 - val_loss: 18651.2539\n",
      "Epoch 9848/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12446.3242 - val_loss: 18682.9629\n",
      "Epoch 9849/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12536.9453 - val_loss: 18709.9980\n",
      "Epoch 9850/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12624.6807 - val_loss: 18695.3633\n",
      "Epoch 9851/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12580.0176 - val_loss: 18668.9062\n",
      "Epoch 9852/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12497.8779 - val_loss: 18668.0684\n",
      "Epoch 9853/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12499.1533 - val_loss: 18693.1016\n",
      "Epoch 9854/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.2510 - val_loss: 18703.1328\n",
      "Epoch 9855/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12608.9902 - val_loss: 18673.4492\n",
      "Epoch 9856/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12516.9678 - val_loss: 18666.5293\n",
      "Epoch 9857/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12492.0859 - val_loss: 18676.7617\n",
      "Epoch 9858/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12519.6758 - val_loss: 18676.5742\n",
      "Epoch 9859/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.3018 - val_loss: 18658.4219\n",
      "Epoch 9860/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12467.8711 - val_loss: 18653.3691\n",
      "Epoch 9861/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12449.7832 - val_loss: 18674.5273\n",
      "Epoch 9862/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12514.2979 - val_loss: 18671.4043\n",
      "Epoch 9863/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12507.0205 - val_loss: 18661.9609\n",
      "Epoch 9864/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12480.8809 - val_loss: 18672.5469\n",
      "Epoch 9865/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12512.9072 - val_loss: 18680.8613\n",
      "Epoch 9866/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12531.9414 - val_loss: 18676.1172\n",
      "Epoch 9867/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12519.1602 - val_loss: 18665.7051\n",
      "Epoch 9868/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12490.5693 - val_loss: 18672.1270\n",
      "Epoch 9869/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12511.7139 - val_loss: 18681.0000\n",
      "Epoch 9870/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12540.5273 - val_loss: 18687.8340\n",
      "Epoch 9871/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12566.3223 - val_loss: 18678.6191\n",
      "Epoch 9872/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12533.2578 - val_loss: 18676.2188\n",
      "Epoch 9873/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12525.0537 - val_loss: 18673.9180\n",
      "Epoch 9874/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12516.7598 - val_loss: 18665.6074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9875/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12493.2139 - val_loss: 18664.7305\n",
      "Epoch 9876/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12489.3760 - val_loss: 18676.9766\n",
      "Epoch 9877/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12522.0205 - val_loss: 18670.2539\n",
      "Epoch 9878/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12504.9785 - val_loss: 18665.1035\n",
      "Epoch 9879/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12489.0830 - val_loss: 18689.7090\n",
      "Epoch 9880/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12565.6455 - val_loss: 18680.9375\n",
      "Epoch 9881/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.5596 - val_loss: 18694.9902\n",
      "Epoch 9882/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12579.7920 - val_loss: 18706.4688\n",
      "Epoch 9883/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12617.7783 - val_loss: 18686.4668\n",
      "Epoch 9884/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12552.3809 - val_loss: 18705.9043\n",
      "Epoch 9885/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12614.9600 - val_loss: 18699.2051\n",
      "Epoch 9886/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12593.7441 - val_loss: 18671.7246\n",
      "Epoch 9887/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12509.1270 - val_loss: 18700.5879\n",
      "Epoch 9888/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12599.3984 - val_loss: 18710.4375\n",
      "Epoch 9889/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12628.2793 - val_loss: 18676.8516\n",
      "Epoch 9890/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12521.1221 - val_loss: 18653.7988\n",
      "Epoch 9891/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12454.5996 - val_loss: 18679.5859\n",
      "Epoch 9892/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12537.7246 - val_loss: 18692.6797\n",
      "Epoch 9893/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12576.3594 - val_loss: 18673.0742\n",
      "Epoch 9894/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12513.0449 - val_loss: 18667.2422\n",
      "Epoch 9895/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12492.0273 - val_loss: 18672.8047\n",
      "Epoch 9896/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12513.1025 - val_loss: 18678.2500\n",
      "Epoch 9897/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12530.5830 - val_loss: 18666.9004\n",
      "Epoch 9898/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12496.2529 - val_loss: 18634.2793\n",
      "Epoch 9899/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12394.4277 - val_loss: 18675.5742\n",
      "Epoch 9900/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12518.1699 - val_loss: 18687.7246\n",
      "Epoch 9901/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12558.8477 - val_loss: 18697.8926\n",
      "Epoch 9902/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12589.7188 - val_loss: 18681.7422\n",
      "Epoch 9903/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12535.0205 - val_loss: 18672.7207\n",
      "Epoch 9904/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12510.6016 - val_loss: 18683.5352\n",
      "Epoch 9905/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12547.9990 - val_loss: 18692.3691\n",
      "Epoch 9906/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12575.8174 - val_loss: 18667.7988\n",
      "Epoch 9907/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12498.3809 - val_loss: 18676.9414\n",
      "Epoch 9908/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12520.8389 - val_loss: 18708.6562\n",
      "Epoch 9909/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12621.6729 - val_loss: 18695.7734\n",
      "Epoch 9910/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12580.9170 - val_loss: 18657.6953\n",
      "Epoch 9911/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12462.6924 - val_loss: 18676.2754\n",
      "Epoch 9912/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12524.8594 - val_loss: 18650.2734\n",
      "Epoch 9913/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12441.2852 - val_loss: 18633.7656\n",
      "Epoch 9914/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12389.9004 - val_loss: 18667.4941\n",
      "Epoch 9915/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12501.1143 - val_loss: 18668.6699\n",
      "Epoch 9916/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12500.8750 - val_loss: 18672.2930\n",
      "Epoch 9917/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12507.1143 - val_loss: 18682.4785\n",
      "Epoch 9918/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12542.8037 - val_loss: 18653.9434\n",
      "Epoch 9919/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12452.7432 - val_loss: 18646.4453\n",
      "Epoch 9920/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12431.6484 - val_loss: 18675.9336\n",
      "Epoch 9921/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12525.6064 - val_loss: 18654.6504\n",
      "Epoch 9922/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12453.2803 - val_loss: 18637.2148\n",
      "Epoch 9923/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12401.8213 - val_loss: 18671.3027\n",
      "Epoch 9924/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12507.7891 - val_loss: 18666.4746\n",
      "Epoch 9925/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12492.9326 - val_loss: 18668.9844\n",
      "Epoch 9926/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12501.1631 - val_loss: 18674.6641\n",
      "Epoch 9927/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12519.2148 - val_loss: 18678.6914\n",
      "Epoch 9928/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12529.0391 - val_loss: 18668.1465\n",
      "Epoch 9929/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12496.2070 - val_loss: 18700.4648\n",
      "Epoch 9930/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.1445 - val_loss: 18695.6094\n",
      "Epoch 9931/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.3789 - val_loss: 18671.2207\n",
      "Epoch 9932/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12510.2910 - val_loss: 18696.4961\n",
      "Epoch 9933/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12586.4912 - val_loss: 18688.6191\n",
      "Epoch 9934/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12559.2822 - val_loss: 18719.6621\n",
      "Epoch 9935/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12660.6719 - val_loss: 18728.7012\n",
      "Epoch 9936/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12688.0088 - val_loss: 18700.9980\n",
      "Epoch 9937/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.5889 - val_loss: 18675.3496\n",
      "Epoch 9938/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12519.6211 - val_loss: 18710.7070\n",
      "Epoch 9939/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.3691 - val_loss: 18722.3379\n",
      "Epoch 9940/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12668.7695 - val_loss: 18703.8555\n",
      "Epoch 9941/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.4658 - val_loss: 18718.4727\n",
      "Epoch 9942/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12650.5859 - val_loss: 18685.9844\n",
      "Epoch 9943/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12552.4072 - val_loss: 18697.9707\n",
      "Epoch 9944/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12595.1846 - val_loss: 18712.0273\n",
      "Epoch 9945/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.2041 - val_loss: 18699.9980\n",
      "Epoch 9946/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12596.7578 - val_loss: 18708.5352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9947/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12622.9014 - val_loss: 18713.8828\n",
      "Epoch 9948/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12637.6982 - val_loss: 18680.8906\n",
      "Epoch 9949/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12536.2842 - val_loss: 18689.5645\n",
      "Epoch 9950/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12564.3271 - val_loss: 18696.3457\n",
      "Epoch 9951/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12596.4297 - val_loss: 18709.7266\n",
      "Epoch 9952/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12629.2695 - val_loss: 18692.2402\n",
      "Epoch 9953/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12573.0156 - val_loss: 18706.5566\n",
      "Epoch 9954/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12614.5088 - val_loss: 18693.2695\n",
      "Epoch 9955/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12574.5771 - val_loss: 18700.5117\n",
      "Epoch 9956/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12598.6484 - val_loss: 18701.7246\n",
      "Epoch 9957/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12599.8350 - val_loss: 18679.0586\n",
      "Epoch 9958/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12533.9092 - val_loss: 18696.3945\n",
      "Epoch 9959/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12587.7188 - val_loss: 18719.5430\n",
      "Epoch 9960/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12658.1768 - val_loss: 18687.1055\n",
      "Epoch 9961/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12557.7354 - val_loss: 18677.9805\n",
      "Epoch 9962/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12523.9971 - val_loss: 18700.3652\n",
      "Epoch 9963/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12597.9541 - val_loss: 18685.6875\n",
      "Epoch 9964/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12552.6006 - val_loss: 18687.2988\n",
      "Epoch 9965/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12558.1816 - val_loss: 18686.5664\n",
      "Epoch 9966/10000\n",
      "630/630 [==============================] - 0s 8us/step - loss: 12552.6787 - val_loss: 18675.8008\n",
      "Epoch 9967/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12520.1406 - val_loss: 18681.2773\n",
      "Epoch 9968/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12541.5615 - val_loss: 18707.7305\n",
      "Epoch 9969/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12621.6143 - val_loss: 18705.3145\n",
      "Epoch 9970/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12612.7969 - val_loss: 18679.4727\n",
      "Epoch 9971/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12536.9160 - val_loss: 18716.5723\n",
      "Epoch 9972/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12649.7959 - val_loss: 18719.1738\n",
      "Epoch 9973/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12662.6553 - val_loss: 18732.4395\n",
      "Epoch 9974/10000\n",
      "630/630 [==============================] - 0s 10us/step - loss: 12710.2197 - val_loss: 18702.1738\n",
      "Epoch 9975/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12599.9424 - val_loss: 18702.2227\n",
      "Epoch 9976/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12606.1396 - val_loss: 18708.2773\n",
      "Epoch 9977/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12627.5439 - val_loss: 18732.0234\n",
      "Epoch 9978/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12698.5771 - val_loss: 18716.9629\n",
      "Epoch 9979/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12650.4873 - val_loss: 18716.2168\n",
      "Epoch 9980/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12648.9590 - val_loss: 18731.9766\n",
      "Epoch 9981/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12698.1514 - val_loss: 18709.2988\n",
      "Epoch 9982/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12625.3857 - val_loss: 18721.2480\n",
      "Epoch 9983/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12658.4336 - val_loss: 18727.0566\n",
      "Epoch 9984/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12681.4688 - val_loss: 18704.3730\n",
      "Epoch 9985/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12617.7256 - val_loss: 18720.7539\n",
      "Epoch 9986/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12663.4434 - val_loss: 18688.2852\n",
      "Epoch 9987/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12561.1504 - val_loss: 18661.7539\n",
      "Epoch 9988/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12475.3320 - val_loss: 18696.2910\n",
      "Epoch 9989/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12584.3848 - val_loss: 18718.8535\n",
      "Epoch 9990/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12652.9238 - val_loss: 18713.8516\n",
      "Epoch 9991/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12641.7080 - val_loss: 18710.8848\n",
      "Epoch 9992/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12634.3213 - val_loss: 18711.6172\n",
      "Epoch 9993/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12635.8730 - val_loss: 18691.3340\n",
      "Epoch 9994/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12570.2383 - val_loss: 18686.1699\n",
      "Epoch 9995/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12546.9346 - val_loss: 18704.3105\n",
      "Epoch 9996/10000\n",
      "630/630 [==============================] - 0s 9us/step - loss: 12609.5830 - val_loss: 18704.3145\n",
      "Epoch 9997/10000\n",
      "630/630 [==============================] - 0s 13us/step - loss: 12612.6611 - val_loss: 18732.9512\n",
      "Epoch 9998/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12700.0879 - val_loss: 18704.3418\n",
      "Epoch 9999/10000\n",
      "630/630 [==============================] - 0s 14us/step - loss: 12612.6367 - val_loss: 18681.5234\n",
      "Epoch 10000/10000\n",
      "630/630 [==============================] - 0s 11us/step - loss: 12543.0635 - val_loss: 18685.1797\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_25 (InputLayer)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "LR (Dense)                   (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 200)               4200      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 20)                2020      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 26,561\n",
      "Trainable params: 26,561\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28271a1e5c0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315/315 [==============================] - 0s 48us/step\n",
      "18586.6196305\n"
     ]
    }
   ],
   "source": [
    "history2 = LossHistory()\n",
    "#采用编码层的网络结构，从新构成一个新的model，此model的参数跟原来autoencode的训练的参数一样。\n",
    "out=Dense(200,activation='relu',activity_regularizer=regularizers.l1(0.01))(LR)\n",
    "out=Dense(100,activation='sigmoid',activity_regularizer=regularizers.l1(0.01))(out)\n",
    "out=Dense(20,activation='sigmoid',activity_regularizer=regularizers.l1(0.01))(out)\n",
    "out=Dense(1,activation='relu',activity_regularizer=regularizers.l1(0.01))(out)\n",
    "encoder=Model(inputs=input_img,outputs=out)\n",
    "encoder.compile(optimizer='adam',loss='mse')\n",
    "encoder.fit(X_train,y_train,epochs=10000,batch_size=100,validation_data=(X_test,y_test),shuffle=True,callbacks=[history2])\n",
    "#score=encoder.evaluate(X_test,y_test)\n",
    "#print(score)\n",
    "print(encoder.summary())\n",
    "history2.loss_plot('epoch')\n",
    "encoder.save('SAE-DNN.model')\n",
    "score=encoder.evaluate(X_test,y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model('SAE-DNN.model')\n",
    "pred=model.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
